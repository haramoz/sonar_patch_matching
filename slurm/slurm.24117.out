python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 31s - loss: 0.4750 - acc: 0.8071 - val_loss: 0.2283 - val_acc: 0.9238

Epoch 00001: val_loss improved from inf to 0.22828, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2350 - acc: 0.9184 - val_loss: 0.1734 - val_acc: 0.9438

Epoch 00002: val_loss improved from 0.22828 to 0.17339, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1564 - acc: 0.9502 - val_loss: 0.0898 - val_acc: 0.9785

Epoch 00003: val_loss improved from 0.17339 to 0.08983, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1175 - acc: 0.9645 - val_loss: 0.0560 - val_acc: 0.9872

Epoch 00004: val_loss improved from 0.08983 to 0.05599, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.0973 - acc: 0.9720 - val_loss: 0.1089 - val_acc: 0.9664

Epoch 00005: val_loss did not improve from 0.05599
Epoch 6/6
 - 24s - loss: 0.0828 - acc: 0.9774 - val_loss: 0.0900 - val_acc: 0.9744

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.

Epoch 00006: val_loss did not improve from 0.05599
Test accuracy:0.723
current auc_score ------------------> 0.821
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5012 - acc: 0.7992 - val_loss: 3.4544 - val_acc: 0.6235

Epoch 00001: val_loss improved from inf to 3.45437, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2918 - acc: 0.9017 - val_loss: 0.1354 - val_acc: 0.9680

Epoch 00002: val_loss improved from 3.45437 to 0.13538, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1620 - acc: 0.9506 - val_loss: 0.1355 - val_acc: 0.9676

Epoch 00003: val_loss did not improve from 0.13538
Epoch 4/6
 - 24s - loss: 0.1254 - acc: 0.9629 - val_loss: 0.1430 - val_acc: 0.9522

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.

Epoch 00004: val_loss did not improve from 0.13538
Epoch 5/6
 - 24s - loss: 0.0680 - acc: 0.9832 - val_loss: 0.0332 - val_acc: 0.9946

Epoch 00005: val_loss improved from 0.13538 to 0.03318, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0544 - acc: 0.9861 - val_loss: 0.0486 - val_acc: 0.9897

Epoch 00006: val_loss did not improve from 0.03318
Test accuracy:0.691
current auc_score ------------------> 0.841
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4323 - acc: 0.8372 - val_loss: 0.2245 - val_acc: 0.9248

Epoch 00001: val_loss improved from inf to 0.22453, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.1972 - acc: 0.9345 - val_loss: 0.1342 - val_acc: 0.9595

Epoch 00002: val_loss improved from 0.22453 to 0.13421, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1366 - acc: 0.9562 - val_loss: 0.6355 - val_acc: 0.8094

Epoch 00003: val_loss did not improve from 0.13421
Epoch 4/6
 - 23s - loss: 0.1079 - acc: 0.9668 - val_loss: 0.0791 - val_acc: 0.9798

Epoch 00004: val_loss improved from 0.13421 to 0.07913, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1642 - acc: 0.9577 - val_loss: 0.1031 - val_acc: 0.9807

Epoch 00005: val_loss did not improve from 0.07913
Epoch 6/6
 - 23s - loss: 0.0972 - acc: 0.9756 - val_loss: 0.0547 - val_acc: 0.9906

Epoch 00006: val_loss improved from 0.07913 to 0.05467, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.710
current auc_score ------------------> 0.862
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4094 - acc: 0.8481 - val_loss: 1.3371 - val_acc: 0.5478

Epoch 00001: val_loss improved from inf to 1.33707, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1861 - acc: 0.9400 - val_loss: 0.2170 - val_acc: 0.9354

Epoch 00002: val_loss improved from 1.33707 to 0.21702, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1384 - acc: 0.9589 - val_loss: 0.1098 - val_acc: 0.9693

Epoch 00003: val_loss improved from 0.21702 to 0.10984, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.0944 - acc: 0.9726 - val_loss: 0.3650 - val_acc: 0.8618

Epoch 00004: val_loss did not improve from 0.10984
Epoch 5/6
 - 25s - loss: 0.0847 - acc: 0.9766 - val_loss: 0.0458 - val_acc: 0.9907

Epoch 00005: val_loss improved from 0.10984 to 0.04584, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0736 - acc: 0.9797 - val_loss: 0.0762 - val_acc: 0.9755

Epoch 00006: val_loss did not improve from 0.04584
Test accuracy:0.736
current auc_score ------------------> 0.833
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4559 - acc: 0.8272 - val_loss: 0.2230 - val_acc: 0.9360

Epoch 00001: val_loss improved from inf to 0.22304, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2559 - acc: 0.9160 - val_loss: 0.1588 - val_acc: 0.9598

Epoch 00002: val_loss improved from 0.22304 to 0.15876, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1681 - acc: 0.9492 - val_loss: 0.1039 - val_acc: 0.9768

Epoch 00003: val_loss improved from 0.15876 to 0.10392, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1095 - acc: 0.9664 - val_loss: 0.2068 - val_acc: 0.9295

Epoch 00004: val_loss did not improve from 0.10392
Epoch 5/6
 - 24s - loss: 0.0900 - acc: 0.9737 - val_loss: 0.7223 - val_acc: 0.6894

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.

Epoch 00005: val_loss did not improve from 0.10392
Epoch 6/6
 - 24s - loss: 0.0825 - acc: 0.9777 - val_loss: 0.0348 - val_acc: 0.9941

Epoch 00006: val_loss improved from 0.10392 to 0.03479, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.726
current auc_score ------------------> 0.890
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4807 - acc: 0.8099 - val_loss: 2.1304 - val_acc: 0.5973

Epoch 00001: val_loss improved from inf to 2.13043, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2743 - acc: 0.9062 - val_loss: 0.3304 - val_acc: 0.8721

Epoch 00002: val_loss improved from 2.13043 to 0.33036, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2108 - acc: 0.9312 - val_loss: 0.2369 - val_acc: 0.9123

Epoch 00003: val_loss improved from 0.33036 to 0.23694, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1498 - acc: 0.9516 - val_loss: 0.2179 - val_acc: 0.9256

Epoch 00004: val_loss improved from 0.23694 to 0.21792, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1186 - acc: 0.9618 - val_loss: 0.1765 - val_acc: 0.9375

Epoch 00005: val_loss improved from 0.21792 to 0.17646, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0947 - acc: 0.9708 - val_loss: 0.1103 - val_acc: 0.9641

Epoch 00006: val_loss improved from 0.17646 to 0.11030, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.702
current auc_score ------------------> 0.795
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4872 - acc: 0.8002 - val_loss: 2.0095 - val_acc: 0.5323

Epoch 00001: val_loss improved from inf to 2.00948, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2392 - acc: 0.9158 - val_loss: 0.1287 - val_acc: 0.9644

Epoch 00002: val_loss improved from 2.00948 to 0.12873, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1419 - acc: 0.9554 - val_loss: 0.1758 - val_acc: 0.9420

Epoch 00003: val_loss did not improve from 0.12873
Epoch 4/6
 - 24s - loss: 0.1164 - acc: 0.9646 - val_loss: 0.1313 - val_acc: 0.9568

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.

Epoch 00004: val_loss did not improve from 0.12873
Epoch 5/6
 - 24s - loss: 0.0619 - acc: 0.9837 - val_loss: 0.0308 - val_acc: 0.9954

Epoch 00005: val_loss improved from 0.12873 to 0.03081, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0446 - acc: 0.9888 - val_loss: 0.0216 - val_acc: 0.9972

Epoch 00006: val_loss improved from 0.03081 to 0.02162, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.655
current auc_score ------------------> 0.855
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4982 - acc: 0.8006 - val_loss: 0.8600 - val_acc: 0.7334

Epoch 00001: val_loss improved from inf to 0.86004, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3584 - acc: 0.8631 - val_loss: 0.1754 - val_acc: 0.9494

Epoch 00002: val_loss improved from 0.86004 to 0.17536, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2130 - acc: 0.9249 - val_loss: 0.1151 - val_acc: 0.9651

Epoch 00003: val_loss improved from 0.17536 to 0.11507, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1620 - acc: 0.9470 - val_loss: 0.1058 - val_acc: 0.9696

Epoch 00004: val_loss improved from 0.11507 to 0.10577, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1235 - acc: 0.9607 - val_loss: 0.0762 - val_acc: 0.9828

Epoch 00005: val_loss improved from 0.10577 to 0.07625, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1047 - acc: 0.9677 - val_loss: 0.0870 - val_acc: 0.9757

Epoch 00006: val_loss did not improve from 0.07625
Test accuracy:0.729
current auc_score ------------------> 0.864
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4380 - acc: 0.8352 - val_loss: 0.6682 - val_acc: 0.7715

Epoch 00001: val_loss improved from inf to 0.66823, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2136 - acc: 0.9269 - val_loss: 0.1607 - val_acc: 0.9499

Epoch 00002: val_loss improved from 0.66823 to 0.16074, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1576 - acc: 0.9487 - val_loss: 0.1015 - val_acc: 0.9723

Epoch 00003: val_loss improved from 0.16074 to 0.10149, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1136 - acc: 0.9646 - val_loss: 0.1104 - val_acc: 0.9723

Epoch 00004: val_loss did not improve from 0.10149
Epoch 5/6
 - 23s - loss: 0.0947 - acc: 0.9720 - val_loss: 0.0591 - val_acc: 0.9878

Epoch 00005: val_loss improved from 0.10149 to 0.05910, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.0852 - acc: 0.9758 - val_loss: 0.0375 - val_acc: 0.9925

Epoch 00006: val_loss improved from 0.05910 to 0.03753, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.739
current auc_score ------------------> 0.847
Epochs  6  batch_size:  64  lr:  0.01  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4446 - acc: 0.8295 - val_loss: 0.2080 - val_acc: 0.9339

Epoch 00001: val_loss improved from inf to 0.20799, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1778 - acc: 0.9426 - val_loss: 0.0875 - val_acc: 0.9792

Epoch 00002: val_loss improved from 0.20799 to 0.08754, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1267 - acc: 0.9619 - val_loss: 0.1106 - val_acc: 0.9699

Epoch 00003: val_loss did not improve from 0.08754
Epoch 4/6
 - 24s - loss: 0.0965 - acc: 0.9721 - val_loss: 0.4975 - val_acc: 0.8294

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.

Epoch 00004: val_loss did not improve from 0.08754
Epoch 5/6
 - 24s - loss: 0.0556 - acc: 0.9864 - val_loss: 0.0236 - val_acc: 0.9971

Epoch 00005: val_loss improved from 0.08754 to 0.02362, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0380 - acc: 0.9902 - val_loss: 0.0227 - val_acc: 0.9967

Epoch 00006: val_loss improved from 0.02362 to 0.02274, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.653
current auc_score ------------------> 0.818
accuracies:  [0.7228494623655914, 0.6905913978494623, 0.7102150537634409, 0.7364247311827957, 0.7262096774193548, 0.7016129032258065, 0.6553763440860215, 0.7286290322580645, 0.7387096774193549, 0.6528225806451613]
aucs:  [0.8209, 0.8413, 0.8618, 0.8331, 0.8896, 0.7946, 0.8553, 0.8635, 0.8469, 0.818]
mean and std AUC:  0.842+/-0.026  max:   0.8896
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5951 - acc: 0.7556 - val_loss: 0.7713 - val_acc: 0.6540

Epoch 00001: val_loss improved from inf to 0.77129, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3826 - acc: 0.8441 - val_loss: 8.3796 - val_acc: 0.4809

Epoch 00002: val_loss did not improve from 0.77129
Epoch 3/6
 - 24s - loss: 0.3665 - acc: 0.8647 - val_loss: 7.6732 - val_acc: 0.5274

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00003: val_loss did not improve from 0.77129
Epoch 4/6
 - 24s - loss: 0.3159 - acc: 0.8983 - val_loss: 0.3090 - val_acc: 0.8670

Epoch 00004: val_loss improved from 0.77129 to 0.30900, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1713 - acc: 0.9422 - val_loss: 0.1874 - val_acc: 0.9580

Epoch 00005: val_loss improved from 0.30900 to 0.18745, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1334 - acc: 0.9545 - val_loss: 0.1190 - val_acc: 0.9627

Epoch 00006: val_loss improved from 0.18745 to 0.11895, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.726
current auc_score ------------------> 0.908
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.7094 - acc: 0.7540 - val_loss: 0.3745 - val_acc: 0.8653

Epoch 00001: val_loss improved from inf to 0.37454, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3757 - acc: 0.8574 - val_loss: 0.4548 - val_acc: 0.8581

Epoch 00002: val_loss did not improve from 0.37454
Epoch 3/6
 - 24s - loss: 0.3056 - acc: 0.8884 - val_loss: 0.4359 - val_acc: 0.8396

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00003: val_loss did not improve from 0.37454
Epoch 4/6
 - 24s - loss: 0.2024 - acc: 0.9292 - val_loss: 0.1806 - val_acc: 0.9435

Epoch 00004: val_loss improved from 0.37454 to 0.18056, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1717 - acc: 0.9414 - val_loss: 0.4571 - val_acc: 0.7884

Epoch 00005: val_loss did not improve from 0.18056
Epoch 6/6
 - 24s - loss: 0.1481 - acc: 0.9510 - val_loss: 0.0908 - val_acc: 0.9758

Epoch 00006: val_loss improved from 0.18056 to 0.09081, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.777
current auc_score ------------------> 0.903
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.7284 - acc: 0.7162 - val_loss: 0.7473 - val_acc: 0.7034

Epoch 00001: val_loss improved from inf to 0.74732, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.5787 - acc: 0.7488 - val_loss: 0.4085 - val_acc: 0.8392

Epoch 00002: val_loss improved from 0.74732 to 0.40850, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.6013 - acc: 0.7476 - val_loss: 0.5117 - val_acc: 0.7784

Epoch 00003: val_loss did not improve from 0.40850
Epoch 4/6
 - 24s - loss: 0.4407 - acc: 0.8179 - val_loss: 0.5166 - val_acc: 0.7885

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00004: val_loss did not improve from 0.40850
Epoch 5/6
 - 24s - loss: 0.2886 - acc: 0.8917 - val_loss: 0.1738 - val_acc: 0.9393

Epoch 00005: val_loss improved from 0.40850 to 0.17383, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.2568 - acc: 0.9081 - val_loss: 0.2268 - val_acc: 0.9306

Epoch 00006: val_loss did not improve from 0.17383
Test accuracy:0.757
current auc_score ------------------> 0.835
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.6144 - acc: 0.7441 - val_loss: 0.4893 - val_acc: 0.7890

Epoch 00001: val_loss improved from inf to 0.48927, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.4949 - acc: 0.8069 - val_loss: 0.7078 - val_acc: 0.6878

Epoch 00002: val_loss did not improve from 0.48927
Epoch 3/6
 - 24s - loss: 0.5148 - acc: 0.7763 - val_loss: 0.4264 - val_acc: 0.8234

Epoch 00003: val_loss improved from 0.48927 to 0.42636, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.4217 - acc: 0.8316 - val_loss: 2.6581 - val_acc: 0.6687

Epoch 00004: val_loss did not improve from 0.42636
Epoch 5/6
 - 24s - loss: 0.4415 - acc: 0.8315 - val_loss: 0.9501 - val_acc: 0.5659

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00005: val_loss did not improve from 0.42636
Epoch 6/6
 - 24s - loss: 0.2877 - acc: 0.8949 - val_loss: 0.1970 - val_acc: 0.9467

Epoch 00006: val_loss improved from 0.42636 to 0.19700, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.621
current auc_score ------------------> 0.825
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.6568 - acc: 0.7372 - val_loss: 1.2091 - val_acc: 0.6570

Epoch 00001: val_loss improved from inf to 1.20910, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.4974 - acc: 0.7839 - val_loss: 0.4735 - val_acc: 0.8181

Epoch 00002: val_loss improved from 1.20910 to 0.47355, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.3728 - acc: 0.8558 - val_loss: 0.7366 - val_acc: 0.7056

Epoch 00003: val_loss did not improve from 0.47355
Epoch 4/6
 - 24s - loss: 0.2823 - acc: 0.8996 - val_loss: 0.2549 - val_acc: 0.9099

Epoch 00004: val_loss improved from 0.47355 to 0.25489, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.3427 - acc: 0.8975 - val_loss: 0.5223 - val_acc: 0.8341

Epoch 00005: val_loss did not improve from 0.25489
Epoch 6/6
 - 25s - loss: 0.2434 - acc: 0.9240 - val_loss: 0.1860 - val_acc: 0.9483

Epoch 00006: val_loss improved from 0.25489 to 0.18600, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.782
current auc_score ------------------> 0.871
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.6357 - acc: 0.7563 - val_loss: 0.4453 - val_acc: 0.8135

Epoch 00001: val_loss improved from inf to 0.44533, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3801 - acc: 0.8491 - val_loss: 0.6011 - val_acc: 0.7085

Epoch 00002: val_loss did not improve from 0.44533
Epoch 3/6
 - 24s - loss: 0.3052 - acc: 0.8860 - val_loss: 0.3852 - val_acc: 0.8381

Epoch 00003: val_loss improved from 0.44533 to 0.38525, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.2713 - acc: 0.9045 - val_loss: 0.3600 - val_acc: 0.8832

Epoch 00004: val_loss improved from 0.38525 to 0.35999, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.2847 - acc: 0.9057 - val_loss: 0.2235 - val_acc: 0.9354

Epoch 00005: val_loss improved from 0.35999 to 0.22354, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.2225 - acc: 0.9269 - val_loss: 0.1566 - val_acc: 0.9536

Epoch 00006: val_loss improved from 0.22354 to 0.15659, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.813
current auc_score ------------------> 0.896
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.6507 - acc: 0.7559 - val_loss: 0.4359 - val_acc: 0.8235

Epoch 00001: val_loss improved from inf to 0.43593, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.6476 - acc: 0.8143 - val_loss: 2.0080 - val_acc: 0.6305

Epoch 00002: val_loss did not improve from 0.43593
Epoch 3/6
 - 24s - loss: 1.0490 - acc: 0.7508 - val_loss: 0.7460 - val_acc: 0.7868

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00003: val_loss did not improve from 0.43593
Epoch 4/6
 - 24s - loss: 0.6815 - acc: 0.8303 - val_loss: 0.5645 - val_acc: 0.8778

Epoch 00004: val_loss did not improve from 0.43593
Epoch 5/6
 - 24s - loss: 0.5420 - acc: 0.8663 - val_loss: 0.4844 - val_acc: 0.8804

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0050000003198031.

Epoch 00005: val_loss did not improve from 0.43593
Epoch 6/6
 - 24s - loss: 0.4385 - acc: 0.8962 - val_loss: 0.3301 - val_acc: 0.9462

Epoch 00006: val_loss improved from 0.43593 to 0.33006, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.729
current auc_score ------------------> 0.879
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.6794 - acc: 0.7479 - val_loss: 0.4856 - val_acc: 0.7823

Epoch 00001: val_loss improved from inf to 0.48561, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3784 - acc: 0.8525 - val_loss: 0.1971 - val_acc: 0.9347

Epoch 00002: val_loss improved from 0.48561 to 0.19712, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2855 - acc: 0.8974 - val_loss: 0.2841 - val_acc: 0.9069

Epoch 00003: val_loss did not improve from 0.19712
Epoch 4/6
 - 24s - loss: 0.2565 - acc: 0.9137 - val_loss: 0.2968 - val_acc: 0.9006

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00004: val_loss did not improve from 0.19712
Epoch 5/6
 - 24s - loss: 0.1493 - acc: 0.9524 - val_loss: 0.0812 - val_acc: 0.9810

Epoch 00005: val_loss improved from 0.19712 to 0.08124, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1116 - acc: 0.9652 - val_loss: 0.1091 - val_acc: 0.9695

Epoch 00006: val_loss did not improve from 0.08124
Test accuracy:0.733
current auc_score ------------------> 0.859
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.5825 - acc: 0.7622 - val_loss: 0.3618 - val_acc: 0.8592

Epoch 00001: val_loss improved from inf to 0.36177, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.4083 - acc: 0.8441 - val_loss: 0.2817 - val_acc: 0.9037

Epoch 00002: val_loss improved from 0.36177 to 0.28173, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.3338 - acc: 0.8786 - val_loss: 0.3837 - val_acc: 0.8401

Epoch 00003: val_loss did not improve from 0.28173
Epoch 4/6
 - 24s - loss: 0.3544 - acc: 0.8789 - val_loss: 0.2114 - val_acc: 0.9320

Epoch 00004: val_loss improved from 0.28173 to 0.21144, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.2488 - acc: 0.9169 - val_loss: 0.3641 - val_acc: 0.8725

Epoch 00005: val_loss did not improve from 0.21144
Epoch 6/6
 - 24s - loss: 0.2271 - acc: 0.9268 - val_loss: 0.2556 - val_acc: 0.9287

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00006: val_loss did not improve from 0.21144
Test accuracy:0.766
current auc_score ------------------> 0.870
Epochs  6  batch_size:  64  lr:  0.05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.6309 - acc: 0.7481 - val_loss: 0.9750 - val_acc: 0.6718

Epoch 00001: val_loss improved from inf to 0.97504, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.3577 - acc: 0.8573 - val_loss: 0.2603 - val_acc: 0.9059

Epoch 00002: val_loss improved from 0.97504 to 0.26030, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.2921 - acc: 0.8956 - val_loss: 0.3479 - val_acc: 0.8662

Epoch 00003: val_loss did not improve from 0.26030
Epoch 4/6
 - 25s - loss: 0.2628 - acc: 0.9086 - val_loss: 0.1463 - val_acc: 0.9541

Epoch 00004: val_loss improved from 0.26030 to 0.14632, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.2628 - acc: 0.9145 - val_loss: 0.1813 - val_acc: 0.9436

Epoch 00005: val_loss did not improve from 0.14632
Epoch 6/6
 - 25s - loss: 0.2493 - acc: 0.9224 - val_loss: 0.3390 - val_acc: 0.9056

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.015811388536449943.

Epoch 00006: val_loss did not improve from 0.14632
Test accuracy:0.744
current auc_score ------------------> 0.883
accuracies:  [0.7262096774193548, 0.7771505376344086, 0.7573924731182796, 0.6208333333333333, 0.7817204301075269, 0.8130376344086021, 0.7286290322580645, 0.7331989247311828, 0.765994623655914, 0.7438172043010752]
aucs:  [0.9082, 0.9035, 0.8352, 0.8247, 0.8711, 0.8957, 0.8789, 0.8588, 0.8701, 0.8831]
mean and std AUC:  0.873+/-0.026  max:   0.9082
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4289 - acc: 0.8595 - val_loss: 0.2303 - val_acc: 0.9669

Epoch 00001: val_loss improved from inf to 0.23032, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1848 - acc: 0.9670 - val_loss: 0.1366 - val_acc: 0.9878

Epoch 00002: val_loss improved from 0.23032 to 0.13655, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1263 - acc: 0.9824 - val_loss: 0.1075 - val_acc: 0.9867

Epoch 00003: val_loss improved from 0.13655 to 0.10750, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.0955 - acc: 0.9875 - val_loss: 0.0710 - val_acc: 0.9951

Epoch 00004: val_loss improved from 0.10750 to 0.07104, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.0742 - acc: 0.9906 - val_loss: 0.0672 - val_acc: 0.9940

Epoch 00005: val_loss improved from 0.07104 to 0.06720, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.0598 - acc: 0.9931 - val_loss: 0.0401 - val_acc: 0.9980

Epoch 00006: val_loss improved from 0.06720 to 0.04012, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.703
current auc_score ------------------> 0.892
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4671 - acc: 0.8423 - val_loss: 0.2407 - val_acc: 0.9558

Epoch 00001: val_loss improved from inf to 0.24067, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2079 - acc: 0.9586 - val_loss: 0.1380 - val_acc: 0.9851

Epoch 00002: val_loss improved from 0.24067 to 0.13802, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1451 - acc: 0.9768 - val_loss: 0.0955 - val_acc: 0.9931

Epoch 00003: val_loss improved from 0.13802 to 0.09549, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1084 - acc: 0.9837 - val_loss: 0.0994 - val_acc: 0.9883

Epoch 00004: val_loss did not improve from 0.09549
Epoch 5/6
 - 24s - loss: 0.1014 - acc: 0.9822 - val_loss: 0.0577 - val_acc: 0.9972

Epoch 00005: val_loss improved from 0.09549 to 0.05774, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0716 - acc: 0.9899 - val_loss: 0.0575 - val_acc: 0.9956

Epoch 00006: val_loss improved from 0.05774 to 0.05747, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.691
current auc_score ------------------> 0.861
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5388 - acc: 0.8041 - val_loss: 0.3258 - val_acc: 0.9194

Epoch 00001: val_loss improved from inf to 0.32583, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2522 - acc: 0.9430 - val_loss: 0.1845 - val_acc: 0.9755

Epoch 00002: val_loss improved from 0.32583 to 0.18450, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1515 - acc: 0.9770 - val_loss: 0.1174 - val_acc: 0.9892

Epoch 00003: val_loss improved from 0.18450 to 0.11740, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1169 - acc: 0.9832 - val_loss: 0.0934 - val_acc: 0.9913

Epoch 00004: val_loss improved from 0.11740 to 0.09344, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.0979 - acc: 0.9846 - val_loss: 0.6017 - val_acc: 0.8309

Epoch 00005: val_loss did not improve from 0.09344
Epoch 6/6
 - 24s - loss: 0.1159 - acc: 0.9761 - val_loss: 0.0633 - val_acc: 0.9966

Epoch 00006: val_loss improved from 0.09344 to 0.06326, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.794
current auc_score ------------------> 0.895
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4516 - acc: 0.8498 - val_loss: 0.2687 - val_acc: 0.9411

Epoch 00001: val_loss improved from inf to 0.26867, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2080 - acc: 0.9575 - val_loss: 0.1636 - val_acc: 0.9731

Epoch 00002: val_loss improved from 0.26867 to 0.16364, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1365 - acc: 0.9793 - val_loss: 0.1004 - val_acc: 0.9907

Epoch 00003: val_loss improved from 0.16364 to 0.10042, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.0955 - acc: 0.9887 - val_loss: 0.0739 - val_acc: 0.9964

Epoch 00004: val_loss improved from 0.10042 to 0.07393, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.0743 - acc: 0.9917 - val_loss: 0.0646 - val_acc: 0.9940

Epoch 00005: val_loss improved from 0.07393 to 0.06463, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0610 - acc: 0.9918 - val_loss: 0.0606 - val_acc: 0.9933

Epoch 00006: val_loss improved from 0.06463 to 0.06058, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.626
current auc_score ------------------> 0.859
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4601 - acc: 0.8417 - val_loss: 0.2469 - val_acc: 0.9529

Epoch 00001: val_loss improved from inf to 0.24687, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2100 - acc: 0.9586 - val_loss: 0.1280 - val_acc: 0.9843

Epoch 00002: val_loss improved from 0.24687 to 0.12800, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1439 - acc: 0.9768 - val_loss: 0.1086 - val_acc: 0.9864

Epoch 00003: val_loss improved from 0.12800 to 0.10855, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1171 - acc: 0.9808 - val_loss: 0.0770 - val_acc: 0.9939

Epoch 00004: val_loss improved from 0.10855 to 0.07705, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.0858 - acc: 0.9882 - val_loss: 0.0591 - val_acc: 0.9957

Epoch 00005: val_loss improved from 0.07705 to 0.05911, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.0686 - acc: 0.9904 - val_loss: 0.0461 - val_acc: 0.9969

Epoch 00006: val_loss improved from 0.05911 to 0.04614, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.793
current auc_score ------------------> 0.916
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4322 - acc: 0.8571 - val_loss: 0.2656 - val_acc: 0.9492

Epoch 00001: val_loss improved from inf to 0.26564, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1996 - acc: 0.9621 - val_loss: 0.1475 - val_acc: 0.9767

Epoch 00002: val_loss improved from 0.26564 to 0.14750, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1442 - acc: 0.9757 - val_loss: 0.1107 - val_acc: 0.9897

Epoch 00003: val_loss improved from 0.14750 to 0.11073, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.0949 - acc: 0.9891 - val_loss: 0.2107 - val_acc: 0.9296

Epoch 00004: val_loss did not improve from 0.11073
Epoch 5/6
 - 24s - loss: 0.0839 - acc: 0.9885 - val_loss: 0.0533 - val_acc: 0.9965

Epoch 00005: val_loss improved from 0.11073 to 0.05326, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0630 - acc: 0.9923 - val_loss: 0.0482 - val_acc: 0.9961

Epoch 00006: val_loss improved from 0.05326 to 0.04823, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.624
current auc_score ------------------> 0.838
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4554 - acc: 0.8466 - val_loss: 0.2575 - val_acc: 0.9522

Epoch 00001: val_loss improved from inf to 0.25752, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2043 - acc: 0.9602 - val_loss: 0.1459 - val_acc: 0.9856

Epoch 00002: val_loss improved from 0.25752 to 0.14593, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1385 - acc: 0.9777 - val_loss: 0.1090 - val_acc: 0.9854

Epoch 00003: val_loss improved from 0.14593 to 0.10895, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1052 - acc: 0.9846 - val_loss: 0.1243 - val_acc: 0.9736

Epoch 00004: val_loss did not improve from 0.10895
Epoch 5/6
 - 24s - loss: 0.0837 - acc: 0.9878 - val_loss: 0.0712 - val_acc: 0.9942

Epoch 00005: val_loss improved from 0.10895 to 0.07118, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0679 - acc: 0.9900 - val_loss: 0.0534 - val_acc: 0.9932

Epoch 00006: val_loss improved from 0.07118 to 0.05337, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.705
current auc_score ------------------> 0.818
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 29s - loss: 0.4572 - acc: 0.8458 - val_loss: 0.2395 - val_acc: 0.9582

Epoch 00001: val_loss improved from inf to 0.23954, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2124 - acc: 0.9592 - val_loss: 0.1557 - val_acc: 0.9733

Epoch 00002: val_loss improved from 0.23954 to 0.15566, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1382 - acc: 0.9787 - val_loss: 0.1057 - val_acc: 0.9902

Epoch 00003: val_loss improved from 0.15566 to 0.10571, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1110 - acc: 0.9819 - val_loss: 0.0796 - val_acc: 0.9931

Epoch 00004: val_loss improved from 0.10571 to 0.07958, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.0886 - acc: 0.9868 - val_loss: 0.0539 - val_acc: 0.9970

Epoch 00005: val_loss improved from 0.07958 to 0.05388, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.0673 - acc: 0.9908 - val_loss: 3.5894 - val_acc: 0.5595

Epoch 00006: val_loss did not improve from 0.05388
Test accuracy:0.722
current auc_score ------------------> 0.881
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4884 - acc: 0.8289 - val_loss: 0.2480 - val_acc: 0.9504

Epoch 00001: val_loss improved from inf to 0.24802, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2179 - acc: 0.9556 - val_loss: 0.1345 - val_acc: 0.9861

Epoch 00002: val_loss improved from 0.24802 to 0.13448, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1508 - acc: 0.9754 - val_loss: 0.1269 - val_acc: 0.9816

Epoch 00003: val_loss improved from 0.13448 to 0.12693, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1060 - acc: 0.9860 - val_loss: 0.0797 - val_acc: 0.9966

Epoch 00004: val_loss improved from 0.12693 to 0.07971, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.0901 - acc: 0.9873 - val_loss: 0.0643 - val_acc: 0.9965

Epoch 00005: val_loss improved from 0.07971 to 0.06425, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0741 - acc: 0.9892 - val_loss: 0.0484 - val_acc: 0.9965

Epoch 00006: val_loss improved from 0.06425 to 0.04844, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.741
current auc_score ------------------> 0.930
Saved model to disk
Epochs  6  batch_size:  64  lr:  0.001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4809 - acc: 0.8340 - val_loss: 1.6448 - val_acc: 0.5077

Epoch 00001: val_loss improved from inf to 1.64480, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2179 - acc: 0.9553 - val_loss: 0.1423 - val_acc: 0.9821

Epoch 00002: val_loss improved from 1.64480 to 0.14227, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1434 - acc: 0.9783 - val_loss: 0.1065 - val_acc: 0.9918

Epoch 00003: val_loss improved from 0.14227 to 0.10650, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1211 - acc: 0.9810 - val_loss: 0.0823 - val_acc: 0.9945

Epoch 00004: val_loss improved from 0.10650 to 0.08231, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.0824 - acc: 0.9906 - val_loss: 0.0734 - val_acc: 0.9947

Epoch 00005: val_loss improved from 0.08231 to 0.07337, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0706 - acc: 0.9910 - val_loss: 0.0530 - val_acc: 0.9961

Epoch 00006: val_loss improved from 0.07337 to 0.05297, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.703
current auc_score ------------------> 0.789
accuracies:  [0.7028225806451613, 0.6908602150537635, 0.7939516129032258, 0.6256720430107527, 0.793010752688172, 0.6244623655913979, 0.7049731182795699, 0.7215053763440861, 0.741263440860215, 0.7028225806451613]
aucs:  [0.8918, 0.8608, 0.8947, 0.8594, 0.9156, 0.8384, 0.8181, 0.8808, 0.9303, 0.7892]
mean and std AUC:  0.868+/-0.042  max:   0.9303
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 29s - loss: 0.4397 - acc: 0.8390 - val_loss: 0.3049 - val_acc: 0.8990

Epoch 00001: val_loss improved from inf to 0.30494, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2232 - acc: 0.9298 - val_loss: 0.1902 - val_acc: 0.9410

Epoch 00002: val_loss improved from 0.30494 to 0.19024, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1457 - acc: 0.9569 - val_loss: 0.1385 - val_acc: 0.9629

Epoch 00003: val_loss improved from 0.19024 to 0.13851, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1024 - acc: 0.9706 - val_loss: 0.1761 - val_acc: 0.9396

Epoch 00004: val_loss did not improve from 0.13851
Epoch 5/6
 - 25s - loss: 0.0740 - acc: 0.9792 - val_loss: 0.0559 - val_acc: 0.9885

Epoch 00005: val_loss improved from 0.13851 to 0.05586, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.0713 - acc: 0.9807 - val_loss: 0.1061 - val_acc: 0.9665

Epoch 00006: val_loss did not improve from 0.05586
Test accuracy:0.700
current auc_score ------------------> 0.854
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4073 - acc: 0.8559 - val_loss: 0.7506 - val_acc: 0.7108

Epoch 00001: val_loss improved from inf to 0.75061, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1777 - acc: 0.9492 - val_loss: 0.2734 - val_acc: 0.9006

Epoch 00002: val_loss improved from 0.75061 to 0.27337, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1166 - acc: 0.9659 - val_loss: 0.1306 - val_acc: 0.9617

Epoch 00003: val_loss improved from 0.27337 to 0.13061, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.0917 - acc: 0.9739 - val_loss: 0.6378 - val_acc: 0.7428

Epoch 00004: val_loss did not improve from 0.13061
Epoch 5/6
 - 24s - loss: 0.0665 - acc: 0.9824 - val_loss: 0.0786 - val_acc: 0.9848

Epoch 00005: val_loss improved from 0.13061 to 0.07863, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0575 - acc: 0.9851 - val_loss: 0.0762 - val_acc: 0.9808

Epoch 00006: val_loss improved from 0.07863 to 0.07620, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.745
current auc_score ------------------> 0.823
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4233 - acc: 0.8497 - val_loss: 0.2353 - val_acc: 0.9334

Epoch 00001: val_loss improved from inf to 0.23525, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1690 - acc: 0.9499 - val_loss: 0.1887 - val_acc: 0.9383

Epoch 00002: val_loss improved from 0.23525 to 0.18870, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1110 - acc: 0.9682 - val_loss: 0.0774 - val_acc: 0.9816

Epoch 00003: val_loss improved from 0.18870 to 0.07736, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.0864 - acc: 0.9758 - val_loss: 0.5474 - val_acc: 0.7511

Epoch 00004: val_loss did not improve from 0.07736
Epoch 5/6
 - 24s - loss: 0.0690 - acc: 0.9810 - val_loss: 0.1576 - val_acc: 0.9552

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0015811387947429827.

Epoch 00005: val_loss did not improve from 0.07736
Epoch 6/6
 - 24s - loss: 0.0383 - acc: 0.9916 - val_loss: 0.0247 - val_acc: 0.9957

Epoch 00006: val_loss improved from 0.07736 to 0.02468, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.700
current auc_score ------------------> 0.830
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4678 - acc: 0.8186 - val_loss: 0.3682 - val_acc: 0.8783

Epoch 00001: val_loss improved from inf to 0.36824, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.1929 - acc: 0.9404 - val_loss: 0.1064 - val_acc: 0.9748

Epoch 00002: val_loss improved from 0.36824 to 0.10643, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1242 - acc: 0.9647 - val_loss: 0.1461 - val_acc: 0.9526

Epoch 00003: val_loss did not improve from 0.10643
Epoch 4/6
 - 23s - loss: 0.0882 - acc: 0.9752 - val_loss: 0.0914 - val_acc: 0.9709

Epoch 00004: val_loss improved from 0.10643 to 0.09136, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.0679 - acc: 0.9824 - val_loss: 0.0596 - val_acc: 0.9861

Epoch 00005: val_loss improved from 0.09136 to 0.05957, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.0667 - acc: 0.9825 - val_loss: 0.0692 - val_acc: 0.9857

Epoch 00006: val_loss did not improve from 0.05957
Test accuracy:0.805
current auc_score ------------------> 0.879
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4280 - acc: 0.8473 - val_loss: 0.4021 - val_acc: 0.8646

Epoch 00001: val_loss improved from inf to 0.40207, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.1907 - acc: 0.9421 - val_loss: 0.1364 - val_acc: 0.9691

Epoch 00002: val_loss improved from 0.40207 to 0.13637, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1075 - acc: 0.9703 - val_loss: 0.0504 - val_acc: 0.9906

Epoch 00003: val_loss improved from 0.13637 to 0.05040, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.0841 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 0.9789

Epoch 00004: val_loss did not improve from 0.05040
Epoch 5/6
 - 23s - loss: 0.0699 - acc: 0.9817 - val_loss: 0.1058 - val_acc: 0.9667

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0015811387947429827.

Epoch 00005: val_loss did not improve from 0.05040
Epoch 6/6
 - 23s - loss: 0.0400 - acc: 0.9914 - val_loss: 0.0321 - val_acc: 0.9946

Epoch 00006: val_loss improved from 0.05040 to 0.03213, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.711
current auc_score ------------------> 0.911
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4138 - acc: 0.8559 - val_loss: 0.1769 - val_acc: 0.9549

Epoch 00001: val_loss improved from inf to 0.17689, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1785 - acc: 0.9472 - val_loss: 0.1763 - val_acc: 0.9494

Epoch 00002: val_loss improved from 0.17689 to 0.17630, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1240 - acc: 0.9645 - val_loss: 0.1059 - val_acc: 0.9703

Epoch 00003: val_loss improved from 0.17630 to 0.10590, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.0894 - acc: 0.9758 - val_loss: 0.0538 - val_acc: 0.9888

Epoch 00004: val_loss improved from 0.10590 to 0.05385, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.0672 - acc: 0.9828 - val_loss: 0.1053 - val_acc: 0.9672

Epoch 00005: val_loss did not improve from 0.05385
Epoch 6/6
 - 24s - loss: 0.0667 - acc: 0.9829 - val_loss: 0.1768 - val_acc: 0.9463

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0015811387947429827.

Epoch 00006: val_loss did not improve from 0.05385
Test accuracy:0.777
current auc_score ------------------> 0.854
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4379 - acc: 0.8403 - val_loss: 0.2518 - val_acc: 0.9329

Epoch 00001: val_loss improved from inf to 0.25177, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2045 - acc: 0.9368 - val_loss: 0.1555 - val_acc: 0.9541

Epoch 00002: val_loss improved from 0.25177 to 0.15548, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1234 - acc: 0.9639 - val_loss: 0.0643 - val_acc: 0.9851

Epoch 00003: val_loss improved from 0.15548 to 0.06429, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.0909 - acc: 0.9735 - val_loss: 0.0453 - val_acc: 0.9926

Epoch 00004: val_loss improved from 0.06429 to 0.04532, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.0738 - acc: 0.9802 - val_loss: 0.1071 - val_acc: 0.9666

Epoch 00005: val_loss did not improve from 0.04532
Epoch 6/6
 - 25s - loss: 0.0627 - acc: 0.9833 - val_loss: 0.0403 - val_acc: 0.9916

Epoch 00006: val_loss improved from 0.04532 to 0.04028, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.768
current auc_score ------------------> 0.890
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.4375 - acc: 0.8369 - val_loss: 0.2487 - val_acc: 0.9317

Epoch 00001: val_loss improved from inf to 0.24873, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1821 - acc: 0.9448 - val_loss: 0.1319 - val_acc: 0.9723

Epoch 00002: val_loss improved from 0.24873 to 0.13189, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1147 - acc: 0.9670 - val_loss: 0.0611 - val_acc: 0.9868

Epoch 00003: val_loss improved from 0.13189 to 0.06113, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.0903 - acc: 0.9744 - val_loss: 0.1448 - val_acc: 0.9600

Epoch 00004: val_loss did not improve from 0.06113
Epoch 5/6
 - 24s - loss: 0.0684 - acc: 0.9815 - val_loss: 0.0897 - val_acc: 0.9725

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0015811387947429827.

Epoch 00005: val_loss did not improve from 0.06113
Epoch 6/6
 - 24s - loss: 0.0393 - acc: 0.9909 - val_loss: 0.0544 - val_acc: 0.9858

Epoch 00006: val_loss improved from 0.06113 to 0.05443, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.663
current auc_score ------------------> 0.832
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4359 - acc: 0.8404 - val_loss: 0.1917 - val_acc: 0.9519

Epoch 00001: val_loss improved from inf to 0.19169, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.1877 - acc: 0.9426 - val_loss: 0.2388 - val_acc: 0.9312

Epoch 00002: val_loss did not improve from 0.19169
Epoch 3/6
 - 23s - loss: 0.1196 - acc: 0.9657 - val_loss: 0.0658 - val_acc: 0.9861

Epoch 00003: val_loss improved from 0.19169 to 0.06577, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1018 - acc: 0.9705 - val_loss: 0.0858 - val_acc: 0.9767

Epoch 00004: val_loss did not improve from 0.06577
Epoch 5/6
 - 23s - loss: 0.0816 - acc: 0.9778 - val_loss: 0.0523 - val_acc: 0.9901

Epoch 00005: val_loss improved from 0.06577 to 0.05231, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.0635 - acc: 0.9829 - val_loss: 0.0627 - val_acc: 0.9856

Epoch 00006: val_loss did not improve from 0.05231
Test accuracy:0.716
current auc_score ------------------> 0.870
Epochs  6  batch_size:  64  lr:  0.005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4292 - acc: 0.8436 - val_loss: 0.2329 - val_acc: 0.9383

Epoch 00001: val_loss improved from inf to 0.23289, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.1767 - acc: 0.9487 - val_loss: 0.0964 - val_acc: 0.9804

Epoch 00002: val_loss improved from 0.23289 to 0.09638, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1093 - acc: 0.9702 - val_loss: 0.0601 - val_acc: 0.9886

Epoch 00003: val_loss improved from 0.09638 to 0.06014, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.0976 - acc: 0.9727 - val_loss: 0.0785 - val_acc: 0.9814

Epoch 00004: val_loss did not improve from 0.06014
Epoch 5/6
 - 23s - loss: 0.0721 - acc: 0.9811 - val_loss: 0.1200 - val_acc: 0.9650

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0015811387947429827.

Epoch 00005: val_loss did not improve from 0.06014
Epoch 6/6
 - 23s - loss: 0.0420 - acc: 0.9903 - val_loss: 0.0185 - val_acc: 0.9979

Epoch 00006: val_loss improved from 0.06014 to 0.01846, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.709
current auc_score ------------------> 0.875
accuracies:  [0.6998655913978494, 0.7448924731182796, 0.7, 0.805241935483871, 0.7108870967741936, 0.7771505376344086, 0.7678763440860215, 0.6633064516129032, 0.7155913978494624, 0.709005376344086]
aucs:  [0.8539, 0.8231, 0.83, 0.8788, 0.9108, 0.8542, 0.8898, 0.8322, 0.8697, 0.8755]
mean and std AUC:  0.862+/-0.027  max:   0.9108
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 29s - loss: 0.5832 - acc: 0.7897 - val_loss: 0.4139 - val_acc: 0.8671

Epoch 00001: val_loss improved from inf to 0.41392, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3322 - acc: 0.9118 - val_loss: 0.2399 - val_acc: 0.9548

Epoch 00002: val_loss improved from 0.41392 to 0.23992, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.2371 - acc: 0.9549 - val_loss: 0.1801 - val_acc: 0.9798

Epoch 00003: val_loss improved from 0.23992 to 0.18011, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1874 - acc: 0.9745 - val_loss: 0.1517 - val_acc: 0.9893

Epoch 00004: val_loss improved from 0.18011 to 0.15171, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.1603 - acc: 0.9852 - val_loss: 0.1319 - val_acc: 0.9961

Epoch 00005: val_loss improved from 0.15171 to 0.13191, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.1436 - acc: 0.9901 - val_loss: 0.1237 - val_acc: 0.9976

Epoch 00006: val_loss improved from 0.13191 to 0.12366, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.608
current auc_score ------------------> 0.886
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.5635 - acc: 0.7994 - val_loss: 1.3606 - val_acc: 0.5366

Epoch 00001: val_loss improved from inf to 1.36060, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3114 - acc: 0.9196 - val_loss: 0.2299 - val_acc: 0.9632

Epoch 00002: val_loss improved from 1.36060 to 0.22993, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2248 - acc: 0.9618 - val_loss: 0.1725 - val_acc: 0.9846

Epoch 00003: val_loss improved from 0.22993 to 0.17254, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1759 - acc: 0.9801 - val_loss: 0.1476 - val_acc: 0.9910

Epoch 00004: val_loss improved from 0.17254 to 0.14758, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1537 - acc: 0.9874 - val_loss: 0.1321 - val_acc: 0.9937

Epoch 00005: val_loss improved from 0.14758 to 0.13208, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1382 - acc: 0.9912 - val_loss: 0.1454 - val_acc: 0.9878

Epoch 00006: val_loss did not improve from 0.13208
Test accuracy:0.662
current auc_score ------------------> 0.886
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5741 - acc: 0.7905 - val_loss: 0.3459 - val_acc: 0.9085

Epoch 00001: val_loss improved from inf to 0.34593, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3118 - acc: 0.9189 - val_loss: 0.2344 - val_acc: 0.9615

Epoch 00002: val_loss improved from 0.34593 to 0.23445, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.2294 - acc: 0.9592 - val_loss: 0.1730 - val_acc: 0.9817

Epoch 00003: val_loss improved from 0.23445 to 0.17296, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1820 - acc: 0.9768 - val_loss: 0.1481 - val_acc: 0.9920

Epoch 00004: val_loss improved from 0.17296 to 0.14813, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1575 - acc: 0.9856 - val_loss: 0.1319 - val_acc: 0.9956

Epoch 00005: val_loss improved from 0.14813 to 0.13192, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1387 - acc: 0.9910 - val_loss: 0.1269 - val_acc: 0.9945

Epoch 00006: val_loss improved from 0.13192 to 0.12685, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.699
current auc_score ------------------> 0.906
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.5791 - acc: 0.7875 - val_loss: 0.3925 - val_acc: 0.8852

Epoch 00001: val_loss improved from inf to 0.39248, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3226 - acc: 0.9173 - val_loss: 0.2396 - val_acc: 0.9606

Epoch 00002: val_loss improved from 0.39248 to 0.23956, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2295 - acc: 0.9607 - val_loss: 0.1848 - val_acc: 0.9823

Epoch 00003: val_loss improved from 0.23956 to 0.18482, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1832 - acc: 0.9782 - val_loss: 0.1512 - val_acc: 0.9912

Epoch 00004: val_loss improved from 0.18482 to 0.15121, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1572 - acc: 0.9873 - val_loss: 0.1410 - val_acc: 0.9942

Epoch 00005: val_loss improved from 0.15121 to 0.14099, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1388 - acc: 0.9916 - val_loss: 0.1269 - val_acc: 0.9961

Epoch 00006: val_loss improved from 0.14099 to 0.12695, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.603
current auc_score ------------------> 0.890
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.6265 - acc: 0.7621 - val_loss: 0.4326 - val_acc: 0.8519

Epoch 00001: val_loss improved from inf to 0.43263, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3465 - acc: 0.9048 - val_loss: 0.2646 - val_acc: 0.9469

Epoch 00002: val_loss improved from 0.43263 to 0.26459, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2470 - acc: 0.9520 - val_loss: 0.2111 - val_acc: 0.9688

Epoch 00003: val_loss improved from 0.26459 to 0.21109, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1966 - acc: 0.9731 - val_loss: 0.1626 - val_acc: 0.9867

Epoch 00004: val_loss improved from 0.21109 to 0.16258, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1670 - acc: 0.9837 - val_loss: 0.1400 - val_acc: 0.9931

Epoch 00005: val_loss improved from 0.16258 to 0.14001, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1466 - acc: 0.9900 - val_loss: 0.1374 - val_acc: 0.9927

Epoch 00006: val_loss improved from 0.14001 to 0.13742, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.741
current auc_score ------------------> 0.892
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.5802 - acc: 0.7919 - val_loss: 0.3729 - val_acc: 0.9001

Epoch 00001: val_loss improved from inf to 0.37289, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.3195 - acc: 0.9182 - val_loss: 0.2303 - val_acc: 0.9674

Epoch 00002: val_loss improved from 0.37289 to 0.23027, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2280 - acc: 0.9613 - val_loss: 0.1953 - val_acc: 0.9824

Epoch 00003: val_loss improved from 0.23027 to 0.19535, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1805 - acc: 0.9790 - val_loss: 0.1521 - val_acc: 0.9916

Epoch 00004: val_loss improved from 0.19535 to 0.15211, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1551 - acc: 0.9878 - val_loss: 0.1343 - val_acc: 0.9944

Epoch 00005: val_loss improved from 0.15211 to 0.13431, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1418 - acc: 0.9906 - val_loss: 0.1301 - val_acc: 0.9961

Epoch 00006: val_loss improved from 0.13431 to 0.13006, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.692
current auc_score ------------------> 0.889
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.5676 - acc: 0.7983 - val_loss: 0.3749 - val_acc: 0.8992

Epoch 00001: val_loss improved from inf to 0.37495, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.3030 - acc: 0.9256 - val_loss: 0.2451 - val_acc: 0.9582

Epoch 00002: val_loss improved from 0.37495 to 0.24505, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.2196 - acc: 0.9629 - val_loss: 0.1854 - val_acc: 0.9799

Epoch 00003: val_loss improved from 0.24505 to 0.18536, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1760 - acc: 0.9796 - val_loss: 0.1445 - val_acc: 0.9902

Epoch 00004: val_loss improved from 0.18536 to 0.14446, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1491 - acc: 0.9885 - val_loss: 0.1313 - val_acc: 0.9951

Epoch 00005: val_loss improved from 0.14446 to 0.13126, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.1344 - acc: 0.9922 - val_loss: 0.1216 - val_acc: 0.9974

Epoch 00006: val_loss improved from 0.13126 to 0.12157, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.674
current auc_score ------------------> 0.905
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.5569 - acc: 0.8002 - val_loss: 0.3632 - val_acc: 0.8986

Epoch 00001: val_loss improved from inf to 0.36319, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.3044 - acc: 0.9241 - val_loss: 0.2350 - val_acc: 0.9654

Epoch 00002: val_loss improved from 0.36319 to 0.23501, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.2190 - acc: 0.9641 - val_loss: 0.1695 - val_acc: 0.9833

Epoch 00003: val_loss improved from 0.23501 to 0.16949, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1750 - acc: 0.9801 - val_loss: 0.1439 - val_acc: 0.9923

Epoch 00004: val_loss improved from 0.16949 to 0.14394, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1535 - acc: 0.9870 - val_loss: 0.1306 - val_acc: 0.9937

Epoch 00005: val_loss improved from 0.14394 to 0.13065, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.1355 - acc: 0.9930 - val_loss: 0.1210 - val_acc: 0.9960

Epoch 00006: val_loss improved from 0.13065 to 0.12098, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.661
current auc_score ------------------> 0.894
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 29s - loss: 0.5873 - acc: 0.7831 - val_loss: 0.3425 - val_acc: 0.9091

Epoch 00001: val_loss improved from inf to 0.34247, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.3210 - acc: 0.9163 - val_loss: 0.2331 - val_acc: 0.9603

Epoch 00002: val_loss improved from 0.34247 to 0.23309, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.2284 - acc: 0.9605 - val_loss: 0.1811 - val_acc: 0.9810

Epoch 00003: val_loss improved from 0.23309 to 0.18110, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1802 - acc: 0.9798 - val_loss: 0.1500 - val_acc: 0.9896

Epoch 00004: val_loss improved from 0.18110 to 0.14995, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.1585 - acc: 0.9865 - val_loss: 0.1340 - val_acc: 0.9947

Epoch 00005: val_loss improved from 0.14995 to 0.13400, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.1388 - acc: 0.9924 - val_loss: 0.1216 - val_acc: 0.9972

Epoch 00006: val_loss improved from 0.13400 to 0.12159, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.641
current auc_score ------------------> 0.932
Saved model to disk
Epochs  6  batch_size:  64  lr:  0.0001  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5594 - acc: 0.7976 - val_loss: 0.3598 - val_acc: 0.8993

Epoch 00001: val_loss improved from inf to 0.35976, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.3227 - acc: 0.9155 - val_loss: 0.2665 - val_acc: 0.9444

Epoch 00002: val_loss improved from 0.35976 to 0.26652, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.2315 - acc: 0.9566 - val_loss: 0.1925 - val_acc: 0.9774

Epoch 00003: val_loss improved from 0.26652 to 0.19253, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1860 - acc: 0.9752 - val_loss: 0.1576 - val_acc: 0.9887

Epoch 00004: val_loss improved from 0.19253 to 0.15759, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.1558 - acc: 0.9876 - val_loss: 0.1408 - val_acc: 0.9921

Epoch 00005: val_loss improved from 0.15759 to 0.14081, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 25s - loss: 0.1439 - acc: 0.9899 - val_loss: 0.1297 - val_acc: 0.9951

Epoch 00006: val_loss improved from 0.14081 to 0.12967, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.600
current auc_score ------------------> 0.904
accuracies:  [0.6075268817204301, 0.6623655913978495, 0.6990591397849463, 0.6028225806451613, 0.7411290322580645, 0.6924731182795699, 0.6740591397849462, 0.6612903225806451, 0.6413978494623656, 0.5998655913978495]
aucs:  [0.8864, 0.886, 0.9064, 0.8903, 0.892, 0.8892, 0.9055, 0.8943, 0.932, 0.9043]
mean and std AUC:  0.899+/-0.013  max:   0.932
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 29s - loss: 0.5553 - acc: 0.7963 - val_loss: 0.3367 - val_acc: 0.9213

Epoch 00001: val_loss improved from inf to 0.33674, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2534 - acc: 0.9460 - val_loss: 0.1940 - val_acc: 0.9758

Epoch 00002: val_loss improved from 0.33674 to 0.19404, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 25s - loss: 0.1679 - acc: 0.9772 - val_loss: 0.1358 - val_acc: 0.9898

Epoch 00003: val_loss improved from 0.19404 to 0.13576, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1325 - acc: 0.9863 - val_loss: 0.1055 - val_acc: 0.9944

Epoch 00004: val_loss improved from 0.13576 to 0.10553, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.1138 - acc: 0.9889 - val_loss: 0.0889 - val_acc: 0.9962

Epoch 00005: val_loss improved from 0.10553 to 0.08887, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1017 - acc: 0.9899 - val_loss: 0.0757 - val_acc: 0.9977

Epoch 00006: val_loss improved from 0.08887 to 0.07566, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.733
current auc_score ------------------> 0.906
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5178 - acc: 0.8198 - val_loss: 0.3067 - val_acc: 0.9354

Epoch 00001: val_loss improved from inf to 0.30672, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2479 - acc: 0.9508 - val_loss: 0.1874 - val_acc: 0.9728

Epoch 00002: val_loss improved from 0.30672 to 0.18736, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1752 - acc: 0.9749 - val_loss: 0.1318 - val_acc: 0.9926

Epoch 00003: val_loss improved from 0.18736 to 0.13181, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1393 - acc: 0.9840 - val_loss: 0.1823 - val_acc: 0.9686

Epoch 00004: val_loss did not improve from 0.13181
Epoch 5/6
 - 24s - loss: 0.1215 - acc: 0.9864 - val_loss: 0.0915 - val_acc: 0.9960

Epoch 00005: val_loss improved from 0.13181 to 0.09154, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0958 - acc: 0.9931 - val_loss: 0.1072 - val_acc: 0.9858

Epoch 00006: val_loss did not improve from 0.09154
Test accuracy:0.727
current auc_score ------------------> 0.866
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4991 - acc: 0.8308 - val_loss: 0.2473 - val_acc: 0.9534

Epoch 00001: val_loss improved from inf to 0.24730, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2325 - acc: 0.9551 - val_loss: 0.1844 - val_acc: 0.9799

Epoch 00002: val_loss improved from 0.24730 to 0.18438, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1604 - acc: 0.9797 - val_loss: 0.1233 - val_acc: 0.9922

Epoch 00003: val_loss improved from 0.18438 to 0.12331, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1293 - acc: 0.9862 - val_loss: 0.1227 - val_acc: 0.9881

Epoch 00004: val_loss improved from 0.12331 to 0.12267, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1050 - acc: 0.9921 - val_loss: 0.0903 - val_acc: 0.9942

Epoch 00005: val_loss improved from 0.12267 to 0.09028, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0951 - acc: 0.9918 - val_loss: 0.0732 - val_acc: 0.9981

Epoch 00006: val_loss improved from 0.09028 to 0.07320, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.662
current auc_score ------------------> 0.875
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 26s - loss: 0.4945 - acc: 0.8318 - val_loss: 0.2693 - val_acc: 0.9445

Epoch 00001: val_loss improved from inf to 0.26926, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2293 - acc: 0.9559 - val_loss: 0.1692 - val_acc: 0.9836

Epoch 00002: val_loss improved from 0.26926 to 0.16920, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1585 - acc: 0.9804 - val_loss: 0.1302 - val_acc: 0.9910

Epoch 00003: val_loss improved from 0.16920 to 0.13018, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1278 - acc: 0.9876 - val_loss: 0.1111 - val_acc: 0.9930

Epoch 00004: val_loss improved from 0.13018 to 0.11108, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1052 - acc: 0.9914 - val_loss: 0.1100 - val_acc: 0.9887

Epoch 00005: val_loss improved from 0.11108 to 0.10995, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.0907 - acc: 0.9934 - val_loss: 0.0712 - val_acc: 0.9975

Epoch 00006: val_loss improved from 0.10995 to 0.07119, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.606
current auc_score ------------------> 0.916
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4916 - acc: 0.8319 - val_loss: 0.2633 - val_acc: 0.9572

Epoch 00001: val_loss improved from inf to 0.26330, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2283 - acc: 0.9589 - val_loss: 0.1884 - val_acc: 0.9695

Epoch 00002: val_loss improved from 0.26330 to 0.18839, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1629 - acc: 0.9793 - val_loss: 0.1436 - val_acc: 0.9837

Epoch 00003: val_loss improved from 0.18839 to 0.14363, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 23s - loss: 0.1248 - acc: 0.9890 - val_loss: 0.1004 - val_acc: 0.9960

Epoch 00004: val_loss improved from 0.14363 to 0.10035, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1079 - acc: 0.9900 - val_loss: 0.1051 - val_acc: 0.9913

Epoch 00005: val_loss did not improve from 0.10035
Epoch 6/6
 - 23s - loss: 0.0929 - acc: 0.9927 - val_loss: 0.0857 - val_acc: 0.9951

Epoch 00006: val_loss improved from 0.10035 to 0.08567, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.668
current auc_score ------------------> 0.884
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 28s - loss: 0.5140 - acc: 0.8199 - val_loss: 0.2927 - val_acc: 0.9498

Epoch 00001: val_loss improved from inf to 0.29271, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2396 - acc: 0.9519 - val_loss: 0.1717 - val_acc: 0.9805

Epoch 00002: val_loss improved from 0.29271 to 0.17171, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1735 - acc: 0.9749 - val_loss: 0.1491 - val_acc: 0.9826

Epoch 00003: val_loss improved from 0.17171 to 0.14907, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 25s - loss: 0.1370 - acc: 0.9843 - val_loss: 0.0997 - val_acc: 0.9952

Epoch 00004: val_loss improved from 0.14907 to 0.09966, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1137 - acc: 0.9886 - val_loss: 0.0925 - val_acc: 0.9967

Epoch 00005: val_loss improved from 0.09966 to 0.09248, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.1000 - acc: 0.9910 - val_loss: 0.0786 - val_acc: 0.9962

Epoch 00006: val_loss improved from 0.09248 to 0.07860, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.727
current auc_score ------------------> 0.877
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4755 - acc: 0.8417 - val_loss: 0.2848 - val_acc: 0.9411

Epoch 00001: val_loss improved from inf to 0.28483, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2269 - acc: 0.9583 - val_loss: 0.1609 - val_acc: 0.9848

Epoch 00002: val_loss improved from 0.28483 to 0.16092, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1596 - acc: 0.9798 - val_loss: 0.1201 - val_acc: 0.9907

Epoch 00003: val_loss improved from 0.16092 to 0.12015, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1317 - acc: 0.9858 - val_loss: 0.1147 - val_acc: 0.9918

Epoch 00004: val_loss improved from 0.12015 to 0.11475, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1045 - acc: 0.9928 - val_loss: 0.0843 - val_acc: 0.9971

Epoch 00005: val_loss improved from 0.11475 to 0.08432, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.0922 - acc: 0.9928 - val_loss: 0.0724 - val_acc: 0.9976

Epoch 00006: val_loss improved from 0.08432 to 0.07241, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.696
current auc_score ------------------> 0.878
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4830 - acc: 0.8356 - val_loss: 0.2737 - val_acc: 0.9522

Epoch 00001: val_loss improved from inf to 0.27367, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 23s - loss: 0.2328 - acc: 0.9548 - val_loss: 0.1694 - val_acc: 0.9807

Epoch 00002: val_loss improved from 0.27367 to 0.16941, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 23s - loss: 0.1724 - acc: 0.9749 - val_loss: 0.1396 - val_acc: 0.9862

Epoch 00003: val_loss improved from 0.16941 to 0.13964, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1288 - acc: 0.9888 - val_loss: 0.0986 - val_acc: 0.9951

Epoch 00004: val_loss improved from 0.13964 to 0.09857, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 23s - loss: 0.1069 - acc: 0.9905 - val_loss: 0.0807 - val_acc: 0.9976

Epoch 00005: val_loss improved from 0.09857 to 0.08074, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0964 - acc: 0.9919 - val_loss: 0.0777 - val_acc: 0.9972

Epoch 00006: val_loss improved from 0.08074 to 0.07774, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.760
current auc_score ------------------> 0.845
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 29s - loss: 0.5411 - acc: 0.8083 - val_loss: 0.3647 - val_acc: 0.9116

Epoch 00001: val_loss improved from inf to 0.36469, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 25s - loss: 0.2496 - acc: 0.9471 - val_loss: 0.1797 - val_acc: 0.9829

Epoch 00002: val_loss improved from 0.36469 to 0.17969, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1690 - acc: 0.9777 - val_loss: 0.1272 - val_acc: 0.9911

Epoch 00003: val_loss improved from 0.17969 to 0.12723, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1354 - acc: 0.9856 - val_loss: 0.1169 - val_acc: 0.9946

Epoch 00004: val_loss improved from 0.12723 to 0.11692, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 25s - loss: 0.1152 - acc: 0.9892 - val_loss: 0.0918 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.11692 to 0.09184, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 24s - loss: 0.0970 - acc: 0.9928 - val_loss: 0.1039 - val_acc: 0.9900

Epoch 00006: val_loss did not improve from 0.09184
Test accuracy:0.729
current auc_score ------------------> 0.838
Epochs  6  batch_size:  64  lr:  0.0005  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 27s - loss: 0.4785 - acc: 0.8381 - val_loss: 0.2915 - val_acc: 0.9389

Epoch 00001: val_loss improved from inf to 0.29155, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/6
 - 24s - loss: 0.2244 - acc: 0.9594 - val_loss: 0.1730 - val_acc: 0.9828

Epoch 00002: val_loss improved from 0.29155 to 0.17297, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/6
 - 24s - loss: 0.1615 - acc: 0.9793 - val_loss: 0.1162 - val_acc: 0.9933

Epoch 00003: val_loss improved from 0.17297 to 0.11617, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/6
 - 24s - loss: 0.1282 - acc: 0.9871 - val_loss: 0.1048 - val_acc: 0.9946

Epoch 00004: val_loss improved from 0.11617 to 0.10482, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/6
 - 24s - loss: 0.1094 - acc: 0.9902 - val_loss: 0.1005 - val_acc: 0.9920

Epoch 00005: val_loss improved from 0.10482 to 0.10051, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/6
 - 23s - loss: 0.0908 - acc: 0.9935 - val_loss: 0.0713 - val_acc: 0.9979

Epoch 00006: val_loss improved from 0.10051 to 0.07126, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.701
current auc_score ------------------> 0.864
accuracies:  [0.7330645161290322, 0.7268817204301076, 0.6620967741935484, 0.6064516129032258, 0.6676075268817204, 0.7272849462365591, 0.6956989247311828, 0.7595430107526882, 0.728763440860215, 0.7012096774193548]
aucs:  [0.906, 0.8658, 0.8754, 0.9158, 0.8836, 0.8769, 0.8782, 0.8453, 0.8384, 0.8641]
mean and std AUC:  0.875+/-0.023  max:   0.9158
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 28s - loss: 0.8164 - acc: 0.6820 - val_loss: 0.5764 - val_acc: 0.7585

Epoch 00001: val_loss improved from inf to 0.57637, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 24s - loss: 0.6035 - acc: 0.7793 - val_loss: 0.4655 - val_acc: 0.8331

Epoch 00002: val_loss improved from 0.57637 to 0.46555, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 24s - loss: 0.4893 - acc: 0.8316 - val_loss: 0.3878 - val_acc: 0.8811

Epoch 00003: val_loss improved from 0.46555 to 0.38779, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 24s - loss: 0.4169 - acc: 0.8676 - val_loss: 0.3438 - val_acc: 0.9061

Epoch 00004: val_loss improved from 0.38779 to 0.34377, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 24s - loss: 0.3617 - acc: 0.8939 - val_loss: 0.3158 - val_acc: 0.9174

Epoch 00005: val_loss improved from 0.34377 to 0.31582, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 24s - loss: 0.3176 - acc: 0.9145 - val_loss: 0.2764 - val_acc: 0.9384

Epoch 00006: val_loss improved from 0.31582 to 0.27642, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2874 - acc: 0.9299 - val_loss: 0.2474 - val_acc: 0.9526

Epoch 00007: val_loss improved from 0.27642 to 0.24741, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 24s - loss: 0.2573 - acc: 0.9426 - val_loss: 0.2124 - val_acc: 0.9641

Epoch 00008: val_loss improved from 0.24741 to 0.21240, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 24s - loss: 0.2352 - acc: 0.9528 - val_loss: 0.1938 - val_acc: 0.9695

Epoch 00009: val_loss improved from 0.21240 to 0.19382, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 24s - loss: 0.2155 - acc: 0.9621 - val_loss: 0.1820 - val_acc: 0.9777

Epoch 00010: val_loss improved from 0.19382 to 0.18197, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.689
current auc_score ------------------> 0.927
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 29s - loss: 0.8026 - acc: 0.6905 - val_loss: 0.5192 - val_acc: 0.8070

Epoch 00001: val_loss improved from inf to 0.51916, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 25s - loss: 0.5894 - acc: 0.7881 - val_loss: 0.4402 - val_acc: 0.8505

Epoch 00002: val_loss improved from 0.51916 to 0.44017, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 24s - loss: 0.4816 - acc: 0.8390 - val_loss: 0.3506 - val_acc: 0.9009

Epoch 00003: val_loss improved from 0.44017 to 0.35064, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 25s - loss: 0.4107 - acc: 0.8701 - val_loss: 0.3283 - val_acc: 0.9185

Epoch 00004: val_loss improved from 0.35064 to 0.32828, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 24s - loss: 0.3541 - acc: 0.8971 - val_loss: 0.2809 - val_acc: 0.9424

Epoch 00005: val_loss improved from 0.32828 to 0.28094, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 24s - loss: 0.3179 - acc: 0.9156 - val_loss: 0.2679 - val_acc: 0.9478

Epoch 00006: val_loss improved from 0.28094 to 0.26792, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2837 - acc: 0.9303 - val_loss: 0.2458 - val_acc: 0.9563

Epoch 00007: val_loss improved from 0.26792 to 0.24580, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 24s - loss: 0.2584 - acc: 0.9433 - val_loss: 0.2081 - val_acc: 0.9696

Epoch 00008: val_loss improved from 0.24580 to 0.20806, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 24s - loss: 0.2334 - acc: 0.9544 - val_loss: 0.2042 - val_acc: 0.9716

Epoch 00009: val_loss improved from 0.20806 to 0.20416, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 24s - loss: 0.2174 - acc: 0.9611 - val_loss: 0.1800 - val_acc: 0.9782

Epoch 00010: val_loss improved from 0.20416 to 0.17999, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.699
current auc_score ------------------> 0.881
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 27s - loss: 0.7900 - acc: 0.6938 - val_loss: 0.6340 - val_acc: 0.7127

Epoch 00001: val_loss improved from inf to 0.63400, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 23s - loss: 0.5902 - acc: 0.7835 - val_loss: 0.4587 - val_acc: 0.8363

Epoch 00002: val_loss improved from 0.63400 to 0.45867, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 23s - loss: 0.4833 - acc: 0.8384 - val_loss: 0.4109 - val_acc: 0.8671

Epoch 00003: val_loss improved from 0.45867 to 0.41095, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 23s - loss: 0.4094 - acc: 0.8708 - val_loss: 0.3215 - val_acc: 0.9207

Epoch 00004: val_loss improved from 0.41095 to 0.32148, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 23s - loss: 0.3581 - acc: 0.8983 - val_loss: 0.2796 - val_acc: 0.9405

Epoch 00005: val_loss improved from 0.32148 to 0.27956, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 23s - loss: 0.3174 - acc: 0.9162 - val_loss: 0.2584 - val_acc: 0.9501

Epoch 00006: val_loss improved from 0.27956 to 0.25839, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 23s - loss: 0.2827 - acc: 0.9316 - val_loss: 0.2338 - val_acc: 0.9598

Epoch 00007: val_loss improved from 0.25839 to 0.23383, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 23s - loss: 0.2585 - acc: 0.9437 - val_loss: 0.2250 - val_acc: 0.9592

Epoch 00008: val_loss improved from 0.23383 to 0.22502, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 23s - loss: 0.2374 - acc: 0.9531 - val_loss: 0.2097 - val_acc: 0.9667

Epoch 00009: val_loss improved from 0.22502 to 0.20972, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 23s - loss: 0.2167 - acc: 0.9614 - val_loss: 0.1959 - val_acc: 0.9736

Epoch 00010: val_loss improved from 0.20972 to 0.19590, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.743
current auc_score ------------------> 0.927
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 29s - loss: 0.8076 - acc: 0.6844 - val_loss: 0.5488 - val_acc: 0.7801

Epoch 00001: val_loss improved from inf to 0.54884, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 25s - loss: 0.6006 - acc: 0.7770 - val_loss: 0.4467 - val_acc: 0.8499

Epoch 00002: val_loss improved from 0.54884 to 0.44668, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 25s - loss: 0.4961 - acc: 0.8276 - val_loss: 0.3992 - val_acc: 0.8753

Epoch 00003: val_loss improved from 0.44668 to 0.39918, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 25s - loss: 0.4245 - acc: 0.8615 - val_loss: 0.3423 - val_acc: 0.9036

Epoch 00004: val_loss improved from 0.39918 to 0.34235, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 25s - loss: 0.3701 - acc: 0.8904 - val_loss: 0.3169 - val_acc: 0.9207

Epoch 00005: val_loss improved from 0.34235 to 0.31688, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 25s - loss: 0.3333 - acc: 0.9091 - val_loss: 0.2709 - val_acc: 0.9425

Epoch 00006: val_loss improved from 0.31688 to 0.27088, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 25s - loss: 0.2977 - acc: 0.9260 - val_loss: 0.2526 - val_acc: 0.9537

Epoch 00007: val_loss improved from 0.27088 to 0.25260, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 25s - loss: 0.2677 - acc: 0.9393 - val_loss: 0.2255 - val_acc: 0.9629

Epoch 00008: val_loss improved from 0.25260 to 0.22553, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 25s - loss: 0.2439 - acc: 0.9510 - val_loss: 0.2177 - val_acc: 0.9665

Epoch 00009: val_loss improved from 0.22553 to 0.21767, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 25s - loss: 0.2251 - acc: 0.9591 - val_loss: 0.1971 - val_acc: 0.9729

Epoch 00010: val_loss improved from 0.21767 to 0.19710, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.692
current auc_score ------------------> 0.849
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 27s - loss: 0.8159 - acc: 0.6848 - val_loss: 0.5629 - val_acc: 0.7762

Epoch 00001: val_loss improved from inf to 0.56286, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 24s - loss: 0.6002 - acc: 0.7796 - val_loss: 0.4616 - val_acc: 0.8382

Epoch 00002: val_loss improved from 0.56286 to 0.46164, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 24s - loss: 0.4981 - acc: 0.8271 - val_loss: 0.3827 - val_acc: 0.8864

Epoch 00003: val_loss improved from 0.46164 to 0.38275, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 24s - loss: 0.4238 - acc: 0.8621 - val_loss: 0.3482 - val_acc: 0.9019

Epoch 00004: val_loss improved from 0.38275 to 0.34824, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 24s - loss: 0.3770 - acc: 0.8866 - val_loss: 0.3196 - val_acc: 0.9175

Epoch 00005: val_loss improved from 0.34824 to 0.31961, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 23s - loss: 0.3293 - acc: 0.9094 - val_loss: 0.2836 - val_acc: 0.9327

Epoch 00006: val_loss improved from 0.31961 to 0.28364, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2974 - acc: 0.9257 - val_loss: 0.2640 - val_acc: 0.9478

Epoch 00007: val_loss improved from 0.28364 to 0.26401, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 24s - loss: 0.2664 - acc: 0.9393 - val_loss: 0.2261 - val_acc: 0.9608

Epoch 00008: val_loss improved from 0.26401 to 0.22609, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 24s - loss: 0.2469 - acc: 0.9487 - val_loss: 0.2089 - val_acc: 0.9698

Epoch 00009: val_loss improved from 0.22609 to 0.20892, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 24s - loss: 0.2249 - acc: 0.9588 - val_loss: 0.2058 - val_acc: 0.9699

Epoch 00010: val_loss improved from 0.20892 to 0.20578, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.624
current auc_score ------------------> 0.890
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 29s - loss: 0.8205 - acc: 0.6807 - val_loss: 0.5822 - val_acc: 0.7539

Epoch 00001: val_loss improved from inf to 0.58218, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 24s - loss: 0.6038 - acc: 0.7755 - val_loss: 0.4700 - val_acc: 0.8293

Epoch 00002: val_loss improved from 0.58218 to 0.47003, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 24s - loss: 0.5002 - acc: 0.8249 - val_loss: 0.4215 - val_acc: 0.8613

Epoch 00003: val_loss improved from 0.47003 to 0.42152, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 25s - loss: 0.4265 - acc: 0.8624 - val_loss: 0.3363 - val_acc: 0.9084

Epoch 00004: val_loss improved from 0.42152 to 0.33631, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 24s - loss: 0.3693 - acc: 0.8894 - val_loss: 0.3208 - val_acc: 0.9179

Epoch 00005: val_loss improved from 0.33631 to 0.32078, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 24s - loss: 0.3264 - acc: 0.9117 - val_loss: 0.2928 - val_acc: 0.9307

Epoch 00006: val_loss improved from 0.32078 to 0.29281, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2910 - acc: 0.9263 - val_loss: 0.2604 - val_acc: 0.9438

Epoch 00007: val_loss improved from 0.29281 to 0.26040, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 25s - loss: 0.2665 - acc: 0.9388 - val_loss: 0.2213 - val_acc: 0.9615

Epoch 00008: val_loss improved from 0.26040 to 0.22125, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 25s - loss: 0.2418 - acc: 0.9496 - val_loss: 0.2098 - val_acc: 0.9667

Epoch 00009: val_loss improved from 0.22125 to 0.20982, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 24s - loss: 0.2248 - acc: 0.9560 - val_loss: 0.1899 - val_acc: 0.9734

Epoch 00010: val_loss improved from 0.20982 to 0.18987, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.708
current auc_score ------------------> 0.928
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 28s - loss: 0.7986 - acc: 0.6900 - val_loss: 0.5336 - val_acc: 0.7988

Epoch 00001: val_loss improved from inf to 0.53359, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 25s - loss: 0.5823 - acc: 0.7867 - val_loss: 0.4330 - val_acc: 0.8552

Epoch 00002: val_loss improved from 0.53359 to 0.43302, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 25s - loss: 0.4692 - acc: 0.8407 - val_loss: 0.3702 - val_acc: 0.8873

Epoch 00003: val_loss improved from 0.43302 to 0.37025, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 24s - loss: 0.3986 - acc: 0.8773 - val_loss: 0.3285 - val_acc: 0.9157

Epoch 00004: val_loss improved from 0.37025 to 0.32846, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 24s - loss: 0.3408 - acc: 0.9052 - val_loss: 0.2714 - val_acc: 0.9388

Epoch 00005: val_loss improved from 0.32846 to 0.27136, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 24s - loss: 0.3039 - acc: 0.9221 - val_loss: 0.2452 - val_acc: 0.9492

Epoch 00006: val_loss improved from 0.27136 to 0.24516, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2701 - acc: 0.9388 - val_loss: 0.2457 - val_acc: 0.9523

Epoch 00007: val_loss did not improve from 0.24516
Epoch 8/10
 - 24s - loss: 0.2452 - acc: 0.9479 - val_loss: 0.2044 - val_acc: 0.9695

Epoch 00008: val_loss improved from 0.24516 to 0.20439, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 24s - loss: 0.2252 - acc: 0.9585 - val_loss: 0.2012 - val_acc: 0.9701

Epoch 00009: val_loss improved from 0.20439 to 0.20115, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 25s - loss: 0.2067 - acc: 0.9666 - val_loss: 0.1863 - val_acc: 0.9739

Epoch 00010: val_loss improved from 0.20115 to 0.18630, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.682
current auc_score ------------------> 0.895
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 28s - loss: 0.7845 - acc: 0.6924 - val_loss: 0.5362 - val_acc: 0.7983

Epoch 00001: val_loss improved from inf to 0.53616, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 25s - loss: 0.5707 - acc: 0.7907 - val_loss: 0.4571 - val_acc: 0.8444

Epoch 00002: val_loss improved from 0.53616 to 0.45714, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 24s - loss: 0.4683 - acc: 0.8424 - val_loss: 0.3755 - val_acc: 0.8922

Epoch 00003: val_loss improved from 0.45714 to 0.37548, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 25s - loss: 0.4043 - acc: 0.8752 - val_loss: 0.3397 - val_acc: 0.9134

Epoch 00004: val_loss improved from 0.37548 to 0.33971, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 25s - loss: 0.3499 - acc: 0.9006 - val_loss: 0.2891 - val_acc: 0.9362

Epoch 00005: val_loss improved from 0.33971 to 0.28909, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 24s - loss: 0.3125 - acc: 0.9187 - val_loss: 0.2541 - val_acc: 0.9522

Epoch 00006: val_loss improved from 0.28909 to 0.25410, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2747 - acc: 0.9354 - val_loss: 0.2304 - val_acc: 0.9607

Epoch 00007: val_loss improved from 0.25410 to 0.23038, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 24s - loss: 0.2537 - acc: 0.9449 - val_loss: 0.2243 - val_acc: 0.9631

Epoch 00008: val_loss improved from 0.23038 to 0.22428, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 24s - loss: 0.2313 - acc: 0.9572 - val_loss: 0.2083 - val_acc: 0.9694

Epoch 00009: val_loss improved from 0.22428 to 0.20831, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 24s - loss: 0.2112 - acc: 0.9650 - val_loss: 0.1900 - val_acc: 0.9738

Epoch 00010: val_loss improved from 0.20831 to 0.19002, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.708
current auc_score ------------------> 0.924
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 27s - loss: 0.7883 - acc: 0.6963 - val_loss: 0.5424 - val_acc: 0.7883

Epoch 00001: val_loss improved from inf to 0.54235, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 24s - loss: 0.5792 - acc: 0.7877 - val_loss: 0.4368 - val_acc: 0.8538

Epoch 00002: val_loss improved from 0.54235 to 0.43680, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 24s - loss: 0.4764 - acc: 0.8372 - val_loss: 0.3783 - val_acc: 0.8883

Epoch 00003: val_loss improved from 0.43680 to 0.37826, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 24s - loss: 0.4061 - acc: 0.8739 - val_loss: 0.3440 - val_acc: 0.9041

Epoch 00004: val_loss improved from 0.37826 to 0.34400, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 24s - loss: 0.3599 - acc: 0.8958 - val_loss: 0.3030 - val_acc: 0.9221

Epoch 00005: val_loss improved from 0.34400 to 0.30301, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 23s - loss: 0.3175 - acc: 0.9153 - val_loss: 0.2643 - val_acc: 0.9480

Epoch 00006: val_loss improved from 0.30301 to 0.26426, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 24s - loss: 0.2880 - acc: 0.9295 - val_loss: 0.2406 - val_acc: 0.9542

Epoch 00007: val_loss improved from 0.26426 to 0.24058, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 24s - loss: 0.2595 - acc: 0.9427 - val_loss: 0.2148 - val_acc: 0.9641

Epoch 00008: val_loss improved from 0.24058 to 0.21477, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 23s - loss: 0.2369 - acc: 0.9534 - val_loss: 0.2072 - val_acc: 0.9710

Epoch 00009: val_loss improved from 0.21477 to 0.20716, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 24s - loss: 0.2191 - acc: 0.9615 - val_loss: 0.1864 - val_acc: 0.9778

Epoch 00010: val_loss improved from 0.20716 to 0.18637, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.676
current auc_score ------------------> 0.885
Epochs  10  batch_size:  64  lr:  1e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 29s - loss: 0.8226 - acc: 0.6784 - val_loss: 0.5600 - val_acc: 0.7762

Epoch 00001: val_loss improved from inf to 0.55998, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/10
 - 25s - loss: 0.6059 - acc: 0.7728 - val_loss: 0.4576 - val_acc: 0.8412

Epoch 00002: val_loss improved from 0.55998 to 0.45755, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/10
 - 25s - loss: 0.5011 - acc: 0.8270 - val_loss: 0.3917 - val_acc: 0.8822

Epoch 00003: val_loss improved from 0.45755 to 0.39172, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/10
 - 25s - loss: 0.4284 - acc: 0.8599 - val_loss: 0.3511 - val_acc: 0.9051

Epoch 00004: val_loss improved from 0.39172 to 0.35107, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/10
 - 25s - loss: 0.3723 - acc: 0.8881 - val_loss: 0.2997 - val_acc: 0.9300

Epoch 00005: val_loss improved from 0.35107 to 0.29968, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/10
 - 25s - loss: 0.3248 - acc: 0.9122 - val_loss: 0.2943 - val_acc: 0.9320

Epoch 00006: val_loss improved from 0.29968 to 0.29428, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/10
 - 25s - loss: 0.2930 - acc: 0.9258 - val_loss: 0.2444 - val_acc: 0.9562

Epoch 00007: val_loss improved from 0.29428 to 0.24443, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/10
 - 25s - loss: 0.2633 - acc: 0.9399 - val_loss: 0.2206 - val_acc: 0.9645

Epoch 00008: val_loss improved from 0.24443 to 0.22061, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 9/10
 - 25s - loss: 0.2432 - acc: 0.9507 - val_loss: 0.2019 - val_acc: 0.9726

Epoch 00009: val_loss improved from 0.22061 to 0.20188, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 10/10
 - 25s - loss: 0.2201 - acc: 0.9602 - val_loss: 0.1860 - val_acc: 0.9775

Epoch 00010: val_loss improved from 0.20188 to 0.18600, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.678
current auc_score ------------------> 0.912
accuracies:  [0.689247311827957, 0.698521505376344, 0.7428763440860215, 0.6920698924731182, 0.6240591397849462, 0.7081989247311828, 0.6823924731182796, 0.7084677419354839, 0.6763440860215054, 0.6782258064516129]
aucs:  [0.9268, 0.8814, 0.9268, 0.8491, 0.8897, 0.9283, 0.8952, 0.9244, 0.8855, 0.9119]
mean and std AUC:  0.902+/-0.025  max:   0.9283
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 28s - loss: 0.6211 - acc: 0.7742 - val_loss: 0.3961 - val_acc: 0.8769

Epoch 00001: val_loss improved from inf to 0.39606, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 24s - loss: 0.3595 - acc: 0.8949 - val_loss: 0.2752 - val_acc: 0.9502

Epoch 00002: val_loss improved from 0.39606 to 0.27519, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2639 - acc: 0.9421 - val_loss: 0.2102 - val_acc: 0.9672

Epoch 00003: val_loss improved from 0.27519 to 0.21023, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2113 - acc: 0.9660 - val_loss: 0.1748 - val_acc: 0.9828

Epoch 00004: val_loss improved from 0.21023 to 0.17483, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1813 - acc: 0.9762 - val_loss: 0.1494 - val_acc: 0.9895

Epoch 00005: val_loss improved from 0.17483 to 0.14937, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1584 - acc: 0.9855 - val_loss: 0.1393 - val_acc: 0.9941

Epoch 00006: val_loss improved from 0.14937 to 0.13931, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1479 - acc: 0.9892 - val_loss: 0.1296 - val_acc: 0.9954

Epoch 00007: val_loss improved from 0.13931 to 0.12956, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 23s - loss: 0.1349 - acc: 0.9934 - val_loss: 0.1205 - val_acc: 0.9970

Epoch 00008: val_loss improved from 0.12956 to 0.12049, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.679
current auc_score ------------------> 0.897
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 27s - loss: 0.6256 - acc: 0.7680 - val_loss: 0.4073 - val_acc: 0.8729

Epoch 00001: val_loss improved from inf to 0.40727, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 24s - loss: 0.3621 - acc: 0.8934 - val_loss: 0.2877 - val_acc: 0.9347

Epoch 00002: val_loss improved from 0.40727 to 0.28767, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2712 - acc: 0.9393 - val_loss: 0.2150 - val_acc: 0.9671

Epoch 00003: val_loss improved from 0.28767 to 0.21495, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2151 - acc: 0.9646 - val_loss: 0.1839 - val_acc: 0.9802

Epoch 00004: val_loss improved from 0.21495 to 0.18392, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1814 - acc: 0.9793 - val_loss: 0.1636 - val_acc: 0.9856

Epoch 00005: val_loss improved from 0.18392 to 0.16363, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1610 - acc: 0.9859 - val_loss: 0.1469 - val_acc: 0.9932

Epoch 00006: val_loss improved from 0.16363 to 0.14693, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1438 - acc: 0.9912 - val_loss: 0.1330 - val_acc: 0.9947

Epoch 00007: val_loss improved from 0.14693 to 0.13297, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 24s - loss: 0.1342 - acc: 0.9942 - val_loss: 0.1213 - val_acc: 0.9980

Epoch 00008: val_loss improved from 0.13297 to 0.12135, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.598
current auc_score ------------------> 0.903
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 28s - loss: 0.6118 - acc: 0.7767 - val_loss: 0.3786 - val_acc: 0.8916

Epoch 00001: val_loss improved from inf to 0.37856, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 24s - loss: 0.3611 - acc: 0.8952 - val_loss: 0.2763 - val_acc: 0.9453

Epoch 00002: val_loss improved from 0.37856 to 0.27625, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2696 - acc: 0.9391 - val_loss: 0.2282 - val_acc: 0.9637

Epoch 00003: val_loss improved from 0.27625 to 0.22822, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2147 - acc: 0.9648 - val_loss: 0.1859 - val_acc: 0.9803

Epoch 00004: val_loss improved from 0.22822 to 0.18585, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1838 - acc: 0.9772 - val_loss: 0.1550 - val_acc: 0.9874

Epoch 00005: val_loss improved from 0.18585 to 0.15497, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1645 - acc: 0.9842 - val_loss: 0.1445 - val_acc: 0.9900

Epoch 00006: val_loss improved from 0.15497 to 0.14451, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1514 - acc: 0.9891 - val_loss: 0.1326 - val_acc: 0.9936

Epoch 00007: val_loss improved from 0.14451 to 0.13261, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 24s - loss: 0.1395 - acc: 0.9922 - val_loss: 0.1224 - val_acc: 0.9971

Epoch 00008: val_loss improved from 0.13261 to 0.12245, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.699
current auc_score ------------------> 0.906
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 27s - loss: 0.6477 - acc: 0.7550 - val_loss: 0.4311 - val_acc: 0.8518

Epoch 00001: val_loss improved from inf to 0.43114, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 24s - loss: 0.3876 - acc: 0.8824 - val_loss: 0.3121 - val_acc: 0.9275

Epoch 00002: val_loss improved from 0.43114 to 0.31206, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2833 - acc: 0.9349 - val_loss: 0.2287 - val_acc: 0.9631

Epoch 00003: val_loss improved from 0.31206 to 0.22868, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2269 - acc: 0.9599 - val_loss: 0.1871 - val_acc: 0.9794

Epoch 00004: val_loss improved from 0.22868 to 0.18713, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1896 - acc: 0.9747 - val_loss: 0.1742 - val_acc: 0.9857

Epoch 00005: val_loss improved from 0.18713 to 0.17421, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1652 - acc: 0.9846 - val_loss: 0.1473 - val_acc: 0.9930

Epoch 00006: val_loss improved from 0.17421 to 0.14727, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 23s - loss: 0.1494 - acc: 0.9887 - val_loss: 0.1332 - val_acc: 0.9944

Epoch 00007: val_loss improved from 0.14727 to 0.13323, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 23s - loss: 0.1400 - acc: 0.9920 - val_loss: 0.1270 - val_acc: 0.9969

Epoch 00008: val_loss improved from 0.13323 to 0.12704, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.638
current auc_score ------------------> 0.871
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 27s - loss: 0.6099 - acc: 0.7780 - val_loss: 0.3778 - val_acc: 0.8844

Epoch 00001: val_loss improved from inf to 0.37777, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 24s - loss: 0.3642 - acc: 0.8929 - val_loss: 0.2778 - val_acc: 0.9409

Epoch 00002: val_loss improved from 0.37777 to 0.27782, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2749 - acc: 0.9381 - val_loss: 0.2148 - val_acc: 0.9706

Epoch 00003: val_loss improved from 0.27782 to 0.21476, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2174 - acc: 0.9632 - val_loss: 0.1745 - val_acc: 0.9849

Epoch 00004: val_loss improved from 0.21476 to 0.17446, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1843 - acc: 0.9764 - val_loss: 0.1542 - val_acc: 0.9896

Epoch 00005: val_loss improved from 0.17446 to 0.15423, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1608 - acc: 0.9859 - val_loss: 0.1394 - val_acc: 0.9932

Epoch 00006: val_loss improved from 0.15423 to 0.13939, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1483 - acc: 0.9895 - val_loss: 0.1278 - val_acc: 0.9955

Epoch 00007: val_loss improved from 0.13939 to 0.12778, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 24s - loss: 0.1360 - acc: 0.9934 - val_loss: 0.1220 - val_acc: 0.9955

Epoch 00008: val_loss improved from 0.12778 to 0.12196, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.668
current auc_score ------------------> 0.917
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 27s - loss: 0.6184 - acc: 0.7740 - val_loss: 0.4065 - val_acc: 0.8647

Epoch 00001: val_loss improved from inf to 0.40646, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 23s - loss: 0.3722 - acc: 0.8907 - val_loss: 0.3008 - val_acc: 0.9331

Epoch 00002: val_loss improved from 0.40646 to 0.30078, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 23s - loss: 0.2770 - acc: 0.9356 - val_loss: 0.2310 - val_acc: 0.9608

Epoch 00003: val_loss improved from 0.30078 to 0.23101, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 23s - loss: 0.2211 - acc: 0.9619 - val_loss: 0.1881 - val_acc: 0.9784

Epoch 00004: val_loss improved from 0.23101 to 0.18811, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 23s - loss: 0.1859 - acc: 0.9767 - val_loss: 0.1598 - val_acc: 0.9862

Epoch 00005: val_loss improved from 0.18811 to 0.15984, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 23s - loss: 0.1638 - acc: 0.9849 - val_loss: 0.1507 - val_acc: 0.9901

Epoch 00006: val_loss improved from 0.15984 to 0.15066, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1465 - acc: 0.9905 - val_loss: 0.1334 - val_acc: 0.9930

Epoch 00007: val_loss improved from 0.15066 to 0.13341, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 24s - loss: 0.1377 - acc: 0.9926 - val_loss: 0.1284 - val_acc: 0.9964

Epoch 00008: val_loss improved from 0.13341 to 0.12836, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.654
current auc_score ------------------> 0.901
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 27s - loss: 0.5834 - acc: 0.7893 - val_loss: 0.3782 - val_acc: 0.8899

Epoch 00001: val_loss improved from inf to 0.37817, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 23s - loss: 0.3519 - acc: 0.9005 - val_loss: 0.2884 - val_acc: 0.9391

Epoch 00002: val_loss improved from 0.37817 to 0.28836, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 23s - loss: 0.2680 - acc: 0.9419 - val_loss: 0.2495 - val_acc: 0.9551

Epoch 00003: val_loss improved from 0.28836 to 0.24954, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2169 - acc: 0.9650 - val_loss: 0.1899 - val_acc: 0.9774

Epoch 00004: val_loss improved from 0.24954 to 0.18991, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1842 - acc: 0.9768 - val_loss: 0.1710 - val_acc: 0.9849

Epoch 00005: val_loss improved from 0.18991 to 0.17096, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1628 - acc: 0.9851 - val_loss: 0.1417 - val_acc: 0.9937

Epoch 00006: val_loss improved from 0.17096 to 0.14171, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1480 - acc: 0.9896 - val_loss: 0.1373 - val_acc: 0.9933

Epoch 00007: val_loss improved from 0.14171 to 0.13727, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 24s - loss: 0.1367 - acc: 0.9936 - val_loss: 0.1276 - val_acc: 0.9955

Epoch 00008: val_loss improved from 0.13727 to 0.12759, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.663
current auc_score ------------------> 0.848
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 27s - loss: 0.5987 - acc: 0.7814 - val_loss: 0.3792 - val_acc: 0.8867

Epoch 00001: val_loss improved from inf to 0.37916, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 24s - loss: 0.3562 - acc: 0.8958 - val_loss: 0.2777 - val_acc: 0.9443

Epoch 00002: val_loss improved from 0.37916 to 0.27774, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2663 - acc: 0.9407 - val_loss: 0.2163 - val_acc: 0.9672

Epoch 00003: val_loss improved from 0.27774 to 0.21634, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2113 - acc: 0.9653 - val_loss: 0.1852 - val_acc: 0.9823

Epoch 00004: val_loss improved from 0.21634 to 0.18516, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 24s - loss: 0.1795 - acc: 0.9784 - val_loss: 0.1562 - val_acc: 0.9885

Epoch 00005: val_loss improved from 0.18516 to 0.15616, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1596 - acc: 0.9861 - val_loss: 0.1463 - val_acc: 0.9921

Epoch 00006: val_loss improved from 0.15616 to 0.14627, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1454 - acc: 0.9904 - val_loss: 0.1296 - val_acc: 0.9946

Epoch 00007: val_loss improved from 0.14627 to 0.12957, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 24s - loss: 0.1368 - acc: 0.9927 - val_loss: 0.1211 - val_acc: 0.9966

Epoch 00008: val_loss improved from 0.12957 to 0.12106, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.696
current auc_score ------------------> 0.875
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 28s - loss: 0.6363 - acc: 0.7615 - val_loss: 0.3910 - val_acc: 0.8766

Epoch 00001: val_loss improved from inf to 0.39096, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 25s - loss: 0.3700 - acc: 0.8894 - val_loss: 0.2727 - val_acc: 0.9419

Epoch 00002: val_loss improved from 0.39096 to 0.27268, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 25s - loss: 0.2769 - acc: 0.9365 - val_loss: 0.2297 - val_acc: 0.9631

Epoch 00003: val_loss improved from 0.27268 to 0.22974, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 25s - loss: 0.2189 - acc: 0.9639 - val_loss: 0.1690 - val_acc: 0.9821

Epoch 00004: val_loss improved from 0.22974 to 0.16902, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 25s - loss: 0.1837 - acc: 0.9773 - val_loss: 0.1508 - val_acc: 0.9892

Epoch 00005: val_loss improved from 0.16902 to 0.15084, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 24s - loss: 0.1632 - acc: 0.9841 - val_loss: 0.1451 - val_acc: 0.9913

Epoch 00006: val_loss improved from 0.15084 to 0.14508, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 24s - loss: 0.1437 - acc: 0.9917 - val_loss: 0.1306 - val_acc: 0.9946

Epoch 00007: val_loss improved from 0.14508 to 0.13056, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 25s - loss: 0.1355 - acc: 0.9927 - val_loss: 0.1243 - val_acc: 0.9954

Epoch 00008: val_loss improved from 0.13056 to 0.12431, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.618
current auc_score ------------------> 0.910
Epochs  8  batch_size:  64  lr:  5e-05  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/8
 - 28s - loss: 0.5986 - acc: 0.7800 - val_loss: 0.4021 - val_acc: 0.8768

Epoch 00001: val_loss improved from inf to 0.40208, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 2/8
 - 25s - loss: 0.3618 - acc: 0.8953 - val_loss: 0.3158 - val_acc: 0.9300

Epoch 00002: val_loss improved from 0.40208 to 0.31580, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 3/8
 - 24s - loss: 0.2752 - acc: 0.9366 - val_loss: 0.2358 - val_acc: 0.9581

Epoch 00003: val_loss improved from 0.31580 to 0.23576, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 4/8
 - 24s - loss: 0.2183 - acc: 0.9634 - val_loss: 0.1819 - val_acc: 0.9800

Epoch 00004: val_loss improved from 0.23576 to 0.18193, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 5/8
 - 25s - loss: 0.1849 - acc: 0.9770 - val_loss: 0.1792 - val_acc: 0.9812

Epoch 00005: val_loss improved from 0.18193 to 0.17918, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 6/8
 - 25s - loss: 0.1628 - acc: 0.9842 - val_loss: 0.1461 - val_acc: 0.9922

Epoch 00006: val_loss improved from 0.17918 to 0.14615, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 7/8
 - 25s - loss: 0.1482 - acc: 0.9897 - val_loss: 0.1314 - val_acc: 0.9937

Epoch 00007: val_loss improved from 0.14615 to 0.13141, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Epoch 8/8
 - 25s - loss: 0.1364 - acc: 0.9927 - val_loss: 0.1296 - val_acc: 0.9960

Epoch 00008: val_loss improved from 0.13141 to 0.12960, saving model to keras_densenet_siamese_27Oct_420_weights.h5
Test accuracy:0.614
current auc_score ------------------> 0.858
accuracies:  [0.6790322580645162, 0.5983870967741935, 0.6986559139784946, 0.6376344086021506, 0.6681451612903225, 0.6538978494623656, 0.6633064516129032, 0.6956989247311828, 0.6176075268817204, 0.6143817204301075]
aucs:  [0.897, 0.9028, 0.906, 0.871, 0.9173, 0.9009, 0.8479, 0.8752, 0.9102, 0.8583]
mean and std AUC:  0.889+/-0.023  max:   0.9173
(['2-2', '30', '2', '16', '0.2', '0.01', '6', 'adam'], '0.842+/-0.026', 0.89)
(['2-2', '30', '2', '16', '0.2', '0.05', '6', 'adam'], '0.873+/-0.026', 0.908)
(['2-2', '30', '2', '16', '0.2', '0.001', '6', 'adam'], '0.868+/-0.042', 0.93)
(['2-2', '30', '2', '16', '0.2', '0.005', '6', 'adam'], '0.862+/-0.027', 0.911)
(['2-2', '30', '2', '16', '0.2', '0.0001', '6', 'adam'], '0.899+/-0.013', 0.932)
(['2-2', '30', '2', '16', '0.2', '0.0005', '6', 'adam'], '0.875+/-0.023', 0.916)
(['2-2', '30', '2', '16', '0.2', '0.00001', '10', 'adam'], '0.902+/-0.025', 0.928)
(['2-2', '30', '2', '16', '0.2', '0.00005', '8', 'adam'], '0.889+/-0.023', 0.917)
python custom_gridsearch_dn_siamese_layers_avg.py
