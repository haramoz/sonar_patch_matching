python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
python custom_gridsearch_dn_siamese_layers.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, pooling
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 26s - loss: 0.5165 - acc: 0.7633 - val_loss: 0.4756 - val_acc: 0.7864
Epoch 2/21
 - 20s - loss: 0.4256 - acc: 0.8163 - val_loss: 0.4423 - val_acc: 0.8052
Epoch 3/21
 - 21s - loss: 0.3845 - acc: 0.8415 - val_loss: 0.3927 - val_acc: 0.8337
Epoch 4/21
 - 20s - loss: 0.3559 - acc: 0.8595 - val_loss: 0.3414 - val_acc: 0.8645
Epoch 5/21
 - 21s - loss: 0.3301 - acc: 0.8741 - val_loss: 0.3045 - val_acc: 0.8847
Epoch 6/21
 - 20s - loss: 0.3094 - acc: 0.8844 - val_loss: 0.4272 - val_acc: 0.8168
Epoch 7/21
 - 20s - loss: 0.2926 - acc: 0.8933 - val_loss: 0.2781 - val_acc: 0.8950
Epoch 8/21
 - 20s - loss: 0.2754 - acc: 0.9034 - val_loss: 0.2546 - val_acc: 0.9115
Epoch 9/21
 - 20s - loss: 0.2601 - acc: 0.9107 - val_loss: 0.2260 - val_acc: 0.9223
Epoch 10/21
 - 20s - loss: 0.2499 - acc: 0.9153 - val_loss: 0.2191 - val_acc: 0.9272
Epoch 11/21
 - 20s - loss: 0.2377 - acc: 0.9210 - val_loss: 0.2892 - val_acc: 0.8893
Epoch 12/21
 - 20s - loss: 0.2275 - acc: 0.9258 - val_loss: 0.2000 - val_acc: 0.9376
Epoch 13/21
 - 20s - loss: 0.2162 - acc: 0.9307 - val_loss: 0.1834 - val_acc: 0.9455
Epoch 14/21
 - 20s - loss: 0.2070 - acc: 0.9351 - val_loss: 0.1998 - val_acc: 0.9380
Epoch 15/21
 - 20s - loss: 0.1950 - acc: 0.9406 - val_loss: 0.1614 - val_acc: 0.9551
Epoch 16/21
 - 20s - loss: 0.1904 - acc: 0.9420 - val_loss: 0.1601 - val_acc: 0.9538
Epoch 17/21
 - 20s - loss: 0.1825 - acc: 0.9457 - val_loss: 0.1896 - val_acc: 0.9405
Epoch 18/21
 - 20s - loss: 0.1740 - acc: 0.9503 - val_loss: 0.1464 - val_acc: 0.9591
Epoch 19/21
 - 20s - loss: 0.1694 - acc: 0.9512 - val_loss: 0.1534 - val_acc: 0.9595
Epoch 20/21
 - 20s - loss: 0.1649 - acc: 0.9520 - val_loss: 0.1482 - val_acc: 0.9570
Epoch 21/21
 - 20s - loss: 0.1564 - acc: 0.9567 - val_loss: 0.1534 - val_acc: 0.9587

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.824
current auc_score ------------------> 0.954
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5297 - acc: 0.7583 - val_loss: 0.8024 - val_acc: 0.6355
Epoch 2/21
 - 21s - loss: 0.4328 - acc: 0.8099 - val_loss: 0.4532 - val_acc: 0.7984
Epoch 3/21
 - 21s - loss: 0.3910 - acc: 0.8358 - val_loss: 0.4974 - val_acc: 0.7649
Epoch 4/21
 - 20s - loss: 0.3610 - acc: 0.8531 - val_loss: 0.3878 - val_acc: 0.8448
Epoch 5/21
 - 21s - loss: 0.3391 - acc: 0.8652 - val_loss: 0.3433 - val_acc: 0.8630
Epoch 6/21
 - 21s - loss: 0.3189 - acc: 0.8769 - val_loss: 0.3050 - val_acc: 0.8881
Epoch 7/21
 - 20s - loss: 0.3009 - acc: 0.8869 - val_loss: 0.3549 - val_acc: 0.8545
Epoch 8/21
 - 20s - loss: 0.2857 - acc: 0.8956 - val_loss: 0.2725 - val_acc: 0.9029
Epoch 9/21
 - 20s - loss: 0.2708 - acc: 0.9030 - val_loss: 0.2593 - val_acc: 0.9090
Epoch 10/21
 - 20s - loss: 0.2571 - acc: 0.9107 - val_loss: 0.2492 - val_acc: 0.9173
Epoch 11/21
 - 20s - loss: 0.2406 - acc: 0.9196 - val_loss: 0.2489 - val_acc: 0.9138
Epoch 12/21
 - 20s - loss: 0.2293 - acc: 0.9244 - val_loss: 0.2121 - val_acc: 0.9296
Epoch 13/21
 - 20s - loss: 0.2205 - acc: 0.9280 - val_loss: 0.1954 - val_acc: 0.9443
Epoch 14/21
 - 20s - loss: 0.2072 - acc: 0.9355 - val_loss: 0.2477 - val_acc: 0.9125
Epoch 15/21
 - 20s - loss: 0.1991 - acc: 0.9374 - val_loss: 0.2135 - val_acc: 0.9253
Epoch 16/21
 - 20s - loss: 0.1898 - acc: 0.9419 - val_loss: 0.1862 - val_acc: 0.9465
Epoch 17/21
 - 20s - loss: 0.1817 - acc: 0.9457 - val_loss: 0.1744 - val_acc: 0.9478
Epoch 18/21
 - 20s - loss: 0.1746 - acc: 0.9495 - val_loss: 0.1983 - val_acc: 0.9346
Epoch 19/21
 - 20s - loss: 0.1692 - acc: 0.9512 - val_loss: 0.1483 - val_acc: 0.9582
Epoch 20/21
 - 20s - loss: 0.1608 - acc: 0.9558 - val_loss: 0.1491 - val_acc: 0.9587
Epoch 21/21
 - 20s - loss: 0.1547 - acc: 0.9575 - val_loss: 0.1859 - val_acc: 0.9425
Test accuracy:0.761
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5307 - acc: 0.7547 - val_loss: 0.6018 - val_acc: 0.7160
Epoch 2/21
 - 21s - loss: 0.4260 - acc: 0.8151 - val_loss: 0.4437 - val_acc: 0.8104
Epoch 3/21
 - 21s - loss: 0.3747 - acc: 0.8502 - val_loss: 0.3998 - val_acc: 0.8268
Epoch 4/21
 - 20s - loss: 0.3416 - acc: 0.8697 - val_loss: 0.3223 - val_acc: 0.8804
Epoch 5/21
 - 20s - loss: 0.3164 - acc: 0.8830 - val_loss: 0.3233 - val_acc: 0.8726
Epoch 6/21
 - 20s - loss: 0.2905 - acc: 0.8953 - val_loss: 0.2991 - val_acc: 0.8860
Epoch 7/21
 - 20s - loss: 0.2732 - acc: 0.9056 - val_loss: 0.2532 - val_acc: 0.9089
Epoch 8/21
 - 20s - loss: 0.2571 - acc: 0.9126 - val_loss: 0.2581 - val_acc: 0.9070
Epoch 9/21
 - 20s - loss: 0.2456 - acc: 0.9178 - val_loss: 0.2200 - val_acc: 0.9260
Epoch 10/21
 - 20s - loss: 0.2334 - acc: 0.9245 - val_loss: 0.2055 - val_acc: 0.9329
Epoch 11/21
 - 20s - loss: 0.2228 - acc: 0.9277 - val_loss: 0.1863 - val_acc: 0.9458
Epoch 12/21
 - 20s - loss: 0.2121 - acc: 0.9337 - val_loss: 0.1986 - val_acc: 0.9360
Epoch 13/21
 - 20s - loss: 0.2049 - acc: 0.9373 - val_loss: 0.1925 - val_acc: 0.9380
Epoch 14/21
 - 20s - loss: 0.1948 - acc: 0.9400 - val_loss: 0.1934 - val_acc: 0.9388

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 20s - loss: 0.1809 - acc: 0.9465 - val_loss: 0.1515 - val_acc: 0.9565
Epoch 16/21
 - 20s - loss: 0.1774 - acc: 0.9497 - val_loss: 0.1435 - val_acc: 0.9627
Epoch 17/21
 - 20s - loss: 0.1742 - acc: 0.9497 - val_loss: 0.1440 - val_acc: 0.9606
Epoch 18/21
 - 20s - loss: 0.1700 - acc: 0.9528 - val_loss: 0.1491 - val_acc: 0.9578
Epoch 19/21
 - 20s - loss: 0.1686 - acc: 0.9519 - val_loss: 0.1416 - val_acc: 0.9615
Epoch 20/21
 - 20s - loss: 0.1657 - acc: 0.9534 - val_loss: 0.1486 - val_acc: 0.9591
Epoch 00020: early stopping
Test accuracy:0.854
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5212 - acc: 0.7649 - val_loss: 0.5116 - val_acc: 0.7587
Epoch 2/21
 - 20s - loss: 0.4218 - acc: 0.8183 - val_loss: 0.4051 - val_acc: 0.8258
Epoch 3/21
 - 20s - loss: 0.3759 - acc: 0.8497 - val_loss: 0.4568 - val_acc: 0.7925
Epoch 4/21
 - 20s - loss: 0.3444 - acc: 0.8664 - val_loss: 0.3096 - val_acc: 0.8852
Epoch 5/21
 - 20s - loss: 0.3187 - acc: 0.8832 - val_loss: 0.3251 - val_acc: 0.8714
Epoch 6/21
 - 20s - loss: 0.2974 - acc: 0.8939 - val_loss: 0.2618 - val_acc: 0.9119
Epoch 7/21
 - 20s - loss: 0.2772 - acc: 0.9034 - val_loss: 0.2903 - val_acc: 0.8950
Epoch 8/21
 - 20s - loss: 0.2611 - acc: 0.9113 - val_loss: 0.2717 - val_acc: 0.8983
Epoch 9/21
 - 20s - loss: 0.2463 - acc: 0.9174 - val_loss: 0.2256 - val_acc: 0.9271
Epoch 10/21
 - 20s - loss: 0.2347 - acc: 0.9232 - val_loss: 0.2337 - val_acc: 0.9216
Epoch 11/21
 - 20s - loss: 0.2233 - acc: 0.9284 - val_loss: 0.2573 - val_acc: 0.9066
Epoch 12/21
 - 20s - loss: 0.2130 - acc: 0.9329 - val_loss: 0.1806 - val_acc: 0.9498
Epoch 13/21
 - 20s - loss: 0.2021 - acc: 0.9376 - val_loss: 0.2039 - val_acc: 0.9360
Epoch 14/21
 - 20s - loss: 0.1967 - acc: 0.9404 - val_loss: 0.2186 - val_acc: 0.9271
Epoch 15/21
 - 20s - loss: 0.1860 - acc: 0.9450 - val_loss: 0.1694 - val_acc: 0.9527
Epoch 16/21
 - 20s - loss: 0.1806 - acc: 0.9475 - val_loss: 0.2045 - val_acc: 0.9345
Epoch 17/21
 - 20s - loss: 0.1723 - acc: 0.9497 - val_loss: 0.2088 - val_acc: 0.9308
Epoch 18/21
 - 20s - loss: 0.1643 - acc: 0.9541 - val_loss: 0.1903 - val_acc: 0.9413

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 20s - loss: 0.1528 - acc: 0.9590 - val_loss: 0.1492 - val_acc: 0.9632
Epoch 20/21
 - 21s - loss: 0.1495 - acc: 0.9612 - val_loss: 0.1432 - val_acc: 0.9655
Epoch 21/21
 - 21s - loss: 0.1475 - acc: 0.9618 - val_loss: 0.1494 - val_acc: 0.9620
Test accuracy:0.810
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5288 - acc: 0.7627 - val_loss: 0.6699 - val_acc: 0.6680
Epoch 2/21
 - 20s - loss: 0.4387 - acc: 0.8088 - val_loss: 0.4862 - val_acc: 0.7662
Epoch 3/21
 - 21s - loss: 0.3962 - acc: 0.8332 - val_loss: 0.5379 - val_acc: 0.7361
Epoch 4/21
 - 21s - loss: 0.3633 - acc: 0.8524 - val_loss: 0.4376 - val_acc: 0.8138
Epoch 5/21
 - 20s - loss: 0.3386 - acc: 0.8679 - val_loss: 0.3833 - val_acc: 0.8420
Epoch 6/21
 - 21s - loss: 0.3168 - acc: 0.8805 - val_loss: 0.4202 - val_acc: 0.8107
Epoch 7/21
 - 21s - loss: 0.2976 - acc: 0.8902 - val_loss: 0.3321 - val_acc: 0.8656
Epoch 8/21
 - 21s - loss: 0.2791 - acc: 0.9009 - val_loss: 0.5668 - val_acc: 0.7722
Epoch 9/21
 - 21s - loss: 0.2670 - acc: 0.9078 - val_loss: 0.2793 - val_acc: 0.8931
Epoch 10/21
 - 21s - loss: 0.2544 - acc: 0.9138 - val_loss: 0.2357 - val_acc: 0.9211
Epoch 11/21
 - 21s - loss: 0.2384 - acc: 0.9198 - val_loss: 0.2467 - val_acc: 0.9157
Epoch 12/21
 - 21s - loss: 0.2301 - acc: 0.9232 - val_loss: 0.2352 - val_acc: 0.9188
Epoch 13/21
 - 21s - loss: 0.2203 - acc: 0.9293 - val_loss: 0.2543 - val_acc: 0.9111
Epoch 14/21
 - 21s - loss: 0.2088 - acc: 0.9335 - val_loss: 0.1848 - val_acc: 0.9450
Epoch 15/21
 - 21s - loss: 0.1999 - acc: 0.9372 - val_loss: 0.2554 - val_acc: 0.9149
Epoch 16/21
 - 21s - loss: 0.1907 - acc: 0.9416 - val_loss: 0.1740 - val_acc: 0.9460
Epoch 17/21
 - 20s - loss: 0.1856 - acc: 0.9455 - val_loss: 0.1588 - val_acc: 0.9531
Epoch 18/21
 - 20s - loss: 0.1782 - acc: 0.9459 - val_loss: 0.2023 - val_acc: 0.9372
Epoch 19/21
 - 21s - loss: 0.1702 - acc: 0.9520 - val_loss: 0.1458 - val_acc: 0.9593
Epoch 20/21
 - 20s - loss: 0.1661 - acc: 0.9525 - val_loss: 0.1498 - val_acc: 0.9546
Epoch 21/21
 - 21s - loss: 0.1591 - acc: 0.9549 - val_loss: 0.1954 - val_acc: 0.9371
Test accuracy:0.791
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5193 - acc: 0.7677 - val_loss: 0.6291 - val_acc: 0.6824
Epoch 2/21
 - 20s - loss: 0.4237 - acc: 0.8176 - val_loss: 0.4162 - val_acc: 0.8205
Epoch 3/21
 - 20s - loss: 0.3842 - acc: 0.8415 - val_loss: 0.3679 - val_acc: 0.8508
Epoch 4/21
 - 20s - loss: 0.3557 - acc: 0.8581 - val_loss: 0.3571 - val_acc: 0.8548
Epoch 5/21
 - 20s - loss: 0.3333 - acc: 0.8711 - val_loss: 0.3216 - val_acc: 0.8796
Epoch 6/21
 - 21s - loss: 0.3106 - acc: 0.8852 - val_loss: 0.3715 - val_acc: 0.8419
Epoch 7/21
 - 21s - loss: 0.2947 - acc: 0.8914 - val_loss: 0.2820 - val_acc: 0.8963
Epoch 8/21
 - 21s - loss: 0.2806 - acc: 0.8991 - val_loss: 0.3271 - val_acc: 0.8648
Epoch 9/21
 - 22s - loss: 0.2664 - acc: 0.9061 - val_loss: 0.2443 - val_acc: 0.9178
Epoch 10/21
 - 21s - loss: 0.2521 - acc: 0.9146 - val_loss: 0.3407 - val_acc: 0.8589
Epoch 11/21
 - 21s - loss: 0.2397 - acc: 0.9203 - val_loss: 0.2019 - val_acc: 0.9380
Epoch 12/21
 - 21s - loss: 0.2278 - acc: 0.9273 - val_loss: 0.2060 - val_acc: 0.9331
Epoch 13/21
 - 21s - loss: 0.2181 - acc: 0.9310 - val_loss: 0.1935 - val_acc: 0.9428
Epoch 14/21
 - 21s - loss: 0.2089 - acc: 0.9350 - val_loss: 0.2842 - val_acc: 0.8921
Epoch 15/21
 - 21s - loss: 0.2002 - acc: 0.9386 - val_loss: 0.1724 - val_acc: 0.9516
Epoch 16/21
 - 21s - loss: 0.1910 - acc: 0.9420 - val_loss: 0.1861 - val_acc: 0.9426
Epoch 17/21
 - 21s - loss: 0.1880 - acc: 0.9432 - val_loss: 0.2394 - val_acc: 0.9178
Epoch 18/21
 - 21s - loss: 0.1789 - acc: 0.9476 - val_loss: 0.1549 - val_acc: 0.9578
Epoch 19/21
 - 21s - loss: 0.1721 - acc: 0.9509 - val_loss: 0.1617 - val_acc: 0.9502
Epoch 20/21
 - 21s - loss: 0.1657 - acc: 0.9531 - val_loss: 0.1575 - val_acc: 0.9536
Epoch 21/21
 - 21s - loss: 0.1580 - acc: 0.9555 - val_loss: 0.1335 - val_acc: 0.9666
Test accuracy:0.792
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5217 - acc: 0.7619 - val_loss: 0.4381 - val_acc: 0.8051
Epoch 2/21
 - 21s - loss: 0.4297 - acc: 0.8163 - val_loss: 0.3863 - val_acc: 0.8353
Epoch 3/21
 - 21s - loss: 0.3864 - acc: 0.8418 - val_loss: 0.3957 - val_acc: 0.8358
Epoch 4/21
 - 21s - loss: 0.3543 - acc: 0.8602 - val_loss: 0.3331 - val_acc: 0.8716
Epoch 5/21
 - 21s - loss: 0.3293 - acc: 0.8756 - val_loss: 0.3168 - val_acc: 0.8756
Epoch 6/21
 - 21s - loss: 0.3097 - acc: 0.8869 - val_loss: 0.2771 - val_acc: 0.8991
Epoch 7/21
 - 21s - loss: 0.2909 - acc: 0.8947 - val_loss: 0.2725 - val_acc: 0.9017
Epoch 8/21
 - 21s - loss: 0.2737 - acc: 0.9052 - val_loss: 0.2457 - val_acc: 0.9140
Epoch 9/21
 - 21s - loss: 0.2593 - acc: 0.9110 - val_loss: 0.2611 - val_acc: 0.9073
Epoch 10/21
 - 21s - loss: 0.2464 - acc: 0.9176 - val_loss: 0.2395 - val_acc: 0.9153
Epoch 11/21
 - 21s - loss: 0.2323 - acc: 0.9247 - val_loss: 0.2023 - val_acc: 0.9342
Epoch 12/21
 - 20s - loss: 0.2220 - acc: 0.9282 - val_loss: 0.2294 - val_acc: 0.9214
Epoch 13/21
 - 20s - loss: 0.2123 - acc: 0.9322 - val_loss: 0.1758 - val_acc: 0.9472
Epoch 14/21
 - 21s - loss: 0.2028 - acc: 0.9377 - val_loss: 0.1835 - val_acc: 0.9410
Epoch 15/21
 - 21s - loss: 0.1959 - acc: 0.9402 - val_loss: 0.2342 - val_acc: 0.9216
Epoch 16/21
 - 21s - loss: 0.1876 - acc: 0.9432 - val_loss: 0.1807 - val_acc: 0.9452

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/21
 - 21s - loss: 0.1731 - acc: 0.9507 - val_loss: 0.1495 - val_acc: 0.9575
Epoch 18/21
 - 21s - loss: 0.1717 - acc: 0.9510 - val_loss: 0.1396 - val_acc: 0.9625
Epoch 19/21
 - 21s - loss: 0.1681 - acc: 0.9526 - val_loss: 0.1398 - val_acc: 0.9612
Epoch 20/21
 - 21s - loss: 0.1669 - acc: 0.9543 - val_loss: 0.1391 - val_acc: 0.9615
Epoch 21/21
 - 21s - loss: 0.1647 - acc: 0.9542 - val_loss: 0.1385 - val_acc: 0.9625
Test accuracy:0.840
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5211 - acc: 0.7621 - val_loss: 0.4641 - val_acc: 0.7922
Epoch 2/21
 - 21s - loss: 0.4252 - acc: 0.8175 - val_loss: 0.3884 - val_acc: 0.8380
Epoch 3/21
 - 21s - loss: 0.3838 - acc: 0.8432 - val_loss: 0.4113 - val_acc: 0.8258
Epoch 4/21
 - 21s - loss: 0.3582 - acc: 0.8569 - val_loss: 0.3201 - val_acc: 0.8804
Epoch 5/21
 - 21s - loss: 0.3323 - acc: 0.8731 - val_loss: 0.2922 - val_acc: 0.8926
Epoch 6/21
 - 21s - loss: 0.3156 - acc: 0.8819 - val_loss: 0.2792 - val_acc: 0.9025
Epoch 7/21
 - 21s - loss: 0.3005 - acc: 0.8896 - val_loss: 0.2659 - val_acc: 0.9059
Epoch 8/21
 - 21s - loss: 0.2866 - acc: 0.8975 - val_loss: 0.2599 - val_acc: 0.9095
Epoch 9/21
 - 21s - loss: 0.2729 - acc: 0.9046 - val_loss: 0.2525 - val_acc: 0.9119
Epoch 10/21
 - 21s - loss: 0.2624 - acc: 0.9082 - val_loss: 0.2445 - val_acc: 0.9153
Epoch 11/21
 - 21s - loss: 0.2511 - acc: 0.9141 - val_loss: 0.2350 - val_acc: 0.9180
Epoch 12/21
 - 20s - loss: 0.2405 - acc: 0.9182 - val_loss: 0.2076 - val_acc: 0.9334
Epoch 13/21
 - 21s - loss: 0.2300 - acc: 0.9236 - val_loss: 0.2224 - val_acc: 0.9295
Epoch 14/21
 - 21s - loss: 0.2204 - acc: 0.9302 - val_loss: 0.1986 - val_acc: 0.9401
Epoch 15/21
 - 21s - loss: 0.2120 - acc: 0.9327 - val_loss: 0.1962 - val_acc: 0.9385
Epoch 16/21
 - 21s - loss: 0.2035 - acc: 0.9381 - val_loss: 0.1985 - val_acc: 0.9336
Epoch 17/21
 - 20s - loss: 0.1953 - acc: 0.9405 - val_loss: 0.1750 - val_acc: 0.9487
Epoch 18/21
 - 21s - loss: 0.1876 - acc: 0.9425 - val_loss: 0.2773 - val_acc: 0.8973
Epoch 19/21
 - 21s - loss: 0.1796 - acc: 0.9461 - val_loss: 0.1987 - val_acc: 0.9357
Epoch 20/21
 - 21s - loss: 0.1760 - acc: 0.9488 - val_loss: 0.1433 - val_acc: 0.9607
Epoch 21/21
 - 21s - loss: 0.1713 - acc: 0.9514 - val_loss: 0.1391 - val_acc: 0.9617
Test accuracy:0.837
current auc_score ------------------> 0.962
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5254 - acc: 0.7609 - val_loss: 0.4845 - val_acc: 0.7831
Epoch 2/21
 - 21s - loss: 0.4321 - acc: 0.8097 - val_loss: 0.4034 - val_acc: 0.8286
Epoch 3/21
 - 20s - loss: 0.3877 - acc: 0.8396 - val_loss: 0.3663 - val_acc: 0.8560
Epoch 4/21
 - 21s - loss: 0.3577 - acc: 0.8556 - val_loss: 0.3298 - val_acc: 0.8760
Epoch 5/21
 - 21s - loss: 0.3324 - acc: 0.8707 - val_loss: 0.3062 - val_acc: 0.8800
Epoch 6/21
 - 21s - loss: 0.3105 - acc: 0.8829 - val_loss: 0.3088 - val_acc: 0.8800
Epoch 7/21
 - 21s - loss: 0.2911 - acc: 0.8946 - val_loss: 0.2792 - val_acc: 0.9012
Epoch 8/21
 - 21s - loss: 0.2740 - acc: 0.9035 - val_loss: 0.3982 - val_acc: 0.8335
Epoch 9/21
 - 21s - loss: 0.2566 - acc: 0.9132 - val_loss: 0.2308 - val_acc: 0.9204
Epoch 10/21
 - 21s - loss: 0.2425 - acc: 0.9193 - val_loss: 0.2897 - val_acc: 0.8896
Epoch 11/21
 - 21s - loss: 0.2279 - acc: 0.9263 - val_loss: 0.2107 - val_acc: 0.9329
Epoch 12/21
 - 21s - loss: 0.2203 - acc: 0.9292 - val_loss: 0.2044 - val_acc: 0.9341
Epoch 13/21
 - 21s - loss: 0.2077 - acc: 0.9338 - val_loss: 0.1987 - val_acc: 0.9384
Epoch 14/21
 - 21s - loss: 0.1990 - acc: 0.9389 - val_loss: 0.1622 - val_acc: 0.9547
Epoch 15/21
 - 21s - loss: 0.1894 - acc: 0.9433 - val_loss: 0.1724 - val_acc: 0.9467
Epoch 16/21
 - 21s - loss: 0.1824 - acc: 0.9474 - val_loss: 0.1771 - val_acc: 0.9483
Epoch 17/21
 - 21s - loss: 0.1748 - acc: 0.9490 - val_loss: 0.1487 - val_acc: 0.9570
Epoch 18/21
 - 21s - loss: 0.1667 - acc: 0.9531 - val_loss: 0.1475 - val_acc: 0.9603
Epoch 19/21
 - 21s - loss: 0.1622 - acc: 0.9549 - val_loss: 0.1547 - val_acc: 0.9585
Epoch 20/21
 - 21s - loss: 0.1526 - acc: 0.9582 - val_loss: 0.1571 - val_acc: 0.9563
Epoch 21/21
 - 21s - loss: 0.1485 - acc: 0.9601 - val_loss: 0.1303 - val_acc: 0.9677
Test accuracy:0.771
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   28620       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     36720       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     44820       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 177,337
Trainable params: 175,397
Non-trainable params: 1,940
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5373 - acc: 0.7588 - val_loss: 0.5794 - val_acc: 0.7072
Epoch 2/21
 - 21s - loss: 0.4364 - acc: 0.8127 - val_loss: 0.4590 - val_acc: 0.7888
Epoch 3/21
 - 21s - loss: 0.3887 - acc: 0.8396 - val_loss: 0.3568 - val_acc: 0.8579
Epoch 4/21
 - 21s - loss: 0.3564 - acc: 0.8582 - val_loss: 0.3933 - val_acc: 0.8338
Epoch 5/21
 - 21s - loss: 0.3324 - acc: 0.8740 - val_loss: 0.2975 - val_acc: 0.8928
Epoch 6/21
 - 21s - loss: 0.3108 - acc: 0.8841 - val_loss: 0.3476 - val_acc: 0.8609
Epoch 7/21
 - 20s - loss: 0.2910 - acc: 0.8953 - val_loss: 0.2991 - val_acc: 0.8953
Epoch 8/21
 - 20s - loss: 0.2746 - acc: 0.9041 - val_loss: 0.2899 - val_acc: 0.8991
Epoch 9/21
 - 20s - loss: 0.2589 - acc: 0.9100 - val_loss: 0.2579 - val_acc: 0.9090
Epoch 10/21
 - 20s - loss: 0.2490 - acc: 0.9141 - val_loss: 0.2988 - val_acc: 0.8908
Epoch 11/21
 - 21s - loss: 0.2370 - acc: 0.9226 - val_loss: 0.2593 - val_acc: 0.9088
Epoch 12/21
 - 21s - loss: 0.2212 - acc: 0.9289 - val_loss: 0.2555 - val_acc: 0.9071
Epoch 13/21
 - 21s - loss: 0.2122 - acc: 0.9329 - val_loss: 0.2150 - val_acc: 0.9308
Epoch 14/21
 - 21s - loss: 0.2040 - acc: 0.9365 - val_loss: 0.1816 - val_acc: 0.9447
Epoch 15/21
 - 21s - loss: 0.1964 - acc: 0.9392 - val_loss: 0.1995 - val_acc: 0.9374
Epoch 16/21
 - 21s - loss: 0.1891 - acc: 0.9433 - val_loss: 0.1643 - val_acc: 0.9529
Epoch 17/21
 - 21s - loss: 0.1805 - acc: 0.9470 - val_loss: 0.1554 - val_acc: 0.9565
Epoch 18/21
 - 21s - loss: 0.1733 - acc: 0.9482 - val_loss: 0.1478 - val_acc: 0.9623
Epoch 19/21
 - 21s - loss: 0.1674 - acc: 0.9534 - val_loss: 0.1476 - val_acc: 0.9612
Epoch 20/21
 - 21s - loss: 0.1609 - acc: 0.9556 - val_loss: 0.1472 - val_acc: 0.9577
Epoch 21/21
 - 21s - loss: 0.1581 - acc: 0.9562 - val_loss: 0.1287 - val_acc: 0.9684
Test accuracy:0.882
current auc_score ------------------> 0.961
Saved model to disk
accuracies:  [0.8244623655913978, 0.7608870967741935, 0.8540322580645161, 0.8099462365591398, 0.7911290322580645, 0.7920698924731183, 0.8399193548387097, 0.8365591397849462, 0.7713709677419355, 0.8819892473118279]
aucs:  [0.9543, 0.9201, 0.934, 0.9385, 0.9339, 0.9448, 0.9464, 0.9615, 0.924, 0.9608]
mean and std AUC:  0.942+/-0.014  max:   0.9615
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.2', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5330 - acc: 0.7488 - val_loss: 0.4602 - val_acc: 0.7853
Epoch 2/21
 - 21s - loss: 0.4279 - acc: 0.8047 - val_loss: 0.4235 - val_acc: 0.8066
Epoch 3/21
 - 21s - loss: 0.3797 - acc: 0.8358 - val_loss: 0.4056 - val_acc: 0.8160
Epoch 4/21
 - 20s - loss: 0.3476 - acc: 0.8558 - val_loss: 0.4216 - val_acc: 0.8184
Epoch 5/21
 - 20s - loss: 0.3212 - acc: 0.8706 - val_loss: 0.3244 - val_acc: 0.8695
Epoch 6/21
 - 20s - loss: 0.3030 - acc: 0.8826 - val_loss: 0.2719 - val_acc: 0.8958
Epoch 7/21
 - 20s - loss: 0.2841 - acc: 0.8930 - val_loss: 0.2506 - val_acc: 0.9037
Epoch 8/21
 - 20s - loss: 0.2698 - acc: 0.9014 - val_loss: 0.2566 - val_acc: 0.9020
Epoch 9/21
 - 20s - loss: 0.2540 - acc: 0.9087 - val_loss: 0.2467 - val_acc: 0.9093
Epoch 10/21
 - 20s - loss: 0.2430 - acc: 0.9127 - val_loss: 0.2193 - val_acc: 0.9239
Epoch 11/21
 - 20s - loss: 0.2319 - acc: 0.9189 - val_loss: 0.2249 - val_acc: 0.9185
Epoch 12/21
 - 20s - loss: 0.2217 - acc: 0.9237 - val_loss: 0.1929 - val_acc: 0.9354
Epoch 13/21
 - 20s - loss: 0.2144 - acc: 0.9281 - val_loss: 0.2202 - val_acc: 0.9203
Epoch 14/21
 - 20s - loss: 0.2047 - acc: 0.9309 - val_loss: 0.1926 - val_acc: 0.9366
Epoch 15/21
 - 20s - loss: 0.1961 - acc: 0.9354 - val_loss: 0.1895 - val_acc: 0.9352
Epoch 16/21
 - 20s - loss: 0.1882 - acc: 0.9402 - val_loss: 0.1839 - val_acc: 0.9365
Epoch 17/21
 - 20s - loss: 0.1802 - acc: 0.9427 - val_loss: 0.1708 - val_acc: 0.9440
Epoch 18/21
 - 20s - loss: 0.1750 - acc: 0.9443 - val_loss: 0.1737 - val_acc: 0.9394
Epoch 19/21
 - 20s - loss: 0.1669 - acc: 0.9482 - val_loss: 0.1531 - val_acc: 0.9512
Epoch 20/21
 - 20s - loss: 0.1628 - acc: 0.9495 - val_loss: 0.1328 - val_acc: 0.9600
Epoch 21/21
 - 20s - loss: 0.1568 - acc: 0.9526 - val_loss: 0.1489 - val_acc: 0.9556
Test accuracy:0.809
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5176 - acc: 0.7596 - val_loss: 0.5674 - val_acc: 0.7402
Epoch 2/21
 - 20s - loss: 0.4138 - acc: 0.8151 - val_loss: 0.5299 - val_acc: 0.7539
Epoch 3/21
 - 21s - loss: 0.3708 - acc: 0.8410 - val_loss: 0.3601 - val_acc: 0.8409
Epoch 4/21
 - 20s - loss: 0.3450 - acc: 0.8570 - val_loss: 0.3475 - val_acc: 0.8547
Epoch 5/21
 - 21s - loss: 0.3196 - acc: 0.8712 - val_loss: 0.3442 - val_acc: 0.8602
Epoch 6/21
 - 21s - loss: 0.3014 - acc: 0.8824 - val_loss: 0.3710 - val_acc: 0.8483
Epoch 7/21
 - 20s - loss: 0.2851 - acc: 0.8895 - val_loss: 0.2921 - val_acc: 0.8850
Epoch 8/21
 - 21s - loss: 0.2717 - acc: 0.8977 - val_loss: 0.2541 - val_acc: 0.9044
Epoch 9/21
 - 20s - loss: 0.2555 - acc: 0.9073 - val_loss: 0.2494 - val_acc: 0.9096
Epoch 10/21
 - 20s - loss: 0.2413 - acc: 0.9153 - val_loss: 0.2548 - val_acc: 0.9026
Epoch 11/21
 - 20s - loss: 0.2335 - acc: 0.9166 - val_loss: 0.2656 - val_acc: 0.9000
Epoch 12/21
 - 21s - loss: 0.2232 - acc: 0.9217 - val_loss: 0.2799 - val_acc: 0.8950

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 21s - loss: 0.2077 - acc: 0.9297 - val_loss: 0.1912 - val_acc: 0.9342
Epoch 14/21
 - 21s - loss: 0.2051 - acc: 0.9317 - val_loss: 0.1918 - val_acc: 0.9352
Epoch 15/21
 - 20s - loss: 0.1995 - acc: 0.9348 - val_loss: 0.1960 - val_acc: 0.9321
Epoch 16/21
 - 20s - loss: 0.1980 - acc: 0.9355 - val_loss: 0.1985 - val_acc: 0.9291

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 17/21
 - 20s - loss: 0.1947 - acc: 0.9361 - val_loss: 0.2048 - val_acc: 0.9270
Epoch 18/21
 - 20s - loss: 0.1934 - acc: 0.9359 - val_loss: 0.1930 - val_acc: 0.9339
Epoch 00018: early stopping
Test accuracy:0.802
current auc_score ------------------> 0.937
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5033 - acc: 0.7684 - val_loss: 0.6359 - val_acc: 0.6870
Epoch 2/21
 - 21s - loss: 0.4190 - acc: 0.8103 - val_loss: 0.4125 - val_acc: 0.8081
Epoch 3/21
 - 21s - loss: 0.3788 - acc: 0.8365 - val_loss: 0.3928 - val_acc: 0.8225
Epoch 4/21
 - 21s - loss: 0.3510 - acc: 0.8563 - val_loss: 0.4582 - val_acc: 0.7923
Epoch 5/21
 - 21s - loss: 0.3275 - acc: 0.8695 - val_loss: 0.3656 - val_acc: 0.8494
Epoch 6/21
 - 20s - loss: 0.3103 - acc: 0.8781 - val_loss: 0.3068 - val_acc: 0.8739
Epoch 7/21
 - 20s - loss: 0.2929 - acc: 0.8880 - val_loss: 0.2831 - val_acc: 0.8881
Epoch 8/21
 - 20s - loss: 0.2779 - acc: 0.8950 - val_loss: 0.2945 - val_acc: 0.8803
Epoch 9/21
 - 20s - loss: 0.2646 - acc: 0.9025 - val_loss: 0.2607 - val_acc: 0.9045
Epoch 10/21
 - 20s - loss: 0.2518 - acc: 0.9093 - val_loss: 0.2426 - val_acc: 0.9119
Epoch 11/21
 - 20s - loss: 0.2404 - acc: 0.9151 - val_loss: 0.2089 - val_acc: 0.9266
Epoch 12/21
 - 20s - loss: 0.2267 - acc: 0.9204 - val_loss: 0.1993 - val_acc: 0.9298
Epoch 13/21
 - 20s - loss: 0.2172 - acc: 0.9255 - val_loss: 0.2006 - val_acc: 0.9322
Epoch 14/21
 - 21s - loss: 0.2062 - acc: 0.9311 - val_loss: 0.2133 - val_acc: 0.9255
Epoch 15/21
 - 21s - loss: 0.2001 - acc: 0.9335 - val_loss: 0.1677 - val_acc: 0.9490
Epoch 16/21
 - 20s - loss: 0.1924 - acc: 0.9362 - val_loss: 0.1703 - val_acc: 0.9449
Epoch 17/21
 - 21s - loss: 0.1829 - acc: 0.9412 - val_loss: 0.1727 - val_acc: 0.9408
Epoch 18/21
 - 21s - loss: 0.1762 - acc: 0.9440 - val_loss: 0.1468 - val_acc: 0.9566
Epoch 19/21
 - 21s - loss: 0.1694 - acc: 0.9477 - val_loss: 0.1746 - val_acc: 0.9415
Epoch 20/21
 - 20s - loss: 0.1631 - acc: 0.9500 - val_loss: 0.1740 - val_acc: 0.9425
Epoch 21/21
 - 21s - loss: 0.1567 - acc: 0.9529 - val_loss: 0.1299 - val_acc: 0.9621
Test accuracy:0.847
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5249 - acc: 0.7548 - val_loss: 0.5581 - val_acc: 0.7426
Epoch 2/21
 - 20s - loss: 0.4101 - acc: 0.8187 - val_loss: 0.4903 - val_acc: 0.7725
Epoch 3/21
 - 20s - loss: 0.3715 - acc: 0.8438 - val_loss: 0.4606 - val_acc: 0.7935
Epoch 4/21
 - 20s - loss: 0.3428 - acc: 0.8597 - val_loss: 0.3758 - val_acc: 0.8322
Epoch 5/21
 - 21s - loss: 0.3193 - acc: 0.8745 - val_loss: 0.3112 - val_acc: 0.8760
Epoch 6/21
 - 20s - loss: 0.2987 - acc: 0.8848 - val_loss: 0.3217 - val_acc: 0.8759
Epoch 7/21
 - 20s - loss: 0.2827 - acc: 0.8934 - val_loss: 0.2860 - val_acc: 0.8922
Epoch 8/21
 - 20s - loss: 0.2655 - acc: 0.9026 - val_loss: 0.3183 - val_acc: 0.8662
Epoch 9/21
 - 20s - loss: 0.2506 - acc: 0.9107 - val_loss: 0.2196 - val_acc: 0.9222
Epoch 10/21
 - 20s - loss: 0.2382 - acc: 0.9167 - val_loss: 0.2465 - val_acc: 0.9124
Epoch 11/21
 - 20s - loss: 0.2267 - acc: 0.9218 - val_loss: 0.2043 - val_acc: 0.9337
Epoch 12/21
 - 20s - loss: 0.2140 - acc: 0.9287 - val_loss: 0.2085 - val_acc: 0.9303
Epoch 13/21
 - 21s - loss: 0.2066 - acc: 0.9305 - val_loss: 0.2105 - val_acc: 0.9303
Epoch 14/21
 - 20s - loss: 0.1978 - acc: 0.9341 - val_loss: 0.1778 - val_acc: 0.9426
Epoch 15/21
 - 20s - loss: 0.1899 - acc: 0.9385 - val_loss: 0.1657 - val_acc: 0.9474
Epoch 16/21
 - 21s - loss: 0.1801 - acc: 0.9428 - val_loss: 0.1502 - val_acc: 0.9551
Epoch 17/21
 - 20s - loss: 0.1741 - acc: 0.9457 - val_loss: 0.1554 - val_acc: 0.9516
Epoch 18/21
 - 21s - loss: 0.1658 - acc: 0.9487 - val_loss: 0.2136 - val_acc: 0.9291
Epoch 19/21
 - 21s - loss: 0.1606 - acc: 0.9508 - val_loss: 0.1482 - val_acc: 0.9522
Epoch 20/21
 - 20s - loss: 0.1589 - acc: 0.9524 - val_loss: 0.1313 - val_acc: 0.9625
Epoch 21/21
 - 20s - loss: 0.1508 - acc: 0.9546 - val_loss: 0.1257 - val_acc: 0.9646
Test accuracy:0.856
current auc_score ------------------> 0.942
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5088 - acc: 0.7638 - val_loss: 0.5786 - val_acc: 0.7142
Epoch 2/21
 - 21s - loss: 0.4155 - acc: 0.8133 - val_loss: 0.4004 - val_acc: 0.8264
Epoch 3/21
 - 20s - loss: 0.3787 - acc: 0.8386 - val_loss: 0.3803 - val_acc: 0.8307
Epoch 4/21
 - 21s - loss: 0.3486 - acc: 0.8568 - val_loss: 0.3892 - val_acc: 0.8352
Epoch 5/21
 - 20s - loss: 0.3268 - acc: 0.8690 - val_loss: 0.2920 - val_acc: 0.8916
Epoch 6/21
 - 21s - loss: 0.3066 - acc: 0.8791 - val_loss: 0.3234 - val_acc: 0.8719
Epoch 7/21
 - 20s - loss: 0.2891 - acc: 0.8901 - val_loss: 0.2957 - val_acc: 0.8881
Epoch 8/21
 - 20s - loss: 0.2728 - acc: 0.8993 - val_loss: 0.2626 - val_acc: 0.9019
Epoch 9/21
 - 20s - loss: 0.2608 - acc: 0.9048 - val_loss: 0.2688 - val_acc: 0.9017
Epoch 10/21
 - 20s - loss: 0.2458 - acc: 0.9133 - val_loss: 0.2564 - val_acc: 0.9059
Epoch 11/21
 - 20s - loss: 0.2378 - acc: 0.9155 - val_loss: 0.2225 - val_acc: 0.9173
Epoch 12/21
 - 21s - loss: 0.2224 - acc: 0.9239 - val_loss: 0.2475 - val_acc: 0.9164
Epoch 13/21
 - 20s - loss: 0.2144 - acc: 0.9278 - val_loss: 0.2901 - val_acc: 0.8911
Epoch 14/21
 - 20s - loss: 0.2067 - acc: 0.9321 - val_loss: 0.2082 - val_acc: 0.9297
Epoch 15/21
 - 20s - loss: 0.1997 - acc: 0.9338 - val_loss: 0.2005 - val_acc: 0.9329
Epoch 16/21
 - 20s - loss: 0.1932 - acc: 0.9371 - val_loss: 0.2184 - val_acc: 0.9238
Epoch 17/21
 - 20s - loss: 0.1836 - acc: 0.9420 - val_loss: 0.1648 - val_acc: 0.9462
Epoch 18/21
 - 20s - loss: 0.1808 - acc: 0.9427 - val_loss: 0.1936 - val_acc: 0.9320
Epoch 19/21
 - 20s - loss: 0.1722 - acc: 0.9464 - val_loss: 0.1572 - val_acc: 0.9508
Epoch 20/21
 - 20s - loss: 0.1661 - acc: 0.9500 - val_loss: 0.1681 - val_acc: 0.9464
Epoch 21/21
 - 21s - loss: 0.1628 - acc: 0.9492 - val_loss: 0.1738 - val_acc: 0.9443
Test accuracy:0.828
current auc_score ------------------> 0.899
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5146 - acc: 0.7670 - val_loss: 0.4770 - val_acc: 0.7669
Epoch 2/21
 - 21s - loss: 0.4165 - acc: 0.8146 - val_loss: 0.4792 - val_acc: 0.7791
Epoch 3/21
 - 20s - loss: 0.3738 - acc: 0.8407 - val_loss: 0.3463 - val_acc: 0.8493
Epoch 4/21
 - 21s - loss: 0.3470 - acc: 0.8573 - val_loss: 0.3342 - val_acc: 0.8637
Epoch 5/21
 - 21s - loss: 0.3240 - acc: 0.8720 - val_loss: 0.3333 - val_acc: 0.8608
Epoch 6/21
 - 21s - loss: 0.3064 - acc: 0.8782 - val_loss: 0.2859 - val_acc: 0.8904
Epoch 7/21
 - 21s - loss: 0.2899 - acc: 0.8889 - val_loss: 0.3561 - val_acc: 0.8545
Epoch 8/21
 - 21s - loss: 0.2739 - acc: 0.8982 - val_loss: 0.2926 - val_acc: 0.8845
Epoch 9/21
 - 21s - loss: 0.2591 - acc: 0.9050 - val_loss: 0.2392 - val_acc: 0.9140
Epoch 10/21
 - 20s - loss: 0.2504 - acc: 0.9084 - val_loss: 0.3186 - val_acc: 0.8724
Epoch 11/21
 - 20s - loss: 0.2379 - acc: 0.9170 - val_loss: 0.2248 - val_acc: 0.9193
Epoch 12/21
 - 20s - loss: 0.2270 - acc: 0.9199 - val_loss: 0.2135 - val_acc: 0.9247
Epoch 13/21
 - 20s - loss: 0.2189 - acc: 0.9252 - val_loss: 0.2500 - val_acc: 0.9109
Epoch 14/21
 - 21s - loss: 0.2099 - acc: 0.9289 - val_loss: 0.1952 - val_acc: 0.9359
Epoch 15/21
 - 21s - loss: 0.2032 - acc: 0.9310 - val_loss: 0.2088 - val_acc: 0.9281
Epoch 16/21
 - 21s - loss: 0.1950 - acc: 0.9361 - val_loss: 0.2113 - val_acc: 0.9281
Epoch 17/21
 - 21s - loss: 0.1856 - acc: 0.9399 - val_loss: 0.1532 - val_acc: 0.9544
Epoch 18/21
 - 20s - loss: 0.1814 - acc: 0.9418 - val_loss: 0.1523 - val_acc: 0.9590
Epoch 19/21
 - 21s - loss: 0.1743 - acc: 0.9438 - val_loss: 0.1543 - val_acc: 0.9533
Epoch 20/21
 - 20s - loss: 0.1671 - acc: 0.9482 - val_loss: 0.1410 - val_acc: 0.9596
Epoch 21/21
 - 20s - loss: 0.1629 - acc: 0.9494 - val_loss: 0.1551 - val_acc: 0.9504
Test accuracy:0.833
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5171 - acc: 0.7591 - val_loss: 0.4413 - val_acc: 0.7972
Epoch 2/21
 - 21s - loss: 0.4141 - acc: 0.8174 - val_loss: 0.3896 - val_acc: 0.8333
Epoch 3/21
 - 21s - loss: 0.3683 - acc: 0.8459 - val_loss: 0.3412 - val_acc: 0.8601
Epoch 4/21
 - 21s - loss: 0.3403 - acc: 0.8620 - val_loss: 0.3075 - val_acc: 0.8789
Epoch 5/21
 - 21s - loss: 0.3158 - acc: 0.8769 - val_loss: 0.2844 - val_acc: 0.8872
Epoch 6/21
 - 21s - loss: 0.2967 - acc: 0.8849 - val_loss: 0.2651 - val_acc: 0.8993
Epoch 7/21
 - 20s - loss: 0.2784 - acc: 0.8965 - val_loss: 0.3205 - val_acc: 0.8805
Epoch 8/21
 - 21s - loss: 0.2653 - acc: 0.9019 - val_loss: 0.2669 - val_acc: 0.8990
Epoch 9/21
 - 20s - loss: 0.2538 - acc: 0.9096 - val_loss: 0.2888 - val_acc: 0.8834

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 20s - loss: 0.2372 - acc: 0.9172 - val_loss: 0.2161 - val_acc: 0.9238
Epoch 11/21
 - 20s - loss: 0.2327 - acc: 0.9192 - val_loss: 0.2060 - val_acc: 0.9307
Epoch 12/21
 - 20s - loss: 0.2331 - acc: 0.9194 - val_loss: 0.2014 - val_acc: 0.9300
Epoch 13/21
 - 20s - loss: 0.2242 - acc: 0.9230 - val_loss: 0.2053 - val_acc: 0.9287
Epoch 14/21
 - 20s - loss: 0.2214 - acc: 0.9230 - val_loss: 0.2080 - val_acc: 0.9251
Epoch 15/21
 - 20s - loss: 0.2212 - acc: 0.9242 - val_loss: 0.1997 - val_acc: 0.9312
Epoch 16/21
 - 21s - loss: 0.2151 - acc: 0.9262 - val_loss: 0.1917 - val_acc: 0.9362
Epoch 17/21
 - 20s - loss: 0.2124 - acc: 0.9289 - val_loss: 0.2157 - val_acc: 0.9197
Epoch 18/21
 - 21s - loss: 0.2098 - acc: 0.9310 - val_loss: 0.1868 - val_acc: 0.9376
Epoch 19/21
 - 20s - loss: 0.2068 - acc: 0.9321 - val_loss: 0.1900 - val_acc: 0.9354
Epoch 20/21
 - 21s - loss: 0.2051 - acc: 0.9313 - val_loss: 0.1754 - val_acc: 0.9430
Epoch 21/21
 - 20s - loss: 0.2024 - acc: 0.9328 - val_loss: 0.1945 - val_acc: 0.9314
Test accuracy:0.812
current auc_score ------------------> 0.932
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5081 - acc: 0.7693 - val_loss: 0.5956 - val_acc: 0.6942
Epoch 2/21
 - 20s - loss: 0.4191 - acc: 0.8137 - val_loss: 0.3991 - val_acc: 0.8208
Epoch 3/21
 - 21s - loss: 0.3777 - acc: 0.8396 - val_loss: 0.3868 - val_acc: 0.8312
Epoch 4/21
 - 20s - loss: 0.3480 - acc: 0.8566 - val_loss: 0.3405 - val_acc: 0.8613
Epoch 5/21
 - 20s - loss: 0.3237 - acc: 0.8715 - val_loss: 0.3047 - val_acc: 0.8780
Epoch 6/21
 - 20s - loss: 0.3048 - acc: 0.8817 - val_loss: 0.3015 - val_acc: 0.8824
Epoch 7/21
 - 21s - loss: 0.2825 - acc: 0.8953 - val_loss: 0.3020 - val_acc: 0.8834
Epoch 8/21
 - 20s - loss: 0.2701 - acc: 0.9018 - val_loss: 0.2749 - val_acc: 0.8958
Epoch 9/21
 - 21s - loss: 0.2560 - acc: 0.9089 - val_loss: 0.3622 - val_acc: 0.8504
Epoch 10/21
 - 21s - loss: 0.2435 - acc: 0.9141 - val_loss: 0.3195 - val_acc: 0.8763
Epoch 11/21
 - 21s - loss: 0.2316 - acc: 0.9195 - val_loss: 0.2414 - val_acc: 0.9108
Epoch 12/21
 - 21s - loss: 0.2191 - acc: 0.9252 - val_loss: 0.2488 - val_acc: 0.9109
Epoch 13/21
 - 21s - loss: 0.2103 - acc: 0.9293 - val_loss: 0.2127 - val_acc: 0.9339
Epoch 14/21
 - 21s - loss: 0.2008 - acc: 0.9345 - val_loss: 0.2212 - val_acc: 0.9229
Epoch 15/21
 - 21s - loss: 0.1929 - acc: 0.9353 - val_loss: 0.3674 - val_acc: 0.8464
Epoch 16/21
 - 21s - loss: 0.1854 - acc: 0.9404 - val_loss: 0.1769 - val_acc: 0.9474
Epoch 17/21
 - 21s - loss: 0.1786 - acc: 0.9430 - val_loss: 0.3651 - val_acc: 0.8584
Epoch 18/21
 - 21s - loss: 0.1719 - acc: 0.9467 - val_loss: 0.1364 - val_acc: 0.9635
Epoch 19/21
 - 21s - loss: 0.1652 - acc: 0.9489 - val_loss: 0.1659 - val_acc: 0.9457
Epoch 20/21
 - 21s - loss: 0.1581 - acc: 0.9522 - val_loss: 0.1430 - val_acc: 0.9617
Epoch 21/21
 - 21s - loss: 0.1535 - acc: 0.9538 - val_loss: 0.1890 - val_acc: 0.9345

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.745
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5143 - acc: 0.7629 - val_loss: 0.6026 - val_acc: 0.7218
Epoch 2/21
 - 21s - loss: 0.4150 - acc: 0.8157 - val_loss: 0.3820 - val_acc: 0.8350
Epoch 3/21
 - 21s - loss: 0.3746 - acc: 0.8398 - val_loss: 0.3571 - val_acc: 0.8444
Epoch 4/21
 - 21s - loss: 0.3446 - acc: 0.8589 - val_loss: 0.3175 - val_acc: 0.8663
Epoch 5/21
 - 21s - loss: 0.3200 - acc: 0.8728 - val_loss: 0.2991 - val_acc: 0.8794
Epoch 6/21
 - 21s - loss: 0.3007 - acc: 0.8839 - val_loss: 0.2764 - val_acc: 0.8917
Epoch 7/21
 - 20s - loss: 0.2810 - acc: 0.8951 - val_loss: 0.2655 - val_acc: 0.9019
Epoch 8/21
 - 21s - loss: 0.2700 - acc: 0.9003 - val_loss: 0.2524 - val_acc: 0.9089
Epoch 9/21
 - 20s - loss: 0.2534 - acc: 0.9104 - val_loss: 0.2303 - val_acc: 0.9192
Epoch 10/21
 - 20s - loss: 0.2447 - acc: 0.9133 - val_loss: 0.2171 - val_acc: 0.9229
Epoch 11/21
 - 21s - loss: 0.2321 - acc: 0.9193 - val_loss: 0.2097 - val_acc: 0.9300
Epoch 12/21
 - 21s - loss: 0.2225 - acc: 0.9229 - val_loss: 0.2170 - val_acc: 0.9249
Epoch 13/21
 - 20s - loss: 0.2129 - acc: 0.9285 - val_loss: 0.2127 - val_acc: 0.9262
Epoch 14/21
 - 21s - loss: 0.2044 - acc: 0.9315 - val_loss: 0.1821 - val_acc: 0.9393
Epoch 15/21
 - 21s - loss: 0.1978 - acc: 0.9352 - val_loss: 0.2195 - val_acc: 0.9237
Epoch 16/21
 - 21s - loss: 0.1888 - acc: 0.9371 - val_loss: 0.1606 - val_acc: 0.9497
Epoch 17/21
 - 21s - loss: 0.1822 - acc: 0.9419 - val_loss: 0.1802 - val_acc: 0.9389
Epoch 18/21
 - 21s - loss: 0.1760 - acc: 0.9440 - val_loss: 0.1645 - val_acc: 0.9482
Epoch 19/21
 - 21s - loss: 0.1690 - acc: 0.9476 - val_loss: 0.1539 - val_acc: 0.9504
Epoch 20/21
 - 21s - loss: 0.1648 - acc: 0.9482 - val_loss: 0.1466 - val_acc: 0.9523
Epoch 21/21
 - 21s - loss: 0.1611 - acc: 0.9507 - val_loss: 0.1537 - val_acc: 0.9511
Test accuracy:0.845
current auc_score ------------------> 0.925
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16200       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24300       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     25920       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     34020       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 138,193
Trainable params: 136,589
Non-trainable params: 1,604
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5100 - acc: 0.7668 - val_loss: 0.4341 - val_acc: 0.7977
Epoch 2/21
 - 21s - loss: 0.4190 - acc: 0.8126 - val_loss: 0.3910 - val_acc: 0.8215
Epoch 3/21
 - 21s - loss: 0.3812 - acc: 0.8337 - val_loss: 0.3736 - val_acc: 0.8384
Epoch 4/21
 - 21s - loss: 0.3524 - acc: 0.8534 - val_loss: 0.3266 - val_acc: 0.8608
Epoch 5/21
 - 21s - loss: 0.3286 - acc: 0.8678 - val_loss: 0.4044 - val_acc: 0.8312
Epoch 6/21
 - 21s - loss: 0.3091 - acc: 0.8795 - val_loss: 0.3033 - val_acc: 0.8766
Epoch 7/21
 - 21s - loss: 0.2886 - acc: 0.8913 - val_loss: 0.2609 - val_acc: 0.9034
Epoch 8/21
 - 20s - loss: 0.2707 - acc: 0.8998 - val_loss: 0.2697 - val_acc: 0.8950
Epoch 9/21
 - 21s - loss: 0.2555 - acc: 0.9074 - val_loss: 0.2379 - val_acc: 0.9137
Epoch 10/21
 - 21s - loss: 0.2428 - acc: 0.9147 - val_loss: 0.2239 - val_acc: 0.9218
Epoch 11/21
 - 21s - loss: 0.2343 - acc: 0.9181 - val_loss: 0.2619 - val_acc: 0.9012
Epoch 12/21
 - 21s - loss: 0.2214 - acc: 0.9242 - val_loss: 0.2360 - val_acc: 0.9139
Epoch 13/21
 - 20s - loss: 0.2118 - acc: 0.9276 - val_loss: 0.2724 - val_acc: 0.8965

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/21
 - 20s - loss: 0.1985 - acc: 0.9353 - val_loss: 0.1737 - val_acc: 0.9424
Epoch 15/21
 - 21s - loss: 0.1967 - acc: 0.9351 - val_loss: 0.1790 - val_acc: 0.9384
Epoch 16/21
 - 21s - loss: 0.1917 - acc: 0.9372 - val_loss: 0.1761 - val_acc: 0.9408
Epoch 17/21
 - 21s - loss: 0.1848 - acc: 0.9408 - val_loss: 0.1771 - val_acc: 0.9416

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 18/21
 - 20s - loss: 0.1833 - acc: 0.9422 - val_loss: 0.1720 - val_acc: 0.9419
Epoch 00018: early stopping
Test accuracy:0.855
current auc_score ------------------> 0.937
accuracies:  [0.8094086021505377, 0.8016129032258065, 0.8466397849462366, 0.8564516129032258, 0.8276881720430107, 0.8330645161290322, 0.8120967741935484, 0.7448924731182796, 0.8454301075268817, 0.8548387096774194]
aucs:  [0.9225, 0.9366, 0.9341, 0.9419, 0.8995, 0.92, 0.9324, 0.939, 0.9251, 0.937]
mean and std AUC:  0.929+/-0.012  max:   0.9419
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.3', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5045 - acc: 0.7655 - val_loss: 0.4939 - val_acc: 0.7762
Epoch 2/21
 - 20s - loss: 0.4139 - acc: 0.8136 - val_loss: 0.3954 - val_acc: 0.8235
Epoch 3/21
 - 20s - loss: 0.3702 - acc: 0.8377 - val_loss: 0.4555 - val_acc: 0.7873
Epoch 4/21
 - 20s - loss: 0.3398 - acc: 0.8574 - val_loss: 0.4758 - val_acc: 0.7873
Epoch 5/21
 - 20s - loss: 0.3146 - acc: 0.8741 - val_loss: 0.3602 - val_acc: 0.8445
Epoch 6/21
 - 20s - loss: 0.2991 - acc: 0.8831 - val_loss: 0.3342 - val_acc: 0.8571
Epoch 7/21
 - 20s - loss: 0.2784 - acc: 0.8928 - val_loss: 0.3624 - val_acc: 0.8478
Epoch 8/21
 - 20s - loss: 0.2655 - acc: 0.9006 - val_loss: 0.2546 - val_acc: 0.9012
Epoch 9/21
 - 20s - loss: 0.2534 - acc: 0.9079 - val_loss: 0.2519 - val_acc: 0.9021
Epoch 10/21
 - 20s - loss: 0.2422 - acc: 0.9120 - val_loss: 0.2955 - val_acc: 0.8808
Epoch 11/21
 - 20s - loss: 0.2285 - acc: 0.9179 - val_loss: 0.2432 - val_acc: 0.9029
Epoch 12/21
 - 20s - loss: 0.2205 - acc: 0.9228 - val_loss: 0.2016 - val_acc: 0.9295
Epoch 13/21
 - 20s - loss: 0.2135 - acc: 0.9260 - val_loss: 0.2380 - val_acc: 0.9100
Epoch 14/21
 - 20s - loss: 0.1996 - acc: 0.9325 - val_loss: 0.2626 - val_acc: 0.8995
Epoch 15/21
 - 20s - loss: 0.1928 - acc: 0.9355 - val_loss: 0.2543 - val_acc: 0.9007

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/21
 - 20s - loss: 0.1835 - acc: 0.9408 - val_loss: 0.1824 - val_acc: 0.9400
Epoch 17/21
 - 20s - loss: 0.1800 - acc: 0.9417 - val_loss: 0.1640 - val_acc: 0.9477
Epoch 18/21
 - 20s - loss: 0.1768 - acc: 0.9417 - val_loss: 0.1890 - val_acc: 0.9357
Epoch 19/21
 - 20s - loss: 0.1730 - acc: 0.9442 - val_loss: 0.1580 - val_acc: 0.9529
Epoch 20/21
 - 20s - loss: 0.1742 - acc: 0.9441 - val_loss: 0.1805 - val_acc: 0.9396
Epoch 21/21
 - 20s - loss: 0.1713 - acc: 0.9453 - val_loss: 0.1623 - val_acc: 0.9480
Test accuracy:0.803
current auc_score ------------------> 0.903
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5056 - acc: 0.7645 - val_loss: 0.4429 - val_acc: 0.7913
Epoch 2/21
 - 20s - loss: 0.4108 - acc: 0.8148 - val_loss: 0.4111 - val_acc: 0.8173
Epoch 3/21
 - 20s - loss: 0.3714 - acc: 0.8390 - val_loss: 0.3535 - val_acc: 0.8454
Epoch 4/21
 - 20s - loss: 0.3442 - acc: 0.8544 - val_loss: 0.3187 - val_acc: 0.8666
Epoch 5/21
 - 20s - loss: 0.3246 - acc: 0.8676 - val_loss: 0.3230 - val_acc: 0.8651
Epoch 6/21
 - 20s - loss: 0.3056 - acc: 0.8766 - val_loss: 0.3754 - val_acc: 0.8466
Epoch 7/21
 - 20s - loss: 0.2886 - acc: 0.8876 - val_loss: 0.2542 - val_acc: 0.9034
Epoch 8/21
 - 20s - loss: 0.2728 - acc: 0.8958 - val_loss: 0.2970 - val_acc: 0.8843
Epoch 9/21
 - 20s - loss: 0.2592 - acc: 0.9023 - val_loss: 0.2465 - val_acc: 0.9096
Epoch 10/21
 - 20s - loss: 0.2464 - acc: 0.9089 - val_loss: 0.2728 - val_acc: 0.8957
Epoch 11/21
 - 20s - loss: 0.2343 - acc: 0.9153 - val_loss: 0.2970 - val_acc: 0.8850
Epoch 12/21
 - 20s - loss: 0.2259 - acc: 0.9166 - val_loss: 0.2587 - val_acc: 0.9026

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 20s - loss: 0.2131 - acc: 0.9259 - val_loss: 0.2048 - val_acc: 0.9288
Epoch 14/21
 - 20s - loss: 0.2075 - acc: 0.9289 - val_loss: 0.2194 - val_acc: 0.9206
Epoch 15/21
 - 20s - loss: 0.2074 - acc: 0.9275 - val_loss: 0.2193 - val_acc: 0.9207
Epoch 16/21
 - 20s - loss: 0.2022 - acc: 0.9292 - val_loss: 0.2156 - val_acc: 0.9206

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 17/21
 - 20s - loss: 0.1972 - acc: 0.9324 - val_loss: 0.2151 - val_acc: 0.9234
Epoch 00017: early stopping
Test accuracy:0.882
current auc_score ------------------> 0.952
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5189 - acc: 0.7515 - val_loss: 0.5714 - val_acc: 0.7162
Epoch 2/21
 - 20s - loss: 0.4188 - acc: 0.8090 - val_loss: 0.4065 - val_acc: 0.8117
Epoch 3/21
 - 20s - loss: 0.3754 - acc: 0.8370 - val_loss: 0.3779 - val_acc: 0.8299
Epoch 4/21
 - 20s - loss: 0.3435 - acc: 0.8583 - val_loss: 0.3259 - val_acc: 0.8637
Epoch 5/21
 - 20s - loss: 0.3185 - acc: 0.8714 - val_loss: 0.2886 - val_acc: 0.8848
Epoch 6/21
 - 20s - loss: 0.2934 - acc: 0.8852 - val_loss: 0.2893 - val_acc: 0.8891
Epoch 7/21
 - 20s - loss: 0.2779 - acc: 0.8940 - val_loss: 0.2692 - val_acc: 0.8909
Epoch 8/21
 - 20s - loss: 0.2602 - acc: 0.9017 - val_loss: 0.2479 - val_acc: 0.9081
Epoch 9/21
 - 20s - loss: 0.2482 - acc: 0.9077 - val_loss: 0.2611 - val_acc: 0.9020
Epoch 10/21
 - 20s - loss: 0.2363 - acc: 0.9130 - val_loss: 0.2684 - val_acc: 0.8993
Epoch 11/21
 - 20s - loss: 0.2239 - acc: 0.9203 - val_loss: 0.2043 - val_acc: 0.9317
Epoch 12/21
 - 20s - loss: 0.2180 - acc: 0.9226 - val_loss: 0.1990 - val_acc: 0.9352
Epoch 13/21
 - 20s - loss: 0.2050 - acc: 0.9287 - val_loss: 0.1875 - val_acc: 0.9356
Epoch 14/21
 - 20s - loss: 0.1992 - acc: 0.9310 - val_loss: 0.1746 - val_acc: 0.9410
Epoch 15/21
 - 20s - loss: 0.1930 - acc: 0.9348 - val_loss: 0.1701 - val_acc: 0.9447
Epoch 16/21
 - 20s - loss: 0.1863 - acc: 0.9374 - val_loss: 0.1800 - val_acc: 0.9406
Epoch 17/21
 - 20s - loss: 0.1758 - acc: 0.9429 - val_loss: 0.1484 - val_acc: 0.9538
Epoch 18/21
 - 20s - loss: 0.1682 - acc: 0.9452 - val_loss: 0.1447 - val_acc: 0.9561
Epoch 19/21
 - 20s - loss: 0.1655 - acc: 0.9466 - val_loss: 0.1611 - val_acc: 0.9445
Epoch 20/21
 - 20s - loss: 0.1593 - acc: 0.9492 - val_loss: 0.1289 - val_acc: 0.9630
Epoch 21/21
 - 20s - loss: 0.1533 - acc: 0.9507 - val_loss: 0.1393 - val_acc: 0.9591
Test accuracy:0.765
current auc_score ------------------> 0.921
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5235 - acc: 0.7566 - val_loss: 0.6116 - val_acc: 0.7130
Epoch 2/21
 - 20s - loss: 0.4282 - acc: 0.8045 - val_loss: 0.5691 - val_acc: 0.7284
Epoch 3/21
 - 20s - loss: 0.3884 - acc: 0.8297 - val_loss: 0.4789 - val_acc: 0.7838
Epoch 4/21
 - 20s - loss: 0.3583 - acc: 0.8477 - val_loss: 0.3453 - val_acc: 0.8513
Epoch 5/21
 - 20s - loss: 0.3361 - acc: 0.8617 - val_loss: 0.3295 - val_acc: 0.8555
Epoch 6/21
 - 20s - loss: 0.3195 - acc: 0.8706 - val_loss: 0.3109 - val_acc: 0.8749
Epoch 7/21
 - 20s - loss: 0.3004 - acc: 0.8821 - val_loss: 0.2715 - val_acc: 0.8961
Epoch 8/21
 - 20s - loss: 0.2865 - acc: 0.8890 - val_loss: 0.2596 - val_acc: 0.9073
Epoch 9/21
 - 20s - loss: 0.2715 - acc: 0.8967 - val_loss: 0.2402 - val_acc: 0.9129
Epoch 10/21
 - 20s - loss: 0.2600 - acc: 0.9021 - val_loss: 0.2271 - val_acc: 0.9193
Epoch 11/21
 - 20s - loss: 0.2470 - acc: 0.9089 - val_loss: 0.2126 - val_acc: 0.9251
Epoch 12/21
 - 20s - loss: 0.2364 - acc: 0.9137 - val_loss: 0.2055 - val_acc: 0.9277
Epoch 13/21
 - 20s - loss: 0.2286 - acc: 0.9182 - val_loss: 0.2322 - val_acc: 0.9148
Epoch 14/21
 - 20s - loss: 0.2171 - acc: 0.9244 - val_loss: 0.1849 - val_acc: 0.9379
Epoch 15/21
 - 20s - loss: 0.2112 - acc: 0.9264 - val_loss: 0.2238 - val_acc: 0.9199
Epoch 16/21
 - 20s - loss: 0.2016 - acc: 0.9302 - val_loss: 0.1633 - val_acc: 0.9467
Epoch 17/21
 - 20s - loss: 0.1929 - acc: 0.9335 - val_loss: 0.1673 - val_acc: 0.9436
Epoch 18/21
 - 20s - loss: 0.1875 - acc: 0.9381 - val_loss: 0.1557 - val_acc: 0.9513
Epoch 19/21
 - 20s - loss: 0.1813 - acc: 0.9379 - val_loss: 0.1963 - val_acc: 0.9329
Epoch 20/21
 - 20s - loss: 0.1776 - acc: 0.9409 - val_loss: 0.1640 - val_acc: 0.9428
Epoch 21/21
 - 20s - loss: 0.1686 - acc: 0.9452 - val_loss: 0.1375 - val_acc: 0.9576
Test accuracy:0.847
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5177 - acc: 0.7554 - val_loss: 0.8384 - val_acc: 0.5911
Epoch 2/21
 - 20s - loss: 0.4244 - acc: 0.8025 - val_loss: 0.4864 - val_acc: 0.7659
Epoch 3/21
 - 20s - loss: 0.3878 - acc: 0.8262 - val_loss: 0.4182 - val_acc: 0.8094
Epoch 4/21
 - 20s - loss: 0.3581 - acc: 0.8465 - val_loss: 0.3937 - val_acc: 0.8239
Epoch 5/21
 - 20s - loss: 0.3357 - acc: 0.8616 - val_loss: 0.3438 - val_acc: 0.8583
Epoch 6/21
 - 20s - loss: 0.3170 - acc: 0.8705 - val_loss: 0.3405 - val_acc: 0.8547
Epoch 7/21
 - 20s - loss: 0.2986 - acc: 0.8805 - val_loss: 0.2594 - val_acc: 0.9078
Epoch 8/21
 - 20s - loss: 0.2824 - acc: 0.8903 - val_loss: 0.2560 - val_acc: 0.9019
Epoch 9/21
 - 20s - loss: 0.2672 - acc: 0.8983 - val_loss: 0.2645 - val_acc: 0.8988
Epoch 10/21
 - 20s - loss: 0.2524 - acc: 0.9062 - val_loss: 0.2523 - val_acc: 0.9021
Epoch 11/21
 - 20s - loss: 0.2412 - acc: 0.9125 - val_loss: 0.2161 - val_acc: 0.9247
Epoch 12/21
 - 20s - loss: 0.2302 - acc: 0.9163 - val_loss: 0.2403 - val_acc: 0.9128
Epoch 13/21
 - 20s - loss: 0.2212 - acc: 0.9199 - val_loss: 0.2235 - val_acc: 0.9164
Epoch 14/21
 - 20s - loss: 0.2117 - acc: 0.9256 - val_loss: 0.2197 - val_acc: 0.9208

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 20s - loss: 0.1998 - acc: 0.9306 - val_loss: 0.1794 - val_acc: 0.9405
Epoch 16/21
 - 20s - loss: 0.1943 - acc: 0.9339 - val_loss: 0.1679 - val_acc: 0.9465
Epoch 17/21
 - 20s - loss: 0.1938 - acc: 0.9349 - val_loss: 0.1765 - val_acc: 0.9386
Epoch 18/21
 - 20s - loss: 0.1892 - acc: 0.9362 - val_loss: 0.1725 - val_acc: 0.9411
Epoch 19/21
 - 20s - loss: 0.1876 - acc: 0.9369 - val_loss: 0.1599 - val_acc: 0.9483
Epoch 20/21
 - 20s - loss: 0.1843 - acc: 0.9382 - val_loss: 0.1746 - val_acc: 0.9389
Epoch 21/21
 - 20s - loss: 0.1826 - acc: 0.9386 - val_loss: 0.1648 - val_acc: 0.9440
Test accuracy:0.829
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5232 - acc: 0.7486 - val_loss: 0.4623 - val_acc: 0.7873
Epoch 2/21
 - 20s - loss: 0.4337 - acc: 0.7992 - val_loss: 0.4644 - val_acc: 0.7875
Epoch 3/21
 - 20s - loss: 0.3888 - acc: 0.8278 - val_loss: 0.7770 - val_acc: 0.6921
Epoch 4/21
 - 20s - loss: 0.3571 - acc: 0.8468 - val_loss: 0.4144 - val_acc: 0.8164
Epoch 5/21
 - 20s - loss: 0.3365 - acc: 0.8612 - val_loss: 0.5364 - val_acc: 0.7800
Epoch 6/21
 - 20s - loss: 0.3169 - acc: 0.8728 - val_loss: 0.5211 - val_acc: 0.7972
Epoch 7/21
 - 20s - loss: 0.3021 - acc: 0.8809 - val_loss: 0.3637 - val_acc: 0.8475
Epoch 8/21
 - 20s - loss: 0.2840 - acc: 0.8906 - val_loss: 0.3868 - val_acc: 0.8594
Epoch 9/21
 - 20s - loss: 0.2705 - acc: 0.8967 - val_loss: 0.2595 - val_acc: 0.9019
Epoch 10/21
 - 20s - loss: 0.2570 - acc: 0.9038 - val_loss: 0.5331 - val_acc: 0.8037
Epoch 11/21
 - 20s - loss: 0.2486 - acc: 0.9085 - val_loss: 0.3290 - val_acc: 0.8785
Epoch 12/21
 - 20s - loss: 0.2375 - acc: 0.9132 - val_loss: 0.2959 - val_acc: 0.8843

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 20s - loss: 0.2256 - acc: 0.9189 - val_loss: 0.2414 - val_acc: 0.9104
Epoch 14/21
 - 20s - loss: 0.2223 - acc: 0.9225 - val_loss: 0.2436 - val_acc: 0.9085
Epoch 15/21
 - 20s - loss: 0.2187 - acc: 0.9220 - val_loss: 0.2471 - val_acc: 0.9081
Epoch 16/21
 - 20s - loss: 0.2141 - acc: 0.9239 - val_loss: 0.2180 - val_acc: 0.9217
Epoch 17/21
 - 21s - loss: 0.2115 - acc: 0.9260 - val_loss: 0.2230 - val_acc: 0.9212
Epoch 18/21
 - 20s - loss: 0.2082 - acc: 0.9278 - val_loss: 0.2005 - val_acc: 0.9280
Epoch 19/21
 - 20s - loss: 0.2077 - acc: 0.9274 - val_loss: 0.2105 - val_acc: 0.9288
Epoch 20/21
 - 20s - loss: 0.2039 - acc: 0.9291 - val_loss: 0.2279 - val_acc: 0.9216
Epoch 21/21
 - 20s - loss: 0.2027 - acc: 0.9294 - val_loss: 0.2021 - val_acc: 0.9276

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Test accuracy:0.825
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5212 - acc: 0.7594 - val_loss: 0.5195 - val_acc: 0.7459
Epoch 2/21
 - 20s - loss: 0.4228 - acc: 0.8107 - val_loss: 0.3998 - val_acc: 0.8215
Epoch 3/21
 - 20s - loss: 0.3795 - acc: 0.8373 - val_loss: 0.3645 - val_acc: 0.8391
Epoch 4/21
 - 20s - loss: 0.3478 - acc: 0.8567 - val_loss: 0.3104 - val_acc: 0.8727
Epoch 5/21
 - 20s - loss: 0.3223 - acc: 0.8723 - val_loss: 0.2976 - val_acc: 0.8840
Epoch 6/21
 - 20s - loss: 0.3013 - acc: 0.8822 - val_loss: 0.2715 - val_acc: 0.8927
Epoch 7/21
 - 20s - loss: 0.2840 - acc: 0.8904 - val_loss: 0.2722 - val_acc: 0.8992
Epoch 8/21
 - 20s - loss: 0.2713 - acc: 0.8978 - val_loss: 0.2423 - val_acc: 0.9095
Epoch 9/21
 - 20s - loss: 0.2586 - acc: 0.9043 - val_loss: 0.2519 - val_acc: 0.9070
Epoch 10/21
 - 20s - loss: 0.2461 - acc: 0.9114 - val_loss: 0.2134 - val_acc: 0.9228
Epoch 11/21
 - 19s - loss: 0.2347 - acc: 0.9165 - val_loss: 0.1988 - val_acc: 0.9335
Epoch 12/21
 - 20s - loss: 0.2221 - acc: 0.9235 - val_loss: 0.1804 - val_acc: 0.9405
Epoch 13/21
 - 19s - loss: 0.2156 - acc: 0.9233 - val_loss: 0.1917 - val_acc: 0.9371
Epoch 14/21
 - 20s - loss: 0.2049 - acc: 0.9296 - val_loss: 0.1780 - val_acc: 0.9408
Epoch 15/21
 - 19s - loss: 0.1997 - acc: 0.9308 - val_loss: 0.1872 - val_acc: 0.9342
Epoch 16/21
 - 20s - loss: 0.1902 - acc: 0.9358 - val_loss: 0.1695 - val_acc: 0.9433
Epoch 17/21
 - 20s - loss: 0.1869 - acc: 0.9373 - val_loss: 0.1753 - val_acc: 0.9409
Epoch 18/21
 - 20s - loss: 0.1769 - acc: 0.9421 - val_loss: 0.1645 - val_acc: 0.9457
Epoch 19/21
 - 20s - loss: 0.1738 - acc: 0.9431 - val_loss: 0.1319 - val_acc: 0.9613
Epoch 20/21
 - 20s - loss: 0.1645 - acc: 0.9466 - val_loss: 0.1394 - val_acc: 0.9572
Epoch 21/21
 - 20s - loss: 0.1611 - acc: 0.9486 - val_loss: 0.1213 - val_acc: 0.9669
Test accuracy:0.833
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5009 - acc: 0.7669 - val_loss: 0.4447 - val_acc: 0.7812
Epoch 2/21
 - 20s - loss: 0.4126 - acc: 0.8126 - val_loss: 0.4035 - val_acc: 0.8102
Epoch 3/21
 - 20s - loss: 0.3738 - acc: 0.8359 - val_loss: 0.3684 - val_acc: 0.8405
Epoch 4/21
 - 20s - loss: 0.3447 - acc: 0.8566 - val_loss: 0.3194 - val_acc: 0.8643
Epoch 5/21
 - 20s - loss: 0.3203 - acc: 0.8692 - val_loss: 0.2876 - val_acc: 0.8824
Epoch 6/21
 - 20s - loss: 0.3022 - acc: 0.8806 - val_loss: 0.2858 - val_acc: 0.8889
Epoch 7/21
 - 20s - loss: 0.2837 - acc: 0.8898 - val_loss: 0.2492 - val_acc: 0.9040
Epoch 8/21
 - 20s - loss: 0.2713 - acc: 0.8958 - val_loss: 0.2439 - val_acc: 0.9076
Epoch 9/21
 - 19s - loss: 0.2567 - acc: 0.9040 - val_loss: 0.2618 - val_acc: 0.8972
Epoch 10/21
 - 20s - loss: 0.2419 - acc: 0.9110 - val_loss: 0.2152 - val_acc: 0.9198
Epoch 11/21
 - 20s - loss: 0.2340 - acc: 0.9172 - val_loss: 0.2025 - val_acc: 0.9322
Epoch 12/21
 - 20s - loss: 0.2192 - acc: 0.9229 - val_loss: 0.2056 - val_acc: 0.9261
Epoch 13/21
 - 19s - loss: 0.2095 - acc: 0.9271 - val_loss: 0.1836 - val_acc: 0.9401
Epoch 14/21
 - 19s - loss: 0.2024 - acc: 0.9304 - val_loss: 0.1784 - val_acc: 0.9383
Epoch 15/21
 - 20s - loss: 0.1943 - acc: 0.9350 - val_loss: 0.1682 - val_acc: 0.9428
Epoch 16/21
 - 19s - loss: 0.1867 - acc: 0.9388 - val_loss: 0.1734 - val_acc: 0.9429
Epoch 17/21
 - 19s - loss: 0.1808 - acc: 0.9401 - val_loss: 0.1784 - val_acc: 0.9404
Epoch 18/21
 - 20s - loss: 0.1728 - acc: 0.9426 - val_loss: 0.1566 - val_acc: 0.9501
Epoch 19/21
 - 20s - loss: 0.1658 - acc: 0.9470 - val_loss: 0.1340 - val_acc: 0.9591
Epoch 20/21
 - 19s - loss: 0.1613 - acc: 0.9472 - val_loss: 0.1638 - val_acc: 0.9478
Epoch 21/21
 - 19s - loss: 0.1543 - acc: 0.9517 - val_loss: 0.1263 - val_acc: 0.9642
Test accuracy:0.857
current auc_score ------------------> 0.958
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5118 - acc: 0.7548 - val_loss: 0.5301 - val_acc: 0.7442
Epoch 2/21
 - 19s - loss: 0.4151 - acc: 0.8107 - val_loss: 0.3914 - val_acc: 0.8239
Epoch 3/21
 - 20s - loss: 0.3738 - acc: 0.8389 - val_loss: 0.3833 - val_acc: 0.8320
Epoch 4/21
 - 20s - loss: 0.3452 - acc: 0.8565 - val_loss: 0.3429 - val_acc: 0.8557
Epoch 5/21
 - 20s - loss: 0.3173 - acc: 0.8725 - val_loss: 0.2911 - val_acc: 0.8810
Epoch 6/21
 - 20s - loss: 0.3026 - acc: 0.8809 - val_loss: 0.2902 - val_acc: 0.8825
Epoch 7/21
 - 20s - loss: 0.2827 - acc: 0.8906 - val_loss: 0.2535 - val_acc: 0.9045
Epoch 8/21
 - 20s - loss: 0.2680 - acc: 0.8984 - val_loss: 0.2561 - val_acc: 0.9016
Epoch 9/21
 - 20s - loss: 0.2546 - acc: 0.9051 - val_loss: 0.2302 - val_acc: 0.9153
Epoch 10/21
 - 20s - loss: 0.2446 - acc: 0.9109 - val_loss: 0.2436 - val_acc: 0.9064
Epoch 11/21
 - 20s - loss: 0.2316 - acc: 0.9169 - val_loss: 0.2284 - val_acc: 0.9120
Epoch 12/21
 - 20s - loss: 0.2210 - acc: 0.9216 - val_loss: 0.1972 - val_acc: 0.9291
Epoch 13/21
 - 20s - loss: 0.2142 - acc: 0.9250 - val_loss: 0.2035 - val_acc: 0.9270
Epoch 14/21
 - 20s - loss: 0.2066 - acc: 0.9293 - val_loss: 0.2249 - val_acc: 0.9174
Epoch 15/21
 - 20s - loss: 0.1992 - acc: 0.9313 - val_loss: 0.1770 - val_acc: 0.9384
Epoch 16/21
 - 20s - loss: 0.1917 - acc: 0.9334 - val_loss: 0.2547 - val_acc: 0.9029
Epoch 17/21
 - 20s - loss: 0.1851 - acc: 0.9385 - val_loss: 0.1553 - val_acc: 0.9503
Epoch 18/21
 - 20s - loss: 0.1781 - acc: 0.9417 - val_loss: 0.1497 - val_acc: 0.9532
Epoch 19/21
 - 20s - loss: 0.1721 - acc: 0.9422 - val_loss: 0.1925 - val_acc: 0.9320
Epoch 20/21
 - 19s - loss: 0.1656 - acc: 0.9474 - val_loss: 0.1641 - val_acc: 0.9431
Epoch 21/21
 - 19s - loss: 0.1616 - acc: 0.9483 - val_loss: 0.1742 - val_acc: 0.9394

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.860
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     29430       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 121,803
Trainable params: 120,343
Non-trainable params: 1,460
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5320 - acc: 0.7418 - val_loss: 0.6047 - val_acc: 0.7070
Epoch 2/21
 - 20s - loss: 0.4164 - acc: 0.8115 - val_loss: 0.3797 - val_acc: 0.8277
Epoch 3/21
 - 19s - loss: 0.3730 - acc: 0.8387 - val_loss: 0.3528 - val_acc: 0.8520
Epoch 4/21
 - 20s - loss: 0.3461 - acc: 0.8560 - val_loss: 0.3564 - val_acc: 0.8471
Epoch 5/21
 - 20s - loss: 0.3240 - acc: 0.8671 - val_loss: 0.3630 - val_acc: 0.8523
Epoch 6/21
 - 20s - loss: 0.3066 - acc: 0.8769 - val_loss: 0.2839 - val_acc: 0.8872
Epoch 7/21
 - 20s - loss: 0.2922 - acc: 0.8851 - val_loss: 0.2601 - val_acc: 0.8978
Epoch 8/21
 - 20s - loss: 0.2754 - acc: 0.8934 - val_loss: 0.2599 - val_acc: 0.8962
Epoch 9/21
 - 20s - loss: 0.2624 - acc: 0.9023 - val_loss: 0.2977 - val_acc: 0.8901
Epoch 10/21
 - 20s - loss: 0.2489 - acc: 0.9074 - val_loss: 0.2557 - val_acc: 0.9059
Epoch 11/21
 - 19s - loss: 0.2403 - acc: 0.9135 - val_loss: 0.2247 - val_acc: 0.9163
Epoch 12/21
 - 19s - loss: 0.2290 - acc: 0.9164 - val_loss: 0.2033 - val_acc: 0.9285
Epoch 13/21
 - 19s - loss: 0.2206 - acc: 0.9212 - val_loss: 0.2226 - val_acc: 0.9206
Epoch 14/21
 - 19s - loss: 0.2089 - acc: 0.9275 - val_loss: 0.1807 - val_acc: 0.9400
Epoch 15/21
 - 19s - loss: 0.2013 - acc: 0.9292 - val_loss: 0.1829 - val_acc: 0.9355
Epoch 16/21
 - 19s - loss: 0.1955 - acc: 0.9322 - val_loss: 0.1769 - val_acc: 0.9395
Epoch 17/21
 - 19s - loss: 0.1879 - acc: 0.9361 - val_loss: 0.1745 - val_acc: 0.9403
Epoch 18/21
 - 19s - loss: 0.1814 - acc: 0.9382 - val_loss: 0.1541 - val_acc: 0.9484
Epoch 19/21
 - 19s - loss: 0.1755 - acc: 0.9427 - val_loss: 0.1705 - val_acc: 0.9413
Epoch 20/21
 - 19s - loss: 0.1701 - acc: 0.9449 - val_loss: 0.1495 - val_acc: 0.9508
Epoch 21/21
 - 19s - loss: 0.1644 - acc: 0.9464 - val_loss: 0.1550 - val_acc: 0.9483
Test accuracy:0.874
current auc_score ------------------> 0.953
Saved model to disk
accuracies:  [0.8032258064516129, 0.8815860215053763, 0.7647849462365591, 0.8469086021505376, 0.8291666666666667, 0.825, 0.8334677419354839, 0.8569892473118279, 0.8599462365591398, 0.8735215053763441]
aucs:  [0.9035, 0.9524, 0.9206, 0.9456, 0.9238, 0.9488, 0.9437, 0.9584, 0.9352, 0.9531]
mean and std AUC:  0.939+/-0.017  max:   0.9584
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.7', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5027 - acc: 0.7534 - val_loss: 0.4848 - val_acc: 0.7442
Epoch 2/21
 - 19s - loss: 0.4068 - acc: 0.8041 - val_loss: 0.4038 - val_acc: 0.8032
Epoch 3/21
 - 19s - loss: 0.3729 - acc: 0.8234 - val_loss: 0.4083 - val_acc: 0.8116
Epoch 4/21
 - 19s - loss: 0.3508 - acc: 0.8397 - val_loss: 0.3433 - val_acc: 0.8568
Epoch 5/21
 - 19s - loss: 0.3317 - acc: 0.8531 - val_loss: 0.3884 - val_acc: 0.8168
Epoch 6/21
 - 19s - loss: 0.3143 - acc: 0.8614 - val_loss: 0.3035 - val_acc: 0.8824
Epoch 7/21
 - 20s - loss: 0.3029 - acc: 0.8690 - val_loss: 0.3080 - val_acc: 0.8791
Epoch 8/21
 - 19s - loss: 0.2868 - acc: 0.8764 - val_loss: 0.2758 - val_acc: 0.9029
Epoch 9/21
 - 19s - loss: 0.2743 - acc: 0.8846 - val_loss: 0.2681 - val_acc: 0.8963
Epoch 10/21
 - 19s - loss: 0.2656 - acc: 0.8901 - val_loss: 0.2415 - val_acc: 0.9172
Epoch 11/21
 - 19s - loss: 0.2556 - acc: 0.8956 - val_loss: 0.2538 - val_acc: 0.9124
Epoch 12/21
 - 19s - loss: 0.2452 - acc: 0.9007 - val_loss: 0.2328 - val_acc: 0.9236
Epoch 13/21
 - 19s - loss: 0.2383 - acc: 0.9047 - val_loss: 0.2232 - val_acc: 0.9207
Epoch 14/21
 - 19s - loss: 0.2312 - acc: 0.9080 - val_loss: 0.3025 - val_acc: 0.8714
Epoch 15/21
 - 19s - loss: 0.2250 - acc: 0.9098 - val_loss: 0.2072 - val_acc: 0.9257
Epoch 16/21
 - 19s - loss: 0.2194 - acc: 0.9132 - val_loss: 0.2405 - val_acc: 0.9137
Epoch 17/21
 - 19s - loss: 0.2122 - acc: 0.9178 - val_loss: 0.1969 - val_acc: 0.9301
Epoch 18/21
 - 19s - loss: 0.2064 - acc: 0.9197 - val_loss: 0.1838 - val_acc: 0.9388
Epoch 19/21
 - 20s - loss: 0.2027 - acc: 0.9224 - val_loss: 0.1738 - val_acc: 0.9420
Epoch 20/21
 - 19s - loss: 0.1944 - acc: 0.9249 - val_loss: 0.1779 - val_acc: 0.9370
Epoch 21/21
 - 20s - loss: 0.1924 - acc: 0.9255 - val_loss: 0.1748 - val_acc: 0.9371
Test accuracy:0.852
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5170 - acc: 0.7430 - val_loss: 0.4884 - val_acc: 0.7574
Epoch 2/21
 - 19s - loss: 0.4245 - acc: 0.7978 - val_loss: 0.4436 - val_acc: 0.7851
Epoch 3/21
 - 19s - loss: 0.3833 - acc: 0.8185 - val_loss: 0.4406 - val_acc: 0.7834
Epoch 4/21
 - 18s - loss: 0.3567 - acc: 0.8377 - val_loss: 0.3516 - val_acc: 0.8351
Epoch 5/21
 - 19s - loss: 0.3387 - acc: 0.8478 - val_loss: 0.3584 - val_acc: 0.8315
Epoch 6/21
 - 19s - loss: 0.3236 - acc: 0.8558 - val_loss: 0.3313 - val_acc: 0.8446
Epoch 7/21
 - 19s - loss: 0.3106 - acc: 0.8643 - val_loss: 0.2830 - val_acc: 0.8755
Epoch 8/21
 - 19s - loss: 0.2971 - acc: 0.8714 - val_loss: 0.2745 - val_acc: 0.8832
Epoch 9/21
 - 19s - loss: 0.2850 - acc: 0.8774 - val_loss: 0.2509 - val_acc: 0.8966
Epoch 10/21
 - 19s - loss: 0.2779 - acc: 0.8835 - val_loss: 0.2659 - val_acc: 0.8835
Epoch 11/21
 - 19s - loss: 0.2687 - acc: 0.8873 - val_loss: 0.2425 - val_acc: 0.9005
Epoch 12/21
 - 19s - loss: 0.2582 - acc: 0.8942 - val_loss: 0.2290 - val_acc: 0.9046
Epoch 13/21
 - 19s - loss: 0.2506 - acc: 0.8986 - val_loss: 0.2493 - val_acc: 0.8942
Epoch 14/21
 - 19s - loss: 0.2409 - acc: 0.9048 - val_loss: 0.2321 - val_acc: 0.9032
Epoch 15/21
 - 19s - loss: 0.2351 - acc: 0.9055 - val_loss: 0.2420 - val_acc: 0.8980

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/21
 - 19s - loss: 0.2234 - acc: 0.9139 - val_loss: 0.1964 - val_acc: 0.9256
Epoch 17/21
 - 19s - loss: 0.2232 - acc: 0.9121 - val_loss: 0.1955 - val_acc: 0.9249
Epoch 18/21
 - 19s - loss: 0.2193 - acc: 0.9140 - val_loss: 0.1916 - val_acc: 0.9281
Epoch 19/21
 - 19s - loss: 0.2191 - acc: 0.9136 - val_loss: 0.1889 - val_acc: 0.9286
Epoch 20/21
 - 19s - loss: 0.2164 - acc: 0.9161 - val_loss: 0.1954 - val_acc: 0.9229
Epoch 21/21
 - 19s - loss: 0.2145 - acc: 0.9164 - val_loss: 0.1819 - val_acc: 0.9312
Test accuracy:0.851
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5226 - acc: 0.7367 - val_loss: 0.5192 - val_acc: 0.7284
Epoch 2/21
 - 19s - loss: 0.4228 - acc: 0.7991 - val_loss: 0.4623 - val_acc: 0.7752
Epoch 3/21
 - 19s - loss: 0.3830 - acc: 0.8231 - val_loss: 0.3790 - val_acc: 0.8145
Epoch 4/21
 - 19s - loss: 0.3550 - acc: 0.8389 - val_loss: 0.3379 - val_acc: 0.8450
Epoch 5/21
 - 19s - loss: 0.3337 - acc: 0.8527 - val_loss: 0.3360 - val_acc: 0.8484
Epoch 6/21
 - 19s - loss: 0.3189 - acc: 0.8609 - val_loss: 0.3290 - val_acc: 0.8563
Epoch 7/21
 - 19s - loss: 0.3018 - acc: 0.8709 - val_loss: 0.2806 - val_acc: 0.8803
Epoch 8/21
 - 19s - loss: 0.2893 - acc: 0.8767 - val_loss: 0.2773 - val_acc: 0.8879
Epoch 9/21
 - 19s - loss: 0.2792 - acc: 0.8822 - val_loss: 0.2597 - val_acc: 0.8919
Epoch 10/21
 - 19s - loss: 0.2683 - acc: 0.8893 - val_loss: 0.2846 - val_acc: 0.8783
Epoch 11/21
 - 19s - loss: 0.2575 - acc: 0.8943 - val_loss: 0.2539 - val_acc: 0.8908
Epoch 12/21
 - 19s - loss: 0.2491 - acc: 0.8991 - val_loss: 0.2362 - val_acc: 0.9039
Epoch 13/21
 - 19s - loss: 0.2399 - acc: 0.9036 - val_loss: 0.2655 - val_acc: 0.8968
Epoch 14/21
 - 19s - loss: 0.2314 - acc: 0.9071 - val_loss: 0.2022 - val_acc: 0.9217
Epoch 15/21
 - 18s - loss: 0.2263 - acc: 0.9098 - val_loss: 0.2124 - val_acc: 0.9173
Epoch 16/21
 - 19s - loss: 0.2200 - acc: 0.9134 - val_loss: 0.1827 - val_acc: 0.9359
Epoch 17/21
 - 19s - loss: 0.2108 - acc: 0.9169 - val_loss: 0.2044 - val_acc: 0.9221
Epoch 18/21
 - 19s - loss: 0.2081 - acc: 0.9179 - val_loss: 0.1666 - val_acc: 0.9411
Epoch 19/21
 - 19s - loss: 0.2013 - acc: 0.9224 - val_loss: 0.1948 - val_acc: 0.9285
Epoch 20/21
 - 18s - loss: 0.1944 - acc: 0.9261 - val_loss: 0.2027 - val_acc: 0.9223
Epoch 21/21
 - 18s - loss: 0.1893 - acc: 0.9282 - val_loss: 0.2101 - val_acc: 0.9221

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.863
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5118 - acc: 0.7468 - val_loss: 0.4405 - val_acc: 0.7856
Epoch 2/21
 - 19s - loss: 0.4181 - acc: 0.8030 - val_loss: 0.4623 - val_acc: 0.7833
Epoch 3/21
 - 19s - loss: 0.3809 - acc: 0.8245 - val_loss: 0.3860 - val_acc: 0.8171
Epoch 4/21
 - 19s - loss: 0.3517 - acc: 0.8411 - val_loss: 0.3470 - val_acc: 0.8400
Epoch 5/21
 - 19s - loss: 0.3334 - acc: 0.8542 - val_loss: 0.3094 - val_acc: 0.8619
Epoch 6/21
 - 19s - loss: 0.3163 - acc: 0.8631 - val_loss: 0.3243 - val_acc: 0.8569
Epoch 7/21
 - 19s - loss: 0.3011 - acc: 0.8711 - val_loss: 0.3392 - val_acc: 0.8559
Epoch 8/21
 - 19s - loss: 0.2884 - acc: 0.8789 - val_loss: 0.2976 - val_acc: 0.8740
Epoch 9/21
 - 19s - loss: 0.2762 - acc: 0.8856 - val_loss: 0.2509 - val_acc: 0.8986
Epoch 10/21
 - 19s - loss: 0.2643 - acc: 0.8939 - val_loss: 0.2538 - val_acc: 0.8966
Epoch 11/21
 - 19s - loss: 0.2538 - acc: 0.8967 - val_loss: 0.2513 - val_acc: 0.8913
Epoch 12/21
 - 19s - loss: 0.2476 - acc: 0.9000 - val_loss: 0.2199 - val_acc: 0.9086
Epoch 13/21
 - 19s - loss: 0.2346 - acc: 0.9078 - val_loss: 0.2430 - val_acc: 0.9009
Epoch 14/21
 - 19s - loss: 0.2275 - acc: 0.9091 - val_loss: 0.2212 - val_acc: 0.9104
Epoch 15/21
 - 19s - loss: 0.2195 - acc: 0.9142 - val_loss: 0.2135 - val_acc: 0.9135
Epoch 16/21
 - 19s - loss: 0.2123 - acc: 0.9173 - val_loss: 0.2096 - val_acc: 0.9119
Epoch 17/21
 - 19s - loss: 0.2064 - acc: 0.9209 - val_loss: 0.2041 - val_acc: 0.9198
Epoch 18/21
 - 19s - loss: 0.2035 - acc: 0.9209 - val_loss: 0.1632 - val_acc: 0.9371
Epoch 19/21
 - 19s - loss: 0.1969 - acc: 0.9248 - val_loss: 0.1709 - val_acc: 0.9381
Epoch 20/21
 - 19s - loss: 0.1913 - acc: 0.9272 - val_loss: 0.1524 - val_acc: 0.9462
Epoch 21/21
 - 19s - loss: 0.1846 - acc: 0.9309 - val_loss: 0.1609 - val_acc: 0.9406
Test accuracy:0.855
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5080 - acc: 0.7588 - val_loss: 0.4577 - val_acc: 0.7797
Epoch 2/21
 - 19s - loss: 0.4099 - acc: 0.8081 - val_loss: 0.5834 - val_acc: 0.7087
Epoch 3/21
 - 19s - loss: 0.3748 - acc: 0.8292 - val_loss: 0.3363 - val_acc: 0.8504
Epoch 4/21
 - 19s - loss: 0.3459 - acc: 0.8496 - val_loss: 0.3386 - val_acc: 0.8424
Epoch 5/21
 - 19s - loss: 0.3243 - acc: 0.8617 - val_loss: 0.3013 - val_acc: 0.8754
Epoch 6/21
 - 19s - loss: 0.3042 - acc: 0.8717 - val_loss: 0.2639 - val_acc: 0.8914
Epoch 7/21
 - 19s - loss: 0.2875 - acc: 0.8804 - val_loss: 0.2434 - val_acc: 0.9005
Epoch 8/21
 - 19s - loss: 0.2766 - acc: 0.8860 - val_loss: 0.2330 - val_acc: 0.9025
Epoch 9/21
 - 19s - loss: 0.2636 - acc: 0.8946 - val_loss: 0.2219 - val_acc: 0.9110
Epoch 10/21
 - 19s - loss: 0.2504 - acc: 0.8996 - val_loss: 0.2200 - val_acc: 0.9105
Epoch 11/21
 - 19s - loss: 0.2406 - acc: 0.9042 - val_loss: 0.2246 - val_acc: 0.9078
Epoch 12/21
 - 19s - loss: 0.2358 - acc: 0.9053 - val_loss: 0.2191 - val_acc: 0.9121
Epoch 13/21
 - 19s - loss: 0.2269 - acc: 0.9097 - val_loss: 0.1851 - val_acc: 0.9290
Epoch 14/21
 - 19s - loss: 0.2190 - acc: 0.9132 - val_loss: 0.1756 - val_acc: 0.9326
Epoch 15/21
 - 19s - loss: 0.2132 - acc: 0.9175 - val_loss: 0.1856 - val_acc: 0.9276
Epoch 16/21
 - 19s - loss: 0.2069 - acc: 0.9207 - val_loss: 0.1709 - val_acc: 0.9342
Epoch 17/21
 - 19s - loss: 0.2033 - acc: 0.9221 - val_loss: 0.1603 - val_acc: 0.9406
Epoch 18/21
 - 19s - loss: 0.1933 - acc: 0.9270 - val_loss: 0.1582 - val_acc: 0.9433
Epoch 19/21
 - 19s - loss: 0.1910 - acc: 0.9282 - val_loss: 0.1467 - val_acc: 0.9464
Epoch 20/21
 - 19s - loss: 0.1859 - acc: 0.9290 - val_loss: 0.1434 - val_acc: 0.9474
Epoch 21/21
 - 19s - loss: 0.1802 - acc: 0.9330 - val_loss: 0.1485 - val_acc: 0.9494
Test accuracy:0.818
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 20s - loss: 0.5187 - acc: 0.7436 - val_loss: 0.4749 - val_acc: 0.7634
Epoch 2/21
 - 19s - loss: 0.4239 - acc: 0.7952 - val_loss: 0.3928 - val_acc: 0.8116
Epoch 3/21
 - 19s - loss: 0.3905 - acc: 0.8158 - val_loss: 0.4011 - val_acc: 0.8055
Epoch 4/21
 - 18s - loss: 0.3648 - acc: 0.8323 - val_loss: 0.3980 - val_acc: 0.8085
Epoch 5/21
 - 19s - loss: 0.3466 - acc: 0.8430 - val_loss: 0.3286 - val_acc: 0.8514
Epoch 6/21
 - 19s - loss: 0.3258 - acc: 0.8556 - val_loss: 0.3063 - val_acc: 0.8645
Epoch 7/21
 - 19s - loss: 0.3096 - acc: 0.8646 - val_loss: 0.2911 - val_acc: 0.8793
Epoch 8/21
 - 19s - loss: 0.2975 - acc: 0.8721 - val_loss: 0.2750 - val_acc: 0.8813
Epoch 9/21
 - 19s - loss: 0.2836 - acc: 0.8811 - val_loss: 0.2836 - val_acc: 0.8810
Epoch 10/21
 - 19s - loss: 0.2732 - acc: 0.8860 - val_loss: 0.2455 - val_acc: 0.8968
Epoch 11/21
 - 19s - loss: 0.2626 - acc: 0.8920 - val_loss: 0.2391 - val_acc: 0.9032
Epoch 12/21
 - 19s - loss: 0.2522 - acc: 0.8971 - val_loss: 0.2350 - val_acc: 0.9042
Epoch 13/21
 - 19s - loss: 0.2417 - acc: 0.9015 - val_loss: 0.2443 - val_acc: 0.8980
Epoch 14/21
 - 19s - loss: 0.2340 - acc: 0.9081 - val_loss: 0.2381 - val_acc: 0.9041
Epoch 15/21
 - 19s - loss: 0.2221 - acc: 0.9142 - val_loss: 0.2438 - val_acc: 0.9017

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/21
 - 19s - loss: 0.2156 - acc: 0.9155 - val_loss: 0.1945 - val_acc: 0.9242
Epoch 17/21
 - 19s - loss: 0.2120 - acc: 0.9182 - val_loss: 0.1934 - val_acc: 0.9247
Epoch 18/21
 - 19s - loss: 0.2090 - acc: 0.9179 - val_loss: 0.1967 - val_acc: 0.9224
Epoch 19/21
 - 19s - loss: 0.2065 - acc: 0.9205 - val_loss: 0.1924 - val_acc: 0.9248
Epoch 20/21
 - 19s - loss: 0.2047 - acc: 0.9199 - val_loss: 0.1893 - val_acc: 0.9263
Epoch 21/21
 - 19s - loss: 0.2032 - acc: 0.9226 - val_loss: 0.1838 - val_acc: 0.9293
Test accuracy:0.867
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 20s - loss: 0.5005 - acc: 0.7594 - val_loss: 0.5673 - val_acc: 0.7107
Epoch 2/21
 - 19s - loss: 0.4078 - acc: 0.8048 - val_loss: 0.3911 - val_acc: 0.8150
Epoch 3/21
 - 19s - loss: 0.3692 - acc: 0.8314 - val_loss: 0.3516 - val_acc: 0.8449
Epoch 4/21
 - 19s - loss: 0.3461 - acc: 0.8449 - val_loss: 0.3104 - val_acc: 0.8655
Epoch 5/21
 - 20s - loss: 0.3305 - acc: 0.8534 - val_loss: 0.3372 - val_acc: 0.8478
Epoch 6/21
 - 19s - loss: 0.3132 - acc: 0.8633 - val_loss: 0.3266 - val_acc: 0.8537
Epoch 7/21
 - 19s - loss: 0.3015 - acc: 0.8702 - val_loss: 0.2906 - val_acc: 0.8721
Epoch 8/21
 - 19s - loss: 0.2890 - acc: 0.8767 - val_loss: 0.2712 - val_acc: 0.8822
Epoch 9/21
 - 20s - loss: 0.2779 - acc: 0.8820 - val_loss: 0.2517 - val_acc: 0.8943
Epoch 10/21
 - 20s - loss: 0.2696 - acc: 0.8856 - val_loss: 0.2378 - val_acc: 0.9024
Epoch 11/21
 - 19s - loss: 0.2628 - acc: 0.8918 - val_loss: 0.2270 - val_acc: 0.9088
Epoch 12/21
 - 19s - loss: 0.2529 - acc: 0.8966 - val_loss: 0.2275 - val_acc: 0.9076
Epoch 13/21
 - 19s - loss: 0.2436 - acc: 0.9006 - val_loss: 0.2440 - val_acc: 0.8972
Epoch 14/21
 - 19s - loss: 0.2393 - acc: 0.9037 - val_loss: 0.2025 - val_acc: 0.9211
Epoch 15/21
 - 19s - loss: 0.2314 - acc: 0.9087 - val_loss: 0.2257 - val_acc: 0.9080
Epoch 16/21
 - 19s - loss: 0.2237 - acc: 0.9109 - val_loss: 0.1863 - val_acc: 0.9270
Epoch 17/21
 - 19s - loss: 0.2197 - acc: 0.9155 - val_loss: 0.2220 - val_acc: 0.9138
Epoch 18/21
 - 19s - loss: 0.2137 - acc: 0.9169 - val_loss: 0.1762 - val_acc: 0.9325
Epoch 19/21
 - 19s - loss: 0.2091 - acc: 0.9187 - val_loss: 0.1672 - val_acc: 0.9361
Epoch 20/21
 - 19s - loss: 0.2044 - acc: 0.9222 - val_loss: 0.2010 - val_acc: 0.9209
Epoch 21/21
 - 19s - loss: 0.1953 - acc: 0.9241 - val_loss: 0.1636 - val_acc: 0.9369
Test accuracy:0.833
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5097 - acc: 0.7567 - val_loss: 0.5278 - val_acc: 0.7231
Epoch 2/21
 - 19s - loss: 0.4121 - acc: 0.8011 - val_loss: 0.5111 - val_acc: 0.7528
Epoch 3/21
 - 19s - loss: 0.3754 - acc: 0.8244 - val_loss: 0.5413 - val_acc: 0.7299
Epoch 4/21
 - 19s - loss: 0.3473 - acc: 0.8418 - val_loss: 0.3838 - val_acc: 0.8149
Epoch 5/21
 - 19s - loss: 0.3289 - acc: 0.8551 - val_loss: 0.3588 - val_acc: 0.8307
Epoch 6/21
 - 19s - loss: 0.3124 - acc: 0.8634 - val_loss: 0.3286 - val_acc: 0.8469
Epoch 7/21
 - 19s - loss: 0.2982 - acc: 0.8722 - val_loss: 0.3279 - val_acc: 0.8512
Epoch 8/21
 - 19s - loss: 0.2866 - acc: 0.8773 - val_loss: 0.3052 - val_acc: 0.8670
Epoch 9/21
 - 19s - loss: 0.2762 - acc: 0.8840 - val_loss: 0.2549 - val_acc: 0.8932
Epoch 10/21
 - 19s - loss: 0.2649 - acc: 0.8899 - val_loss: 0.3332 - val_acc: 0.8450
Epoch 11/21
 - 19s - loss: 0.2561 - acc: 0.8949 - val_loss: 0.2791 - val_acc: 0.8798
Epoch 12/21
 - 19s - loss: 0.2506 - acc: 0.8964 - val_loss: 0.2307 - val_acc: 0.9078
Epoch 13/21
 - 19s - loss: 0.2392 - acc: 0.9026 - val_loss: 0.2330 - val_acc: 0.9086
Epoch 14/21
 - 19s - loss: 0.2343 - acc: 0.9053 - val_loss: 0.2262 - val_acc: 0.9062
Epoch 15/21
 - 19s - loss: 0.2274 - acc: 0.9086 - val_loss: 0.2039 - val_acc: 0.9217
Epoch 16/21
 - 20s - loss: 0.2199 - acc: 0.9137 - val_loss: 0.2257 - val_acc: 0.9088
Epoch 17/21
 - 19s - loss: 0.2120 - acc: 0.9173 - val_loss: 0.2234 - val_acc: 0.9101
Epoch 18/21
 - 19s - loss: 0.2091 - acc: 0.9192 - val_loss: 0.2771 - val_acc: 0.8844

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 19s - loss: 0.2009 - acc: 0.9227 - val_loss: 0.1827 - val_acc: 0.9286
Epoch 20/21
 - 19s - loss: 0.1975 - acc: 0.9246 - val_loss: 0.1720 - val_acc: 0.9383
Epoch 21/21
 - 19s - loss: 0.1966 - acc: 0.9241 - val_loss: 0.1689 - val_acc: 0.9372
Test accuracy:0.825
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5036 - acc: 0.7587 - val_loss: 0.5259 - val_acc: 0.7275
Epoch 2/21
 - 19s - loss: 0.4146 - acc: 0.7983 - val_loss: 0.5231 - val_acc: 0.7385
Epoch 3/21
 - 19s - loss: 0.3785 - acc: 0.8228 - val_loss: 0.3746 - val_acc: 0.8215
Epoch 4/21
 - 19s - loss: 0.3557 - acc: 0.8374 - val_loss: 0.3777 - val_acc: 0.8282
Epoch 5/21
 - 19s - loss: 0.3376 - acc: 0.8494 - val_loss: 0.3955 - val_acc: 0.8154
Epoch 6/21
 - 19s - loss: 0.3226 - acc: 0.8569 - val_loss: 0.4062 - val_acc: 0.8230

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 7/21
 - 19s - loss: 0.3102 - acc: 0.8649 - val_loss: 0.3252 - val_acc: 0.8566
Epoch 8/21
 - 19s - loss: 0.3053 - acc: 0.8695 - val_loss: 0.3012 - val_acc: 0.8697
Epoch 9/21
 - 19s - loss: 0.3039 - acc: 0.8688 - val_loss: 0.3295 - val_acc: 0.8559
Epoch 10/21
 - 19s - loss: 0.2960 - acc: 0.8736 - val_loss: 0.2985 - val_acc: 0.8697
Epoch 11/21
 - 19s - loss: 0.2944 - acc: 0.8743 - val_loss: 0.2987 - val_acc: 0.8691
Epoch 12/21
 - 19s - loss: 0.2914 - acc: 0.8757 - val_loss: 0.2954 - val_acc: 0.8697
Epoch 00012: early stopping
Test accuracy:0.850
current auc_score ------------------> 0.927
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     6480        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     14580       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 64,961
Trainable params: 64,017
Non-trainable params: 944
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 20s - loss: 0.5026 - acc: 0.7532 - val_loss: 0.5375 - val_acc: 0.7150
Epoch 2/21
 - 19s - loss: 0.4119 - acc: 0.8016 - val_loss: 0.4637 - val_acc: 0.7687
Epoch 3/21
 - 19s - loss: 0.3783 - acc: 0.8221 - val_loss: 0.4244 - val_acc: 0.7964
Epoch 4/21
 - 19s - loss: 0.3549 - acc: 0.8363 - val_loss: 0.4008 - val_acc: 0.8040
Epoch 5/21
 - 19s - loss: 0.3352 - acc: 0.8513 - val_loss: 0.3169 - val_acc: 0.8623
Epoch 6/21
 - 19s - loss: 0.3177 - acc: 0.8612 - val_loss: 0.3081 - val_acc: 0.8702
Epoch 7/21
 - 19s - loss: 0.3051 - acc: 0.8686 - val_loss: 0.3313 - val_acc: 0.8502
Epoch 8/21
 - 19s - loss: 0.2897 - acc: 0.8770 - val_loss: 0.2763 - val_acc: 0.8824
Epoch 9/21
 - 19s - loss: 0.2780 - acc: 0.8850 - val_loss: 0.2691 - val_acc: 0.8855
Epoch 10/21
 - 19s - loss: 0.2669 - acc: 0.8902 - val_loss: 0.2871 - val_acc: 0.8765
Epoch 11/21
 - 19s - loss: 0.2567 - acc: 0.8952 - val_loss: 0.2185 - val_acc: 0.9159
Epoch 12/21
 - 19s - loss: 0.2488 - acc: 0.9003 - val_loss: 0.2293 - val_acc: 0.9083
Epoch 13/21
 - 19s - loss: 0.2372 - acc: 0.9050 - val_loss: 0.2078 - val_acc: 0.9188
Epoch 14/21
 - 19s - loss: 0.2310 - acc: 0.9075 - val_loss: 0.2052 - val_acc: 0.9203
Epoch 15/21
 - 19s - loss: 0.2241 - acc: 0.9109 - val_loss: 0.2053 - val_acc: 0.9191
Epoch 16/21
 - 19s - loss: 0.2210 - acc: 0.9126 - val_loss: 0.1790 - val_acc: 0.9351
Epoch 17/21
 - 19s - loss: 0.2137 - acc: 0.9174 - val_loss: 0.1764 - val_acc: 0.9327
Epoch 18/21
 - 19s - loss: 0.2081 - acc: 0.9205 - val_loss: 0.1875 - val_acc: 0.9292
Epoch 19/21
 - 19s - loss: 0.1996 - acc: 0.9232 - val_loss: 0.1678 - val_acc: 0.9359
Epoch 20/21
 - 19s - loss: 0.1955 - acc: 0.9261 - val_loss: 0.1664 - val_acc: 0.9369
Epoch 21/21
 - 19s - loss: 0.1901 - acc: 0.9277 - val_loss: 0.1642 - val_acc: 0.9374
Test accuracy:0.872
current auc_score ------------------> 0.947
accuracies:  [0.8518817204301076, 0.8506720430107527, 0.8627688172043011, 0.8553763440860215, 0.8182795698924731, 0.8674731182795699, 0.8329301075268817, 0.8245967741935484, 0.850268817204301, 0.8717741935483871]
aucs:  [0.9351, 0.9348, 0.9326, 0.9493, 0.9298, 0.9494, 0.9358, 0.9467, 0.9268, 0.9467]
mean and std AUC:  0.939+/-0.008  max:   0.9494
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0', 'TRUE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 28s - loss: 0.6622 - acc: 0.7679 - val_loss: 0.7515 - val_acc: 0.7472
Epoch 2/21
 - 25s - loss: 0.5546 - acc: 0.8238 - val_loss: 0.5383 - val_acc: 0.8434
Epoch 3/21
 - 26s - loss: 0.4938 - acc: 0.8610 - val_loss: 0.4673 - val_acc: 0.8686
Epoch 4/21
 - 26s - loss: 0.4517 - acc: 0.8844 - val_loss: 0.4366 - val_acc: 0.8839
Epoch 5/21
 - 26s - loss: 0.4174 - acc: 0.9017 - val_loss: 0.3966 - val_acc: 0.9101
Epoch 6/21
 - 26s - loss: 0.3923 - acc: 0.9127 - val_loss: 0.3897 - val_acc: 0.9127
Epoch 7/21
 - 26s - loss: 0.3733 - acc: 0.9210 - val_loss: 0.3581 - val_acc: 0.9372
Epoch 8/21
 - 26s - loss: 0.3561 - acc: 0.9292 - val_loss: 0.3495 - val_acc: 0.9317
Epoch 9/21
 - 26s - loss: 0.3429 - acc: 0.9335 - val_loss: 0.3194 - val_acc: 0.9492
Epoch 10/21
 - 26s - loss: 0.3278 - acc: 0.9404 - val_loss: 0.3062 - val_acc: 0.9551
Epoch 11/21
 - 26s - loss: 0.3175 - acc: 0.9440 - val_loss: 0.3779 - val_acc: 0.9123
Epoch 12/21
 - 26s - loss: 0.3065 - acc: 0.9487 - val_loss: 0.2714 - val_acc: 0.9680
Epoch 13/21
 - 26s - loss: 0.2995 - acc: 0.9506 - val_loss: 0.2801 - val_acc: 0.9608
Epoch 14/21
 - 26s - loss: 0.2901 - acc: 0.9540 - val_loss: 0.2645 - val_acc: 0.9664
Epoch 15/21
 - 26s - loss: 0.2821 - acc: 0.9574 - val_loss: 0.3013 - val_acc: 0.9482
Epoch 16/21
 - 26s - loss: 0.2748 - acc: 0.9598 - val_loss: 0.3242 - val_acc: 0.9355
Epoch 00016: early stopping
Test accuracy:0.752
current auc_score ------------------> 0.915
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6470 - acc: 0.7795 - val_loss: 0.6307 - val_acc: 0.7692
Epoch 2/21
 - 26s - loss: 0.5511 - acc: 0.8254 - val_loss: 0.5235 - val_acc: 0.8376
Epoch 3/21
 - 27s - loss: 0.5027 - acc: 0.8556 - val_loss: 0.5679 - val_acc: 0.8027
Epoch 4/21
 - 26s - loss: 0.4687 - acc: 0.8736 - val_loss: 0.6012 - val_acc: 0.7804
Epoch 5/21
 - 26s - loss: 0.4387 - acc: 0.8879 - val_loss: 0.4519 - val_acc: 0.8725
Epoch 6/21
 - 27s - loss: 0.4095 - acc: 0.9025 - val_loss: 0.4824 - val_acc: 0.8552
Epoch 7/21
 - 26s - loss: 0.3907 - acc: 0.9106 - val_loss: 0.3559 - val_acc: 0.9327
Epoch 8/21
 - 26s - loss: 0.3709 - acc: 0.9208 - val_loss: 0.3346 - val_acc: 0.9335
Epoch 9/21
 - 26s - loss: 0.3518 - acc: 0.9282 - val_loss: 0.3237 - val_acc: 0.9447
Epoch 10/21
 - 27s - loss: 0.3397 - acc: 0.9334 - val_loss: 0.3174 - val_acc: 0.9459
Epoch 11/21
 - 27s - loss: 0.3271 - acc: 0.9392 - val_loss: 0.2952 - val_acc: 0.9533
Epoch 12/21
 - 26s - loss: 0.3172 - acc: 0.9430 - val_loss: 0.2881 - val_acc: 0.9557
Epoch 13/21
 - 27s - loss: 0.3040 - acc: 0.9477 - val_loss: 0.2854 - val_acc: 0.9556
Epoch 14/21
 - 27s - loss: 0.2965 - acc: 0.9510 - val_loss: 0.2588 - val_acc: 0.9679
Epoch 15/21
 - 27s - loss: 0.2863 - acc: 0.9562 - val_loss: 0.2488 - val_acc: 0.9704
Epoch 16/21
 - 26s - loss: 0.2804 - acc: 0.9562 - val_loss: 0.2712 - val_acc: 0.9571
Epoch 17/21
 - 26s - loss: 0.2726 - acc: 0.9598 - val_loss: 0.3180 - val_acc: 0.9320
Epoch 18/21
 - 26s - loss: 0.2633 - acc: 0.9645 - val_loss: 0.2711 - val_acc: 0.9597

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 26s - loss: 0.2509 - acc: 0.9682 - val_loss: 0.2341 - val_acc: 0.9748
Epoch 20/21
 - 26s - loss: 0.2471 - acc: 0.9703 - val_loss: 0.2437 - val_acc: 0.9696
Epoch 21/21
 - 26s - loss: 0.2456 - acc: 0.9707 - val_loss: 0.2198 - val_acc: 0.9798
Test accuracy:0.827
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6436 - acc: 0.7724 - val_loss: 0.5959 - val_acc: 0.8011
Epoch 2/21
 - 26s - loss: 0.5437 - acc: 0.8291 - val_loss: 0.5057 - val_acc: 0.8500
Epoch 3/21
 - 27s - loss: 0.4945 - acc: 0.8590 - val_loss: 0.4542 - val_acc: 0.8847
Epoch 4/21
 - 27s - loss: 0.4583 - acc: 0.8793 - val_loss: 0.4412 - val_acc: 0.8913
Epoch 5/21
 - 27s - loss: 0.4300 - acc: 0.8937 - val_loss: 0.4050 - val_acc: 0.9090
Epoch 6/21
 - 27s - loss: 0.4009 - acc: 0.9085 - val_loss: 0.3820 - val_acc: 0.9121
Epoch 7/21
 - 27s - loss: 0.3809 - acc: 0.9156 - val_loss: 0.3756 - val_acc: 0.9175
Epoch 8/21
 - 27s - loss: 0.3616 - acc: 0.9257 - val_loss: 0.3711 - val_acc: 0.9216
Epoch 9/21
 - 27s - loss: 0.3468 - acc: 0.9320 - val_loss: 0.3304 - val_acc: 0.9376
Epoch 10/21
 - 26s - loss: 0.3357 - acc: 0.9360 - val_loss: 0.3077 - val_acc: 0.9499
Epoch 11/21
 - 27s - loss: 0.3206 - acc: 0.9425 - val_loss: 0.3191 - val_acc: 0.9420
Epoch 12/21
 - 27s - loss: 0.3091 - acc: 0.9465 - val_loss: 0.2892 - val_acc: 0.9573
Epoch 13/21
 - 27s - loss: 0.2998 - acc: 0.9501 - val_loss: 0.2744 - val_acc: 0.9627
Epoch 14/21
 - 27s - loss: 0.2924 - acc: 0.9536 - val_loss: 0.2649 - val_acc: 0.9671
Epoch 15/21
 - 26s - loss: 0.2840 - acc: 0.9566 - val_loss: 0.2588 - val_acc: 0.9695
Epoch 16/21
 - 26s - loss: 0.2749 - acc: 0.9596 - val_loss: 0.2446 - val_acc: 0.9718
Epoch 17/21
 - 27s - loss: 0.2673 - acc: 0.9622 - val_loss: 0.2711 - val_acc: 0.9578
Epoch 18/21
 - 26s - loss: 0.2627 - acc: 0.9637 - val_loss: 0.2597 - val_acc: 0.9634
Epoch 19/21
 - 27s - loss: 0.2566 - acc: 0.9663 - val_loss: 0.2214 - val_acc: 0.9819
Epoch 20/21
 - 27s - loss: 0.2484 - acc: 0.9695 - val_loss: 0.2350 - val_acc: 0.9735
Epoch 21/21
 - 26s - loss: 0.2469 - acc: 0.9685 - val_loss: 0.2173 - val_acc: 0.9787
Test accuracy:0.820
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6403 - acc: 0.7770 - val_loss: 0.6913 - val_acc: 0.7322
Epoch 2/21
 - 26s - loss: 0.5315 - acc: 0.8393 - val_loss: 0.5234 - val_acc: 0.8420
Epoch 3/21
 - 26s - loss: 0.4838 - acc: 0.8672 - val_loss: 0.6180 - val_acc: 0.7784
Epoch 4/21
 - 26s - loss: 0.4467 - acc: 0.8878 - val_loss: 0.4418 - val_acc: 0.8934
Epoch 5/21
 - 26s - loss: 0.4215 - acc: 0.8997 - val_loss: 0.3935 - val_acc: 0.9143
Epoch 6/21
 - 26s - loss: 0.4013 - acc: 0.9093 - val_loss: 0.4596 - val_acc: 0.8741
Epoch 7/21
 - 26s - loss: 0.3797 - acc: 0.9186 - val_loss: 0.3808 - val_acc: 0.9189
Epoch 8/21
 - 26s - loss: 0.3620 - acc: 0.9260 - val_loss: 0.4211 - val_acc: 0.8868
Epoch 9/21
 - 26s - loss: 0.3487 - acc: 0.9326 - val_loss: 0.3441 - val_acc: 0.9319
Epoch 10/21
 - 26s - loss: 0.3340 - acc: 0.9376 - val_loss: 0.3462 - val_acc: 0.9334
Epoch 11/21
 - 26s - loss: 0.3216 - acc: 0.9438 - val_loss: 0.2982 - val_acc: 0.9514
Epoch 12/21
 - 26s - loss: 0.3113 - acc: 0.9468 - val_loss: 0.3412 - val_acc: 0.9311
Epoch 13/21
 - 26s - loss: 0.3024 - acc: 0.9513 - val_loss: 0.2658 - val_acc: 0.9681
Epoch 14/21
 - 26s - loss: 0.2896 - acc: 0.9556 - val_loss: 0.2820 - val_acc: 0.9582
Epoch 15/21
 - 26s - loss: 0.2850 - acc: 0.9566 - val_loss: 0.2568 - val_acc: 0.9675
Epoch 16/21
 - 26s - loss: 0.2770 - acc: 0.9598 - val_loss: 0.2507 - val_acc: 0.9694
Epoch 17/21
 - 26s - loss: 0.2667 - acc: 0.9636 - val_loss: 0.3624 - val_acc: 0.9244
Epoch 18/21
 - 26s - loss: 0.2635 - acc: 0.9653 - val_loss: 0.2450 - val_acc: 0.9725
Epoch 19/21
 - 26s - loss: 0.2573 - acc: 0.9670 - val_loss: 0.2337 - val_acc: 0.9768
Epoch 20/21
 - 26s - loss: 0.2492 - acc: 0.9689 - val_loss: 0.2412 - val_acc: 0.9721
Epoch 21/21
 - 26s - loss: 0.2435 - acc: 0.9715 - val_loss: 0.2339 - val_acc: 0.9757
Test accuracy:0.740
current auc_score ------------------> 0.926
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 28s - loss: 0.6531 - acc: 0.7701 - val_loss: 0.5933 - val_acc: 0.7893
Epoch 2/21
 - 25s - loss: 0.5533 - acc: 0.8219 - val_loss: 0.6748 - val_acc: 0.7602
Epoch 3/21
 - 25s - loss: 0.5038 - acc: 0.8535 - val_loss: 0.4788 - val_acc: 0.8657
Epoch 4/21
 - 26s - loss: 0.4631 - acc: 0.8799 - val_loss: 0.4764 - val_acc: 0.8726
Epoch 5/21
 - 25s - loss: 0.4309 - acc: 0.8943 - val_loss: 0.4061 - val_acc: 0.9036
Epoch 6/21
 - 25s - loss: 0.4011 - acc: 0.9077 - val_loss: 0.3757 - val_acc: 0.9182
Epoch 7/21
 - 25s - loss: 0.3798 - acc: 0.9172 - val_loss: 0.3696 - val_acc: 0.9239
Epoch 8/21
 - 28s - loss: 0.3599 - acc: 0.9270 - val_loss: 0.3468 - val_acc: 0.9337
Epoch 9/21
 - 27s - loss: 0.3452 - acc: 0.9318 - val_loss: 0.3134 - val_acc: 0.9454
Epoch 10/21
 - 26s - loss: 0.3289 - acc: 0.9414 - val_loss: 0.2958 - val_acc: 0.9553
Epoch 11/21
 - 26s - loss: 0.3180 - acc: 0.9450 - val_loss: 0.2939 - val_acc: 0.9532
Epoch 12/21
 - 26s - loss: 0.3074 - acc: 0.9490 - val_loss: 0.2751 - val_acc: 0.9654
Epoch 13/21
 - 26s - loss: 0.2943 - acc: 0.9527 - val_loss: 0.2597 - val_acc: 0.9695
Epoch 14/21
 - 26s - loss: 0.2847 - acc: 0.9577 - val_loss: 0.2697 - val_acc: 0.9632
Epoch 15/21
 - 26s - loss: 0.2785 - acc: 0.9594 - val_loss: 0.2805 - val_acc: 0.9562
Epoch 16/21
 - 26s - loss: 0.2688 - acc: 0.9625 - val_loss: 0.2592 - val_acc: 0.9646
Epoch 17/21
 - 26s - loss: 0.2627 - acc: 0.9658 - val_loss: 0.2856 - val_acc: 0.9541
Epoch 00017: early stopping
Test accuracy:0.768
current auc_score ------------------> 0.932
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6565 - acc: 0.7705 - val_loss: 0.5669 - val_acc: 0.8125
Epoch 2/21
 - 26s - loss: 0.5405 - acc: 0.8344 - val_loss: 0.5031 - val_acc: 0.8527
Epoch 3/21
 - 26s - loss: 0.4882 - acc: 0.8646 - val_loss: 0.4616 - val_acc: 0.8809
Epoch 4/21
 - 26s - loss: 0.4534 - acc: 0.8835 - val_loss: 0.4324 - val_acc: 0.8943
Epoch 5/21
 - 26s - loss: 0.4222 - acc: 0.8985 - val_loss: 0.3864 - val_acc: 0.9132
Epoch 6/21
 - 26s - loss: 0.3974 - acc: 0.9080 - val_loss: 0.4369 - val_acc: 0.8886
Epoch 7/21
 - 26s - loss: 0.3772 - acc: 0.9186 - val_loss: 0.3649 - val_acc: 0.9223
Epoch 8/21
 - 26s - loss: 0.3582 - acc: 0.9270 - val_loss: 0.3378 - val_acc: 0.9395
Epoch 9/21
 - 26s - loss: 0.3422 - acc: 0.9358 - val_loss: 0.3242 - val_acc: 0.9444
Epoch 10/21
 - 26s - loss: 0.3285 - acc: 0.9404 - val_loss: 0.2956 - val_acc: 0.9558
Epoch 11/21
 - 26s - loss: 0.3159 - acc: 0.9449 - val_loss: 0.3061 - val_acc: 0.9449
Epoch 12/21
 - 26s - loss: 0.3047 - acc: 0.9494 - val_loss: 0.3006 - val_acc: 0.9513
Epoch 13/21
 - 26s - loss: 0.2947 - acc: 0.9532 - val_loss: 0.2728 - val_acc: 0.9645
Epoch 14/21
 - 26s - loss: 0.2847 - acc: 0.9566 - val_loss: 0.2631 - val_acc: 0.9637
Epoch 15/21
 - 26s - loss: 0.2771 - acc: 0.9604 - val_loss: 0.2815 - val_acc: 0.9605
Epoch 16/21
 - 28s - loss: 0.2693 - acc: 0.9617 - val_loss: 0.2494 - val_acc: 0.9716
Epoch 17/21
 - 26s - loss: 0.2609 - acc: 0.9659 - val_loss: 0.2554 - val_acc: 0.9655
Epoch 18/21
 - 26s - loss: 0.2579 - acc: 0.9663 - val_loss: 0.2276 - val_acc: 0.9789
Epoch 19/21
 - 26s - loss: 0.2506 - acc: 0.9690 - val_loss: 0.2339 - val_acc: 0.9730
Epoch 20/21
 - 25s - loss: 0.2466 - acc: 0.9699 - val_loss: 0.2378 - val_acc: 0.9728
Epoch 21/21
 - 26s - loss: 0.2402 - acc: 0.9723 - val_loss: 0.2332 - val_acc: 0.9719

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.815
current auc_score ------------------> 0.925
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 28s - loss: 0.6541 - acc: 0.7695 - val_loss: 1.0659 - val_acc: 0.6207
Epoch 2/21
 - 25s - loss: 0.5427 - acc: 0.8323 - val_loss: 0.5157 - val_acc: 0.8539
Epoch 3/21
 - 26s - loss: 0.4946 - acc: 0.8618 - val_loss: 0.5196 - val_acc: 0.8571
Epoch 4/21
 - 25s - loss: 0.4620 - acc: 0.8787 - val_loss: 0.4316 - val_acc: 0.8971
Epoch 5/21
 - 26s - loss: 0.4367 - acc: 0.8918 - val_loss: 0.4258 - val_acc: 0.8942
Epoch 6/21
 - 25s - loss: 0.4131 - acc: 0.9020 - val_loss: 0.3958 - val_acc: 0.9177
Epoch 7/21
 - 26s - loss: 0.3929 - acc: 0.9115 - val_loss: 0.3625 - val_acc: 0.9272
Epoch 8/21
 - 25s - loss: 0.3733 - acc: 0.9209 - val_loss: 0.3445 - val_acc: 0.9364
Epoch 9/21
 - 25s - loss: 0.3544 - acc: 0.9287 - val_loss: 0.3287 - val_acc: 0.9428
Epoch 10/21
 - 25s - loss: 0.3421 - acc: 0.9345 - val_loss: 0.3259 - val_acc: 0.9455
Epoch 11/21
 - 26s - loss: 0.3288 - acc: 0.9402 - val_loss: 0.3178 - val_acc: 0.9439
Epoch 12/21
 - 26s - loss: 0.3192 - acc: 0.9432 - val_loss: 0.3037 - val_acc: 0.9519
Epoch 13/21
 - 26s - loss: 0.3065 - acc: 0.9484 - val_loss: 0.2953 - val_acc: 0.9562
Epoch 14/21
 - 25s - loss: 0.2986 - acc: 0.9520 - val_loss: 0.3240 - val_acc: 0.9365
Epoch 15/21
 - 26s - loss: 0.2908 - acc: 0.9538 - val_loss: 0.2734 - val_acc: 0.9617
Epoch 16/21
 - 25s - loss: 0.2826 - acc: 0.9582 - val_loss: 0.2889 - val_acc: 0.9547
Epoch 17/21
 - 26s - loss: 0.2752 - acc: 0.9594 - val_loss: 0.2617 - val_acc: 0.9684
Epoch 18/21
 - 26s - loss: 0.2688 - acc: 0.9619 - val_loss: 0.2714 - val_acc: 0.9582
Epoch 19/21
 - 26s - loss: 0.2628 - acc: 0.9637 - val_loss: 0.2995 - val_acc: 0.9447
Epoch 20/21
 - 26s - loss: 0.2531 - acc: 0.9676 - val_loss: 0.2464 - val_acc: 0.9674
Epoch 21/21
 - 26s - loss: 0.2509 - acc: 0.9673 - val_loss: 0.2504 - val_acc: 0.9681
Epoch 00021: early stopping
Test accuracy:0.827
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 28s - loss: 0.6449 - acc: 0.7760 - val_loss: 0.8025 - val_acc: 0.6625
Epoch 2/21
 - 26s - loss: 0.5430 - acc: 0.8293 - val_loss: 0.5580 - val_acc: 0.8176
Epoch 3/21
 - 26s - loss: 0.4951 - acc: 0.8603 - val_loss: 0.4606 - val_acc: 0.8779
Epoch 4/21
 - 26s - loss: 0.4550 - acc: 0.8842 - val_loss: 0.4204 - val_acc: 0.8958
Epoch 5/21
 - 26s - loss: 0.4261 - acc: 0.8982 - val_loss: 0.4891 - val_acc: 0.8476
Epoch 6/21
 - 26s - loss: 0.4005 - acc: 0.9088 - val_loss: 0.3787 - val_acc: 0.9197
Epoch 7/21
 - 26s - loss: 0.3833 - acc: 0.9171 - val_loss: 0.3824 - val_acc: 0.9192
Epoch 8/21
 - 26s - loss: 0.3646 - acc: 0.9243 - val_loss: 0.3514 - val_acc: 0.9266
Epoch 9/21
 - 25s - loss: 0.3490 - acc: 0.9314 - val_loss: 0.3214 - val_acc: 0.9423
Epoch 10/21
 - 26s - loss: 0.3372 - acc: 0.9366 - val_loss: 0.3223 - val_acc: 0.9413
Epoch 11/21
 - 26s - loss: 0.3248 - acc: 0.9409 - val_loss: 0.3209 - val_acc: 0.9421
Epoch 12/21
 - 26s - loss: 0.3134 - acc: 0.9449 - val_loss: 0.2838 - val_acc: 0.9585
Epoch 13/21
 - 26s - loss: 0.3054 - acc: 0.9490 - val_loss: 0.2623 - val_acc: 0.9691
Epoch 14/21
 - 26s - loss: 0.2960 - acc: 0.9518 - val_loss: 0.2716 - val_acc: 0.9647
Epoch 15/21
 - 26s - loss: 0.2902 - acc: 0.9541 - val_loss: 0.2767 - val_acc: 0.9591
Epoch 16/21
 - 26s - loss: 0.2789 - acc: 0.9589 - val_loss: 0.2570 - val_acc: 0.9680
Epoch 17/21
 - 26s - loss: 0.2745 - acc: 0.9602 - val_loss: 0.2532 - val_acc: 0.9691
Epoch 00017: early stopping
Test accuracy:0.832
current auc_score ------------------> 0.937
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6409 - acc: 0.7773 - val_loss: 0.5795 - val_acc: 0.8091
Epoch 2/21
 - 27s - loss: 0.5282 - acc: 0.8453 - val_loss: 0.6476 - val_acc: 0.7917
Epoch 3/21
 - 27s - loss: 0.4791 - acc: 0.8722 - val_loss: 0.4512 - val_acc: 0.8847
Epoch 4/21
 - 27s - loss: 0.4397 - acc: 0.8942 - val_loss: 0.4149 - val_acc: 0.9045
Epoch 5/21
 - 27s - loss: 0.4100 - acc: 0.9062 - val_loss: 0.3872 - val_acc: 0.9174
Epoch 6/21
 - 27s - loss: 0.3866 - acc: 0.9185 - val_loss: 0.3715 - val_acc: 0.9226
Epoch 7/21
 - 27s - loss: 0.3672 - acc: 0.9247 - val_loss: 0.3536 - val_acc: 0.9285
Epoch 8/21
 - 27s - loss: 0.3521 - acc: 0.9317 - val_loss: 0.3121 - val_acc: 0.9483
Epoch 9/21
 - 27s - loss: 0.3374 - acc: 0.9362 - val_loss: 0.3539 - val_acc: 0.9272
Epoch 10/21
 - 27s - loss: 0.3238 - acc: 0.9439 - val_loss: 0.3024 - val_acc: 0.9514
Epoch 11/21
 - 27s - loss: 0.3127 - acc: 0.9485 - val_loss: 0.2855 - val_acc: 0.9583
Epoch 12/21
 - 26s - loss: 0.3005 - acc: 0.9518 - val_loss: 0.2925 - val_acc: 0.9543
Epoch 13/21
 - 26s - loss: 0.2905 - acc: 0.9564 - val_loss: 0.2760 - val_acc: 0.9606
Epoch 14/21
 - 26s - loss: 0.2810 - acc: 0.9599 - val_loss: 0.2701 - val_acc: 0.9623
Epoch 15/21
 - 26s - loss: 0.2751 - acc: 0.9612 - val_loss: 0.2675 - val_acc: 0.9659
Epoch 16/21
 - 26s - loss: 0.2668 - acc: 0.9642 - val_loss: 0.2688 - val_acc: 0.9612
Epoch 17/21
 - 27s - loss: 0.2606 - acc: 0.9668 - val_loss: 0.2384 - val_acc: 0.9770
Epoch 18/21
 - 27s - loss: 0.2563 - acc: 0.9666 - val_loss: 0.2398 - val_acc: 0.9736
Epoch 19/21
 - 27s - loss: 0.2516 - acc: 0.9696 - val_loss: 0.2409 - val_acc: 0.9716
Epoch 20/21
 - 27s - loss: 0.2469 - acc: 0.9714 - val_loss: 0.2684 - val_acc: 0.9596

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 27s - loss: 0.2317 - acc: 0.9773 - val_loss: 0.2205 - val_acc: 0.9804
Test accuracy:0.838
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.0  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 76, 24, 24)   5776        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 76, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 76, 12, 12)   304         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 106, 12, 12)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 106, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  12720       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 136, 12, 12)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 136, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 136, 12, 12)  18496       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 136, 6, 6)    0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 136, 6, 6)    544         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 136, 6, 6)    0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    16320       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 166, 6, 6)    664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 166, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    19920       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 196, 6, 6)    784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 196, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 196)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            197         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 292,717
Trainable params: 289,337
Non-trainable params: 3,380
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6482 - acc: 0.7744 - val_loss: 0.5554 - val_acc: 0.8192
Epoch 2/21
 - 27s - loss: 0.5347 - acc: 0.8368 - val_loss: 0.5271 - val_acc: 0.8456
Epoch 3/21
 - 27s - loss: 0.4814 - acc: 0.8672 - val_loss: 0.5504 - val_acc: 0.8391
Epoch 4/21
 - 26s - loss: 0.4465 - acc: 0.8858 - val_loss: 0.4103 - val_acc: 0.9027
Epoch 5/21
 - 27s - loss: 0.4158 - acc: 0.9008 - val_loss: 0.4001 - val_acc: 0.9115
Epoch 6/21
 - 27s - loss: 0.3923 - acc: 0.9130 - val_loss: 0.3820 - val_acc: 0.9125
Epoch 7/21
 - 26s - loss: 0.3671 - acc: 0.9233 - val_loss: 0.3795 - val_acc: 0.9177
Epoch 8/21
 - 27s - loss: 0.3536 - acc: 0.9305 - val_loss: 0.3199 - val_acc: 0.9426
Epoch 9/21
 - 27s - loss: 0.3354 - acc: 0.9368 - val_loss: 0.3083 - val_acc: 0.9462
Epoch 10/21
 - 29s - loss: 0.3231 - acc: 0.9422 - val_loss: 0.3038 - val_acc: 0.9473
Epoch 11/21
 - 28s - loss: 0.3108 - acc: 0.9475 - val_loss: 0.2892 - val_acc: 0.9570
Epoch 12/21
 - 27s - loss: 0.3009 - acc: 0.9517 - val_loss: 0.2950 - val_acc: 0.9490
Epoch 13/21
 - 27s - loss: 0.2927 - acc: 0.9542 - val_loss: 0.2619 - val_acc: 0.9650
Epoch 14/21
 - 27s - loss: 0.2806 - acc: 0.9581 - val_loss: 0.3719 - val_acc: 0.9283
Epoch 15/21
 - 27s - loss: 0.2761 - acc: 0.9603 - val_loss: 0.2773 - val_acc: 0.9577
Epoch 16/21
 - 27s - loss: 0.2667 - acc: 0.9634 - val_loss: 0.2360 - val_acc: 0.9757
Epoch 17/21
 - 27s - loss: 0.2613 - acc: 0.9652 - val_loss: 0.2246 - val_acc: 0.9803
Epoch 18/21
 - 27s - loss: 0.2555 - acc: 0.9668 - val_loss: 0.2199 - val_acc: 0.9818
Epoch 19/21
 - 27s - loss: 0.2488 - acc: 0.9697 - val_loss: 0.2332 - val_acc: 0.9728
Epoch 20/21
 - 27s - loss: 0.2446 - acc: 0.9714 - val_loss: 0.2585 - val_acc: 0.9611
Epoch 21/21
 - 28s - loss: 0.2401 - acc: 0.9727 - val_loss: 0.2015 - val_acc: 0.9885
Test accuracy:0.789
current auc_score ------------------> 0.903
accuracies:  [0.7516129032258064, 0.8271505376344086, 0.8200268817204301, 0.7404569892473118, 0.7681451612903226, 0.8150537634408602, 0.8274193548387097, 0.831989247311828, 0.8379032258064516, 0.7885752688172043]
aucs:  [0.9155, 0.9158, 0.9134, 0.9259, 0.9318, 0.9253, 0.9197, 0.9371, 0.9359, 0.903]
mean and std AUC:  0.922+/-0.01  max:   0.9371
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.2', 'TRUE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6302 - acc: 0.7836 - val_loss: 0.7152 - val_acc: 0.7367
Epoch 2/21
 - 26s - loss: 0.5209 - acc: 0.8379 - val_loss: 0.4771 - val_acc: 0.8609
Epoch 3/21
 - 26s - loss: 0.4725 - acc: 0.8685 - val_loss: 0.4549 - val_acc: 0.8710
Epoch 4/21
 - 26s - loss: 0.4383 - acc: 0.8847 - val_loss: 0.4132 - val_acc: 0.8980
Epoch 5/21
 - 26s - loss: 0.4094 - acc: 0.8991 - val_loss: 0.3853 - val_acc: 0.9073
Epoch 6/21
 - 26s - loss: 0.3853 - acc: 0.9106 - val_loss: 0.3993 - val_acc: 0.8985
Epoch 7/21
 - 26s - loss: 0.3678 - acc: 0.9189 - val_loss: 0.4017 - val_acc: 0.8991
Epoch 8/21
 - 26s - loss: 0.3515 - acc: 0.9260 - val_loss: 0.3868 - val_acc: 0.9036

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/21
 - 26s - loss: 0.3295 - acc: 0.9375 - val_loss: 0.3154 - val_acc: 0.9453
Epoch 10/21
 - 26s - loss: 0.3231 - acc: 0.9393 - val_loss: 0.3097 - val_acc: 0.9488
Epoch 11/21
 - 26s - loss: 0.3167 - acc: 0.9421 - val_loss: 0.2941 - val_acc: 0.9548
Epoch 12/21
 - 26s - loss: 0.3125 - acc: 0.9434 - val_loss: 0.2896 - val_acc: 0.9549
Epoch 13/21
 - 26s - loss: 0.3080 - acc: 0.9455 - val_loss: 0.2993 - val_acc: 0.9533
Epoch 14/21
 - 26s - loss: 0.3054 - acc: 0.9460 - val_loss: 0.3037 - val_acc: 0.9475
Epoch 15/21
 - 26s - loss: 0.3009 - acc: 0.9474 - val_loss: 0.2809 - val_acc: 0.9586
Epoch 16/21
 - 26s - loss: 0.2971 - acc: 0.9501 - val_loss: 0.2739 - val_acc: 0.9634
Epoch 17/21
 - 26s - loss: 0.2943 - acc: 0.9492 - val_loss: 0.2869 - val_acc: 0.9586
Epoch 18/21
 - 26s - loss: 0.2882 - acc: 0.9538 - val_loss: 0.2754 - val_acc: 0.9623
Epoch 19/21
 - 26s - loss: 0.2877 - acc: 0.9531 - val_loss: 0.2596 - val_acc: 0.9661
Epoch 20/21
 - 26s - loss: 0.2859 - acc: 0.9535 - val_loss: 0.2548 - val_acc: 0.9700
Epoch 21/21
 - 26s - loss: 0.2787 - acc: 0.9564 - val_loss: 0.2526 - val_acc: 0.9684
Test accuracy:0.835
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6392 - acc: 0.7728 - val_loss: 0.6050 - val_acc: 0.7771
Epoch 2/21
 - 26s - loss: 0.5291 - acc: 0.8358 - val_loss: 0.5157 - val_acc: 0.8430
Epoch 3/21
 - 26s - loss: 0.4807 - acc: 0.8633 - val_loss: 0.4509 - val_acc: 0.8747
Epoch 4/21
 - 26s - loss: 0.4485 - acc: 0.8796 - val_loss: 0.4625 - val_acc: 0.8692
Epoch 5/21
 - 26s - loss: 0.4159 - acc: 0.8962 - val_loss: 0.4085 - val_acc: 0.9050
Epoch 6/21
 - 26s - loss: 0.3949 - acc: 0.9058 - val_loss: 0.3673 - val_acc: 0.9242
Epoch 7/21
 - 26s - loss: 0.3755 - acc: 0.9152 - val_loss: 0.4111 - val_acc: 0.8998
Epoch 8/21
 - 26s - loss: 0.3569 - acc: 0.9227 - val_loss: 0.3512 - val_acc: 0.9224
Epoch 9/21
 - 26s - loss: 0.3416 - acc: 0.9297 - val_loss: 0.3623 - val_acc: 0.9236
Epoch 10/21
 - 26s - loss: 0.3282 - acc: 0.9352 - val_loss: 0.3117 - val_acc: 0.9449
Epoch 11/21
 - 26s - loss: 0.3162 - acc: 0.9404 - val_loss: 0.2917 - val_acc: 0.9544
Epoch 12/21
 - 26s - loss: 0.3043 - acc: 0.9451 - val_loss: 0.3007 - val_acc: 0.9434
Epoch 13/21
 - 27s - loss: 0.2959 - acc: 0.9499 - val_loss: 0.2964 - val_acc: 0.9504
Epoch 14/21
 - 26s - loss: 0.2873 - acc: 0.9517 - val_loss: 0.2767 - val_acc: 0.9537
Epoch 15/21
 - 27s - loss: 0.2774 - acc: 0.9561 - val_loss: 0.2422 - val_acc: 0.9735
Epoch 16/21
 - 26s - loss: 0.2697 - acc: 0.9588 - val_loss: 0.2462 - val_acc: 0.9694
Epoch 17/21
 - 27s - loss: 0.2637 - acc: 0.9612 - val_loss: 0.2290 - val_acc: 0.9753
Epoch 18/21
 - 26s - loss: 0.2590 - acc: 0.9626 - val_loss: 0.2325 - val_acc: 0.9760
Epoch 19/21
 - 26s - loss: 0.2505 - acc: 0.9656 - val_loss: 0.2183 - val_acc: 0.9810
Epoch 20/21
 - 26s - loss: 0.2452 - acc: 0.9673 - val_loss: 0.2345 - val_acc: 0.9711
Epoch 21/21
 - 26s - loss: 0.2383 - acc: 0.9697 - val_loss: 0.2236 - val_acc: 0.9745
Test accuracy:0.857
current auc_score ------------------> 0.931
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6308 - acc: 0.7775 - val_loss: 0.5582 - val_acc: 0.8130
Epoch 2/21
 - 27s - loss: 0.5242 - acc: 0.8356 - val_loss: 0.4652 - val_acc: 0.8731
Epoch 3/21
 - 27s - loss: 0.4718 - acc: 0.8677 - val_loss: 0.5474 - val_acc: 0.8267
Epoch 4/21
 - 27s - loss: 0.4389 - acc: 0.8832 - val_loss: 0.4216 - val_acc: 0.8901
Epoch 5/21
 - 26s - loss: 0.4096 - acc: 0.8987 - val_loss: 0.3695 - val_acc: 0.9213
Epoch 6/21
 - 27s - loss: 0.3874 - acc: 0.9107 - val_loss: 0.3599 - val_acc: 0.9219
Epoch 7/21
 - 27s - loss: 0.3679 - acc: 0.9198 - val_loss: 0.3295 - val_acc: 0.9366
Epoch 8/21
 - 27s - loss: 0.3511 - acc: 0.9263 - val_loss: 0.3987 - val_acc: 0.8937
Epoch 9/21
 - 27s - loss: 0.3382 - acc: 0.9299 - val_loss: 0.3092 - val_acc: 0.9434
Epoch 10/21
 - 27s - loss: 0.3219 - acc: 0.9386 - val_loss: 0.3186 - val_acc: 0.9420
Epoch 11/21
 - 27s - loss: 0.3125 - acc: 0.9420 - val_loss: 0.2900 - val_acc: 0.9499
Epoch 12/21
 - 27s - loss: 0.3032 - acc: 0.9450 - val_loss: 0.2630 - val_acc: 0.9620
Epoch 13/21
 - 27s - loss: 0.2924 - acc: 0.9494 - val_loss: 0.2623 - val_acc: 0.9646
Epoch 14/21
 - 27s - loss: 0.2840 - acc: 0.9522 - val_loss: 0.2444 - val_acc: 0.9723
Epoch 15/21
 - 27s - loss: 0.2761 - acc: 0.9559 - val_loss: 0.2510 - val_acc: 0.9671
Epoch 16/21
 - 27s - loss: 0.2697 - acc: 0.9586 - val_loss: 0.2324 - val_acc: 0.9765
Epoch 17/21
 - 26s - loss: 0.2597 - acc: 0.9629 - val_loss: 0.2470 - val_acc: 0.9671
Epoch 18/21
 - 27s - loss: 0.2565 - acc: 0.9623 - val_loss: 0.2351 - val_acc: 0.9704
Epoch 19/21
 - 27s - loss: 0.2512 - acc: 0.9639 - val_loss: 0.2238 - val_acc: 0.9767
Epoch 20/21
 - 27s - loss: 0.2464 - acc: 0.9659 - val_loss: 0.2283 - val_acc: 0.9746
Epoch 21/21
 - 27s - loss: 0.2415 - acc: 0.9680 - val_loss: 0.2133 - val_acc: 0.9792
Test accuracy:0.786
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6274 - acc: 0.7816 - val_loss: 0.5618 - val_acc: 0.8124
Epoch 2/21
 - 26s - loss: 0.5224 - acc: 0.8394 - val_loss: 0.4835 - val_acc: 0.8675
Epoch 3/21
 - 26s - loss: 0.4735 - acc: 0.8676 - val_loss: 0.4717 - val_acc: 0.8677
Epoch 4/21
 - 26s - loss: 0.4372 - acc: 0.8861 - val_loss: 0.4503 - val_acc: 0.8746
Epoch 5/21
 - 26s - loss: 0.4092 - acc: 0.8998 - val_loss: 0.4711 - val_acc: 0.8612
Epoch 6/21
 - 26s - loss: 0.3855 - acc: 0.9101 - val_loss: 0.4367 - val_acc: 0.8823
Epoch 7/21
 - 26s - loss: 0.3705 - acc: 0.9180 - val_loss: 0.3625 - val_acc: 0.9192
Epoch 8/21
 - 27s - loss: 0.3523 - acc: 0.9277 - val_loss: 0.3276 - val_acc: 0.9347
Epoch 9/21
 - 26s - loss: 0.3379 - acc: 0.9309 - val_loss: 0.3110 - val_acc: 0.9463
Epoch 10/21
 - 26s - loss: 0.3245 - acc: 0.9370 - val_loss: 0.3293 - val_acc: 0.9320
Epoch 11/21
 - 26s - loss: 0.3129 - acc: 0.9427 - val_loss: 0.3017 - val_acc: 0.9462
Epoch 12/21
 - 26s - loss: 0.3040 - acc: 0.9459 - val_loss: 0.2603 - val_acc: 0.9660
Epoch 13/21
 - 26s - loss: 0.2954 - acc: 0.9503 - val_loss: 0.2535 - val_acc: 0.9672
Epoch 14/21
 - 26s - loss: 0.2827 - acc: 0.9542 - val_loss: 0.2527 - val_acc: 0.9654
Epoch 15/21
 - 26s - loss: 0.2768 - acc: 0.9564 - val_loss: 0.2603 - val_acc: 0.9620
Epoch 16/21
 - 26s - loss: 0.2708 - acc: 0.9577 - val_loss: 0.2345 - val_acc: 0.9730
Epoch 17/21
 - 26s - loss: 0.2641 - acc: 0.9610 - val_loss: 0.2331 - val_acc: 0.9746
Epoch 18/21
 - 26s - loss: 0.2582 - acc: 0.9618 - val_loss: 0.2664 - val_acc: 0.9544
Epoch 19/21
 - 26s - loss: 0.2513 - acc: 0.9641 - val_loss: 0.2338 - val_acc: 0.9711
Epoch 20/21
 - 26s - loss: 0.2460 - acc: 0.9667 - val_loss: 0.2568 - val_acc: 0.9573

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 26s - loss: 0.2316 - acc: 0.9723 - val_loss: 0.2144 - val_acc: 0.9787
Test accuracy:0.869
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6227 - acc: 0.7800 - val_loss: 0.5838 - val_acc: 0.8021
Epoch 2/21
 - 26s - loss: 0.5161 - acc: 0.8418 - val_loss: 0.4896 - val_acc: 0.8568
Epoch 3/21
 - 26s - loss: 0.4666 - acc: 0.8700 - val_loss: 0.4388 - val_acc: 0.8823
Epoch 4/21
 - 26s - loss: 0.4347 - acc: 0.8871 - val_loss: 0.4199 - val_acc: 0.8916
Epoch 5/21
 - 26s - loss: 0.4101 - acc: 0.8997 - val_loss: 0.4054 - val_acc: 0.8967
Epoch 6/21
 - 26s - loss: 0.3889 - acc: 0.9086 - val_loss: 0.3701 - val_acc: 0.9147
Epoch 7/21
 - 26s - loss: 0.3673 - acc: 0.9198 - val_loss: 0.3316 - val_acc: 0.9372
Epoch 8/21
 - 26s - loss: 0.3493 - acc: 0.9272 - val_loss: 0.3879 - val_acc: 0.9021
Epoch 9/21
 - 26s - loss: 0.3350 - acc: 0.9334 - val_loss: 0.2934 - val_acc: 0.9511
Epoch 10/21
 - 26s - loss: 0.3256 - acc: 0.9372 - val_loss: 0.3078 - val_acc: 0.9428
Epoch 11/21
 - 26s - loss: 0.3116 - acc: 0.9423 - val_loss: 0.2911 - val_acc: 0.9553
Epoch 12/21
 - 26s - loss: 0.3002 - acc: 0.9470 - val_loss: 0.2830 - val_acc: 0.9523
Epoch 13/21
 - 26s - loss: 0.2917 - acc: 0.9509 - val_loss: 0.2694 - val_acc: 0.9567
Epoch 14/21
 - 26s - loss: 0.2849 - acc: 0.9533 - val_loss: 0.2677 - val_acc: 0.9598
Epoch 15/21
 - 26s - loss: 0.2755 - acc: 0.9574 - val_loss: 0.2731 - val_acc: 0.9542
Epoch 16/21
 - 27s - loss: 0.2672 - acc: 0.9596 - val_loss: 0.2480 - val_acc: 0.9659
Epoch 17/21
 - 26s - loss: 0.2614 - acc: 0.9622 - val_loss: 0.2302 - val_acc: 0.9726
Epoch 18/21
 - 26s - loss: 0.2537 - acc: 0.9639 - val_loss: 0.2938 - val_acc: 0.9444
Epoch 19/21
 - 27s - loss: 0.2486 - acc: 0.9662 - val_loss: 0.2219 - val_acc: 0.9763
Epoch 20/21
 - 27s - loss: 0.2407 - acc: 0.9680 - val_loss: 0.2126 - val_acc: 0.9793
Epoch 21/21
 - 27s - loss: 0.2375 - acc: 0.9704 - val_loss: 0.2013 - val_acc: 0.9849
Test accuracy:0.837
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6338 - acc: 0.7770 - val_loss: 0.5488 - val_acc: 0.8092
Epoch 2/21
 - 27s - loss: 0.5189 - acc: 0.8381 - val_loss: 0.4809 - val_acc: 0.8616
Epoch 3/21
 - 27s - loss: 0.4672 - acc: 0.8692 - val_loss: 0.4514 - val_acc: 0.8786
Epoch 4/21
 - 27s - loss: 0.4347 - acc: 0.8865 - val_loss: 0.4158 - val_acc: 0.9025
Epoch 5/21
 - 27s - loss: 0.4060 - acc: 0.9027 - val_loss: 0.4559 - val_acc: 0.8710
Epoch 6/21
 - 27s - loss: 0.3840 - acc: 0.9114 - val_loss: 0.3800 - val_acc: 0.9175
Epoch 7/21
 - 26s - loss: 0.3642 - acc: 0.9208 - val_loss: 0.3689 - val_acc: 0.9197
Epoch 8/21
 - 27s - loss: 0.3480 - acc: 0.9275 - val_loss: 0.3153 - val_acc: 0.9443
Epoch 9/21
 - 27s - loss: 0.3352 - acc: 0.9313 - val_loss: 0.3279 - val_acc: 0.9329
Epoch 10/21
 - 27s - loss: 0.3199 - acc: 0.9391 - val_loss: 0.2932 - val_acc: 0.9507
Epoch 11/21
 - 27s - loss: 0.3108 - acc: 0.9440 - val_loss: 0.2926 - val_acc: 0.9502
Epoch 12/21
 - 26s - loss: 0.3001 - acc: 0.9471 - val_loss: 0.2639 - val_acc: 0.9640
Epoch 13/21
 - 26s - loss: 0.2913 - acc: 0.9507 - val_loss: 0.2615 - val_acc: 0.9641
Epoch 14/21
 - 27s - loss: 0.2839 - acc: 0.9532 - val_loss: 0.2548 - val_acc: 0.9674
Epoch 15/21
 - 27s - loss: 0.2752 - acc: 0.9559 - val_loss: 0.2448 - val_acc: 0.9682
Epoch 16/21
 - 27s - loss: 0.2682 - acc: 0.9593 - val_loss: 0.2738 - val_acc: 0.9539
Epoch 17/21
 - 26s - loss: 0.2600 - acc: 0.9619 - val_loss: 0.2436 - val_acc: 0.9693
Epoch 18/21
 - 27s - loss: 0.2570 - acc: 0.9620 - val_loss: 0.2284 - val_acc: 0.9744
Epoch 19/21
 - 26s - loss: 0.2488 - acc: 0.9655 - val_loss: 0.2473 - val_acc: 0.9632
Epoch 20/21
 - 26s - loss: 0.2452 - acc: 0.9670 - val_loss: 0.2335 - val_acc: 0.9691
Epoch 21/21
 - 26s - loss: 0.2376 - acc: 0.9697 - val_loss: 0.2166 - val_acc: 0.9764
Test accuracy:0.801
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6350 - acc: 0.7751 - val_loss: 0.5528 - val_acc: 0.8145
Epoch 2/21
 - 27s - loss: 0.5275 - acc: 0.8345 - val_loss: 0.4926 - val_acc: 0.8603
Epoch 3/21
 - 27s - loss: 0.4834 - acc: 0.8590 - val_loss: 0.4497 - val_acc: 0.8756
Epoch 4/21
 - 27s - loss: 0.4466 - acc: 0.8798 - val_loss: 0.3961 - val_acc: 0.9078
Epoch 5/21
 - 27s - loss: 0.4147 - acc: 0.8968 - val_loss: 0.3857 - val_acc: 0.9163
Epoch 6/21
 - 27s - loss: 0.3905 - acc: 0.9072 - val_loss: 0.3574 - val_acc: 0.9222
Epoch 7/21
 - 27s - loss: 0.3711 - acc: 0.9160 - val_loss: 0.3333 - val_acc: 0.9355
Epoch 8/21
 - 27s - loss: 0.3556 - acc: 0.9238 - val_loss: 0.3554 - val_acc: 0.9214
Epoch 9/21
 - 27s - loss: 0.3408 - acc: 0.9300 - val_loss: 0.3027 - val_acc: 0.9449
Epoch 10/21
 - 27s - loss: 0.3286 - acc: 0.9349 - val_loss: 0.2928 - val_acc: 0.9542
Epoch 11/21
 - 26s - loss: 0.3150 - acc: 0.9399 - val_loss: 0.2747 - val_acc: 0.9631
Epoch 12/21
 - 27s - loss: 0.3072 - acc: 0.9435 - val_loss: 0.3509 - val_acc: 0.9239
Epoch 13/21
 - 27s - loss: 0.2929 - acc: 0.9489 - val_loss: 0.2885 - val_acc: 0.9499
Epoch 14/21
 - 27s - loss: 0.2843 - acc: 0.9528 - val_loss: 0.2489 - val_acc: 0.9679
Epoch 15/21
 - 26s - loss: 0.2781 - acc: 0.9553 - val_loss: 0.2477 - val_acc: 0.9694
Epoch 16/21
 - 27s - loss: 0.2707 - acc: 0.9570 - val_loss: 0.2504 - val_acc: 0.9676
Epoch 17/21
 - 27s - loss: 0.2648 - acc: 0.9597 - val_loss: 0.2284 - val_acc: 0.9779
Epoch 18/21
 - 27s - loss: 0.2588 - acc: 0.9621 - val_loss: 0.2381 - val_acc: 0.9700
Epoch 19/21
 - 26s - loss: 0.2502 - acc: 0.9647 - val_loss: 0.2524 - val_acc: 0.9636
Epoch 20/21
 - 27s - loss: 0.2445 - acc: 0.9669 - val_loss: 0.2493 - val_acc: 0.9596

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 26s - loss: 0.2314 - acc: 0.9712 - val_loss: 0.2200 - val_acc: 0.9777
Epoch 00021: early stopping
Test accuracy:0.856
current auc_score ------------------> 0.928
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6399 - acc: 0.7738 - val_loss: 0.7884 - val_acc: 0.6881
Epoch 2/21
 - 26s - loss: 0.5324 - acc: 0.8331 - val_loss: 0.5413 - val_acc: 0.8155
Epoch 3/21
 - 26s - loss: 0.4816 - acc: 0.8609 - val_loss: 0.5332 - val_acc: 0.8202
Epoch 4/21
 - 26s - loss: 0.4412 - acc: 0.8848 - val_loss: 0.4744 - val_acc: 0.8592
Epoch 5/21
 - 26s - loss: 0.4084 - acc: 0.8994 - val_loss: 0.4590 - val_acc: 0.8691
Epoch 6/21
 - 26s - loss: 0.3886 - acc: 0.9090 - val_loss: 0.4405 - val_acc: 0.8847
Epoch 7/21
 - 26s - loss: 0.3659 - acc: 0.9188 - val_loss: 0.3475 - val_acc: 0.9280
Epoch 8/21
 - 26s - loss: 0.3493 - acc: 0.9283 - val_loss: 0.3196 - val_acc: 0.9391
Epoch 9/21
 - 26s - loss: 0.3329 - acc: 0.9345 - val_loss: 0.3116 - val_acc: 0.9445
Epoch 10/21
 - 26s - loss: 0.3208 - acc: 0.9385 - val_loss: 0.3392 - val_acc: 0.9290
Epoch 11/21
 - 26s - loss: 0.3100 - acc: 0.9439 - val_loss: 0.2955 - val_acc: 0.9467
Epoch 12/21
 - 26s - loss: 0.2988 - acc: 0.9493 - val_loss: 0.2952 - val_acc: 0.9492
Epoch 13/21
 - 26s - loss: 0.2904 - acc: 0.9516 - val_loss: 0.2537 - val_acc: 0.9672
Epoch 14/21
 - 26s - loss: 0.2805 - acc: 0.9567 - val_loss: 0.2730 - val_acc: 0.9553
Epoch 15/21
 - 26s - loss: 0.2730 - acc: 0.9581 - val_loss: 0.2395 - val_acc: 0.9735
Epoch 16/21
 - 27s - loss: 0.2667 - acc: 0.9599 - val_loss: 0.2341 - val_acc: 0.9730
Epoch 17/21
 - 27s - loss: 0.2600 - acc: 0.9614 - val_loss: 0.2307 - val_acc: 0.9739
Epoch 18/21
 - 27s - loss: 0.2517 - acc: 0.9653 - val_loss: 0.2977 - val_acc: 0.9403
Epoch 19/21
 - 26s - loss: 0.2458 - acc: 0.9671 - val_loss: 0.2238 - val_acc: 0.9735
Epoch 20/21
 - 26s - loss: 0.2396 - acc: 0.9695 - val_loss: 0.2078 - val_acc: 0.9812
Epoch 21/21
 - 26s - loss: 0.2368 - acc: 0.9696 - val_loss: 0.2366 - val_acc: 0.9664
Test accuracy:0.813
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6515 - acc: 0.7588 - val_loss: 0.6561 - val_acc: 0.7528
Epoch 2/21
 - 26s - loss: 0.5338 - acc: 0.8295 - val_loss: 0.6286 - val_acc: 0.7740
Epoch 3/21
 - 26s - loss: 0.4804 - acc: 0.8626 - val_loss: 0.4362 - val_acc: 0.8933
Epoch 4/21
 - 26s - loss: 0.4462 - acc: 0.8814 - val_loss: 0.4798 - val_acc: 0.8663
Epoch 5/21
 - 26s - loss: 0.4197 - acc: 0.8938 - val_loss: 0.3799 - val_acc: 0.9133
Epoch 6/21
 - 26s - loss: 0.3952 - acc: 0.9059 - val_loss: 0.3680 - val_acc: 0.9189
Epoch 7/21
 - 26s - loss: 0.3765 - acc: 0.9148 - val_loss: 0.3544 - val_acc: 0.9266
Epoch 8/21
 - 26s - loss: 0.3612 - acc: 0.9208 - val_loss: 0.3454 - val_acc: 0.9257
Epoch 9/21
 - 26s - loss: 0.3454 - acc: 0.9279 - val_loss: 0.3144 - val_acc: 0.9443
Epoch 10/21
 - 26s - loss: 0.3338 - acc: 0.9318 - val_loss: 0.2909 - val_acc: 0.9522
Epoch 11/21
 - 26s - loss: 0.3224 - acc: 0.9368 - val_loss: 0.3092 - val_acc: 0.9452
Epoch 12/21
 - 26s - loss: 0.3098 - acc: 0.9433 - val_loss: 0.2800 - val_acc: 0.9576
Epoch 13/21
 - 26s - loss: 0.2982 - acc: 0.9465 - val_loss: 0.2926 - val_acc: 0.9533
Epoch 14/21
 - 26s - loss: 0.2900 - acc: 0.9499 - val_loss: 0.2523 - val_acc: 0.9698
Epoch 15/21
 - 26s - loss: 0.2784 - acc: 0.9546 - val_loss: 0.2505 - val_acc: 0.9691
Epoch 16/21
 - 26s - loss: 0.2742 - acc: 0.9559 - val_loss: 0.2425 - val_acc: 0.9714
Epoch 17/21
 - 26s - loss: 0.2653 - acc: 0.9594 - val_loss: 0.2437 - val_acc: 0.9701
Epoch 18/21
 - 26s - loss: 0.2594 - acc: 0.9611 - val_loss: 0.2556 - val_acc: 0.9591
Epoch 19/21
 - 26s - loss: 0.2556 - acc: 0.9613 - val_loss: 0.2223 - val_acc: 0.9779
Epoch 20/21
 - 26s - loss: 0.2505 - acc: 0.9636 - val_loss: 0.2202 - val_acc: 0.9784
Epoch 21/21
 - 26s - loss: 0.2419 - acc: 0.9669 - val_loss: 0.2315 - val_acc: 0.9689
Test accuracy:0.826
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.2  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 60, 24, 24)   4560        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 60, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 60, 12, 12)   240         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 60, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7200        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 90, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 90, 12, 12)   360         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  10800       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 120, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 120, 12, 12)  480         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 120, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 96, 12, 12)   11520       activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 96, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 96, 6, 6)     384         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 96, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    11520       activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 126, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 126, 6, 6)    504         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 126, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    15120       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 156, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 156, 6, 6)    624         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 156, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 156)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            157         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 270,373
Trainable params: 267,329
Non-trainable params: 3,044
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6390 - acc: 0.7711 - val_loss: 0.7043 - val_acc: 0.7471
Epoch 2/21
 - 27s - loss: 0.5261 - acc: 0.8380 - val_loss: 0.5873 - val_acc: 0.8035
Epoch 3/21
 - 27s - loss: 0.4725 - acc: 0.8684 - val_loss: 0.4577 - val_acc: 0.8760
Epoch 4/21
 - 27s - loss: 0.4361 - acc: 0.8879 - val_loss: 0.4220 - val_acc: 0.8928
Epoch 5/21
 - 27s - loss: 0.4028 - acc: 0.9059 - val_loss: 0.3868 - val_acc: 0.9103
Epoch 6/21
 - 27s - loss: 0.3823 - acc: 0.9133 - val_loss: 0.3897 - val_acc: 0.9062
Epoch 7/21
 - 26s - loss: 0.3599 - acc: 0.9238 - val_loss: 0.3851 - val_acc: 0.9071
Epoch 8/21
 - 27s - loss: 0.3435 - acc: 0.9300 - val_loss: 0.3593 - val_acc: 0.9206
Epoch 9/21
 - 26s - loss: 0.3291 - acc: 0.9362 - val_loss: 0.3331 - val_acc: 0.9291
Epoch 10/21
 - 27s - loss: 0.3175 - acc: 0.9410 - val_loss: 0.3149 - val_acc: 0.9420
Epoch 11/21
 - 27s - loss: 0.3078 - acc: 0.9446 - val_loss: 0.2893 - val_acc: 0.9509
Epoch 12/21
 - 27s - loss: 0.2952 - acc: 0.9501 - val_loss: 0.3015 - val_acc: 0.9440
Epoch 13/21
 - 26s - loss: 0.2883 - acc: 0.9516 - val_loss: 0.2916 - val_acc: 0.9502
Epoch 14/21
 - 26s - loss: 0.2767 - acc: 0.9562 - val_loss: 0.2832 - val_acc: 0.9546
Epoch 15/21
 - 26s - loss: 0.2706 - acc: 0.9583 - val_loss: 0.2854 - val_acc: 0.9507
Epoch 16/21
 - 26s - loss: 0.2645 - acc: 0.9604 - val_loss: 0.2491 - val_acc: 0.9696
Epoch 17/21
 - 26s - loss: 0.2589 - acc: 0.9622 - val_loss: 0.2717 - val_acc: 0.9597
Epoch 18/21
 - 26s - loss: 0.2507 - acc: 0.9668 - val_loss: 0.2143 - val_acc: 0.9799
Epoch 19/21
 - 26s - loss: 0.2444 - acc: 0.9678 - val_loss: 0.2317 - val_acc: 0.9721
Epoch 20/21
 - 26s - loss: 0.2394 - acc: 0.9688 - val_loss: 0.2100 - val_acc: 0.9794
Epoch 21/21
 - 26s - loss: 0.2347 - acc: 0.9714 - val_loss: 0.2065 - val_acc: 0.9819
Test accuracy:0.820
current auc_score ------------------> 0.918
accuracies:  [0.8346774193548387, 0.8571236559139785, 0.7862903225806451, 0.8688172043010752, 0.8369623655913978, 0.8013440860215054, 0.8561827956989247, 0.8131720430107527, 0.8263440860215053, 0.8201612903225807]
aucs:  [0.9299, 0.9315, 0.908, 0.943, 0.9347, 0.9334, 0.9276, 0.9101, 0.9221, 0.9178]
mean and std AUC:  0.926+/-0.011  max:   0.943
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.3', 'TRUE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6175 - acc: 0.7822 - val_loss: 0.7128 - val_acc: 0.7376
Epoch 2/21
 - 26s - loss: 0.5225 - acc: 0.8333 - val_loss: 0.7073 - val_acc: 0.7246
Epoch 3/21
 - 26s - loss: 0.4725 - acc: 0.8630 - val_loss: 0.4399 - val_acc: 0.8761
Epoch 4/21
 - 26s - loss: 0.4357 - acc: 0.8842 - val_loss: 0.3962 - val_acc: 0.9051
Epoch 5/21
 - 26s - loss: 0.4047 - acc: 0.8989 - val_loss: 0.5844 - val_acc: 0.8017
Epoch 6/21
 - 26s - loss: 0.3813 - acc: 0.9086 - val_loss: 0.4130 - val_acc: 0.8896
Epoch 7/21
 - 26s - loss: 0.3597 - acc: 0.9198 - val_loss: 0.4040 - val_acc: 0.8926

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 26s - loss: 0.3354 - acc: 0.9316 - val_loss: 0.3731 - val_acc: 0.9052
Epoch 9/21
 - 26s - loss: 0.3290 - acc: 0.9351 - val_loss: 0.3677 - val_acc: 0.9108
Epoch 10/21
 - 26s - loss: 0.3217 - acc: 0.9379 - val_loss: 0.3015 - val_acc: 0.9439
Epoch 11/21
 - 26s - loss: 0.3183 - acc: 0.9390 - val_loss: 0.3342 - val_acc: 0.9297
Epoch 12/21
 - 26s - loss: 0.3116 - acc: 0.9415 - val_loss: 0.2975 - val_acc: 0.9484
Epoch 13/21
 - 26s - loss: 0.3099 - acc: 0.9424 - val_loss: 0.2976 - val_acc: 0.9460
Epoch 14/21
 - 26s - loss: 0.3048 - acc: 0.9452 - val_loss: 0.3239 - val_acc: 0.9359
Epoch 15/21
 - 26s - loss: 0.3026 - acc: 0.9449 - val_loss: 0.3085 - val_acc: 0.9415

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 16/21
 - 27s - loss: 0.2955 - acc: 0.9468 - val_loss: 0.2837 - val_acc: 0.9541
Epoch 17/21
 - 26s - loss: 0.2911 - acc: 0.9506 - val_loss: 0.3008 - val_acc: 0.9445
Epoch 18/21
 - 26s - loss: 0.2897 - acc: 0.9510 - val_loss: 0.2976 - val_acc: 0.9454
Epoch 19/21
 - 26s - loss: 0.2892 - acc: 0.9507 - val_loss: 0.2754 - val_acc: 0.9586
Epoch 20/21
 - 26s - loss: 0.2884 - acc: 0.9518 - val_loss: 0.2792 - val_acc: 0.9562
Epoch 21/21
 - 26s - loss: 0.2866 - acc: 0.9516 - val_loss: 0.2722 - val_acc: 0.9595
Test accuracy:0.811
current auc_score ------------------> 0.926
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6313 - acc: 0.7714 - val_loss: 0.5680 - val_acc: 0.8090
Epoch 2/21
 - 26s - loss: 0.5157 - acc: 0.8408 - val_loss: 0.4903 - val_acc: 0.8628
Epoch 3/21
 - 27s - loss: 0.4631 - acc: 0.8716 - val_loss: 0.4832 - val_acc: 0.8641
Epoch 4/21
 - 27s - loss: 0.4262 - acc: 0.8915 - val_loss: 0.3999 - val_acc: 0.9085
Epoch 5/21
 - 27s - loss: 0.3993 - acc: 0.9030 - val_loss: 0.3671 - val_acc: 0.9233
Epoch 6/21
 - 27s - loss: 0.3726 - acc: 0.9167 - val_loss: 0.3383 - val_acc: 0.9319
Epoch 7/21
 - 27s - loss: 0.3562 - acc: 0.9220 - val_loss: 0.3272 - val_acc: 0.9372
Epoch 8/21
 - 27s - loss: 0.3400 - acc: 0.9303 - val_loss: 0.3417 - val_acc: 0.9306
Epoch 9/21
 - 26s - loss: 0.3240 - acc: 0.9359 - val_loss: 0.3085 - val_acc: 0.9474
Epoch 10/21
 - 26s - loss: 0.3132 - acc: 0.9424 - val_loss: 0.2778 - val_acc: 0.9590
Epoch 11/21
 - 27s - loss: 0.3010 - acc: 0.9465 - val_loss: 0.2790 - val_acc: 0.9561
Epoch 12/21
 - 26s - loss: 0.2896 - acc: 0.9504 - val_loss: 0.2600 - val_acc: 0.9642
Epoch 13/21
 - 27s - loss: 0.2810 - acc: 0.9545 - val_loss: 0.2604 - val_acc: 0.9610
Epoch 14/21
 - 27s - loss: 0.2726 - acc: 0.9560 - val_loss: 0.2523 - val_acc: 0.9661
Epoch 15/21
 - 26s - loss: 0.2666 - acc: 0.9581 - val_loss: 0.2685 - val_acc: 0.9548
Epoch 16/21
 - 26s - loss: 0.2602 - acc: 0.9603 - val_loss: 0.2637 - val_acc: 0.9585
Epoch 17/21
 - 26s - loss: 0.2556 - acc: 0.9624 - val_loss: 0.2407 - val_acc: 0.9640
Epoch 18/21
 - 26s - loss: 0.2463 - acc: 0.9660 - val_loss: 0.2196 - val_acc: 0.9810
Epoch 19/21
 - 26s - loss: 0.2431 - acc: 0.9657 - val_loss: 0.2105 - val_acc: 0.9818
Epoch 20/21
 - 26s - loss: 0.2375 - acc: 0.9680 - val_loss: 0.2122 - val_acc: 0.9805
Epoch 21/21
 - 26s - loss: 0.2321 - acc: 0.9704 - val_loss: 0.2172 - val_acc: 0.9793
Test accuracy:0.840
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6383 - acc: 0.7663 - val_loss: 0.6632 - val_acc: 0.7439
Epoch 2/21
 - 27s - loss: 0.5282 - acc: 0.8295 - val_loss: 0.4853 - val_acc: 0.8508
Epoch 3/21
 - 27s - loss: 0.4754 - acc: 0.8619 - val_loss: 0.4415 - val_acc: 0.8798
Epoch 4/21
 - 27s - loss: 0.4391 - acc: 0.8833 - val_loss: 0.4072 - val_acc: 0.9000
Epoch 5/21
 - 27s - loss: 0.4081 - acc: 0.8986 - val_loss: 0.3982 - val_acc: 0.9005
Epoch 6/21
 - 27s - loss: 0.3880 - acc: 0.9083 - val_loss: 0.3603 - val_acc: 0.9243
Epoch 7/21
 - 27s - loss: 0.3668 - acc: 0.9178 - val_loss: 0.3341 - val_acc: 0.9339
Epoch 8/21
 - 27s - loss: 0.3452 - acc: 0.9288 - val_loss: 0.4040 - val_acc: 0.8946
Epoch 9/21
 - 27s - loss: 0.3305 - acc: 0.9344 - val_loss: 0.3138 - val_acc: 0.9396
Epoch 10/21
 - 27s - loss: 0.3167 - acc: 0.9400 - val_loss: 0.3139 - val_acc: 0.9378
Epoch 11/21
 - 27s - loss: 0.3074 - acc: 0.9423 - val_loss: 0.3865 - val_acc: 0.9075
Epoch 12/21
 - 27s - loss: 0.2967 - acc: 0.9479 - val_loss: 0.2787 - val_acc: 0.9537
Epoch 13/21
 - 28s - loss: 0.2847 - acc: 0.9524 - val_loss: 0.2790 - val_acc: 0.9507
Epoch 14/21
 - 27s - loss: 0.2772 - acc: 0.9547 - val_loss: 0.2588 - val_acc: 0.9606
Epoch 15/21
 - 27s - loss: 0.2706 - acc: 0.9559 - val_loss: 0.2613 - val_acc: 0.9596
Epoch 16/21
 - 27s - loss: 0.2629 - acc: 0.9602 - val_loss: 0.2389 - val_acc: 0.9704
Epoch 17/21
 - 27s - loss: 0.2603 - acc: 0.9602 - val_loss: 0.2318 - val_acc: 0.9718
Epoch 18/21
 - 27s - loss: 0.2533 - acc: 0.9629 - val_loss: 0.2591 - val_acc: 0.9591
Epoch 19/21
 - 27s - loss: 0.2463 - acc: 0.9656 - val_loss: 0.2466 - val_acc: 0.9615
Epoch 20/21
 - 27s - loss: 0.2427 - acc: 0.9662 - val_loss: 0.2388 - val_acc: 0.9674

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 26s - loss: 0.2292 - acc: 0.9721 - val_loss: 0.2035 - val_acc: 0.9812
Test accuracy:0.804
current auc_score ------------------> 0.928
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6235 - acc: 0.7811 - val_loss: 0.5530 - val_acc: 0.8095
Epoch 2/21
 - 27s - loss: 0.5179 - acc: 0.8384 - val_loss: 0.4943 - val_acc: 0.8523
Epoch 3/21
 - 28s - loss: 0.4646 - acc: 0.8682 - val_loss: 0.4426 - val_acc: 0.8799
Epoch 4/21
 - 28s - loss: 0.4274 - acc: 0.8874 - val_loss: 0.4568 - val_acc: 0.8697
Epoch 5/21
 - 28s - loss: 0.3975 - acc: 0.9015 - val_loss: 0.3834 - val_acc: 0.9076
Epoch 6/21
 - 28s - loss: 0.3715 - acc: 0.9150 - val_loss: 0.3628 - val_acc: 0.9211
Epoch 7/21
 - 28s - loss: 0.3529 - acc: 0.9233 - val_loss: 0.3220 - val_acc: 0.9337
Epoch 8/21
 - 28s - loss: 0.3380 - acc: 0.9289 - val_loss: 0.3316 - val_acc: 0.9327
Epoch 9/21
 - 28s - loss: 0.3257 - acc: 0.9346 - val_loss: 0.3123 - val_acc: 0.9445
Epoch 10/21
 - 27s - loss: 0.3104 - acc: 0.9400 - val_loss: 0.2883 - val_acc: 0.9516
Epoch 11/21
 - 28s - loss: 0.3020 - acc: 0.9443 - val_loss: 0.3073 - val_acc: 0.9408
Epoch 12/21
 - 27s - loss: 0.2900 - acc: 0.9500 - val_loss: 0.2695 - val_acc: 0.9559
Epoch 13/21
 - 27s - loss: 0.2845 - acc: 0.9506 - val_loss: 0.3427 - val_acc: 0.9260
Epoch 14/21
 - 27s - loss: 0.2754 - acc: 0.9538 - val_loss: 0.3105 - val_acc: 0.9379
Epoch 15/21
 - 28s - loss: 0.2692 - acc: 0.9572 - val_loss: 0.2473 - val_acc: 0.9655
Epoch 16/21
 - 27s - loss: 0.2647 - acc: 0.9577 - val_loss: 0.2392 - val_acc: 0.9701
Epoch 17/21
 - 27s - loss: 0.2568 - acc: 0.9609 - val_loss: 0.2213 - val_acc: 0.9772
Epoch 18/21
 - 28s - loss: 0.2498 - acc: 0.9642 - val_loss: 0.2703 - val_acc: 0.9506
Epoch 19/21
 - 27s - loss: 0.2436 - acc: 0.9664 - val_loss: 0.2463 - val_acc: 0.9626
Epoch 20/21
 - 27s - loss: 0.2403 - acc: 0.9664 - val_loss: 0.2503 - val_acc: 0.9595

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 27s - loss: 0.2277 - acc: 0.9727 - val_loss: 0.1957 - val_acc: 0.9839
Test accuracy:0.854
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 28s - loss: 0.6262 - acc: 0.7811 - val_loss: 0.5745 - val_acc: 0.7937
Epoch 2/21
 - 25s - loss: 0.5185 - acc: 0.8372 - val_loss: 0.4800 - val_acc: 0.8586
Epoch 3/21
 - 25s - loss: 0.4702 - acc: 0.8650 - val_loss: 0.5040 - val_acc: 0.8402
Epoch 4/21
 - 25s - loss: 0.4356 - acc: 0.8834 - val_loss: 0.4537 - val_acc: 0.8650
Epoch 5/21
 - 25s - loss: 0.4059 - acc: 0.8993 - val_loss: 0.3781 - val_acc: 0.9164
Epoch 6/21
 - 25s - loss: 0.3825 - acc: 0.9094 - val_loss: 0.4353 - val_acc: 0.8736
Epoch 7/21
 - 25s - loss: 0.3622 - acc: 0.9206 - val_loss: 0.3477 - val_acc: 0.9244
Epoch 8/21
 - 25s - loss: 0.3445 - acc: 0.9271 - val_loss: 0.3763 - val_acc: 0.9130
Epoch 9/21
 - 25s - loss: 0.3311 - acc: 0.9330 - val_loss: 0.3094 - val_acc: 0.9436
Epoch 10/21
 - 25s - loss: 0.3169 - acc: 0.9384 - val_loss: 0.2987 - val_acc: 0.9433
Epoch 11/21
 - 25s - loss: 0.3054 - acc: 0.9437 - val_loss: 0.2829 - val_acc: 0.9528
Epoch 12/21
 - 26s - loss: 0.2945 - acc: 0.9482 - val_loss: 0.2602 - val_acc: 0.9608
Epoch 13/21
 - 25s - loss: 0.2886 - acc: 0.9505 - val_loss: 0.2592 - val_acc: 0.9610
Epoch 14/21
 - 25s - loss: 0.2798 - acc: 0.9520 - val_loss: 0.2649 - val_acc: 0.9588
Epoch 15/21
 - 25s - loss: 0.2724 - acc: 0.9559 - val_loss: 0.2334 - val_acc: 0.9750
Epoch 16/21
 - 25s - loss: 0.2630 - acc: 0.9594 - val_loss: 0.2351 - val_acc: 0.9701
Epoch 17/21
 - 25s - loss: 0.2583 - acc: 0.9614 - val_loss: 0.2292 - val_acc: 0.9711
Epoch 18/21
 - 25s - loss: 0.2520 - acc: 0.9643 - val_loss: 0.2174 - val_acc: 0.9774
Epoch 19/21
 - 26s - loss: 0.2473 - acc: 0.9644 - val_loss: 0.2228 - val_acc: 0.9738
Epoch 20/21
 - 25s - loss: 0.2408 - acc: 0.9673 - val_loss: 0.2538 - val_acc: 0.9591
Epoch 21/21
 - 26s - loss: 0.2366 - acc: 0.9683 - val_loss: 0.2108 - val_acc: 0.9774
Test accuracy:0.839
current auc_score ------------------> 0.942
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6235 - acc: 0.7762 - val_loss: 0.6338 - val_acc: 0.7760
Epoch 2/21
 - 26s - loss: 0.5141 - acc: 0.8397 - val_loss: 0.5227 - val_acc: 0.8325
Epoch 3/21
 - 27s - loss: 0.4618 - acc: 0.8731 - val_loss: 0.4277 - val_acc: 0.8847
Epoch 4/21
 - 26s - loss: 0.4254 - acc: 0.8913 - val_loss: 0.4006 - val_acc: 0.9030
Epoch 5/21
 - 26s - loss: 0.3954 - acc: 0.9052 - val_loss: 0.3767 - val_acc: 0.9138
Epoch 6/21
 - 26s - loss: 0.3716 - acc: 0.9155 - val_loss: 0.3330 - val_acc: 0.9370
Epoch 7/21
 - 26s - loss: 0.3525 - acc: 0.9248 - val_loss: 0.3769 - val_acc: 0.9085
Epoch 8/21
 - 27s - loss: 0.3351 - acc: 0.9311 - val_loss: 0.3331 - val_acc: 0.9351
Epoch 9/21
 - 26s - loss: 0.3234 - acc: 0.9368 - val_loss: 0.3457 - val_acc: 0.9270

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 27s - loss: 0.3041 - acc: 0.9455 - val_loss: 0.2798 - val_acc: 0.9557
Epoch 11/21
 - 27s - loss: 0.2976 - acc: 0.9482 - val_loss: 0.2936 - val_acc: 0.9477
Epoch 12/21
 - 26s - loss: 0.2913 - acc: 0.9513 - val_loss: 0.2583 - val_acc: 0.9664
Epoch 13/21
 - 26s - loss: 0.2903 - acc: 0.9513 - val_loss: 0.2944 - val_acc: 0.9470
Epoch 14/21
 - 27s - loss: 0.2860 - acc: 0.9536 - val_loss: 0.2626 - val_acc: 0.9618
Epoch 15/21
 - 26s - loss: 0.2853 - acc: 0.9526 - val_loss: 0.2462 - val_acc: 0.9690
Epoch 16/21
 - 26s - loss: 0.2807 - acc: 0.9548 - val_loss: 0.3082 - val_acc: 0.9375
Epoch 17/21
 - 27s - loss: 0.2750 - acc: 0.9574 - val_loss: 0.2783 - val_acc: 0.9524
Epoch 18/21
 - 27s - loss: 0.2715 - acc: 0.9578 - val_loss: 0.2648 - val_acc: 0.9603

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 19/21
 - 27s - loss: 0.2677 - acc: 0.9599 - val_loss: 0.2591 - val_acc: 0.9606
Epoch 00019: early stopping
Test accuracy:0.786
current auc_score ------------------> 0.906
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6259 - acc: 0.7803 - val_loss: 0.6174 - val_acc: 0.7859
Epoch 2/21
 - 26s - loss: 0.5151 - acc: 0.8408 - val_loss: 0.5039 - val_acc: 0.8426
Epoch 3/21
 - 26s - loss: 0.4619 - acc: 0.8715 - val_loss: 0.4377 - val_acc: 0.8835
Epoch 4/21
 - 26s - loss: 0.4269 - acc: 0.8889 - val_loss: 0.4075 - val_acc: 0.8942
Epoch 5/21
 - 27s - loss: 0.4005 - acc: 0.9018 - val_loss: 0.4133 - val_acc: 0.8926
Epoch 6/21
 - 27s - loss: 0.3788 - acc: 0.9124 - val_loss: 0.4159 - val_acc: 0.8865
Epoch 7/21
 - 26s - loss: 0.3607 - acc: 0.9201 - val_loss: 0.3365 - val_acc: 0.9326
Epoch 8/21
 - 26s - loss: 0.3453 - acc: 0.9276 - val_loss: 0.3221 - val_acc: 0.9350
Epoch 9/21
 - 26s - loss: 0.3321 - acc: 0.9320 - val_loss: 0.3146 - val_acc: 0.9404
Epoch 10/21
 - 26s - loss: 0.3190 - acc: 0.9381 - val_loss: 0.2926 - val_acc: 0.9537
Epoch 11/21
 - 26s - loss: 0.3082 - acc: 0.9419 - val_loss: 0.2798 - val_acc: 0.9524
Epoch 12/21
 - 26s - loss: 0.2986 - acc: 0.9460 - val_loss: 0.2977 - val_acc: 0.9431
Epoch 13/21
 - 27s - loss: 0.2863 - acc: 0.9504 - val_loss: 0.3331 - val_acc: 0.9261
Epoch 14/21
 - 26s - loss: 0.2789 - acc: 0.9541 - val_loss: 0.2479 - val_acc: 0.9664
Epoch 15/21
 - 26s - loss: 0.2747 - acc: 0.9550 - val_loss: 0.2759 - val_acc: 0.9487
Epoch 16/21
 - 27s - loss: 0.2662 - acc: 0.9584 - val_loss: 0.2674 - val_acc: 0.9517
Epoch 17/21
 - 27s - loss: 0.2572 - acc: 0.9626 - val_loss: 0.2846 - val_acc: 0.9474

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 18/21
 - 26s - loss: 0.2454 - acc: 0.9666 - val_loss: 0.2182 - val_acc: 0.9753
Epoch 19/21
 - 26s - loss: 0.2412 - acc: 0.9679 - val_loss: 0.2162 - val_acc: 0.9760
Epoch 20/21
 - 26s - loss: 0.2412 - acc: 0.9671 - val_loss: 0.2680 - val_acc: 0.9499
Epoch 21/21
 - 26s - loss: 0.2374 - acc: 0.9691 - val_loss: 0.2288 - val_acc: 0.9679
Test accuracy:0.830
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6361 - acc: 0.7686 - val_loss: 0.5634 - val_acc: 0.8126
Epoch 2/21
 - 26s - loss: 0.5333 - acc: 0.8284 - val_loss: 0.4798 - val_acc: 0.8602
Epoch 3/21
 - 26s - loss: 0.4811 - acc: 0.8598 - val_loss: 0.4985 - val_acc: 0.8471
Epoch 4/21
 - 26s - loss: 0.4401 - acc: 0.8824 - val_loss: 0.4381 - val_acc: 0.8750
Epoch 5/21
 - 26s - loss: 0.4117 - acc: 0.8964 - val_loss: 0.4949 - val_acc: 0.8532
Epoch 6/21
 - 26s - loss: 0.3859 - acc: 0.9073 - val_loss: 0.3587 - val_acc: 0.9155
Epoch 7/21
 - 26s - loss: 0.3673 - acc: 0.9178 - val_loss: 0.3434 - val_acc: 0.9273
Epoch 8/21
 - 26s - loss: 0.3480 - acc: 0.9258 - val_loss: 0.3201 - val_acc: 0.9360
Epoch 9/21
 - 26s - loss: 0.3319 - acc: 0.9322 - val_loss: 0.3030 - val_acc: 0.9442
Epoch 10/21
 - 26s - loss: 0.3174 - acc: 0.9395 - val_loss: 0.3796 - val_acc: 0.9049
Epoch 11/21
 - 27s - loss: 0.3071 - acc: 0.9432 - val_loss: 0.3036 - val_acc: 0.9418
Epoch 12/21
 - 26s - loss: 0.2968 - acc: 0.9461 - val_loss: 0.2691 - val_acc: 0.9596
Epoch 13/21
 - 26s - loss: 0.2875 - acc: 0.9505 - val_loss: 0.3399 - val_acc: 0.9246
Epoch 14/21
 - 26s - loss: 0.2781 - acc: 0.9541 - val_loss: 0.2487 - val_acc: 0.9666
Epoch 15/21
 - 26s - loss: 0.2683 - acc: 0.9580 - val_loss: 0.2414 - val_acc: 0.9680
Epoch 16/21
 - 27s - loss: 0.2641 - acc: 0.9588 - val_loss: 0.2602 - val_acc: 0.9566
Epoch 17/21
 - 27s - loss: 0.2556 - acc: 0.9618 - val_loss: 0.2192 - val_acc: 0.9782
Epoch 18/21
 - 27s - loss: 0.2488 - acc: 0.9644 - val_loss: 0.2132 - val_acc: 0.9799
Epoch 19/21
 - 26s - loss: 0.2453 - acc: 0.9656 - val_loss: 0.2200 - val_acc: 0.9753
Epoch 20/21
 - 26s - loss: 0.2381 - acc: 0.9684 - val_loss: 0.2136 - val_acc: 0.9764
Epoch 21/21
 - 27s - loss: 0.2321 - acc: 0.9709 - val_loss: 0.2030 - val_acc: 0.9824
Test accuracy:0.830
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6423 - acc: 0.7688 - val_loss: 0.5709 - val_acc: 0.8016
Epoch 2/21
 - 25s - loss: 0.5338 - acc: 0.8276 - val_loss: 0.5173 - val_acc: 0.8469
Epoch 3/21
 - 26s - loss: 0.4831 - acc: 0.8600 - val_loss: 0.4595 - val_acc: 0.8824
Epoch 4/21
 - 27s - loss: 0.4451 - acc: 0.8802 - val_loss: 0.4682 - val_acc: 0.8735
Epoch 5/21
 - 27s - loss: 0.4133 - acc: 0.8960 - val_loss: 0.5145 - val_acc: 0.8345
Epoch 6/21
 - 26s - loss: 0.3896 - acc: 0.9063 - val_loss: 0.3820 - val_acc: 0.9101
Epoch 7/21
 - 26s - loss: 0.3726 - acc: 0.9134 - val_loss: 0.3572 - val_acc: 0.9222
Epoch 8/21
 - 26s - loss: 0.3548 - acc: 0.9234 - val_loss: 0.3656 - val_acc: 0.9154
Epoch 9/21
 - 26s - loss: 0.3379 - acc: 0.9297 - val_loss: 0.3576 - val_acc: 0.9162
Epoch 10/21
 - 26s - loss: 0.3230 - acc: 0.9364 - val_loss: 0.3117 - val_acc: 0.9429
Epoch 11/21
 - 26s - loss: 0.3141 - acc: 0.9400 - val_loss: 0.3060 - val_acc: 0.9395
Epoch 12/21
 - 26s - loss: 0.3049 - acc: 0.9435 - val_loss: 0.2703 - val_acc: 0.9639
Epoch 13/21
 - 26s - loss: 0.2929 - acc: 0.9468 - val_loss: 0.2772 - val_acc: 0.9559
Epoch 14/21
 - 26s - loss: 0.2839 - acc: 0.9514 - val_loss: 0.2610 - val_acc: 0.9622
Epoch 15/21
 - 26s - loss: 0.2751 - acc: 0.9540 - val_loss: 0.2495 - val_acc: 0.9667
Epoch 16/21
 - 26s - loss: 0.2696 - acc: 0.9556 - val_loss: 0.2703 - val_acc: 0.9553
Epoch 17/21
 - 26s - loss: 0.2621 - acc: 0.9588 - val_loss: 0.2645 - val_acc: 0.9565
Epoch 18/21
 - 26s - loss: 0.2548 - acc: 0.9625 - val_loss: 0.2240 - val_acc: 0.9779
Epoch 19/21
 - 25s - loss: 0.2480 - acc: 0.9643 - val_loss: 0.2269 - val_acc: 0.9749
Epoch 20/21
 - 26s - loss: 0.2421 - acc: 0.9667 - val_loss: 0.2241 - val_acc: 0.9733
Epoch 21/21
 - 26s - loss: 0.2382 - acc: 0.9678 - val_loss: 0.2276 - val_acc: 0.9720

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.785
current auc_score ------------------> 0.891
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.3  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 79, 12, 12)   8927        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 79, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 79, 6, 6)     316         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 79, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 109, 6, 6)    0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 109, 6, 6)    436         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 109, 6, 6)    0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    13080       activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 139, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 139, 6, 6)    556         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 139, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 139)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            140         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 261,183
Trainable params: 258,283
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 28s - loss: 0.6307 - acc: 0.7810 - val_loss: 0.6635 - val_acc: 0.7929
Epoch 2/21
 - 25s - loss: 0.5194 - acc: 0.8378 - val_loss: 0.4632 - val_acc: 0.8707
Epoch 3/21
 - 26s - loss: 0.4678 - acc: 0.8677 - val_loss: 0.4548 - val_acc: 0.8722
Epoch 4/21
 - 25s - loss: 0.4320 - acc: 0.8881 - val_loss: 0.4120 - val_acc: 0.8952
Epoch 5/21
 - 27s - loss: 0.4062 - acc: 0.8992 - val_loss: 0.3885 - val_acc: 0.9080
Epoch 6/21
 - 26s - loss: 0.3823 - acc: 0.9112 - val_loss: 0.3911 - val_acc: 0.9041
Epoch 7/21
 - 26s - loss: 0.3637 - acc: 0.9199 - val_loss: 0.3408 - val_acc: 0.9311
Epoch 8/21
 - 26s - loss: 0.3471 - acc: 0.9254 - val_loss: 0.3774 - val_acc: 0.9106
Epoch 9/21
 - 26s - loss: 0.3330 - acc: 0.9327 - val_loss: 0.3411 - val_acc: 0.9277
Epoch 10/21
 - 26s - loss: 0.3209 - acc: 0.9376 - val_loss: 0.2994 - val_acc: 0.9469
Epoch 11/21
 - 26s - loss: 0.3098 - acc: 0.9418 - val_loss: 0.4114 - val_acc: 0.8997
Epoch 12/21
 - 26s - loss: 0.2974 - acc: 0.9472 - val_loss: 0.2810 - val_acc: 0.9538
Epoch 13/21
 - 25s - loss: 0.2904 - acc: 0.9495 - val_loss: 0.2645 - val_acc: 0.9613
Epoch 14/21
 - 26s - loss: 0.2789 - acc: 0.9548 - val_loss: 0.2643 - val_acc: 0.9630
Epoch 15/21
 - 26s - loss: 0.2697 - acc: 0.9574 - val_loss: 0.2516 - val_acc: 0.9645
Epoch 16/21
 - 26s - loss: 0.2634 - acc: 0.9603 - val_loss: 0.2319 - val_acc: 0.9691
Epoch 17/21
 - 26s - loss: 0.2564 - acc: 0.9620 - val_loss: 0.2291 - val_acc: 0.9710
Epoch 18/21
 - 26s - loss: 0.2541 - acc: 0.9622 - val_loss: 0.2250 - val_acc: 0.9760
Epoch 19/21
 - 26s - loss: 0.2442 - acc: 0.9674 - val_loss: 0.2273 - val_acc: 0.9726
Epoch 20/21
 - 26s - loss: 0.2410 - acc: 0.9674 - val_loss: 0.2107 - val_acc: 0.9810
Epoch 21/21
 - 26s - loss: 0.2349 - acc: 0.9692 - val_loss: 0.2229 - val_acc: 0.9733
Test accuracy:0.738
current auc_score ------------------> 0.902
accuracies:  [0.8106182795698925, 0.8404569892473118, 0.8043010752688172, 0.8538978494623656, 0.8388440860215054, 0.7856182795698925, 0.8301075268817204, 0.8301075268817204, 0.7853494623655914, 0.7383064516129032]
aucs:  [0.926, 0.9242, 0.9279, 0.9236, 0.9424, 0.906, 0.9203, 0.943, 0.891, 0.9018]
mean and std AUC:  0.921+/-0.016  max:   0.943
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'TRUE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6184 - acc: 0.7761 - val_loss: 0.5266 - val_acc: 0.8186
Epoch 2/21
 - 26s - loss: 0.5147 - acc: 0.8314 - val_loss: 0.7165 - val_acc: 0.7588
Epoch 3/21
 - 26s - loss: 0.4685 - acc: 0.8594 - val_loss: 0.4843 - val_acc: 0.8569
Epoch 4/21
 - 26s - loss: 0.4329 - acc: 0.8782 - val_loss: 0.4578 - val_acc: 0.8707
Epoch 5/21
 - 26s - loss: 0.4052 - acc: 0.8943 - val_loss: 0.4080 - val_acc: 0.8887
Epoch 6/21
 - 26s - loss: 0.3836 - acc: 0.9045 - val_loss: 0.3767 - val_acc: 0.9040
Epoch 7/21
 - 26s - loss: 0.3629 - acc: 0.9140 - val_loss: 0.4223 - val_acc: 0.8888
Epoch 8/21
 - 26s - loss: 0.3457 - acc: 0.9226 - val_loss: 0.3227 - val_acc: 0.9319
Epoch 9/21
 - 26s - loss: 0.3322 - acc: 0.9273 - val_loss: 0.3174 - val_acc: 0.9347
Epoch 10/21
 - 26s - loss: 0.3192 - acc: 0.9330 - val_loss: 0.2895 - val_acc: 0.9453
Epoch 11/21
 - 26s - loss: 0.3089 - acc: 0.9376 - val_loss: 0.2842 - val_acc: 0.9480
Epoch 12/21
 - 26s - loss: 0.2979 - acc: 0.9416 - val_loss: 0.2870 - val_acc: 0.9458
Epoch 13/21
 - 26s - loss: 0.2894 - acc: 0.9461 - val_loss: 0.2884 - val_acc: 0.9404
Epoch 14/21
 - 26s - loss: 0.2795 - acc: 0.9491 - val_loss: 0.2728 - val_acc: 0.9475
Epoch 15/21
 - 26s - loss: 0.2721 - acc: 0.9512 - val_loss: 0.2652 - val_acc: 0.9524
Epoch 16/21
 - 26s - loss: 0.2645 - acc: 0.9548 - val_loss: 0.2540 - val_acc: 0.9565
Epoch 17/21
 - 26s - loss: 0.2621 - acc: 0.9548 - val_loss: 0.2277 - val_acc: 0.9688
Epoch 18/21
 - 26s - loss: 0.2526 - acc: 0.9593 - val_loss: 0.2309 - val_acc: 0.9672
Epoch 19/21
 - 26s - loss: 0.2472 - acc: 0.9606 - val_loss: 0.2292 - val_acc: 0.9644
Epoch 20/21
 - 26s - loss: 0.2412 - acc: 0.9623 - val_loss: 0.2248 - val_acc: 0.9677
Epoch 21/21
 - 26s - loss: 0.2398 - acc: 0.9623 - val_loss: 0.1999 - val_acc: 0.9802
Test accuracy:0.853
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6209 - acc: 0.7718 - val_loss: 0.7364 - val_acc: 0.7098
Epoch 2/21
 - 26s - loss: 0.5154 - acc: 0.8355 - val_loss: 0.4665 - val_acc: 0.8623
Epoch 3/21
 - 26s - loss: 0.4619 - acc: 0.8665 - val_loss: 0.4229 - val_acc: 0.8882
Epoch 4/21
 - 27s - loss: 0.4242 - acc: 0.8864 - val_loss: 0.3892 - val_acc: 0.9037
Epoch 5/21
 - 27s - loss: 0.3963 - acc: 0.8993 - val_loss: 0.4075 - val_acc: 0.8948
Epoch 6/21
 - 27s - loss: 0.3732 - acc: 0.9102 - val_loss: 0.5072 - val_acc: 0.8564
Epoch 7/21
 - 27s - loss: 0.3539 - acc: 0.9177 - val_loss: 0.3164 - val_acc: 0.9386
Epoch 8/21
 - 27s - loss: 0.3398 - acc: 0.9243 - val_loss: 0.3671 - val_acc: 0.9083
Epoch 9/21
 - 26s - loss: 0.3241 - acc: 0.9318 - val_loss: 0.3103 - val_acc: 0.9326
Epoch 10/21
 - 26s - loss: 0.3095 - acc: 0.9396 - val_loss: 0.3086 - val_acc: 0.9366
Epoch 11/21
 - 26s - loss: 0.2987 - acc: 0.9417 - val_loss: 0.3006 - val_acc: 0.9403
Epoch 12/21
 - 26s - loss: 0.2884 - acc: 0.9469 - val_loss: 0.2914 - val_acc: 0.9413
Epoch 13/21
 - 26s - loss: 0.2801 - acc: 0.9497 - val_loss: 0.2740 - val_acc: 0.9516
Epoch 14/21
 - 26s - loss: 0.2719 - acc: 0.9530 - val_loss: 0.3137 - val_acc: 0.9336
Epoch 15/21
 - 26s - loss: 0.2621 - acc: 0.9560 - val_loss: 0.2743 - val_acc: 0.9497
Epoch 16/21
 - 26s - loss: 0.2577 - acc: 0.9576 - val_loss: 0.2366 - val_acc: 0.9664
Epoch 17/21
 - 26s - loss: 0.2488 - acc: 0.9609 - val_loss: 0.3183 - val_acc: 0.9253
Epoch 18/21
 - 26s - loss: 0.2401 - acc: 0.9638 - val_loss: 0.2441 - val_acc: 0.9588
Epoch 19/21
 - 26s - loss: 0.2395 - acc: 0.9642 - val_loss: 0.2773 - val_acc: 0.9445

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 26s - loss: 0.2258 - acc: 0.9697 - val_loss: 0.2241 - val_acc: 0.9690
Epoch 21/21
 - 26s - loss: 0.2249 - acc: 0.9700 - val_loss: 0.2455 - val_acc: 0.9581
Test accuracy:0.856
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6184 - acc: 0.7741 - val_loss: 0.5831 - val_acc: 0.7989
Epoch 2/21
 - 27s - loss: 0.5080 - acc: 0.8387 - val_loss: 0.4698 - val_acc: 0.8666
Epoch 3/21
 - 27s - loss: 0.4608 - acc: 0.8673 - val_loss: 0.4548 - val_acc: 0.8676
Epoch 4/21
 - 27s - loss: 0.4280 - acc: 0.8861 - val_loss: 0.4117 - val_acc: 0.8946
Epoch 5/21
 - 27s - loss: 0.4000 - acc: 0.8971 - val_loss: 0.4710 - val_acc: 0.8514
Epoch 6/21
 - 27s - loss: 0.3759 - acc: 0.9094 - val_loss: 0.3312 - val_acc: 0.9335
Epoch 7/21
 - 27s - loss: 0.3594 - acc: 0.9183 - val_loss: 0.3616 - val_acc: 0.9120
Epoch 8/21
 - 28s - loss: 0.3404 - acc: 0.9263 - val_loss: 0.3048 - val_acc: 0.9391
Epoch 9/21
 - 27s - loss: 0.3272 - acc: 0.9312 - val_loss: 0.3251 - val_acc: 0.9300
Epoch 10/21
 - 27s - loss: 0.3154 - acc: 0.9365 - val_loss: 0.3057 - val_acc: 0.9410
Epoch 11/21
 - 27s - loss: 0.3000 - acc: 0.9422 - val_loss: 0.3125 - val_acc: 0.9340

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 27s - loss: 0.2840 - acc: 0.9497 - val_loss: 0.2511 - val_acc: 0.9655
Epoch 13/21
 - 27s - loss: 0.2794 - acc: 0.9508 - val_loss: 0.2581 - val_acc: 0.9616
Epoch 14/21
 - 27s - loss: 0.2749 - acc: 0.9528 - val_loss: 0.2506 - val_acc: 0.9642
Epoch 15/21
 - 27s - loss: 0.2728 - acc: 0.9548 - val_loss: 0.2405 - val_acc: 0.9680
Epoch 16/21
 - 27s - loss: 0.2698 - acc: 0.9554 - val_loss: 0.2393 - val_acc: 0.9685
Epoch 17/21
 - 27s - loss: 0.2670 - acc: 0.9557 - val_loss: 0.2353 - val_acc: 0.9711
Epoch 18/21
 - 27s - loss: 0.2642 - acc: 0.9567 - val_loss: 0.2263 - val_acc: 0.9759
Epoch 19/21
 - 27s - loss: 0.2632 - acc: 0.9572 - val_loss: 0.2283 - val_acc: 0.9729
Epoch 20/21
 - 27s - loss: 0.2604 - acc: 0.9584 - val_loss: 0.2282 - val_acc: 0.9735
Epoch 21/21
 - 27s - loss: 0.2549 - acc: 0.9611 - val_loss: 0.2236 - val_acc: 0.9764
Test accuracy:0.809
current auc_score ------------------> 0.903
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6187 - acc: 0.7789 - val_loss: 0.5967 - val_acc: 0.7870
Epoch 2/21
 - 26s - loss: 0.5118 - acc: 0.8367 - val_loss: 0.5418 - val_acc: 0.8190
Epoch 3/21
 - 26s - loss: 0.4621 - acc: 0.8670 - val_loss: 0.4958 - val_acc: 0.8417
Epoch 4/21
 - 26s - loss: 0.4269 - acc: 0.8849 - val_loss: 0.5118 - val_acc: 0.8351
Epoch 5/21
 - 26s - loss: 0.3974 - acc: 0.8988 - val_loss: 0.3835 - val_acc: 0.9127
Epoch 6/21
 - 26s - loss: 0.3761 - acc: 0.9094 - val_loss: 0.3695 - val_acc: 0.9137
Epoch 7/21
 - 26s - loss: 0.3605 - acc: 0.9171 - val_loss: 0.4463 - val_acc: 0.8691
Epoch 8/21
 - 26s - loss: 0.3443 - acc: 0.9240 - val_loss: 0.3227 - val_acc: 0.9327
Epoch 9/21
 - 26s - loss: 0.3303 - acc: 0.9302 - val_loss: 0.3203 - val_acc: 0.9325
Epoch 10/21
 - 26s - loss: 0.3163 - acc: 0.9350 - val_loss: 0.3473 - val_acc: 0.9184
Epoch 11/21
 - 26s - loss: 0.3053 - acc: 0.9414 - val_loss: 0.2757 - val_acc: 0.9546
Epoch 12/21
 - 26s - loss: 0.2977 - acc: 0.9436 - val_loss: 0.3090 - val_acc: 0.9357
Epoch 13/21
 - 26s - loss: 0.2876 - acc: 0.9489 - val_loss: 0.2661 - val_acc: 0.9562
Epoch 14/21
 - 26s - loss: 0.2775 - acc: 0.9508 - val_loss: 0.2483 - val_acc: 0.9649
Epoch 15/21
 - 26s - loss: 0.2711 - acc: 0.9537 - val_loss: 0.2486 - val_acc: 0.9621
Epoch 16/21
 - 26s - loss: 0.2633 - acc: 0.9570 - val_loss: 0.2229 - val_acc: 0.9758
Epoch 17/21
 - 26s - loss: 0.2547 - acc: 0.9607 - val_loss: 0.2187 - val_acc: 0.9764
Epoch 18/21
 - 26s - loss: 0.2516 - acc: 0.9610 - val_loss: 0.2135 - val_acc: 0.9765
Epoch 19/21
 - 26s - loss: 0.2453 - acc: 0.9634 - val_loss: 0.2303 - val_acc: 0.9686
Epoch 20/21
 - 26s - loss: 0.2380 - acc: 0.9652 - val_loss: 0.2019 - val_acc: 0.9807
Epoch 21/21
 - 26s - loss: 0.2331 - acc: 0.9669 - val_loss: 0.1985 - val_acc: 0.9826
Test accuracy:0.805
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6086 - acc: 0.7796 - val_loss: 0.5327 - val_acc: 0.8227
Epoch 2/21
 - 27s - loss: 0.4945 - acc: 0.8456 - val_loss: 0.5214 - val_acc: 0.8218
Epoch 3/21
 - 27s - loss: 0.4449 - acc: 0.8741 - val_loss: 0.4104 - val_acc: 0.8971
Epoch 4/21
 - 27s - loss: 0.4139 - acc: 0.8926 - val_loss: 0.4094 - val_acc: 0.9012
Epoch 5/21
 - 27s - loss: 0.3883 - acc: 0.9030 - val_loss: 0.3719 - val_acc: 0.9212
Epoch 6/21
 - 26s - loss: 0.3674 - acc: 0.9136 - val_loss: 0.3594 - val_acc: 0.9163
Epoch 7/21
 - 27s - loss: 0.3512 - acc: 0.9203 - val_loss: 0.3119 - val_acc: 0.9434
Epoch 8/21
 - 26s - loss: 0.3337 - acc: 0.9274 - val_loss: 0.3195 - val_acc: 0.9366
Epoch 9/21
 - 27s - loss: 0.3225 - acc: 0.9315 - val_loss: 0.2913 - val_acc: 0.9485
Epoch 10/21
 - 27s - loss: 0.3091 - acc: 0.9388 - val_loss: 0.2849 - val_acc: 0.9488
Epoch 11/21
 - 27s - loss: 0.2991 - acc: 0.9423 - val_loss: 0.3034 - val_acc: 0.9435
Epoch 12/21
 - 27s - loss: 0.2870 - acc: 0.9469 - val_loss: 0.2995 - val_acc: 0.9435
Epoch 13/21
 - 27s - loss: 0.2789 - acc: 0.9512 - val_loss: 0.2486 - val_acc: 0.9676
Epoch 14/21
 - 27s - loss: 0.2710 - acc: 0.9536 - val_loss: 0.2590 - val_acc: 0.9601
Epoch 15/21
 - 26s - loss: 0.2654 - acc: 0.9547 - val_loss: 0.2937 - val_acc: 0.9399
Epoch 16/21
 - 26s - loss: 0.2594 - acc: 0.9572 - val_loss: 0.2858 - val_acc: 0.9429

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/21
 - 27s - loss: 0.2463 - acc: 0.9629 - val_loss: 0.2280 - val_acc: 0.9726
Epoch 18/21
 - 27s - loss: 0.2422 - acc: 0.9643 - val_loss: 0.2238 - val_acc: 0.9745
Epoch 19/21
 - 27s - loss: 0.2411 - acc: 0.9651 - val_loss: 0.2160 - val_acc: 0.9779
Epoch 20/21
 - 27s - loss: 0.2373 - acc: 0.9655 - val_loss: 0.2157 - val_acc: 0.9764
Epoch 21/21
 - 27s - loss: 0.2332 - acc: 0.9675 - val_loss: 0.2428 - val_acc: 0.9635
Test accuracy:0.746
current auc_score ------------------> 0.892
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6082 - acc: 0.7835 - val_loss: 0.5238 - val_acc: 0.8240
Epoch 2/21
 - 26s - loss: 0.4961 - acc: 0.8469 - val_loss: 0.4619 - val_acc: 0.8668
Epoch 3/21
 - 26s - loss: 0.4493 - acc: 0.8734 - val_loss: 0.4057 - val_acc: 0.9004
Epoch 4/21
 - 26s - loss: 0.4182 - acc: 0.8904 - val_loss: 0.3777 - val_acc: 0.9124
Epoch 5/21
 - 26s - loss: 0.3925 - acc: 0.9049 - val_loss: 0.3734 - val_acc: 0.9124
Epoch 6/21
 - 26s - loss: 0.3718 - acc: 0.9123 - val_loss: 0.3552 - val_acc: 0.9198
Epoch 7/21
 - 26s - loss: 0.3537 - acc: 0.9206 - val_loss: 0.3238 - val_acc: 0.9296
Epoch 8/21
 - 26s - loss: 0.3356 - acc: 0.9302 - val_loss: 0.3727 - val_acc: 0.9042
Epoch 9/21
 - 26s - loss: 0.3215 - acc: 0.9338 - val_loss: 0.3208 - val_acc: 0.9330
Epoch 10/21
 - 26s - loss: 0.3100 - acc: 0.9388 - val_loss: 0.2807 - val_acc: 0.9462
Epoch 11/21
 - 26s - loss: 0.3014 - acc: 0.9427 - val_loss: 0.3350 - val_acc: 0.9227
Epoch 12/21
 - 26s - loss: 0.2859 - acc: 0.9485 - val_loss: 0.3298 - val_acc: 0.9281
Epoch 13/21
 - 26s - loss: 0.2807 - acc: 0.9494 - val_loss: 0.2447 - val_acc: 0.9641
Epoch 14/21
 - 26s - loss: 0.2701 - acc: 0.9550 - val_loss: 0.2335 - val_acc: 0.9698
Epoch 15/21
 - 26s - loss: 0.2625 - acc: 0.9568 - val_loss: 0.2590 - val_acc: 0.9559
Epoch 16/21
 - 26s - loss: 0.2570 - acc: 0.9593 - val_loss: 0.2356 - val_acc: 0.9661
Epoch 17/21
 - 26s - loss: 0.2484 - acc: 0.9623 - val_loss: 0.2281 - val_acc: 0.9719
Epoch 18/21
 - 26s - loss: 0.2451 - acc: 0.9625 - val_loss: 0.2218 - val_acc: 0.9715
Epoch 19/21
 - 26s - loss: 0.2400 - acc: 0.9645 - val_loss: 0.2181 - val_acc: 0.9738
Epoch 20/21
 - 26s - loss: 0.2338 - acc: 0.9677 - val_loss: 0.2020 - val_acc: 0.9799
Epoch 21/21
 - 26s - loss: 0.2291 - acc: 0.9678 - val_loss: 0.2395 - val_acc: 0.9620
Test accuracy:0.856
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6178 - acc: 0.7777 - val_loss: 0.5427 - val_acc: 0.8195
Epoch 2/21
 - 27s - loss: 0.5139 - acc: 0.8352 - val_loss: 0.4706 - val_acc: 0.8500
Epoch 3/21
 - 26s - loss: 0.4574 - acc: 0.8702 - val_loss: 0.4231 - val_acc: 0.8897
Epoch 4/21
 - 27s - loss: 0.4202 - acc: 0.8885 - val_loss: 0.3780 - val_acc: 0.9085
Epoch 5/21
 - 27s - loss: 0.3903 - acc: 0.9055 - val_loss: 0.3566 - val_acc: 0.9212
Epoch 6/21
 - 27s - loss: 0.3678 - acc: 0.9144 - val_loss: 0.3512 - val_acc: 0.9227
Epoch 7/21
 - 27s - loss: 0.3498 - acc: 0.9231 - val_loss: 0.3267 - val_acc: 0.9350
Epoch 8/21
 - 27s - loss: 0.3324 - acc: 0.9300 - val_loss: 0.2987 - val_acc: 0.9428
Epoch 9/21
 - 27s - loss: 0.3189 - acc: 0.9365 - val_loss: 0.3233 - val_acc: 0.9320
Epoch 10/21
 - 27s - loss: 0.3073 - acc: 0.9405 - val_loss: 0.3021 - val_acc: 0.9408
Epoch 11/21
 - 27s - loss: 0.2991 - acc: 0.9427 - val_loss: 0.2666 - val_acc: 0.9588
Epoch 12/21
 - 27s - loss: 0.2876 - acc: 0.9466 - val_loss: 0.2588 - val_acc: 0.9618
Epoch 13/21
 - 27s - loss: 0.2803 - acc: 0.9511 - val_loss: 0.2703 - val_acc: 0.9575
Epoch 14/21
 - 27s - loss: 0.2710 - acc: 0.9534 - val_loss: 0.2881 - val_acc: 0.9413
Epoch 15/21
 - 27s - loss: 0.2657 - acc: 0.9555 - val_loss: 0.2330 - val_acc: 0.9694
Epoch 16/21
 - 27s - loss: 0.2563 - acc: 0.9596 - val_loss: 0.2280 - val_acc: 0.9714
Epoch 17/21
 - 27s - loss: 0.2508 - acc: 0.9613 - val_loss: 0.2348 - val_acc: 0.9676
Epoch 18/21
 - 27s - loss: 0.2448 - acc: 0.9632 - val_loss: 0.2222 - val_acc: 0.9743
Epoch 19/21
 - 27s - loss: 0.2398 - acc: 0.9640 - val_loss: 0.2419 - val_acc: 0.9617
Epoch 20/21
 - 27s - loss: 0.2335 - acc: 0.9671 - val_loss: 0.1983 - val_acc: 0.9812
Epoch 21/21
 - 27s - loss: 0.2276 - acc: 0.9695 - val_loss: 0.2044 - val_acc: 0.9790
Test accuracy:0.772
current auc_score ------------------> 0.937
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6066 - acc: 0.7851 - val_loss: 0.5553 - val_acc: 0.8052
Epoch 2/21
 - 27s - loss: 0.4976 - acc: 0.8457 - val_loss: 0.5015 - val_acc: 0.8426
Epoch 3/21
 - 27s - loss: 0.4501 - acc: 0.8720 - val_loss: 0.4266 - val_acc: 0.8835
Epoch 4/21
 - 27s - loss: 0.4139 - acc: 0.8907 - val_loss: 0.4391 - val_acc: 0.8789
Epoch 5/21
 - 27s - loss: 0.3908 - acc: 0.9017 - val_loss: 0.3679 - val_acc: 0.9120
Epoch 6/21
 - 27s - loss: 0.3684 - acc: 0.9120 - val_loss: 0.3536 - val_acc: 0.9226
Epoch 7/21
 - 27s - loss: 0.3502 - acc: 0.9201 - val_loss: 0.3275 - val_acc: 0.9295
Epoch 8/21
 - 27s - loss: 0.3347 - acc: 0.9267 - val_loss: 0.3306 - val_acc: 0.9276
Epoch 9/21
 - 27s - loss: 0.3191 - acc: 0.9346 - val_loss: 0.3000 - val_acc: 0.9396
Epoch 10/21
 - 27s - loss: 0.3117 - acc: 0.9366 - val_loss: 0.3187 - val_acc: 0.9301
Epoch 11/21
 - 27s - loss: 0.2988 - acc: 0.9424 - val_loss: 0.3129 - val_acc: 0.9357
Epoch 12/21
 - 26s - loss: 0.2915 - acc: 0.9447 - val_loss: 0.2695 - val_acc: 0.9582
Epoch 13/21
 - 27s - loss: 0.2778 - acc: 0.9498 - val_loss: 0.2668 - val_acc: 0.9511
Epoch 14/21
 - 26s - loss: 0.2754 - acc: 0.9515 - val_loss: 0.2586 - val_acc: 0.9586
Epoch 15/21
 - 27s - loss: 0.2678 - acc: 0.9538 - val_loss: 0.2417 - val_acc: 0.9636
Epoch 16/21
 - 27s - loss: 0.2577 - acc: 0.9571 - val_loss: 0.2213 - val_acc: 0.9724
Epoch 17/21
 - 27s - loss: 0.2518 - acc: 0.9595 - val_loss: 0.2184 - val_acc: 0.9744
Epoch 18/21
 - 26s - loss: 0.2432 - acc: 0.9632 - val_loss: 0.2182 - val_acc: 0.9733
Epoch 19/21
 - 26s - loss: 0.2423 - acc: 0.9628 - val_loss: 0.2344 - val_acc: 0.9672
Epoch 20/21
 - 27s - loss: 0.2365 - acc: 0.9651 - val_loss: 0.2179 - val_acc: 0.9704
Epoch 21/21
 - 26s - loss: 0.2312 - acc: 0.9667 - val_loss: 0.2029 - val_acc: 0.9773
Test accuracy:0.826
current auc_score ------------------> 0.923
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6261 - acc: 0.7669 - val_loss: 0.5276 - val_acc: 0.8228
Epoch 2/21
 - 26s - loss: 0.5144 - acc: 0.8347 - val_loss: 0.5237 - val_acc: 0.8363
Epoch 3/21
 - 26s - loss: 0.4614 - acc: 0.8648 - val_loss: 0.4312 - val_acc: 0.8818
Epoch 4/21
 - 26s - loss: 0.4255 - acc: 0.8854 - val_loss: 0.4620 - val_acc: 0.8701
Epoch 5/21
 - 26s - loss: 0.3948 - acc: 0.8990 - val_loss: 0.4270 - val_acc: 0.8780
Epoch 6/21
 - 26s - loss: 0.3741 - acc: 0.9099 - val_loss: 0.3675 - val_acc: 0.9110
Epoch 7/21
 - 26s - loss: 0.3536 - acc: 0.9198 - val_loss: 0.3150 - val_acc: 0.9365
Epoch 8/21
 - 26s - loss: 0.3373 - acc: 0.9268 - val_loss: 0.3458 - val_acc: 0.9214
Epoch 9/21
 - 26s - loss: 0.3230 - acc: 0.9338 - val_loss: 0.3086 - val_acc: 0.9379
Epoch 10/21
 - 26s - loss: 0.3104 - acc: 0.9391 - val_loss: 0.2958 - val_acc: 0.9435
Epoch 11/21
 - 26s - loss: 0.2977 - acc: 0.9435 - val_loss: 0.2910 - val_acc: 0.9440
Epoch 12/21
 - 26s - loss: 0.2833 - acc: 0.9498 - val_loss: 0.2938 - val_acc: 0.9399
Epoch 13/21
 - 26s - loss: 0.2789 - acc: 0.9497 - val_loss: 0.2496 - val_acc: 0.9620
Epoch 14/21
 - 26s - loss: 0.2697 - acc: 0.9539 - val_loss: 0.2360 - val_acc: 0.9662
Epoch 15/21
 - 26s - loss: 0.2622 - acc: 0.9575 - val_loss: 0.2518 - val_acc: 0.9591
Epoch 16/21
 - 26s - loss: 0.2543 - acc: 0.9604 - val_loss: 0.2246 - val_acc: 0.9715
Epoch 17/21
 - 26s - loss: 0.2500 - acc: 0.9615 - val_loss: 0.2318 - val_acc: 0.9684
Epoch 18/21
 - 26s - loss: 0.2437 - acc: 0.9641 - val_loss: 0.2185 - val_acc: 0.9723
Epoch 19/21
 - 26s - loss: 0.2371 - acc: 0.9656 - val_loss: 0.2369 - val_acc: 0.9631
Epoch 20/21
 - 26s - loss: 0.2306 - acc: 0.9680 - val_loss: 0.2687 - val_acc: 0.9504
Epoch 21/21
 - 26s - loss: 0.2270 - acc: 0.9699 - val_loss: 0.2460 - val_acc: 0.9606

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.753
current auc_score ------------------> 0.927
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    5880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    9480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 244,548
Trainable params: 241,918
Non-trainable params: 2,630
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6156 - acc: 0.7785 - val_loss: 0.7149 - val_acc: 0.7252
Epoch 2/21
 - 27s - loss: 0.5147 - acc: 0.8362 - val_loss: 0.5404 - val_acc: 0.8203
Epoch 3/21
 - 27s - loss: 0.4669 - acc: 0.8644 - val_loss: 0.4398 - val_acc: 0.8818
Epoch 4/21
 - 27s - loss: 0.4292 - acc: 0.8850 - val_loss: 0.4338 - val_acc: 0.8849
Epoch 5/21
 - 26s - loss: 0.4053 - acc: 0.8964 - val_loss: 0.3942 - val_acc: 0.9044
Epoch 6/21
 - 26s - loss: 0.3808 - acc: 0.9082 - val_loss: 0.3905 - val_acc: 0.9014
Epoch 7/21
 - 26s - loss: 0.3594 - acc: 0.9187 - val_loss: 0.3689 - val_acc: 0.9163
Epoch 8/21
 - 27s - loss: 0.3479 - acc: 0.9230 - val_loss: 0.3438 - val_acc: 0.9244
Epoch 9/21
 - 26s - loss: 0.3307 - acc: 0.9303 - val_loss: 0.3488 - val_acc: 0.9179
Epoch 10/21
 - 27s - loss: 0.3180 - acc: 0.9366 - val_loss: 0.3386 - val_acc: 0.9242
Epoch 11/21
 - 27s - loss: 0.3066 - acc: 0.9404 - val_loss: 0.2945 - val_acc: 0.9453
Epoch 12/21
 - 27s - loss: 0.2947 - acc: 0.9447 - val_loss: 0.2713 - val_acc: 0.9551
Epoch 13/21
 - 27s - loss: 0.2874 - acc: 0.9482 - val_loss: 0.2720 - val_acc: 0.9542
Epoch 14/21
 - 27s - loss: 0.2780 - acc: 0.9510 - val_loss: 0.2366 - val_acc: 0.9688
Epoch 15/21
 - 26s - loss: 0.2703 - acc: 0.9536 - val_loss: 0.2719 - val_acc: 0.9521
Epoch 16/21
 - 26s - loss: 0.2636 - acc: 0.9572 - val_loss: 0.2331 - val_acc: 0.9706
Epoch 17/21
 - 27s - loss: 0.2551 - acc: 0.9604 - val_loss: 0.2184 - val_acc: 0.9745
Epoch 18/21
 - 27s - loss: 0.2514 - acc: 0.9601 - val_loss: 0.2238 - val_acc: 0.9757
Epoch 19/21
 - 27s - loss: 0.2422 - acc: 0.9639 - val_loss: 0.2198 - val_acc: 0.9764
Epoch 20/21
 - 27s - loss: 0.2394 - acc: 0.9646 - val_loss: 0.2307 - val_acc: 0.9674

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 27s - loss: 0.2251 - acc: 0.9707 - val_loss: 0.2048 - val_acc: 0.9817
Test accuracy:0.790
current auc_score ------------------> 0.935
accuracies:  [0.853494623655914, 0.8557795698924732, 0.8086021505376344, 0.8048387096774193, 0.7461021505376344, 0.8563172043010753, 0.7720430107526882, 0.8260752688172043, 0.7529569892473118, 0.7896505376344086]
aucs:  [0.9406, 0.9384, 0.903, 0.9377, 0.8917, 0.9345, 0.9366, 0.9232, 0.9271, 0.9351]
mean and std AUC:  0.927+/-0.016  max:   0.9406
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.7', 'TRUE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6003 - acc: 0.7793 - val_loss: 0.5919 - val_acc: 0.7801
Epoch 2/21
 - 27s - loss: 0.4947 - acc: 0.8409 - val_loss: 0.4802 - val_acc: 0.8599
Epoch 3/21
 - 27s - loss: 0.4438 - acc: 0.8702 - val_loss: 0.4353 - val_acc: 0.8791
Epoch 4/21
 - 27s - loss: 0.4155 - acc: 0.8867 - val_loss: 0.3951 - val_acc: 0.9000
Epoch 5/21
 - 27s - loss: 0.3862 - acc: 0.9011 - val_loss: 0.3667 - val_acc: 0.9134
Epoch 6/21
 - 26s - loss: 0.3671 - acc: 0.9090 - val_loss: 0.3395 - val_acc: 0.9224
Epoch 7/21
 - 26s - loss: 0.3461 - acc: 0.9198 - val_loss: 0.3137 - val_acc: 0.9398
Epoch 8/21
 - 26s - loss: 0.3302 - acc: 0.9266 - val_loss: 0.3071 - val_acc: 0.9415
Epoch 9/21
 - 26s - loss: 0.3148 - acc: 0.9339 - val_loss: 0.2890 - val_acc: 0.9454
Epoch 10/21
 - 26s - loss: 0.3045 - acc: 0.9374 - val_loss: 0.3065 - val_acc: 0.9345
Epoch 11/21
 - 27s - loss: 0.2931 - acc: 0.9425 - val_loss: 0.2551 - val_acc: 0.9608
Epoch 12/21
 - 26s - loss: 0.2840 - acc: 0.9461 - val_loss: 0.2497 - val_acc: 0.9639
Epoch 13/21
 - 27s - loss: 0.2746 - acc: 0.9496 - val_loss: 0.2664 - val_acc: 0.9576
Epoch 14/21
 - 26s - loss: 0.2632 - acc: 0.9540 - val_loss: 0.2258 - val_acc: 0.9704
Epoch 15/21
 - 26s - loss: 0.2571 - acc: 0.9566 - val_loss: 0.2445 - val_acc: 0.9600
Epoch 16/21
 - 26s - loss: 0.2545 - acc: 0.9562 - val_loss: 0.2135 - val_acc: 0.9760
Epoch 17/21
 - 26s - loss: 0.2455 - acc: 0.9607 - val_loss: 0.2176 - val_acc: 0.9704
Epoch 18/21
 - 26s - loss: 0.2440 - acc: 0.9608 - val_loss: 0.2317 - val_acc: 0.9621
Epoch 19/21
 - 26s - loss: 0.2352 - acc: 0.9638 - val_loss: 0.1922 - val_acc: 0.9846
Epoch 20/21
 - 26s - loss: 0.2297 - acc: 0.9650 - val_loss: 0.2029 - val_acc: 0.9764
Epoch 21/21
 - 26s - loss: 0.2259 - acc: 0.9673 - val_loss: 0.1920 - val_acc: 0.9827
Test accuracy:0.844
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6030 - acc: 0.7734 - val_loss: 0.7696 - val_acc: 0.7007
Epoch 2/21
 - 26s - loss: 0.4871 - acc: 0.8464 - val_loss: 0.5601 - val_acc: 0.7941
Epoch 3/21
 - 26s - loss: 0.4375 - acc: 0.8738 - val_loss: 0.4016 - val_acc: 0.8963
Epoch 4/21
 - 26s - loss: 0.4035 - acc: 0.8918 - val_loss: 0.3646 - val_acc: 0.9196
Epoch 5/21
 - 27s - loss: 0.3768 - acc: 0.9062 - val_loss: 0.3353 - val_acc: 0.9306
Epoch 6/21
 - 27s - loss: 0.3556 - acc: 0.9153 - val_loss: 0.3276 - val_acc: 0.9340
Epoch 7/21
 - 27s - loss: 0.3367 - acc: 0.9241 - val_loss: 0.3065 - val_acc: 0.9438
Epoch 8/21
 - 27s - loss: 0.3224 - acc: 0.9310 - val_loss: 0.2964 - val_acc: 0.9489
Epoch 9/21
 - 27s - loss: 0.3091 - acc: 0.9349 - val_loss: 0.2736 - val_acc: 0.9556
Epoch 10/21
 - 27s - loss: 0.2994 - acc: 0.9390 - val_loss: 0.2642 - val_acc: 0.9573
Epoch 11/21
 - 26s - loss: 0.2869 - acc: 0.9432 - val_loss: 0.2779 - val_acc: 0.9450
Epoch 12/21
 - 26s - loss: 0.2774 - acc: 0.9479 - val_loss: 0.2685 - val_acc: 0.9485
Epoch 13/21
 - 26s - loss: 0.2699 - acc: 0.9509 - val_loss: 0.2510 - val_acc: 0.9636
Epoch 14/21
 - 27s - loss: 0.2589 - acc: 0.9542 - val_loss: 0.2401 - val_acc: 0.9642
Epoch 15/21
 - 27s - loss: 0.2572 - acc: 0.9559 - val_loss: 0.2200 - val_acc: 0.9695
Epoch 16/21
 - 26s - loss: 0.2481 - acc: 0.9590 - val_loss: 0.2095 - val_acc: 0.9767
Epoch 17/21
 - 27s - loss: 0.2409 - acc: 0.9608 - val_loss: 0.2186 - val_acc: 0.9728
Epoch 18/21
 - 27s - loss: 0.2356 - acc: 0.9635 - val_loss: 0.2024 - val_acc: 0.9784
Epoch 19/21
 - 27s - loss: 0.2325 - acc: 0.9638 - val_loss: 0.1933 - val_acc: 0.9838
Epoch 20/21
 - 27s - loss: 0.2257 - acc: 0.9664 - val_loss: 0.2021 - val_acc: 0.9790
Epoch 21/21
 - 27s - loss: 0.2226 - acc: 0.9679 - val_loss: 0.2024 - val_acc: 0.9725
Test accuracy:0.822
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6059 - acc: 0.7723 - val_loss: 0.5864 - val_acc: 0.7953
Epoch 2/21
 - 27s - loss: 0.4904 - acc: 0.8447 - val_loss: 0.4551 - val_acc: 0.8671
Epoch 3/21
 - 27s - loss: 0.4447 - acc: 0.8695 - val_loss: 0.4334 - val_acc: 0.8731
Epoch 4/21
 - 27s - loss: 0.4136 - acc: 0.8862 - val_loss: 0.4326 - val_acc: 0.8741
Epoch 5/21
 - 27s - loss: 0.3911 - acc: 0.8980 - val_loss: 0.3554 - val_acc: 0.9162
Epoch 6/21
 - 27s - loss: 0.3691 - acc: 0.9082 - val_loss: 0.3641 - val_acc: 0.9094
Epoch 7/21
 - 27s - loss: 0.3508 - acc: 0.9164 - val_loss: 0.3190 - val_acc: 0.9356
Epoch 8/21
 - 27s - loss: 0.3357 - acc: 0.9243 - val_loss: 0.3541 - val_acc: 0.9125
Epoch 9/21
 - 27s - loss: 0.3240 - acc: 0.9287 - val_loss: 0.3053 - val_acc: 0.9335
Epoch 10/21
 - 27s - loss: 0.3143 - acc: 0.9332 - val_loss: 0.3974 - val_acc: 0.8973
Epoch 11/21
 - 27s - loss: 0.3020 - acc: 0.9383 - val_loss: 0.3206 - val_acc: 0.9252
Epoch 00011: early stopping
Test accuracy:0.853
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.6104 - acc: 0.7733 - val_loss: 0.6454 - val_acc: 0.7496
Epoch 2/21
 - 27s - loss: 0.5063 - acc: 0.8320 - val_loss: 0.4853 - val_acc: 0.8469
Epoch 3/21
 - 27s - loss: 0.4598 - acc: 0.8583 - val_loss: 0.4375 - val_acc: 0.8744
Epoch 4/21
 - 27s - loss: 0.4225 - acc: 0.8826 - val_loss: 0.3912 - val_acc: 0.8947
Epoch 5/21
 - 27s - loss: 0.3964 - acc: 0.8958 - val_loss: 0.3605 - val_acc: 0.9162
Epoch 6/21
 - 26s - loss: 0.3742 - acc: 0.9059 - val_loss: 0.3922 - val_acc: 0.8922
Epoch 7/21
 - 26s - loss: 0.3528 - acc: 0.9154 - val_loss: 0.3172 - val_acc: 0.9330
Epoch 8/21
 - 26s - loss: 0.3363 - acc: 0.9236 - val_loss: 0.3492 - val_acc: 0.9164
Epoch 9/21
 - 26s - loss: 0.3210 - acc: 0.9306 - val_loss: 0.2891 - val_acc: 0.9413
Epoch 10/21
 - 26s - loss: 0.3073 - acc: 0.9365 - val_loss: 0.2826 - val_acc: 0.9455
Epoch 11/21
 - 26s - loss: 0.2973 - acc: 0.9412 - val_loss: 0.2626 - val_acc: 0.9571
Epoch 12/21
 - 26s - loss: 0.2882 - acc: 0.9433 - val_loss: 0.2571 - val_acc: 0.9562
Epoch 13/21
 - 27s - loss: 0.2804 - acc: 0.9470 - val_loss: 0.2694 - val_acc: 0.9499
Epoch 14/21
 - 27s - loss: 0.2734 - acc: 0.9502 - val_loss: 0.2671 - val_acc: 0.9508
Epoch 15/21
 - 27s - loss: 0.2636 - acc: 0.9531 - val_loss: 0.2317 - val_acc: 0.9684
Epoch 16/21
 - 26s - loss: 0.2581 - acc: 0.9556 - val_loss: 0.2249 - val_acc: 0.9704
Epoch 17/21
 - 27s - loss: 0.2509 - acc: 0.9575 - val_loss: 0.2168 - val_acc: 0.9719
Epoch 18/21
 - 26s - loss: 0.2492 - acc: 0.9579 - val_loss: 0.2333 - val_acc: 0.9610
Epoch 19/21
 - 26s - loss: 0.2395 - acc: 0.9616 - val_loss: 0.2042 - val_acc: 0.9777
Epoch 20/21
 - 27s - loss: 0.2356 - acc: 0.9630 - val_loss: 0.2051 - val_acc: 0.9719
Epoch 21/21
 - 27s - loss: 0.2294 - acc: 0.9654 - val_loss: 0.1873 - val_acc: 0.9828
Test accuracy:0.826
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6049 - acc: 0.7832 - val_loss: 0.5570 - val_acc: 0.8075
Epoch 2/21
 - 26s - loss: 0.4866 - acc: 0.8506 - val_loss: 0.4642 - val_acc: 0.8572
Epoch 3/21
 - 27s - loss: 0.4393 - acc: 0.8743 - val_loss: 0.4081 - val_acc: 0.8940
Epoch 4/21
 - 27s - loss: 0.4108 - acc: 0.8885 - val_loss: 0.4236 - val_acc: 0.8799
Epoch 5/21
 - 27s - loss: 0.3868 - acc: 0.9013 - val_loss: 0.3855 - val_acc: 0.8968
Epoch 6/21
 - 27s - loss: 0.3644 - acc: 0.9092 - val_loss: 0.3850 - val_acc: 0.8981
Epoch 7/21
 - 27s - loss: 0.3484 - acc: 0.9174 - val_loss: 0.3700 - val_acc: 0.9052
Epoch 8/21
 - 27s - loss: 0.3324 - acc: 0.9267 - val_loss: 0.3005 - val_acc: 0.9415
Epoch 9/21
 - 27s - loss: 0.3225 - acc: 0.9288 - val_loss: 0.3294 - val_acc: 0.9302
Epoch 10/21
 - 26s - loss: 0.3080 - acc: 0.9374 - val_loss: 0.2826 - val_acc: 0.9480
Epoch 11/21
 - 26s - loss: 0.2999 - acc: 0.9386 - val_loss: 0.2982 - val_acc: 0.9356
Epoch 12/21
 - 27s - loss: 0.2914 - acc: 0.9424 - val_loss: 0.2674 - val_acc: 0.9532
Epoch 13/21
 - 27s - loss: 0.2833 - acc: 0.9456 - val_loss: 0.2688 - val_acc: 0.9514
Epoch 14/21
 - 27s - loss: 0.2737 - acc: 0.9506 - val_loss: 0.2592 - val_acc: 0.9570
Epoch 15/21
 - 27s - loss: 0.2660 - acc: 0.9525 - val_loss: 0.2583 - val_acc: 0.9554
Epoch 16/21
 - 27s - loss: 0.2599 - acc: 0.9549 - val_loss: 0.2489 - val_acc: 0.9570
Epoch 17/21
 - 27s - loss: 0.2510 - acc: 0.9578 - val_loss: 0.2629 - val_acc: 0.9501
Epoch 18/21
 - 27s - loss: 0.2485 - acc: 0.9585 - val_loss: 0.2230 - val_acc: 0.9698
Epoch 19/21
 - 27s - loss: 0.2404 - acc: 0.9622 - val_loss: 0.2216 - val_acc: 0.9686
Epoch 20/21
 - 27s - loss: 0.2414 - acc: 0.9599 - val_loss: 0.2273 - val_acc: 0.9662
Epoch 21/21
 - 27s - loss: 0.2316 - acc: 0.9647 - val_loss: 0.2032 - val_acc: 0.9774
Test accuracy:0.786
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 31s - loss: 0.6007 - acc: 0.7818 - val_loss: 1.0027 - val_acc: 0.6658
Epoch 2/21
 - 28s - loss: 0.4910 - acc: 0.8447 - val_loss: 0.4595 - val_acc: 0.8617
Epoch 3/21
 - 28s - loss: 0.4423 - acc: 0.8725 - val_loss: 0.4071 - val_acc: 0.8912
Epoch 4/21
 - 28s - loss: 0.4116 - acc: 0.8890 - val_loss: 0.3937 - val_acc: 0.8987
Epoch 5/21
 - 28s - loss: 0.3871 - acc: 0.8999 - val_loss: 0.3967 - val_acc: 0.8907
Epoch 6/21
 - 28s - loss: 0.3657 - acc: 0.9117 - val_loss: 0.3377 - val_acc: 0.9296
Epoch 7/21
 - 28s - loss: 0.3496 - acc: 0.9182 - val_loss: 0.3617 - val_acc: 0.9150
Epoch 8/21
 - 28s - loss: 0.3326 - acc: 0.9252 - val_loss: 0.3726 - val_acc: 0.8998
Epoch 9/21
 - 28s - loss: 0.3190 - acc: 0.9327 - val_loss: 0.2913 - val_acc: 0.9472
Epoch 10/21
 - 28s - loss: 0.3074 - acc: 0.9383 - val_loss: 0.3100 - val_acc: 0.9356
Epoch 11/21
 - 28s - loss: 0.2985 - acc: 0.9394 - val_loss: 0.2771 - val_acc: 0.9493
Epoch 12/21
 - 28s - loss: 0.2883 - acc: 0.9457 - val_loss: 0.2711 - val_acc: 0.9507
Epoch 13/21
 - 28s - loss: 0.2804 - acc: 0.9482 - val_loss: 0.2963 - val_acc: 0.9395
Epoch 14/21
 - 27s - loss: 0.2719 - acc: 0.9503 - val_loss: 0.2580 - val_acc: 0.9576
Epoch 15/21
 - 27s - loss: 0.2623 - acc: 0.9536 - val_loss: 0.2422 - val_acc: 0.9644
Epoch 16/21
 - 27s - loss: 0.2549 - acc: 0.9578 - val_loss: 0.2347 - val_acc: 0.9689
Epoch 17/21
 - 27s - loss: 0.2501 - acc: 0.9584 - val_loss: 0.2165 - val_acc: 0.9748
Epoch 18/21
 - 27s - loss: 0.2452 - acc: 0.9600 - val_loss: 0.2119 - val_acc: 0.9765
Epoch 19/21
 - 27s - loss: 0.2365 - acc: 0.9633 - val_loss: 0.2180 - val_acc: 0.9694
Epoch 20/21
 - 27s - loss: 0.2341 - acc: 0.9648 - val_loss: 0.2022 - val_acc: 0.9809
Epoch 21/21
 - 27s - loss: 0.2298 - acc: 0.9648 - val_loss: 0.2120 - val_acc: 0.9736
Test accuracy:0.783
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6048 - acc: 0.7709 - val_loss: 0.5987 - val_acc: 0.7745
Epoch 2/21
 - 27s - loss: 0.4936 - acc: 0.8419 - val_loss: 0.6029 - val_acc: 0.7737
Epoch 3/21
 - 27s - loss: 0.4496 - acc: 0.8676 - val_loss: 0.4424 - val_acc: 0.8770
Epoch 4/21
 - 26s - loss: 0.4203 - acc: 0.8836 - val_loss: 0.4297 - val_acc: 0.8776
Epoch 5/21
 - 27s - loss: 0.3920 - acc: 0.8984 - val_loss: 0.4339 - val_acc: 0.8676
Epoch 6/21
 - 27s - loss: 0.3719 - acc: 0.9072 - val_loss: 0.3410 - val_acc: 0.9238
Epoch 7/21
 - 27s - loss: 0.3573 - acc: 0.9125 - val_loss: 0.3256 - val_acc: 0.9346
Epoch 8/21
 - 27s - loss: 0.3434 - acc: 0.9191 - val_loss: 0.3104 - val_acc: 0.9364
Epoch 9/21
 - 27s - loss: 0.3315 - acc: 0.9246 - val_loss: 0.3120 - val_acc: 0.9350
Epoch 10/21
 - 27s - loss: 0.3182 - acc: 0.9303 - val_loss: 0.2964 - val_acc: 0.9420
Epoch 11/21
 - 27s - loss: 0.3057 - acc: 0.9364 - val_loss: 0.2879 - val_acc: 0.9415
Epoch 12/21
 - 27s - loss: 0.2969 - acc: 0.9399 - val_loss: 0.2669 - val_acc: 0.9577
Epoch 13/21
 - 27s - loss: 0.2881 - acc: 0.9436 - val_loss: 0.2632 - val_acc: 0.9543
Epoch 14/21
 - 27s - loss: 0.2806 - acc: 0.9458 - val_loss: 0.2571 - val_acc: 0.9570
Epoch 15/21
 - 27s - loss: 0.2727 - acc: 0.9493 - val_loss: 0.2290 - val_acc: 0.9725
Epoch 16/21
 - 27s - loss: 0.2645 - acc: 0.9524 - val_loss: 0.2426 - val_acc: 0.9635
Epoch 17/21
 - 27s - loss: 0.2591 - acc: 0.9533 - val_loss: 0.2233 - val_acc: 0.9713
Epoch 18/21
 - 27s - loss: 0.2553 - acc: 0.9552 - val_loss: 0.2266 - val_acc: 0.9705
Epoch 19/21
 - 27s - loss: 0.2457 - acc: 0.9582 - val_loss: 0.2160 - val_acc: 0.9721
Epoch 00019: early stopping
Test accuracy:0.838
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6102 - acc: 0.7717 - val_loss: 0.6491 - val_acc: 0.7467
Epoch 2/21
 - 28s - loss: 0.4913 - acc: 0.8449 - val_loss: 0.4720 - val_acc: 0.8470
Epoch 3/21
 - 28s - loss: 0.4423 - acc: 0.8719 - val_loss: 0.4236 - val_acc: 0.8839
Epoch 4/21
 - 28s - loss: 0.4074 - acc: 0.8898 - val_loss: 0.3846 - val_acc: 0.9025
Epoch 5/21
 - 28s - loss: 0.3826 - acc: 0.9008 - val_loss: 0.3942 - val_acc: 0.8933
Epoch 6/21
 - 27s - loss: 0.3653 - acc: 0.9101 - val_loss: 0.3363 - val_acc: 0.9241
Epoch 7/21
 - 27s - loss: 0.3465 - acc: 0.9175 - val_loss: 0.3257 - val_acc: 0.9300
Epoch 8/21
 - 27s - loss: 0.3293 - acc: 0.9264 - val_loss: 0.3002 - val_acc: 0.9434
Epoch 9/21
 - 27s - loss: 0.3184 - acc: 0.9306 - val_loss: 0.3403 - val_acc: 0.9173
Epoch 10/21
 - 27s - loss: 0.3063 - acc: 0.9353 - val_loss: 0.3784 - val_acc: 0.8998
Epoch 11/21
 - 27s - loss: 0.2953 - acc: 0.9408 - val_loss: 0.2904 - val_acc: 0.9404
Epoch 12/21
 - 27s - loss: 0.2879 - acc: 0.9435 - val_loss: 0.2699 - val_acc: 0.9504
Epoch 13/21
 - 27s - loss: 0.2783 - acc: 0.9467 - val_loss: 0.2972 - val_acc: 0.9366
Epoch 14/21
 - 27s - loss: 0.2701 - acc: 0.9491 - val_loss: 0.2526 - val_acc: 0.9541
Epoch 15/21
 - 27s - loss: 0.2636 - acc: 0.9512 - val_loss: 0.2418 - val_acc: 0.9616
Epoch 16/21
 - 27s - loss: 0.2579 - acc: 0.9535 - val_loss: 0.2898 - val_acc: 0.9372
Epoch 17/21
 - 27s - loss: 0.2485 - acc: 0.9584 - val_loss: 0.2496 - val_acc: 0.9581
Epoch 18/21
 - 27s - loss: 0.2438 - acc: 0.9587 - val_loss: 0.2162 - val_acc: 0.9695
Epoch 19/21
 - 28s - loss: 0.2420 - acc: 0.9594 - val_loss: 0.2033 - val_acc: 0.9768
Epoch 20/21
 - 27s - loss: 0.2355 - acc: 0.9617 - val_loss: 0.1978 - val_acc: 0.9785
Epoch 21/21
 - 27s - loss: 0.2281 - acc: 0.9646 - val_loss: 0.2252 - val_acc: 0.9659
Test accuracy:0.814
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 30s - loss: 0.6225 - acc: 0.7625 - val_loss: 0.5743 - val_acc: 0.7888
Epoch 2/21
 - 27s - loss: 0.5165 - acc: 0.8270 - val_loss: 0.4643 - val_acc: 0.8532
Epoch 3/21
 - 27s - loss: 0.4702 - acc: 0.8537 - val_loss: 0.4467 - val_acc: 0.8665
Epoch 4/21
 - 27s - loss: 0.4307 - acc: 0.8770 - val_loss: 0.3996 - val_acc: 0.8883
Epoch 5/21
 - 27s - loss: 0.4028 - acc: 0.8915 - val_loss: 0.3683 - val_acc: 0.9061
Epoch 6/21
 - 27s - loss: 0.3780 - acc: 0.9055 - val_loss: 0.3505 - val_acc: 0.9193
Epoch 7/21
 - 27s - loss: 0.3579 - acc: 0.9140 - val_loss: 0.3289 - val_acc: 0.9267
Epoch 8/21
 - 27s - loss: 0.3425 - acc: 0.9199 - val_loss: 0.3010 - val_acc: 0.9438
Epoch 9/21
 - 27s - loss: 0.3280 - acc: 0.9284 - val_loss: 0.3069 - val_acc: 0.9362
Epoch 10/21
 - 27s - loss: 0.3150 - acc: 0.9340 - val_loss: 0.3016 - val_acc: 0.9355
Epoch 11/21
 - 27s - loss: 0.3043 - acc: 0.9378 - val_loss: 0.2688 - val_acc: 0.9570
Epoch 12/21
 - 27s - loss: 0.2965 - acc: 0.9403 - val_loss: 0.3006 - val_acc: 0.9331
Epoch 13/21
 - 27s - loss: 0.2886 - acc: 0.9446 - val_loss: 0.2743 - val_acc: 0.9485
Epoch 14/21
 - 27s - loss: 0.2768 - acc: 0.9482 - val_loss: 0.2488 - val_acc: 0.9600
Epoch 15/21
 - 27s - loss: 0.2677 - acc: 0.9505 - val_loss: 0.2327 - val_acc: 0.9676
Epoch 16/21
 - 27s - loss: 0.2666 - acc: 0.9509 - val_loss: 0.2672 - val_acc: 0.9470
Epoch 17/21
 - 27s - loss: 0.2545 - acc: 0.9569 - val_loss: 0.2242 - val_acc: 0.9680
Epoch 18/21
 - 27s - loss: 0.2515 - acc: 0.9569 - val_loss: 0.2324 - val_acc: 0.9616
Epoch 19/21
 - 27s - loss: 0.2421 - acc: 0.9601 - val_loss: 0.2203 - val_acc: 0.9675
Epoch 20/21
 - 27s - loss: 0.2399 - acc: 0.9620 - val_loss: 0.2097 - val_acc: 0.9749
Epoch 21/21
 - 27s - loss: 0.2343 - acc: 0.9624 - val_loss: 0.1994 - val_acc: 0.9775
Test accuracy:0.837
current auc_score ------------------> 0.931
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.7  bottleneck:  True
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  2640        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  6240        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 82, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 24, 12, 12)   1968        activation_11[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 24, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 24, 6, 6)     96          average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 24, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 120, 6, 6)    2880        activation_12[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 120, 6, 6)    0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 54, 6, 6)     216         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 54, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 120, 6, 6)    6480        activation_14[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 120, 6, 6)    480         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 120, 6, 6)    0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     32400       activation_15[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 84, 6, 6)     336         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 84, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 84)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            85          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 230,141
Trainable params: 227,757
Non-trainable params: 2,384
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 29s - loss: 0.5987 - acc: 0.7804 - val_loss: 0.5163 - val_acc: 0.8194
Epoch 2/21
 - 27s - loss: 0.4871 - acc: 0.8476 - val_loss: 0.4272 - val_acc: 0.8800
Epoch 3/21
 - 27s - loss: 0.4382 - acc: 0.8756 - val_loss: 0.4236 - val_acc: 0.8892
Epoch 4/21
 - 27s - loss: 0.4064 - acc: 0.8926 - val_loss: 0.4273 - val_acc: 0.8774
Epoch 5/21
 - 27s - loss: 0.3805 - acc: 0.9034 - val_loss: 0.3524 - val_acc: 0.9233
Epoch 6/21
 - 27s - loss: 0.3605 - acc: 0.9122 - val_loss: 0.3556 - val_acc: 0.9227
Epoch 7/21
 - 27s - loss: 0.3435 - acc: 0.9211 - val_loss: 0.3715 - val_acc: 0.9066
Epoch 8/21
 - 27s - loss: 0.3258 - acc: 0.9276 - val_loss: 0.3082 - val_acc: 0.9394
Epoch 9/21
 - 27s - loss: 0.3144 - acc: 0.9337 - val_loss: 0.3060 - val_acc: 0.9389
Epoch 10/21
 - 27s - loss: 0.2982 - acc: 0.9400 - val_loss: 0.2690 - val_acc: 0.9554
Epoch 11/21
 - 27s - loss: 0.2911 - acc: 0.9435 - val_loss: 0.2619 - val_acc: 0.9575
Epoch 12/21
 - 27s - loss: 0.2794 - acc: 0.9472 - val_loss: 0.2738 - val_acc: 0.9503
Epoch 13/21
 - 27s - loss: 0.2732 - acc: 0.9510 - val_loss: 0.2668 - val_acc: 0.9549
Epoch 14/21
 - 27s - loss: 0.2645 - acc: 0.9543 - val_loss: 0.2466 - val_acc: 0.9598
Epoch 15/21
 - 27s - loss: 0.2618 - acc: 0.9540 - val_loss: 0.2867 - val_acc: 0.9419
Epoch 16/21
 - 28s - loss: 0.2514 - acc: 0.9581 - val_loss: 0.2543 - val_acc: 0.9531
Epoch 17/21
 - 27s - loss: 0.2451 - acc: 0.9608 - val_loss: 0.2155 - val_acc: 0.9723
Epoch 18/21
 - 27s - loss: 0.2385 - acc: 0.9632 - val_loss: 0.2244 - val_acc: 0.9713
Epoch 19/21
 - 27s - loss: 0.2360 - acc: 0.9631 - val_loss: 0.2085 - val_acc: 0.9752
Epoch 20/21
 - 27s - loss: 0.2296 - acc: 0.9663 - val_loss: 0.2226 - val_acc: 0.9686
Epoch 21/21
 - 27s - loss: 0.2254 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.9803
Test accuracy:0.813
current auc_score ------------------> 0.925
accuracies:  [0.8443548387096774, 0.8220430107526882, 0.8530913978494624, 0.8256720430107527, 0.785752688172043, 0.7831989247311828, 0.8377688172043011, 0.8137096774193548, 0.8370967741935483, 0.8133064516129033]
aucs:  [0.9174, 0.9144, 0.9349, 0.9376, 0.9104, 0.9294, 0.9174, 0.922, 0.9313, 0.9255]
mean and std AUC:  0.924+/-0.009  max:   0.9376
['2-2-2', '30', '3', '16', '0', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4896 - acc: 0.7707 - val_loss: 0.4291 - val_acc: 0.7997
Epoch 2/21
 - 20s - loss: 0.3760 - acc: 0.8360 - val_loss: 0.3442 - val_acc: 0.8520
Epoch 3/21
 - 20s - loss: 0.3185 - acc: 0.8697 - val_loss: 0.3126 - val_acc: 0.8729
Epoch 4/21
 - 20s - loss: 0.2827 - acc: 0.8882 - val_loss: 0.2535 - val_acc: 0.9039
Epoch 5/21
 - 20s - loss: 0.2557 - acc: 0.9036 - val_loss: 0.2340 - val_acc: 0.9121
Epoch 6/21
 - 20s - loss: 0.2338 - acc: 0.9142 - val_loss: 0.2114 - val_acc: 0.9287
Epoch 7/21
 - 20s - loss: 0.2128 - acc: 0.9246 - val_loss: 0.2207 - val_acc: 0.9196
Epoch 8/21
 - 20s - loss: 0.1970 - acc: 0.9313 - val_loss: 0.1946 - val_acc: 0.9306
Epoch 9/21
 - 20s - loss: 0.1852 - acc: 0.9367 - val_loss: 0.1837 - val_acc: 0.9410
Epoch 10/21
 - 20s - loss: 0.1712 - acc: 0.9426 - val_loss: 0.1790 - val_acc: 0.9376
Epoch 11/21
 - 20s - loss: 0.1588 - acc: 0.9483 - val_loss: 0.1504 - val_acc: 0.9538
Epoch 12/21
 - 20s - loss: 0.1508 - acc: 0.9512 - val_loss: 0.1465 - val_acc: 0.9533
Epoch 13/21
 - 20s - loss: 0.1395 - acc: 0.9568 - val_loss: 0.1491 - val_acc: 0.9493
Epoch 14/21
 - 20s - loss: 0.1322 - acc: 0.9592 - val_loss: 0.1295 - val_acc: 0.9596
Epoch 15/21
 - 20s - loss: 0.1251 - acc: 0.9624 - val_loss: 0.1026 - val_acc: 0.9728
Epoch 16/21
 - 20s - loss: 0.1179 - acc: 0.9655 - val_loss: 0.1072 - val_acc: 0.9714
Epoch 17/21
 - 20s - loss: 0.1100 - acc: 0.9681 - val_loss: 0.2018 - val_acc: 0.9263
Epoch 18/21
 - 20s - loss: 0.1048 - acc: 0.9701 - val_loss: 0.1264 - val_acc: 0.9551

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 20s - loss: 0.0928 - acc: 0.9753 - val_loss: 0.0898 - val_acc: 0.9765
Epoch 20/21
 - 20s - loss: 0.0901 - acc: 0.9766 - val_loss: 0.0739 - val_acc: 0.9842
Epoch 21/21
 - 20s - loss: 0.0866 - acc: 0.9771 - val_loss: 0.0732 - val_acc: 0.9833
Test accuracy:0.820
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4717 - acc: 0.7826 - val_loss: 0.4316 - val_acc: 0.7969
Epoch 2/21
 - 20s - loss: 0.3599 - acc: 0.8467 - val_loss: 0.3339 - val_acc: 0.8586
Epoch 3/21
 - 20s - loss: 0.3130 - acc: 0.8712 - val_loss: 0.3816 - val_acc: 0.8417
Epoch 4/21
 - 20s - loss: 0.2796 - acc: 0.8906 - val_loss: 0.2693 - val_acc: 0.8952
Epoch 5/21
 - 20s - loss: 0.2509 - acc: 0.9057 - val_loss: 0.2475 - val_acc: 0.9052
Epoch 6/21
 - 20s - loss: 0.2299 - acc: 0.9153 - val_loss: 0.2044 - val_acc: 0.9346
Epoch 7/21
 - 20s - loss: 0.2106 - acc: 0.9257 - val_loss: 0.2025 - val_acc: 0.9317
Epoch 8/21
 - 20s - loss: 0.1959 - acc: 0.9322 - val_loss: 0.2019 - val_acc: 0.9296
Epoch 9/21
 - 20s - loss: 0.1811 - acc: 0.9380 - val_loss: 0.2021 - val_acc: 0.9209
Epoch 10/21
 - 20s - loss: 0.1705 - acc: 0.9423 - val_loss: 0.1709 - val_acc: 0.9424
Epoch 11/21
 - 20s - loss: 0.1564 - acc: 0.9487 - val_loss: 0.2683 - val_acc: 0.8916
Epoch 12/21
 - 20s - loss: 0.1480 - acc: 0.9520 - val_loss: 0.1690 - val_acc: 0.9425
Epoch 13/21
 - 20s - loss: 0.1401 - acc: 0.9556 - val_loss: 0.1613 - val_acc: 0.9464
Epoch 14/21
 - 20s - loss: 0.1303 - acc: 0.9587 - val_loss: 0.1404 - val_acc: 0.9512
Epoch 15/21
 - 20s - loss: 0.1267 - acc: 0.9607 - val_loss: 0.2126 - val_acc: 0.9204
Epoch 16/21
 - 20s - loss: 0.1172 - acc: 0.9651 - val_loss: 0.1487 - val_acc: 0.9472
Epoch 17/21
 - 20s - loss: 0.1116 - acc: 0.9668 - val_loss: 0.0845 - val_acc: 0.9799
Epoch 18/21
 - 20s - loss: 0.1081 - acc: 0.9684 - val_loss: 0.0982 - val_acc: 0.9735
Epoch 19/21
 - 20s - loss: 0.0996 - acc: 0.9718 - val_loss: 0.1032 - val_acc: 0.9667
Epoch 20/21
 - 19s - loss: 0.0956 - acc: 0.9723 - val_loss: 0.0813 - val_acc: 0.9813
Epoch 21/21
 - 20s - loss: 0.0905 - acc: 0.9755 - val_loss: 0.0774 - val_acc: 0.9809
Test accuracy:0.811
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4874 - acc: 0.7613 - val_loss: 0.4564 - val_acc: 0.7859
Epoch 2/21
 - 20s - loss: 0.3758 - acc: 0.8298 - val_loss: 0.3410 - val_acc: 0.8444
Epoch 3/21
 - 20s - loss: 0.3211 - acc: 0.8661 - val_loss: 0.2879 - val_acc: 0.8844
Epoch 4/21
 - 20s - loss: 0.2821 - acc: 0.8892 - val_loss: 0.3215 - val_acc: 0.8707
Epoch 5/21
 - 20s - loss: 0.2509 - acc: 0.9060 - val_loss: 0.2520 - val_acc: 0.9045
Epoch 6/21
 - 20s - loss: 0.2263 - acc: 0.9188 - val_loss: 0.2296 - val_acc: 0.9170
Epoch 7/21
 - 20s - loss: 0.2037 - acc: 0.9290 - val_loss: 0.2178 - val_acc: 0.9143
Epoch 8/21
 - 20s - loss: 0.1867 - acc: 0.9374 - val_loss: 0.1676 - val_acc: 0.9433
Epoch 9/21
 - 19s - loss: 0.1726 - acc: 0.9425 - val_loss: 0.1663 - val_acc: 0.9428
Epoch 10/21
 - 20s - loss: 0.1581 - acc: 0.9487 - val_loss: 0.1680 - val_acc: 0.9470
Epoch 11/21
 - 20s - loss: 0.1461 - acc: 0.9524 - val_loss: 0.1387 - val_acc: 0.9590
Epoch 12/21
 - 20s - loss: 0.1373 - acc: 0.9569 - val_loss: 0.1155 - val_acc: 0.9686
Epoch 13/21
 - 20s - loss: 0.1277 - acc: 0.9617 - val_loss: 0.1295 - val_acc: 0.9581
Epoch 14/21
 - 20s - loss: 0.1196 - acc: 0.9648 - val_loss: 0.1087 - val_acc: 0.9708
Epoch 15/21
 - 20s - loss: 0.1136 - acc: 0.9663 - val_loss: 0.1121 - val_acc: 0.9654
Epoch 16/21
 - 20s - loss: 0.1056 - acc: 0.9701 - val_loss: 0.0902 - val_acc: 0.9787
Epoch 17/21
 - 20s - loss: 0.1007 - acc: 0.9718 - val_loss: 0.0788 - val_acc: 0.9827
Epoch 18/21
 - 20s - loss: 0.0956 - acc: 0.9727 - val_loss: 0.0885 - val_acc: 0.9752
Epoch 19/21
 - 20s - loss: 0.0890 - acc: 0.9759 - val_loss: 0.0691 - val_acc: 0.9843
Epoch 20/21
 - 20s - loss: 0.0854 - acc: 0.9776 - val_loss: 0.1642 - val_acc: 0.9409
Epoch 21/21
 - 19s - loss: 0.0808 - acc: 0.9790 - val_loss: 0.1098 - val_acc: 0.9657
Test accuracy:0.786
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4799 - acc: 0.7713 - val_loss: 0.4806 - val_acc: 0.7794
Epoch 2/21
 - 20s - loss: 0.3654 - acc: 0.8421 - val_loss: 0.3499 - val_acc: 0.8435
Epoch 3/21
 - 20s - loss: 0.3115 - acc: 0.8724 - val_loss: 0.3258 - val_acc: 0.8635
Epoch 4/21
 - 20s - loss: 0.2756 - acc: 0.8929 - val_loss: 0.2628 - val_acc: 0.9009
Epoch 5/21
 - 20s - loss: 0.2466 - acc: 0.9065 - val_loss: 0.2179 - val_acc: 0.9191
Epoch 6/21
 - 20s - loss: 0.2254 - acc: 0.9160 - val_loss: 0.2184 - val_acc: 0.9164
Epoch 7/21
 - 20s - loss: 0.2071 - acc: 0.9247 - val_loss: 0.1929 - val_acc: 0.9319
Epoch 8/21
 - 20s - loss: 0.1924 - acc: 0.9327 - val_loss: 0.1717 - val_acc: 0.9429
Epoch 9/21
 - 20s - loss: 0.1792 - acc: 0.9385 - val_loss: 0.1698 - val_acc: 0.9406
Epoch 10/21
 - 20s - loss: 0.1643 - acc: 0.9451 - val_loss: 0.1417 - val_acc: 0.9547
Epoch 11/21
 - 20s - loss: 0.1526 - acc: 0.9514 - val_loss: 0.1305 - val_acc: 0.9606
Epoch 12/21
 - 20s - loss: 0.1430 - acc: 0.9547 - val_loss: 0.1180 - val_acc: 0.9656
Epoch 13/21
 - 20s - loss: 0.1367 - acc: 0.9558 - val_loss: 0.1327 - val_acc: 0.9558
Epoch 14/21
 - 20s - loss: 0.1270 - acc: 0.9615 - val_loss: 0.1298 - val_acc: 0.9591
Epoch 15/21
 - 20s - loss: 0.1182 - acc: 0.9640 - val_loss: 0.1053 - val_acc: 0.9701
Epoch 16/21
 - 20s - loss: 0.1126 - acc: 0.9661 - val_loss: 0.1021 - val_acc: 0.9711
Epoch 17/21
 - 20s - loss: 0.1062 - acc: 0.9692 - val_loss: 0.1677 - val_acc: 0.9401
Epoch 18/21
 - 20s - loss: 0.1012 - acc: 0.9707 - val_loss: 0.1130 - val_acc: 0.9632
Epoch 19/21
 - 20s - loss: 0.0958 - acc: 0.9740 - val_loss: 0.1066 - val_acc: 0.9670

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 20s - loss: 0.0820 - acc: 0.9789 - val_loss: 0.0659 - val_acc: 0.9862
Epoch 21/21
 - 20s - loss: 0.0788 - acc: 0.9810 - val_loss: 0.0654 - val_acc: 0.9877
Test accuracy:0.779
current auc_score ------------------> 0.901
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4895 - acc: 0.7619 - val_loss: 0.3978 - val_acc: 0.8161
Epoch 2/21
 - 20s - loss: 0.3633 - acc: 0.8416 - val_loss: 0.3372 - val_acc: 0.8603
Epoch 3/21
 - 20s - loss: 0.3170 - acc: 0.8690 - val_loss: 0.2908 - val_acc: 0.8822
Epoch 4/21
 - 20s - loss: 0.2850 - acc: 0.8865 - val_loss: 0.2584 - val_acc: 0.8998
Epoch 5/21
 - 20s - loss: 0.2596 - acc: 0.9007 - val_loss: 0.2303 - val_acc: 0.9152
Epoch 6/21
 - 20s - loss: 0.2363 - acc: 0.9127 - val_loss: 0.2591 - val_acc: 0.8918
Epoch 7/21
 - 20s - loss: 0.2181 - acc: 0.9201 - val_loss: 0.2302 - val_acc: 0.9144
Epoch 8/21
 - 20s - loss: 0.2024 - acc: 0.9286 - val_loss: 0.1883 - val_acc: 0.9325
Epoch 9/21
 - 20s - loss: 0.1872 - acc: 0.9345 - val_loss: 0.1637 - val_acc: 0.9418
Epoch 10/21
 - 20s - loss: 0.1747 - acc: 0.9401 - val_loss: 0.1508 - val_acc: 0.9537
Epoch 11/21
 - 20s - loss: 0.1640 - acc: 0.9453 - val_loss: 0.1978 - val_acc: 0.9251
Epoch 12/21
 - 20s - loss: 0.1520 - acc: 0.9511 - val_loss: 0.1492 - val_acc: 0.9513
Epoch 13/21
 - 20s - loss: 0.1424 - acc: 0.9544 - val_loss: 0.1422 - val_acc: 0.9514
Epoch 14/21
 - 19s - loss: 0.1356 - acc: 0.9568 - val_loss: 0.1265 - val_acc: 0.9581
Epoch 15/21
 - 20s - loss: 0.1259 - acc: 0.9615 - val_loss: 0.1287 - val_acc: 0.9544
Epoch 16/21
 - 20s - loss: 0.1174 - acc: 0.9643 - val_loss: 0.1264 - val_acc: 0.9556
Epoch 17/21
 - 20s - loss: 0.1120 - acc: 0.9671 - val_loss: 0.1069 - val_acc: 0.9694
Epoch 18/21
 - 20s - loss: 0.1054 - acc: 0.9700 - val_loss: 0.0894 - val_acc: 0.9755
Epoch 19/21
 - 20s - loss: 0.0988 - acc: 0.9718 - val_loss: 0.1130 - val_acc: 0.9631
Epoch 20/21
 - 20s - loss: 0.0963 - acc: 0.9728 - val_loss: 0.1149 - val_acc: 0.9596
Epoch 21/21
 - 19s - loss: 0.0897 - acc: 0.9752 - val_loss: 0.0695 - val_acc: 0.9842
Test accuracy:0.822
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4772 - acc: 0.7772 - val_loss: 0.4663 - val_acc: 0.7736
Epoch 2/21
 - 20s - loss: 0.3696 - acc: 0.8368 - val_loss: 0.3533 - val_acc: 0.8402
Epoch 3/21
 - 20s - loss: 0.3163 - acc: 0.8688 - val_loss: 0.2844 - val_acc: 0.8878
Epoch 4/21
 - 20s - loss: 0.2814 - acc: 0.8885 - val_loss: 0.2429 - val_acc: 0.9090
Epoch 5/21
 - 20s - loss: 0.2531 - acc: 0.9051 - val_loss: 0.2263 - val_acc: 0.9155
Epoch 6/21
 - 20s - loss: 0.2302 - acc: 0.9161 - val_loss: 0.2008 - val_acc: 0.9344
Epoch 7/21
 - 20s - loss: 0.2106 - acc: 0.9253 - val_loss: 0.2262 - val_acc: 0.9163
Epoch 8/21
 - 20s - loss: 0.1936 - acc: 0.9332 - val_loss: 0.1923 - val_acc: 0.9303
Epoch 9/21
 - 20s - loss: 0.1800 - acc: 0.9390 - val_loss: 0.1779 - val_acc: 0.9386
Epoch 10/21
 - 20s - loss: 0.1687 - acc: 0.9437 - val_loss: 0.1708 - val_acc: 0.9399
Epoch 11/21
 - 20s - loss: 0.1553 - acc: 0.9488 - val_loss: 0.1665 - val_acc: 0.9428
Epoch 12/21
 - 20s - loss: 0.1478 - acc: 0.9524 - val_loss: 0.1541 - val_acc: 0.9470
Epoch 13/21
 - 20s - loss: 0.1381 - acc: 0.9566 - val_loss: 0.1458 - val_acc: 0.9477
Epoch 14/21
 - 19s - loss: 0.1308 - acc: 0.9591 - val_loss: 0.1538 - val_acc: 0.9452
Epoch 15/21
 - 19s - loss: 0.1221 - acc: 0.9629 - val_loss: 0.1416 - val_acc: 0.9493
Epoch 16/21
 - 19s - loss: 0.1158 - acc: 0.9650 - val_loss: 0.1407 - val_acc: 0.9508
Epoch 17/21
 - 20s - loss: 0.1105 - acc: 0.9668 - val_loss: 0.1005 - val_acc: 0.9665
Epoch 18/21
 - 20s - loss: 0.1040 - acc: 0.9706 - val_loss: 0.1013 - val_acc: 0.9710
Epoch 19/21
 - 20s - loss: 0.0977 - acc: 0.9730 - val_loss: 0.0835 - val_acc: 0.9789
Epoch 20/21
 - 20s - loss: 0.0914 - acc: 0.9746 - val_loss: 0.0848 - val_acc: 0.9795
Epoch 21/21
 - 20s - loss: 0.0881 - acc: 0.9770 - val_loss: 0.0693 - val_acc: 0.9832
Test accuracy:0.807
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4792 - acc: 0.7759 - val_loss: 0.4236 - val_acc: 0.7942
Epoch 2/21
 - 20s - loss: 0.3721 - acc: 0.8372 - val_loss: 0.3493 - val_acc: 0.8446
Epoch 3/21
 - 19s - loss: 0.3134 - acc: 0.8733 - val_loss: 0.2806 - val_acc: 0.8903
Epoch 4/21
 - 20s - loss: 0.2716 - acc: 0.8962 - val_loss: 0.2655 - val_acc: 0.8947
Epoch 5/21
 - 20s - loss: 0.2433 - acc: 0.9094 - val_loss: 0.2496 - val_acc: 0.9021
Epoch 6/21
 - 20s - loss: 0.2225 - acc: 0.9191 - val_loss: 0.2148 - val_acc: 0.9167
Epoch 7/21
 - 20s - loss: 0.2043 - acc: 0.9281 - val_loss: 0.1802 - val_acc: 0.9395
Epoch 8/21
 - 20s - loss: 0.1887 - acc: 0.9356 - val_loss: 0.1905 - val_acc: 0.9351
Epoch 9/21
 - 20s - loss: 0.1765 - acc: 0.9391 - val_loss: 0.1655 - val_acc: 0.9445
Epoch 10/21
 - 20s - loss: 0.1655 - acc: 0.9446 - val_loss: 0.1452 - val_acc: 0.9552
Epoch 11/21
 - 20s - loss: 0.1548 - acc: 0.9503 - val_loss: 0.1571 - val_acc: 0.9448
Epoch 12/21
 - 20s - loss: 0.1475 - acc: 0.9518 - val_loss: 0.1689 - val_acc: 0.9369
Epoch 13/21
 - 20s - loss: 0.1358 - acc: 0.9573 - val_loss: 0.2146 - val_acc: 0.9143

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/21
 - 20s - loss: 0.1212 - acc: 0.9636 - val_loss: 0.1010 - val_acc: 0.9745
Epoch 15/21
 - 20s - loss: 0.1172 - acc: 0.9647 - val_loss: 0.0964 - val_acc: 0.9759
Epoch 16/21
 - 20s - loss: 0.1138 - acc: 0.9669 - val_loss: 0.0960 - val_acc: 0.9753
Epoch 17/21
 - 20s - loss: 0.1101 - acc: 0.9682 - val_loss: 0.0917 - val_acc: 0.9778
Epoch 18/21
 - 20s - loss: 0.1085 - acc: 0.9685 - val_loss: 0.0910 - val_acc: 0.9778
Epoch 19/21
 - 20s - loss: 0.1051 - acc: 0.9697 - val_loss: 0.0899 - val_acc: 0.9782
Epoch 20/21
 - 20s - loss: 0.1024 - acc: 0.9707 - val_loss: 0.0845 - val_acc: 0.9798
Epoch 21/21
 - 20s - loss: 0.1006 - acc: 0.9717 - val_loss: 0.0809 - val_acc: 0.9827
Test accuracy:0.805
current auc_score ------------------> 0.904
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4880 - acc: 0.7686 - val_loss: 0.4660 - val_acc: 0.7807
Epoch 2/21
 - 20s - loss: 0.3794 - acc: 0.8323 - val_loss: 0.4141 - val_acc: 0.8001
Epoch 3/21
 - 20s - loss: 0.3274 - acc: 0.8637 - val_loss: 0.3051 - val_acc: 0.8843
Epoch 4/21
 - 20s - loss: 0.2905 - acc: 0.8858 - val_loss: 0.2695 - val_acc: 0.9035
Epoch 5/21
 - 20s - loss: 0.2592 - acc: 0.9027 - val_loss: 0.2791 - val_acc: 0.8908
Epoch 6/21
 - 20s - loss: 0.2336 - acc: 0.9130 - val_loss: 0.2506 - val_acc: 0.8956
Epoch 7/21
 - 20s - loss: 0.2132 - acc: 0.9245 - val_loss: 0.2337 - val_acc: 0.9091
Epoch 8/21
 - 19s - loss: 0.1942 - acc: 0.9327 - val_loss: 0.1677 - val_acc: 0.9483
Epoch 9/21
 - 20s - loss: 0.1793 - acc: 0.9393 - val_loss: 0.1848 - val_acc: 0.9361
Epoch 10/21
 - 20s - loss: 0.1648 - acc: 0.9464 - val_loss: 0.1836 - val_acc: 0.9321
Epoch 11/21
 - 20s - loss: 0.1533 - acc: 0.9501 - val_loss: 0.1410 - val_acc: 0.9544
Epoch 12/21
 - 20s - loss: 0.1416 - acc: 0.9567 - val_loss: 0.1331 - val_acc: 0.9590
Epoch 13/21
 - 20s - loss: 0.1331 - acc: 0.9584 - val_loss: 0.1418 - val_acc: 0.9527
Epoch 14/21
 - 20s - loss: 0.1243 - acc: 0.9628 - val_loss: 0.1417 - val_acc: 0.9514
Epoch 15/21
 - 20s - loss: 0.1164 - acc: 0.9650 - val_loss: 0.0970 - val_acc: 0.9749
Epoch 16/21
 - 20s - loss: 0.1088 - acc: 0.9688 - val_loss: 0.1134 - val_acc: 0.9650
Epoch 17/21
 - 20s - loss: 0.1035 - acc: 0.9713 - val_loss: 0.0851 - val_acc: 0.9775
Epoch 18/21
 - 20s - loss: 0.0964 - acc: 0.9741 - val_loss: 0.0824 - val_acc: 0.9802
Epoch 19/21
 - 20s - loss: 0.0900 - acc: 0.9755 - val_loss: 0.0847 - val_acc: 0.9778
Epoch 20/21
 - 20s - loss: 0.0872 - acc: 0.9768 - val_loss: 0.0682 - val_acc: 0.9836
Epoch 21/21
 - 20s - loss: 0.0840 - acc: 0.9773 - val_loss: 0.0961 - val_acc: 0.9696
Test accuracy:0.807
current auc_score ------------------> 0.907
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4606 - acc: 0.7904 - val_loss: 0.4016 - val_acc: 0.8143
Epoch 2/21
 - 20s - loss: 0.3561 - acc: 0.8469 - val_loss: 0.3371 - val_acc: 0.8576
Epoch 3/21
 - 20s - loss: 0.3108 - acc: 0.8725 - val_loss: 0.2837 - val_acc: 0.8884
Epoch 4/21
 - 20s - loss: 0.2775 - acc: 0.8929 - val_loss: 0.2570 - val_acc: 0.9045
Epoch 5/21
 - 20s - loss: 0.2482 - acc: 0.9071 - val_loss: 0.3307 - val_acc: 0.8584
Epoch 6/21
 - 20s - loss: 0.2249 - acc: 0.9181 - val_loss: 0.2253 - val_acc: 0.9109
Epoch 7/21
 - 20s - loss: 0.2034 - acc: 0.9292 - val_loss: 0.2118 - val_acc: 0.9177
Epoch 8/21
 - 20s - loss: 0.1891 - acc: 0.9364 - val_loss: 0.2071 - val_acc: 0.9224
Epoch 9/21
 - 20s - loss: 0.1758 - acc: 0.9412 - val_loss: 0.2338 - val_acc: 0.9094
Epoch 10/21
 - 20s - loss: 0.1630 - acc: 0.9461 - val_loss: 0.1495 - val_acc: 0.9485
Epoch 11/21
 - 20s - loss: 0.1505 - acc: 0.9518 - val_loss: 0.1296 - val_acc: 0.9626
Epoch 12/21
 - 20s - loss: 0.1436 - acc: 0.9548 - val_loss: 0.1529 - val_acc: 0.9499
Epoch 13/21
 - 20s - loss: 0.1363 - acc: 0.9567 - val_loss: 0.1375 - val_acc: 0.9494
Epoch 14/21
 - 20s - loss: 0.1260 - acc: 0.9611 - val_loss: 0.1056 - val_acc: 0.9684
Epoch 15/21
 - 20s - loss: 0.1206 - acc: 0.9630 - val_loss: 0.1252 - val_acc: 0.9615
Epoch 16/21
 - 20s - loss: 0.1127 - acc: 0.9669 - val_loss: 0.0964 - val_acc: 0.9720
Epoch 17/21
 - 20s - loss: 0.1059 - acc: 0.9681 - val_loss: 0.0951 - val_acc: 0.9754
Epoch 18/21
 - 20s - loss: 0.1011 - acc: 0.9702 - val_loss: 0.0819 - val_acc: 0.9793
Epoch 19/21
 - 20s - loss: 0.0955 - acc: 0.9736 - val_loss: 0.0716 - val_acc: 0.9836
Epoch 20/21
 - 20s - loss: 0.0896 - acc: 0.9751 - val_loss: 0.1980 - val_acc: 0.9265
Epoch 21/21
 - 19s - loss: 0.0859 - acc: 0.9776 - val_loss: 0.0720 - val_acc: 0.9827
Test accuracy:0.847
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.0
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.4745 - acc: 0.7780 - val_loss: 0.4133 - val_acc: 0.8026
Epoch 2/21
 - 20s - loss: 0.3646 - acc: 0.8386 - val_loss: 0.3778 - val_acc: 0.8355
Epoch 3/21
 - 20s - loss: 0.3144 - acc: 0.8700 - val_loss: 0.3011 - val_acc: 0.8722
Epoch 4/21
 - 20s - loss: 0.2803 - acc: 0.8888 - val_loss: 0.2526 - val_acc: 0.9027
Epoch 5/21
 - 20s - loss: 0.2521 - acc: 0.9046 - val_loss: 0.2938 - val_acc: 0.8737
Epoch 6/21
 - 20s - loss: 0.2281 - acc: 0.9170 - val_loss: 0.2192 - val_acc: 0.9144
Epoch 7/21
 - 20s - loss: 0.2086 - acc: 0.9259 - val_loss: 0.2212 - val_acc: 0.9167
Epoch 8/21
 - 20s - loss: 0.1930 - acc: 0.9316 - val_loss: 0.2169 - val_acc: 0.9198
Epoch 9/21
 - 20s - loss: 0.1782 - acc: 0.9382 - val_loss: 0.1973 - val_acc: 0.9282
Epoch 10/21
 - 20s - loss: 0.1664 - acc: 0.9438 - val_loss: 0.1772 - val_acc: 0.9371
Epoch 11/21
 - 20s - loss: 0.1540 - acc: 0.9501 - val_loss: 0.1378 - val_acc: 0.9595
Epoch 12/21
 - 20s - loss: 0.1452 - acc: 0.9536 - val_loss: 0.1410 - val_acc: 0.9571
Epoch 13/21
 - 20s - loss: 0.1386 - acc: 0.9555 - val_loss: 0.2400 - val_acc: 0.9014
Epoch 14/21
 - 20s - loss: 0.1285 - acc: 0.9608 - val_loss: 0.1297 - val_acc: 0.9568
Epoch 15/21
 - 20s - loss: 0.1205 - acc: 0.9641 - val_loss: 0.0953 - val_acc: 0.9749
Epoch 16/21
 - 20s - loss: 0.1152 - acc: 0.9661 - val_loss: 0.1002 - val_acc: 0.9695
Epoch 17/21
 - 20s - loss: 0.1083 - acc: 0.9687 - val_loss: 0.1041 - val_acc: 0.9684
Epoch 18/21
 - 20s - loss: 0.1021 - acc: 0.9707 - val_loss: 0.1115 - val_acc: 0.9642

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 20s - loss: 0.0888 - acc: 0.9767 - val_loss: 0.0728 - val_acc: 0.9831
Epoch 20/21
 - 20s - loss: 0.0867 - acc: 0.9776 - val_loss: 0.0682 - val_acc: 0.9849
Epoch 21/21
 - 20s - loss: 0.0843 - acc: 0.9789 - val_loss: 0.0756 - val_acc: 0.9821
Test accuracy:0.826
current auc_score ------------------> 0.936
accuracies:  [0.819758064516129, 0.810752688172043, 0.7864247311827957, 0.7786290322580646, 0.821505376344086, 0.8073924731182796, 0.8047043010752688, 0.8068548387096774, 0.8473118279569892, 0.8263440860215053]
aucs:  [0.9223, 0.919, 0.908, 0.9007, 0.9221, 0.9078, 0.9036, 0.9069, 0.9291, 0.9362]
mean and std AUC:  0.916+/-0.011  max:   0.9362
['2-2-2', '30', '3', '16', '0.1', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4919 - acc: 0.7637 - val_loss: 0.4499 - val_acc: 0.7884
Epoch 2/21
 - 21s - loss: 0.3930 - acc: 0.8213 - val_loss: 0.4040 - val_acc: 0.8217
Epoch 3/21
 - 21s - loss: 0.3514 - acc: 0.8477 - val_loss: 0.3386 - val_acc: 0.8567
Epoch 4/21
 - 21s - loss: 0.3242 - acc: 0.8632 - val_loss: 0.3088 - val_acc: 0.8690
Epoch 5/21
 - 21s - loss: 0.2981 - acc: 0.8786 - val_loss: 0.2981 - val_acc: 0.8706
Epoch 6/21
 - 21s - loss: 0.2778 - acc: 0.8895 - val_loss: 0.2513 - val_acc: 0.9036
Epoch 7/21
 - 21s - loss: 0.2629 - acc: 0.8972 - val_loss: 0.2527 - val_acc: 0.9036
Epoch 8/21
 - 21s - loss: 0.2500 - acc: 0.9044 - val_loss: 0.2569 - val_acc: 0.8986
Epoch 9/21
 - 21s - loss: 0.2365 - acc: 0.9116 - val_loss: 0.2110 - val_acc: 0.9199
Epoch 10/21
 - 21s - loss: 0.2241 - acc: 0.9177 - val_loss: 0.2093 - val_acc: 0.9246
Epoch 11/21
 - 21s - loss: 0.2136 - acc: 0.9216 - val_loss: 0.1942 - val_acc: 0.9305
Epoch 12/21
 - 21s - loss: 0.2052 - acc: 0.9245 - val_loss: 0.1930 - val_acc: 0.9283
Epoch 13/21
 - 21s - loss: 0.1974 - acc: 0.9299 - val_loss: 0.1824 - val_acc: 0.9375
Epoch 14/21
 - 21s - loss: 0.1883 - acc: 0.9327 - val_loss: 0.1642 - val_acc: 0.9439
Epoch 15/21
 - 21s - loss: 0.1833 - acc: 0.9360 - val_loss: 0.1565 - val_acc: 0.9465
Epoch 16/21
 - 21s - loss: 0.1750 - acc: 0.9399 - val_loss: 0.1372 - val_acc: 0.9571
Epoch 17/21
 - 21s - loss: 0.1675 - acc: 0.9427 - val_loss: 0.1612 - val_acc: 0.9444
Epoch 18/21
 - 21s - loss: 0.1623 - acc: 0.9450 - val_loss: 0.1239 - val_acc: 0.9640
Epoch 19/21
 - 21s - loss: 0.1529 - acc: 0.9492 - val_loss: 0.1401 - val_acc: 0.9517
Epoch 20/21
 - 21s - loss: 0.1500 - acc: 0.9498 - val_loss: 0.1375 - val_acc: 0.9543
Epoch 21/21
 - 21s - loss: 0.1460 - acc: 0.9513 - val_loss: 0.1156 - val_acc: 0.9647
Test accuracy:0.824
current auc_score ------------------> 0.942
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4899 - acc: 0.7715 - val_loss: 0.4228 - val_acc: 0.7989
Epoch 2/21
 - 21s - loss: 0.3936 - acc: 0.8205 - val_loss: 0.3687 - val_acc: 0.8309
Epoch 3/21
 - 21s - loss: 0.3520 - acc: 0.8443 - val_loss: 0.3724 - val_acc: 0.8274
Epoch 4/21
 - 21s - loss: 0.3233 - acc: 0.8615 - val_loss: 0.3127 - val_acc: 0.8651
Epoch 5/21
 - 21s - loss: 0.2967 - acc: 0.8769 - val_loss: 0.2746 - val_acc: 0.8942
Epoch 6/21
 - 21s - loss: 0.2760 - acc: 0.8911 - val_loss: 0.2477 - val_acc: 0.9129
Epoch 7/21
 - 21s - loss: 0.2564 - acc: 0.9008 - val_loss: 0.2478 - val_acc: 0.9044
Epoch 8/21
 - 21s - loss: 0.2396 - acc: 0.9098 - val_loss: 0.2427 - val_acc: 0.9011
Epoch 9/21
 - 21s - loss: 0.2227 - acc: 0.9164 - val_loss: 0.2392 - val_acc: 0.9041
Epoch 10/21
 - 21s - loss: 0.2149 - acc: 0.9212 - val_loss: 0.1776 - val_acc: 0.9411
Epoch 11/21
 - 20s - loss: 0.2021 - acc: 0.9260 - val_loss: 0.1728 - val_acc: 0.9420
Epoch 12/21
 - 20s - loss: 0.1917 - acc: 0.9326 - val_loss: 0.1740 - val_acc: 0.9366
Epoch 13/21
 - 21s - loss: 0.1822 - acc: 0.9364 - val_loss: 0.1638 - val_acc: 0.9468
Epoch 14/21
 - 21s - loss: 0.1737 - acc: 0.9394 - val_loss: 0.1941 - val_acc: 0.9273
Epoch 15/21
 - 21s - loss: 0.1665 - acc: 0.9430 - val_loss: 0.1348 - val_acc: 0.9581
Epoch 16/21
 - 20s - loss: 0.1638 - acc: 0.9439 - val_loss: 0.1327 - val_acc: 0.9576
Epoch 17/21
 - 21s - loss: 0.1553 - acc: 0.9482 - val_loss: 0.1272 - val_acc: 0.9611
Epoch 18/21
 - 20s - loss: 0.1475 - acc: 0.9521 - val_loss: 0.1364 - val_acc: 0.9556
Epoch 19/21
 - 21s - loss: 0.1454 - acc: 0.9528 - val_loss: 0.1132 - val_acc: 0.9688
Epoch 20/21
 - 21s - loss: 0.1395 - acc: 0.9543 - val_loss: 0.1046 - val_acc: 0.9698
Epoch 21/21
 - 20s - loss: 0.1333 - acc: 0.9575 - val_loss: 0.1136 - val_acc: 0.9656
Test accuracy:0.798
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4871 - acc: 0.7686 - val_loss: 0.4150 - val_acc: 0.7998
Epoch 2/21
 - 21s - loss: 0.3894 - acc: 0.8207 - val_loss: 0.3934 - val_acc: 0.8183
Epoch 3/21
 - 21s - loss: 0.3453 - acc: 0.8490 - val_loss: 0.3101 - val_acc: 0.8648
Epoch 4/21
 - 21s - loss: 0.3173 - acc: 0.8665 - val_loss: 0.2833 - val_acc: 0.8863
Epoch 5/21
 - 21s - loss: 0.2946 - acc: 0.8803 - val_loss: 0.2749 - val_acc: 0.8870
Epoch 6/21
 - 21s - loss: 0.2748 - acc: 0.8919 - val_loss: 0.2488 - val_acc: 0.9045
Epoch 7/21
 - 21s - loss: 0.2581 - acc: 0.9001 - val_loss: 0.2459 - val_acc: 0.9109
Epoch 8/21
 - 21s - loss: 0.2436 - acc: 0.9083 - val_loss: 0.2179 - val_acc: 0.9196
Epoch 9/21
 - 21s - loss: 0.2291 - acc: 0.9153 - val_loss: 0.2141 - val_acc: 0.9206
Epoch 10/21
 - 21s - loss: 0.2149 - acc: 0.9205 - val_loss: 0.1935 - val_acc: 0.9283
Epoch 11/21
 - 21s - loss: 0.2055 - acc: 0.9249 - val_loss: 0.2138 - val_acc: 0.9223
Epoch 12/21
 - 21s - loss: 0.1929 - acc: 0.9307 - val_loss: 0.2063 - val_acc: 0.9290
Epoch 13/21
 - 21s - loss: 0.1860 - acc: 0.9342 - val_loss: 0.1521 - val_acc: 0.9470
Epoch 14/21
 - 21s - loss: 0.1775 - acc: 0.9371 - val_loss: 0.1402 - val_acc: 0.9526
Epoch 15/21
 - 21s - loss: 0.1706 - acc: 0.9409 - val_loss: 0.1394 - val_acc: 0.9548
Epoch 16/21
 - 21s - loss: 0.1629 - acc: 0.9453 - val_loss: 0.1494 - val_acc: 0.9504
Epoch 17/21
 - 21s - loss: 0.1576 - acc: 0.9468 - val_loss: 0.1268 - val_acc: 0.9620
Epoch 18/21
 - 21s - loss: 0.1511 - acc: 0.9501 - val_loss: 0.1207 - val_acc: 0.9654
Epoch 19/21
 - 21s - loss: 0.1433 - acc: 0.9527 - val_loss: 0.1062 - val_acc: 0.9705
Epoch 20/21
 - 21s - loss: 0.1423 - acc: 0.9525 - val_loss: 0.1383 - val_acc: 0.9526
Epoch 21/21
 - 21s - loss: 0.1356 - acc: 0.9561 - val_loss: 0.1524 - val_acc: 0.9458
Test accuracy:0.776
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4960 - acc: 0.7650 - val_loss: 0.4202 - val_acc: 0.7971
Epoch 2/21
 - 20s - loss: 0.3906 - acc: 0.8240 - val_loss: 0.3720 - val_acc: 0.8348
Epoch 3/21
 - 20s - loss: 0.3487 - acc: 0.8509 - val_loss: 0.3639 - val_acc: 0.8363
Epoch 4/21
 - 21s - loss: 0.3162 - acc: 0.8711 - val_loss: 0.3198 - val_acc: 0.8640
Epoch 5/21
 - 21s - loss: 0.2898 - acc: 0.8840 - val_loss: 0.2874 - val_acc: 0.8887
Epoch 6/21
 - 21s - loss: 0.2702 - acc: 0.8951 - val_loss: 0.2380 - val_acc: 0.9127
Epoch 7/21
 - 20s - loss: 0.2541 - acc: 0.9042 - val_loss: 0.2356 - val_acc: 0.9158
Epoch 8/21
 - 20s - loss: 0.2371 - acc: 0.9105 - val_loss: 0.2232 - val_acc: 0.9196
Epoch 9/21
 - 20s - loss: 0.2218 - acc: 0.9174 - val_loss: 0.1982 - val_acc: 0.9270
Epoch 10/21
 - 20s - loss: 0.2105 - acc: 0.9237 - val_loss: 0.1965 - val_acc: 0.9342
Epoch 11/21
 - 20s - loss: 0.1990 - acc: 0.9302 - val_loss: 0.1921 - val_acc: 0.9355
Epoch 12/21
 - 21s - loss: 0.1958 - acc: 0.9299 - val_loss: 0.1648 - val_acc: 0.9452
Epoch 13/21
 - 21s - loss: 0.1848 - acc: 0.9352 - val_loss: 0.1597 - val_acc: 0.9478
Epoch 14/21
 - 21s - loss: 0.1736 - acc: 0.9418 - val_loss: 0.1644 - val_acc: 0.9462
Epoch 15/21
 - 21s - loss: 0.1683 - acc: 0.9417 - val_loss: 0.1319 - val_acc: 0.9593
Epoch 16/21
 - 21s - loss: 0.1620 - acc: 0.9456 - val_loss: 0.1544 - val_acc: 0.9459
Epoch 17/21
 - 20s - loss: 0.1569 - acc: 0.9464 - val_loss: 0.1279 - val_acc: 0.9618
Epoch 18/21
 - 20s - loss: 0.1504 - acc: 0.9495 - val_loss: 0.1282 - val_acc: 0.9597
Epoch 19/21
 - 21s - loss: 0.1456 - acc: 0.9518 - val_loss: 0.1115 - val_acc: 0.9700
Epoch 20/21
 - 20s - loss: 0.1396 - acc: 0.9546 - val_loss: 0.1224 - val_acc: 0.9610
Epoch 21/21
 - 20s - loss: 0.1337 - acc: 0.9569 - val_loss: 0.1063 - val_acc: 0.9695
Test accuracy:0.800
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5079 - acc: 0.7584 - val_loss: 0.4219 - val_acc: 0.8107
Epoch 2/21
 - 21s - loss: 0.3915 - acc: 0.8280 - val_loss: 0.3811 - val_acc: 0.8258
Epoch 3/21
 - 20s - loss: 0.3453 - acc: 0.8522 - val_loss: 0.3323 - val_acc: 0.8662
Epoch 4/21
 - 20s - loss: 0.3117 - acc: 0.8741 - val_loss: 0.2832 - val_acc: 0.8891
Epoch 5/21
 - 21s - loss: 0.2896 - acc: 0.8857 - val_loss: 0.2832 - val_acc: 0.8840
Epoch 6/21
 - 21s - loss: 0.2699 - acc: 0.8948 - val_loss: 0.2593 - val_acc: 0.8980
Epoch 7/21
 - 21s - loss: 0.2525 - acc: 0.9032 - val_loss: 0.2544 - val_acc: 0.9012
Epoch 8/21
 - 21s - loss: 0.2373 - acc: 0.9124 - val_loss: 0.2135 - val_acc: 0.9234
Epoch 9/21
 - 20s - loss: 0.2246 - acc: 0.9170 - val_loss: 0.1996 - val_acc: 0.9296
Epoch 10/21
 - 20s - loss: 0.2143 - acc: 0.9214 - val_loss: 0.1817 - val_acc: 0.9359
Epoch 11/21
 - 20s - loss: 0.2035 - acc: 0.9264 - val_loss: 0.1639 - val_acc: 0.9477
Epoch 12/21
 - 20s - loss: 0.1954 - acc: 0.9311 - val_loss: 0.1634 - val_acc: 0.9435
Epoch 13/21
 - 20s - loss: 0.1878 - acc: 0.9325 - val_loss: 0.1991 - val_acc: 0.9263
Epoch 14/21
 - 20s - loss: 0.1797 - acc: 0.9390 - val_loss: 0.1470 - val_acc: 0.9509
Epoch 15/21
 - 20s - loss: 0.1722 - acc: 0.9402 - val_loss: 0.1271 - val_acc: 0.9608
Epoch 16/21
 - 20s - loss: 0.1644 - acc: 0.9437 - val_loss: 0.1547 - val_acc: 0.9434
Epoch 17/21
 - 20s - loss: 0.1572 - acc: 0.9470 - val_loss: 0.1235 - val_acc: 0.9593
Epoch 18/21
 - 20s - loss: 0.1510 - acc: 0.9500 - val_loss: 0.1086 - val_acc: 0.9710
Epoch 19/21
 - 20s - loss: 0.1480 - acc: 0.9512 - val_loss: 0.1081 - val_acc: 0.9693
Epoch 20/21
 - 20s - loss: 0.1424 - acc: 0.9537 - val_loss: 0.1095 - val_acc: 0.9659
Epoch 21/21
 - 20s - loss: 0.1390 - acc: 0.9547 - val_loss: 0.1020 - val_acc: 0.9714
Test accuracy:0.842
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4939 - acc: 0.7671 - val_loss: 0.4140 - val_acc: 0.7984
Epoch 2/21
 - 21s - loss: 0.4028 - acc: 0.8098 - val_loss: 0.3795 - val_acc: 0.8243
Epoch 3/21
 - 20s - loss: 0.3610 - acc: 0.8386 - val_loss: 0.3498 - val_acc: 0.8422
Epoch 4/21
 - 20s - loss: 0.3298 - acc: 0.8602 - val_loss: 0.3561 - val_acc: 0.8400
Epoch 5/21
 - 20s - loss: 0.3042 - acc: 0.8758 - val_loss: 0.2775 - val_acc: 0.8957
Epoch 6/21
 - 20s - loss: 0.2859 - acc: 0.8861 - val_loss: 0.2798 - val_acc: 0.8882
Epoch 7/21
 - 21s - loss: 0.2652 - acc: 0.8988 - val_loss: 0.2740 - val_acc: 0.8896
Epoch 8/21
 - 21s - loss: 0.2539 - acc: 0.9031 - val_loss: 0.2437 - val_acc: 0.9068
Epoch 9/21
 - 20s - loss: 0.2389 - acc: 0.9106 - val_loss: 0.2093 - val_acc: 0.9257
Epoch 10/21
 - 21s - loss: 0.2286 - acc: 0.9161 - val_loss: 0.1899 - val_acc: 0.9347
Epoch 11/21
 - 21s - loss: 0.2174 - acc: 0.9198 - val_loss: 0.1858 - val_acc: 0.9395
Epoch 12/21
 - 20s - loss: 0.2083 - acc: 0.9259 - val_loss: 0.1673 - val_acc: 0.9435
Epoch 13/21
 - 20s - loss: 0.1999 - acc: 0.9287 - val_loss: 0.1854 - val_acc: 0.9360
Epoch 14/21
 - 21s - loss: 0.1926 - acc: 0.9325 - val_loss: 0.1629 - val_acc: 0.9448
Epoch 15/21
 - 20s - loss: 0.1833 - acc: 0.9364 - val_loss: 0.1702 - val_acc: 0.9424
Epoch 16/21
 - 21s - loss: 0.1783 - acc: 0.9376 - val_loss: 0.1424 - val_acc: 0.9572
Epoch 17/21
 - 20s - loss: 0.1692 - acc: 0.9421 - val_loss: 0.1724 - val_acc: 0.9414
Epoch 18/21
 - 21s - loss: 0.1646 - acc: 0.9436 - val_loss: 0.1328 - val_acc: 0.9561
Epoch 19/21
 - 21s - loss: 0.1612 - acc: 0.9459 - val_loss: 0.1161 - val_acc: 0.9672
Epoch 20/21
 - 21s - loss: 0.1554 - acc: 0.9475 - val_loss: 0.1186 - val_acc: 0.9640
Epoch 21/21
 - 21s - loss: 0.1499 - acc: 0.9499 - val_loss: 0.1151 - val_acc: 0.9631
Test accuracy:0.846
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4878 - acc: 0.7707 - val_loss: 0.4068 - val_acc: 0.8116
Epoch 2/21
 - 21s - loss: 0.3871 - acc: 0.8257 - val_loss: 0.3498 - val_acc: 0.8420
Epoch 3/21
 - 21s - loss: 0.3478 - acc: 0.8503 - val_loss: 0.3322 - val_acc: 0.8563
Epoch 4/21
 - 20s - loss: 0.3192 - acc: 0.8654 - val_loss: 0.2985 - val_acc: 0.8776
Epoch 5/21
 - 20s - loss: 0.2959 - acc: 0.8776 - val_loss: 0.2806 - val_acc: 0.8847
Epoch 6/21
 - 21s - loss: 0.2764 - acc: 0.8904 - val_loss: 0.2583 - val_acc: 0.9061
Epoch 7/21
 - 20s - loss: 0.2581 - acc: 0.8989 - val_loss: 0.2272 - val_acc: 0.9140
Epoch 8/21
 - 20s - loss: 0.2409 - acc: 0.9074 - val_loss: 0.2108 - val_acc: 0.9218
Epoch 9/21
 - 20s - loss: 0.2297 - acc: 0.9142 - val_loss: 0.1924 - val_acc: 0.9303
Epoch 10/21
 - 20s - loss: 0.2184 - acc: 0.9194 - val_loss: 0.1802 - val_acc: 0.9359
Epoch 11/21
 - 21s - loss: 0.2056 - acc: 0.9265 - val_loss: 0.1830 - val_acc: 0.9332
Epoch 12/21
 - 21s - loss: 0.1979 - acc: 0.9304 - val_loss: 0.1545 - val_acc: 0.9487
Epoch 13/21
 - 21s - loss: 0.1884 - acc: 0.9341 - val_loss: 0.1540 - val_acc: 0.9477
Epoch 14/21
 - 21s - loss: 0.1789 - acc: 0.9381 - val_loss: 0.1474 - val_acc: 0.9498
Epoch 15/21
 - 21s - loss: 0.1716 - acc: 0.9421 - val_loss: 0.1366 - val_acc: 0.9558
Epoch 16/21
 - 21s - loss: 0.1649 - acc: 0.9447 - val_loss: 0.1297 - val_acc: 0.9595
Epoch 17/21
 - 21s - loss: 0.1595 - acc: 0.9450 - val_loss: 0.1496 - val_acc: 0.9493
Epoch 18/21
 - 21s - loss: 0.1551 - acc: 0.9486 - val_loss: 0.1120 - val_acc: 0.9649
Epoch 19/21
 - 21s - loss: 0.1485 - acc: 0.9498 - val_loss: 0.1111 - val_acc: 0.9671
Epoch 20/21
 - 21s - loss: 0.1453 - acc: 0.9518 - val_loss: 0.1317 - val_acc: 0.9554
Epoch 21/21
 - 21s - loss: 0.1380 - acc: 0.9552 - val_loss: 0.1076 - val_acc: 0.9689
Test accuracy:0.820
current auc_score ------------------> 0.903
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5491 - acc: 0.7407 - val_loss: 0.4757 - val_acc: 0.7647
Epoch 2/21
 - 20s - loss: 0.4020 - acc: 0.8156 - val_loss: 0.4275 - val_acc: 0.8066
Epoch 3/21
 - 21s - loss: 0.3548 - acc: 0.8413 - val_loss: 0.3848 - val_acc: 0.8240
Epoch 4/21
 - 20s - loss: 0.3231 - acc: 0.8651 - val_loss: 0.3698 - val_acc: 0.8431
Epoch 5/21
 - 20s - loss: 0.3048 - acc: 0.8736 - val_loss: 0.3127 - val_acc: 0.8658
Epoch 6/21
 - 20s - loss: 0.2844 - acc: 0.8855 - val_loss: 0.2794 - val_acc: 0.8857
Epoch 7/21
 - 21s - loss: 0.2668 - acc: 0.8948 - val_loss: 0.2512 - val_acc: 0.9021
Epoch 8/21
 - 21s - loss: 0.2534 - acc: 0.9016 - val_loss: 0.2378 - val_acc: 0.9148
Epoch 9/21
 - 20s - loss: 0.2424 - acc: 0.9075 - val_loss: 0.2030 - val_acc: 0.9286
Epoch 10/21
 - 21s - loss: 0.2284 - acc: 0.9138 - val_loss: 0.2358 - val_acc: 0.9068
Epoch 11/21
 - 21s - loss: 0.2194 - acc: 0.9184 - val_loss: 0.2021 - val_acc: 0.9331
Epoch 12/21
 - 21s - loss: 0.2088 - acc: 0.9216 - val_loss: 0.2101 - val_acc: 0.9207
Epoch 13/21
 - 21s - loss: 0.2001 - acc: 0.9278 - val_loss: 0.2009 - val_acc: 0.9251
Epoch 14/21
 - 21s - loss: 0.1915 - acc: 0.9301 - val_loss: 0.1611 - val_acc: 0.9475
Epoch 15/21
 - 21s - loss: 0.1840 - acc: 0.9358 - val_loss: 0.1604 - val_acc: 0.9443
Epoch 16/21
 - 21s - loss: 0.1761 - acc: 0.9380 - val_loss: 0.1940 - val_acc: 0.9257
Epoch 17/21
 - 21s - loss: 0.1705 - acc: 0.9409 - val_loss: 0.1639 - val_acc: 0.9436
Epoch 18/21
 - 20s - loss: 0.1638 - acc: 0.9449 - val_loss: 0.1386 - val_acc: 0.9548
Epoch 19/21
 - 21s - loss: 0.1560 - acc: 0.9474 - val_loss: 0.1371 - val_acc: 0.9513
Epoch 20/21
 - 21s - loss: 0.1537 - acc: 0.9473 - val_loss: 0.1260 - val_acc: 0.9595
Epoch 21/21
 - 21s - loss: 0.1475 - acc: 0.9514 - val_loss: 0.1025 - val_acc: 0.9716
Test accuracy:0.838
current auc_score ------------------> 0.948
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5045 - acc: 0.7570 - val_loss: 0.5586 - val_acc: 0.7129
Epoch 2/21
 - 21s - loss: 0.3933 - acc: 0.8219 - val_loss: 0.3586 - val_acc: 0.8377
Epoch 3/21
 - 21s - loss: 0.3487 - acc: 0.8493 - val_loss: 0.3138 - val_acc: 0.8660
Epoch 4/21
 - 21s - loss: 0.3180 - acc: 0.8668 - val_loss: 0.3389 - val_acc: 0.8559
Epoch 5/21
 - 21s - loss: 0.2931 - acc: 0.8806 - val_loss: 0.2873 - val_acc: 0.8828
Epoch 6/21
 - 21s - loss: 0.2722 - acc: 0.8928 - val_loss: 0.2410 - val_acc: 0.9068
Epoch 7/21
 - 21s - loss: 0.2552 - acc: 0.9008 - val_loss: 0.2402 - val_acc: 0.9064
Epoch 8/21
 - 20s - loss: 0.2384 - acc: 0.9098 - val_loss: 0.2360 - val_acc: 0.9074
Epoch 9/21
 - 20s - loss: 0.2254 - acc: 0.9150 - val_loss: 0.2195 - val_acc: 0.9152
Epoch 10/21
 - 21s - loss: 0.2132 - acc: 0.9227 - val_loss: 0.1886 - val_acc: 0.9321
Epoch 11/21
 - 21s - loss: 0.2002 - acc: 0.9284 - val_loss: 0.2066 - val_acc: 0.9199
Epoch 12/21
 - 21s - loss: 0.1925 - acc: 0.9331 - val_loss: 0.1643 - val_acc: 0.9447
Epoch 13/21
 - 21s - loss: 0.1833 - acc: 0.9353 - val_loss: 0.1527 - val_acc: 0.9489
Epoch 14/21
 - 21s - loss: 0.1739 - acc: 0.9404 - val_loss: 0.1384 - val_acc: 0.9563
Epoch 15/21
 - 21s - loss: 0.1647 - acc: 0.9440 - val_loss: 0.1427 - val_acc: 0.9524
Epoch 16/21
 - 21s - loss: 0.1595 - acc: 0.9460 - val_loss: 0.1241 - val_acc: 0.9631
Epoch 17/21
 - 21s - loss: 0.1522 - acc: 0.9487 - val_loss: 0.1199 - val_acc: 0.9650
Epoch 18/21
 - 21s - loss: 0.1473 - acc: 0.9512 - val_loss: 0.1569 - val_acc: 0.9442
Epoch 19/21
 - 21s - loss: 0.1435 - acc: 0.9536 - val_loss: 0.1032 - val_acc: 0.9689
Epoch 20/21
 - 21s - loss: 0.1362 - acc: 0.9557 - val_loss: 0.1142 - val_acc: 0.9674
Epoch 21/21
 - 21s - loss: 0.1334 - acc: 0.9573 - val_loss: 0.1021 - val_acc: 0.9726
Test accuracy:0.813
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.1
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.4946 - acc: 0.7598 - val_loss: 0.4783 - val_acc: 0.7623
Epoch 2/21
 - 21s - loss: 0.3928 - acc: 0.8179 - val_loss: 0.4053 - val_acc: 0.8141
Epoch 3/21
 - 21s - loss: 0.3526 - acc: 0.8444 - val_loss: 0.3610 - val_acc: 0.8353
Epoch 4/21
 - 21s - loss: 0.3249 - acc: 0.8616 - val_loss: 0.3408 - val_acc: 0.8558
Epoch 5/21
 - 21s - loss: 0.2995 - acc: 0.8751 - val_loss: 0.2945 - val_acc: 0.8751
Epoch 6/21
 - 21s - loss: 0.2786 - acc: 0.8869 - val_loss: 0.2907 - val_acc: 0.8783
Epoch 7/21
 - 21s - loss: 0.2632 - acc: 0.8959 - val_loss: 0.2530 - val_acc: 0.9019
Epoch 8/21
 - 21s - loss: 0.2490 - acc: 0.9053 - val_loss: 0.2999 - val_acc: 0.8724
Epoch 9/21
 - 21s - loss: 0.2368 - acc: 0.9100 - val_loss: 0.2055 - val_acc: 0.9224
Epoch 10/21
 - 21s - loss: 0.2217 - acc: 0.9182 - val_loss: 0.1948 - val_acc: 0.9315
Epoch 11/21
 - 21s - loss: 0.2127 - acc: 0.9221 - val_loss: 0.2585 - val_acc: 0.8929
Epoch 12/21
 - 21s - loss: 0.2034 - acc: 0.9253 - val_loss: 0.1711 - val_acc: 0.9399
Epoch 13/21
 - 21s - loss: 0.1928 - acc: 0.9320 - val_loss: 0.1637 - val_acc: 0.9419
Epoch 14/21
 - 21s - loss: 0.1847 - acc: 0.9348 - val_loss: 0.1798 - val_acc: 0.9365
Epoch 15/21
 - 21s - loss: 0.1804 - acc: 0.9363 - val_loss: 0.1657 - val_acc: 0.9445
Epoch 16/21
 - 21s - loss: 0.1747 - acc: 0.9400 - val_loss: 0.1474 - val_acc: 0.9539
Epoch 17/21
 - 21s - loss: 0.1672 - acc: 0.9433 - val_loss: 0.1547 - val_acc: 0.9494
Epoch 18/21
 - 21s - loss: 0.1612 - acc: 0.9459 - val_loss: 0.1422 - val_acc: 0.9552
Epoch 19/21
 - 21s - loss: 0.1557 - acc: 0.9473 - val_loss: 0.1210 - val_acc: 0.9650
Epoch 20/21
 - 21s - loss: 0.1497 - acc: 0.9510 - val_loss: 0.1453 - val_acc: 0.9533
Epoch 21/21
 - 21s - loss: 0.1468 - acc: 0.9507 - val_loss: 0.1236 - val_acc: 0.9632
Test accuracy:0.853
current auc_score ------------------> 0.941
accuracies:  [0.8236559139784946, 0.7981182795698925, 0.7759408602150538, 0.8001344086021506, 0.8416666666666667, 0.8461021505376344, 0.8198924731182796, 0.8384408602150538, 0.8131720430107527, 0.853225806451613]
aucs:  [0.9416, 0.934, 0.9158, 0.9144, 0.9334, 0.9389, 0.9029, 0.9481, 0.9462, 0.9409]
mean and std AUC:  0.932+/-0.015  max:   0.9481
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5273 - acc: 0.7405 - val_loss: 0.5786 - val_acc: 0.6964
Epoch 2/21
 - 20s - loss: 0.4313 - acc: 0.7952 - val_loss: 0.7930 - val_acc: 0.6408
Epoch 3/21
 - 20s - loss: 0.3872 - acc: 0.8216 - val_loss: 0.4226 - val_acc: 0.7937
Epoch 4/21
 - 20s - loss: 0.3596 - acc: 0.8406 - val_loss: 0.5320 - val_acc: 0.7343
Epoch 5/21
 - 20s - loss: 0.3373 - acc: 0.8537 - val_loss: 0.4306 - val_acc: 0.8021
Epoch 6/21
 - 20s - loss: 0.3201 - acc: 0.8635 - val_loss: 0.5028 - val_acc: 0.7673

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 7/21
 - 20s - loss: 0.3055 - acc: 0.8748 - val_loss: 0.3463 - val_acc: 0.8411
Epoch 8/21
 - 20s - loss: 0.3009 - acc: 0.8758 - val_loss: 0.3433 - val_acc: 0.8401
Epoch 9/21
 - 20s - loss: 0.2956 - acc: 0.8785 - val_loss: 0.3856 - val_acc: 0.8171
Epoch 10/21
 - 20s - loss: 0.2925 - acc: 0.8806 - val_loss: 0.3307 - val_acc: 0.8510
Epoch 11/21
 - 20s - loss: 0.2880 - acc: 0.8815 - val_loss: 0.3341 - val_acc: 0.8480
Epoch 12/21
 - 20s - loss: 0.2832 - acc: 0.8841 - val_loss: 0.3885 - val_acc: 0.8179
Epoch 13/21
 - 20s - loss: 0.2791 - acc: 0.8887 - val_loss: 0.3210 - val_acc: 0.8584
Epoch 14/21
 - 20s - loss: 0.2728 - acc: 0.8894 - val_loss: 0.3072 - val_acc: 0.8647
Epoch 15/21
 - 20s - loss: 0.2723 - acc: 0.8906 - val_loss: 0.3949 - val_acc: 0.8169
Epoch 16/21
 - 20s - loss: 0.2671 - acc: 0.8939 - val_loss: 0.3824 - val_acc: 0.8197
Epoch 17/21
 - 20s - loss: 0.2655 - acc: 0.8938 - val_loss: 0.3525 - val_acc: 0.8392

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 18/21
 - 20s - loss: 0.2621 - acc: 0.8971 - val_loss: 0.3525 - val_acc: 0.8382
Epoch 00018: early stopping
Test accuracy:0.794
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5190 - acc: 0.7458 - val_loss: 0.4526 - val_acc: 0.7802
Epoch 2/21
 - 20s - loss: 0.4196 - acc: 0.8033 - val_loss: 0.4013 - val_acc: 0.8101
Epoch 3/21
 - 20s - loss: 0.3852 - acc: 0.8225 - val_loss: 0.3641 - val_acc: 0.8348
Epoch 4/21
 - 20s - loss: 0.3635 - acc: 0.8371 - val_loss: 0.3384 - val_acc: 0.8517
Epoch 5/21
 - 20s - loss: 0.3402 - acc: 0.8520 - val_loss: 0.3540 - val_acc: 0.8396
Epoch 6/21
 - 20s - loss: 0.3215 - acc: 0.8660 - val_loss: 0.3015 - val_acc: 0.8791
Epoch 7/21
 - 20s - loss: 0.3027 - acc: 0.8757 - val_loss: 0.3270 - val_acc: 0.8604
Epoch 8/21
 - 20s - loss: 0.2855 - acc: 0.8863 - val_loss: 0.2734 - val_acc: 0.8904
Epoch 9/21
 - 20s - loss: 0.2692 - acc: 0.8937 - val_loss: 0.2669 - val_acc: 0.8929
Epoch 10/21
 - 20s - loss: 0.2538 - acc: 0.9022 - val_loss: 0.2258 - val_acc: 0.9158
Epoch 11/21
 - 20s - loss: 0.2468 - acc: 0.9055 - val_loss: 0.2395 - val_acc: 0.9047
Epoch 12/21
 - 20s - loss: 0.2355 - acc: 0.9101 - val_loss: 0.2253 - val_acc: 0.9164
Epoch 13/21
 - 20s - loss: 0.2251 - acc: 0.9145 - val_loss: 0.2491 - val_acc: 0.9034
Epoch 14/21
 - 20s - loss: 0.2198 - acc: 0.9193 - val_loss: 0.2206 - val_acc: 0.9162
Epoch 15/21
 - 20s - loss: 0.2094 - acc: 0.9227 - val_loss: 0.1815 - val_acc: 0.9354
Epoch 16/21
 - 20s - loss: 0.2024 - acc: 0.9258 - val_loss: 0.1897 - val_acc: 0.9307
Epoch 17/21
 - 20s - loss: 0.1967 - acc: 0.9290 - val_loss: 0.1749 - val_acc: 0.9372
Epoch 18/21
 - 20s - loss: 0.1880 - acc: 0.9328 - val_loss: 0.1617 - val_acc: 0.9433
Epoch 19/21
 - 20s - loss: 0.1836 - acc: 0.9343 - val_loss: 0.1604 - val_acc: 0.9428
Epoch 20/21
 - 20s - loss: 0.1806 - acc: 0.9375 - val_loss: 0.1370 - val_acc: 0.9556
Epoch 21/21
 - 20s - loss: 0.1742 - acc: 0.9392 - val_loss: 0.1552 - val_acc: 0.9442
Test accuracy:0.846
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5117 - acc: 0.7559 - val_loss: 0.4441 - val_acc: 0.7899
Epoch 2/21
 - 20s - loss: 0.4170 - acc: 0.8070 - val_loss: 0.3818 - val_acc: 0.8209
Epoch 3/21
 - 20s - loss: 0.3781 - acc: 0.8298 - val_loss: 0.3560 - val_acc: 0.8409
Epoch 4/21
 - 20s - loss: 0.3514 - acc: 0.8466 - val_loss: 0.3413 - val_acc: 0.8520
Epoch 5/21
 - 20s - loss: 0.3289 - acc: 0.8600 - val_loss: 0.3260 - val_acc: 0.8650
Epoch 6/21
 - 20s - loss: 0.3119 - acc: 0.8697 - val_loss: 0.2819 - val_acc: 0.8867
Epoch 7/21
 - 20s - loss: 0.2954 - acc: 0.8777 - val_loss: 0.3186 - val_acc: 0.8662
Epoch 8/21
 - 20s - loss: 0.2814 - acc: 0.8870 - val_loss: 0.2614 - val_acc: 0.8951
Epoch 9/21
 - 20s - loss: 0.2708 - acc: 0.8913 - val_loss: 0.2545 - val_acc: 0.9032
Epoch 10/21
 - 20s - loss: 0.2557 - acc: 0.8996 - val_loss: 0.2450 - val_acc: 0.9065
Epoch 11/21
 - 20s - loss: 0.2453 - acc: 0.9038 - val_loss: 0.2234 - val_acc: 0.9159
Epoch 12/21
 - 20s - loss: 0.2373 - acc: 0.9094 - val_loss: 0.2278 - val_acc: 0.9169
Epoch 13/21
 - 20s - loss: 0.2282 - acc: 0.9135 - val_loss: 0.2275 - val_acc: 0.9137
Epoch 14/21
 - 20s - loss: 0.2205 - acc: 0.9171 - val_loss: 0.1895 - val_acc: 0.9327
Epoch 15/21
 - 20s - loss: 0.2106 - acc: 0.9217 - val_loss: 0.1868 - val_acc: 0.9315
Epoch 16/21
 - 20s - loss: 0.2048 - acc: 0.9257 - val_loss: 0.1883 - val_acc: 0.9310
Epoch 17/21
 - 20s - loss: 0.1982 - acc: 0.9272 - val_loss: 0.1920 - val_acc: 0.9285
Epoch 18/21
 - 20s - loss: 0.1897 - acc: 0.9312 - val_loss: 0.1746 - val_acc: 0.9386
Epoch 19/21
 - 20s - loss: 0.1859 - acc: 0.9330 - val_loss: 0.1592 - val_acc: 0.9434
Epoch 20/21
 - 20s - loss: 0.1798 - acc: 0.9369 - val_loss: 0.1620 - val_acc: 0.9405
Epoch 21/21
 - 20s - loss: 0.1739 - acc: 0.9386 - val_loss: 0.1520 - val_acc: 0.9472
Test accuracy:0.840
current auc_score ------------------> 0.918
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5040 - acc: 0.7575 - val_loss: 0.6681 - val_acc: 0.6742
Epoch 2/21
 - 20s - loss: 0.4050 - acc: 0.8125 - val_loss: 0.3938 - val_acc: 0.8199
Epoch 3/21
 - 20s - loss: 0.3630 - acc: 0.8392 - val_loss: 0.3618 - val_acc: 0.8400
Epoch 4/21
 - 20s - loss: 0.3355 - acc: 0.8564 - val_loss: 0.3056 - val_acc: 0.8716
Epoch 5/21
 - 21s - loss: 0.3134 - acc: 0.8692 - val_loss: 0.2830 - val_acc: 0.8793
Epoch 6/21
 - 20s - loss: 0.2968 - acc: 0.8781 - val_loss: 0.2910 - val_acc: 0.8758
Epoch 7/21
 - 20s - loss: 0.2815 - acc: 0.8878 - val_loss: 0.2475 - val_acc: 0.9050
Epoch 8/21
 - 20s - loss: 0.2664 - acc: 0.8938 - val_loss: 0.2436 - val_acc: 0.9056
Epoch 9/21
 - 20s - loss: 0.2523 - acc: 0.9010 - val_loss: 0.2230 - val_acc: 0.9128
Epoch 10/21
 - 20s - loss: 0.2421 - acc: 0.9079 - val_loss: 0.2104 - val_acc: 0.9193
Epoch 11/21
 - 21s - loss: 0.2369 - acc: 0.9079 - val_loss: 0.1990 - val_acc: 0.9275
Epoch 12/21
 - 20s - loss: 0.2285 - acc: 0.9137 - val_loss: 0.2363 - val_acc: 0.9052
Epoch 13/21
 - 20s - loss: 0.2171 - acc: 0.9192 - val_loss: 0.1895 - val_acc: 0.9302
Epoch 14/21
 - 20s - loss: 0.2080 - acc: 0.9246 - val_loss: 0.1881 - val_acc: 0.9303
Epoch 15/21
 - 20s - loss: 0.2034 - acc: 0.9261 - val_loss: 0.1628 - val_acc: 0.9440
Epoch 16/21
 - 20s - loss: 0.1951 - acc: 0.9298 - val_loss: 0.1691 - val_acc: 0.9388
Epoch 17/21
 - 20s - loss: 0.1864 - acc: 0.9333 - val_loss: 0.1663 - val_acc: 0.9408
Epoch 18/21
 - 20s - loss: 0.1803 - acc: 0.9375 - val_loss: 0.1507 - val_acc: 0.9508
Epoch 19/21
 - 20s - loss: 0.1780 - acc: 0.9372 - val_loss: 0.1604 - val_acc: 0.9439
Epoch 20/21
 - 20s - loss: 0.1711 - acc: 0.9408 - val_loss: 0.1372 - val_acc: 0.9533
Epoch 21/21
 - 20s - loss: 0.1683 - acc: 0.9420 - val_loss: 0.1352 - val_acc: 0.9546
Test accuracy:0.853
current auc_score ------------------> 0.942
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5162 - acc: 0.7517 - val_loss: 0.8201 - val_acc: 0.5963
Epoch 2/21
 - 20s - loss: 0.4302 - acc: 0.7947 - val_loss: 0.5291 - val_acc: 0.7400
Epoch 3/21
 - 20s - loss: 0.3902 - acc: 0.8198 - val_loss: 0.4102 - val_acc: 0.8026
Epoch 4/21
 - 20s - loss: 0.3630 - acc: 0.8395 - val_loss: 0.5408 - val_acc: 0.7417
Epoch 5/21
 - 20s - loss: 0.3403 - acc: 0.8523 - val_loss: 0.3479 - val_acc: 0.8421
Epoch 6/21
 - 20s - loss: 0.3213 - acc: 0.8656 - val_loss: 0.3238 - val_acc: 0.8557
Epoch 7/21
 - 20s - loss: 0.3062 - acc: 0.8725 - val_loss: 0.2920 - val_acc: 0.8770
Epoch 8/21
 - 20s - loss: 0.2926 - acc: 0.8804 - val_loss: 0.2768 - val_acc: 0.8825
Epoch 9/21
 - 20s - loss: 0.2781 - acc: 0.8883 - val_loss: 0.3002 - val_acc: 0.8692
Epoch 10/21
 - 20s - loss: 0.2646 - acc: 0.8961 - val_loss: 0.2449 - val_acc: 0.9017
Epoch 11/21
 - 20s - loss: 0.2571 - acc: 0.8986 - val_loss: 0.2295 - val_acc: 0.9083
Epoch 12/21
 - 20s - loss: 0.2456 - acc: 0.9045 - val_loss: 0.2542 - val_acc: 0.8960
Epoch 13/21
 - 20s - loss: 0.2382 - acc: 0.9083 - val_loss: 0.2225 - val_acc: 0.9144
Epoch 14/21
 - 20s - loss: 0.2290 - acc: 0.9120 - val_loss: 0.2099 - val_acc: 0.9202
Epoch 15/21
 - 20s - loss: 0.2224 - acc: 0.9162 - val_loss: 0.2496 - val_acc: 0.8991
Epoch 16/21
 - 20s - loss: 0.2157 - acc: 0.9190 - val_loss: 0.2219 - val_acc: 0.9116
Epoch 17/21
 - 20s - loss: 0.2089 - acc: 0.9236 - val_loss: 0.1825 - val_acc: 0.9329
Epoch 18/21
 - 20s - loss: 0.2002 - acc: 0.9274 - val_loss: 0.2055 - val_acc: 0.9222
Epoch 19/21
 - 20s - loss: 0.1943 - acc: 0.9306 - val_loss: 0.1706 - val_acc: 0.9393
Epoch 20/21
 - 20s - loss: 0.1901 - acc: 0.9310 - val_loss: 0.1945 - val_acc: 0.9286
Epoch 21/21
 - 20s - loss: 0.1823 - acc: 0.9357 - val_loss: 0.1542 - val_acc: 0.9497
Test accuracy:0.833
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5041 - acc: 0.7654 - val_loss: 0.6201 - val_acc: 0.7049
Epoch 2/21
 - 20s - loss: 0.4144 - acc: 0.8090 - val_loss: 0.4581 - val_acc: 0.7951
Epoch 3/21
 - 20s - loss: 0.3757 - acc: 0.8327 - val_loss: 0.5158 - val_acc: 0.7573
Epoch 4/21
 - 20s - loss: 0.3479 - acc: 0.8489 - val_loss: 0.3855 - val_acc: 0.8282
Epoch 5/21
 - 20s - loss: 0.3286 - acc: 0.8609 - val_loss: 0.3371 - val_acc: 0.8581
Epoch 6/21
 - 20s - loss: 0.3073 - acc: 0.8740 - val_loss: 0.3047 - val_acc: 0.8745
Epoch 7/21
 - 20s - loss: 0.2925 - acc: 0.8801 - val_loss: 0.3017 - val_acc: 0.8753
Epoch 8/21
 - 20s - loss: 0.2830 - acc: 0.8862 - val_loss: 0.2572 - val_acc: 0.8975
Epoch 9/21
 - 20s - loss: 0.2693 - acc: 0.8928 - val_loss: 0.3246 - val_acc: 0.8611
Epoch 10/21
 - 20s - loss: 0.2556 - acc: 0.8999 - val_loss: 0.2552 - val_acc: 0.9044
Epoch 11/21
 - 20s - loss: 0.2450 - acc: 0.9050 - val_loss: 0.2190 - val_acc: 0.9173
Epoch 12/21
 - 20s - loss: 0.2351 - acc: 0.9106 - val_loss: 0.2602 - val_acc: 0.8940
Epoch 13/21
 - 20s - loss: 0.2279 - acc: 0.9138 - val_loss: 0.2442 - val_acc: 0.9047
Epoch 14/21
 - 20s - loss: 0.2194 - acc: 0.9180 - val_loss: 0.2224 - val_acc: 0.9189

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 20s - loss: 0.2096 - acc: 0.9230 - val_loss: 0.1896 - val_acc: 0.9357
Epoch 16/21
 - 20s - loss: 0.2045 - acc: 0.9242 - val_loss: 0.2065 - val_acc: 0.9288
Epoch 17/21
 - 20s - loss: 0.2022 - acc: 0.9255 - val_loss: 0.1779 - val_acc: 0.9391
Epoch 18/21
 - 20s - loss: 0.1992 - acc: 0.9269 - val_loss: 0.1847 - val_acc: 0.9379
Epoch 19/21
 - 20s - loss: 0.1972 - acc: 0.9276 - val_loss: 0.1800 - val_acc: 0.9401
Epoch 20/21
 - 20s - loss: 0.1954 - acc: 0.9305 - val_loss: 0.1828 - val_acc: 0.9398

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 21/21
 - 20s - loss: 0.1937 - acc: 0.9301 - val_loss: 0.1803 - val_acc: 0.9391
Test accuracy:0.840
current auc_score ------------------> 0.959
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5026 - acc: 0.7637 - val_loss: 0.5982 - val_acc: 0.7047
Epoch 2/21
 - 20s - loss: 0.4018 - acc: 0.8165 - val_loss: 0.3913 - val_acc: 0.8192
Epoch 3/21
 - 20s - loss: 0.3600 - acc: 0.8414 - val_loss: 0.3610 - val_acc: 0.8376
Epoch 4/21
 - 20s - loss: 0.3341 - acc: 0.8580 - val_loss: 0.3378 - val_acc: 0.8532
Epoch 5/21
 - 20s - loss: 0.3137 - acc: 0.8670 - val_loss: 0.4162 - val_acc: 0.8109
Epoch 6/21
 - 20s - loss: 0.2969 - acc: 0.8776 - val_loss: 0.2984 - val_acc: 0.8754
Epoch 7/21
 - 20s - loss: 0.2828 - acc: 0.8860 - val_loss: 0.2833 - val_acc: 0.8810
Epoch 8/21
 - 20s - loss: 0.2718 - acc: 0.8928 - val_loss: 0.3202 - val_acc: 0.8677
Epoch 9/21
 - 20s - loss: 0.2598 - acc: 0.8981 - val_loss: 0.4271 - val_acc: 0.8214
Epoch 10/21
 - 20s - loss: 0.2484 - acc: 0.9029 - val_loss: 0.3288 - val_acc: 0.8579

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 11/21
 - 20s - loss: 0.2355 - acc: 0.9101 - val_loss: 0.2757 - val_acc: 0.8881
Epoch 12/21
 - 20s - loss: 0.2296 - acc: 0.9133 - val_loss: 0.2396 - val_acc: 0.9073
Epoch 13/21
 - 20s - loss: 0.2280 - acc: 0.9139 - val_loss: 0.2364 - val_acc: 0.9103
Epoch 14/21
 - 20s - loss: 0.2233 - acc: 0.9156 - val_loss: 0.2737 - val_acc: 0.8884
Epoch 15/21
 - 20s - loss: 0.2234 - acc: 0.9163 - val_loss: 0.2977 - val_acc: 0.8739
Epoch 16/21
 - 20s - loss: 0.2194 - acc: 0.9166 - val_loss: 0.2632 - val_acc: 0.8946

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 17/21
 - 20s - loss: 0.2175 - acc: 0.9190 - val_loss: 0.2324 - val_acc: 0.9076
Epoch 00017: early stopping
Test accuracy:0.815
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5076 - acc: 0.7588 - val_loss: 0.4482 - val_acc: 0.7776
Epoch 2/21
 - 20s - loss: 0.4025 - acc: 0.8162 - val_loss: 0.3749 - val_acc: 0.8291
Epoch 3/21
 - 20s - loss: 0.3660 - acc: 0.8369 - val_loss: 0.3923 - val_acc: 0.8169
Epoch 4/21
 - 20s - loss: 0.3397 - acc: 0.8533 - val_loss: 0.3684 - val_acc: 0.8318
Epoch 5/21
 - 20s - loss: 0.3201 - acc: 0.8656 - val_loss: 0.3123 - val_acc: 0.8677
Epoch 6/21
 - 20s - loss: 0.3009 - acc: 0.8747 - val_loss: 0.2785 - val_acc: 0.8840
Epoch 7/21
 - 20s - loss: 0.2855 - acc: 0.8829 - val_loss: 0.2567 - val_acc: 0.8982
Epoch 8/21
 - 20s - loss: 0.2707 - acc: 0.8943 - val_loss: 0.2420 - val_acc: 0.9064
Epoch 9/21
 - 20s - loss: 0.2591 - acc: 0.8983 - val_loss: 0.2502 - val_acc: 0.9019
Epoch 10/21
 - 20s - loss: 0.2490 - acc: 0.9033 - val_loss: 0.2490 - val_acc: 0.9016
Epoch 11/21
 - 20s - loss: 0.2391 - acc: 0.9080 - val_loss: 0.2228 - val_acc: 0.9159
Epoch 12/21
 - 20s - loss: 0.2279 - acc: 0.9143 - val_loss: 0.2153 - val_acc: 0.9139
Epoch 13/21
 - 20s - loss: 0.2179 - acc: 0.9192 - val_loss: 0.2256 - val_acc: 0.9155
Epoch 14/21
 - 20s - loss: 0.2105 - acc: 0.9238 - val_loss: 0.2447 - val_acc: 0.8996
Epoch 15/21
 - 20s - loss: 0.2031 - acc: 0.9253 - val_loss: 0.2106 - val_acc: 0.9213
Epoch 16/21
 - 20s - loss: 0.1967 - acc: 0.9286 - val_loss: 0.2115 - val_acc: 0.9209
Epoch 17/21
 - 20s - loss: 0.1887 - acc: 0.9336 - val_loss: 0.2014 - val_acc: 0.9266
Epoch 18/21
 - 20s - loss: 0.1856 - acc: 0.9326 - val_loss: 0.1610 - val_acc: 0.9440
Epoch 19/21
 - 20s - loss: 0.1766 - acc: 0.9379 - val_loss: 0.1842 - val_acc: 0.9347
Epoch 20/21
 - 20s - loss: 0.1721 - acc: 0.9406 - val_loss: 0.2086 - val_acc: 0.9213
Epoch 21/21
 - 20s - loss: 0.1686 - acc: 0.9418 - val_loss: 0.1829 - val_acc: 0.9334

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.782
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5207 - acc: 0.7476 - val_loss: 0.5103 - val_acc: 0.7422
Epoch 2/21
 - 20s - loss: 0.4219 - acc: 0.8013 - val_loss: 0.4941 - val_acc: 0.7578
Epoch 3/21
 - 20s - loss: 0.3841 - acc: 0.8251 - val_loss: 0.4166 - val_acc: 0.8051
Epoch 4/21
 - 20s - loss: 0.3582 - acc: 0.8451 - val_loss: 0.3737 - val_acc: 0.8289
Epoch 5/21
 - 20s - loss: 0.3378 - acc: 0.8555 - val_loss: 0.3698 - val_acc: 0.8379
Epoch 6/21
 - 20s - loss: 0.3194 - acc: 0.8645 - val_loss: 0.3812 - val_acc: 0.8277
Epoch 7/21
 - 20s - loss: 0.3027 - acc: 0.8748 - val_loss: 0.3082 - val_acc: 0.8675
Epoch 8/21
 - 20s - loss: 0.2834 - acc: 0.8848 - val_loss: 0.3566 - val_acc: 0.8465
Epoch 9/21
 - 20s - loss: 0.2748 - acc: 0.8905 - val_loss: 0.2993 - val_acc: 0.8804
Epoch 10/21
 - 20s - loss: 0.2607 - acc: 0.8980 - val_loss: 0.2753 - val_acc: 0.8863
Epoch 11/21
 - 20s - loss: 0.2483 - acc: 0.9040 - val_loss: 0.2680 - val_acc: 0.8912
Epoch 12/21
 - 20s - loss: 0.2379 - acc: 0.9092 - val_loss: 0.2276 - val_acc: 0.9066
Epoch 13/21
 - 20s - loss: 0.2297 - acc: 0.9118 - val_loss: 0.2190 - val_acc: 0.9149
Epoch 14/21
 - 20s - loss: 0.2212 - acc: 0.9160 - val_loss: 0.2776 - val_acc: 0.8828
Epoch 15/21
 - 20s - loss: 0.2120 - acc: 0.9214 - val_loss: 0.2066 - val_acc: 0.9222
Epoch 16/21
 - 20s - loss: 0.2066 - acc: 0.9228 - val_loss: 0.2366 - val_acc: 0.9071
Epoch 17/21
 - 20s - loss: 0.1999 - acc: 0.9271 - val_loss: 0.1960 - val_acc: 0.9247
Epoch 18/21
 - 20s - loss: 0.1896 - acc: 0.9312 - val_loss: 0.1708 - val_acc: 0.9381
Epoch 19/21
 - 20s - loss: 0.1855 - acc: 0.9327 - val_loss: 0.1842 - val_acc: 0.9319
Epoch 20/21
 - 20s - loss: 0.1822 - acc: 0.9335 - val_loss: 0.1824 - val_acc: 0.9335
Epoch 21/21
 - 20s - loss: 0.1732 - acc: 0.9389 - val_loss: 0.1631 - val_acc: 0.9433
Test accuracy:0.810
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5086 - acc: 0.7555 - val_loss: 0.5725 - val_acc: 0.7200
Epoch 2/21
 - 20s - loss: 0.4108 - acc: 0.8076 - val_loss: 0.5430 - val_acc: 0.7391
Epoch 3/21
 - 20s - loss: 0.3676 - acc: 0.8342 - val_loss: 0.3955 - val_acc: 0.8168
Epoch 4/21
 - 20s - loss: 0.3370 - acc: 0.8539 - val_loss: 0.3107 - val_acc: 0.8732
Epoch 5/21
 - 20s - loss: 0.3197 - acc: 0.8645 - val_loss: 0.3439 - val_acc: 0.8489
Epoch 6/21
 - 20s - loss: 0.3024 - acc: 0.8748 - val_loss: 0.2906 - val_acc: 0.8839
Epoch 7/21
 - 20s - loss: 0.2872 - acc: 0.8835 - val_loss: 0.2726 - val_acc: 0.8918
Epoch 8/21
 - 20s - loss: 0.2745 - acc: 0.8906 - val_loss: 0.2621 - val_acc: 0.8941
Epoch 9/21
 - 20s - loss: 0.2614 - acc: 0.8960 - val_loss: 0.2374 - val_acc: 0.9094
Epoch 10/21
 - 20s - loss: 0.2510 - acc: 0.9030 - val_loss: 0.2253 - val_acc: 0.9167
Epoch 11/21
 - 20s - loss: 0.2377 - acc: 0.9093 - val_loss: 0.2430 - val_acc: 0.9062
Epoch 12/21
 - 20s - loss: 0.2301 - acc: 0.9133 - val_loss: 0.2388 - val_acc: 0.9105
Epoch 13/21
 - 20s - loss: 0.2219 - acc: 0.9167 - val_loss: 0.2207 - val_acc: 0.9218
Epoch 14/21
 - 20s - loss: 0.2155 - acc: 0.9203 - val_loss: 0.1819 - val_acc: 0.9371
Epoch 15/21
 - 20s - loss: 0.2063 - acc: 0.9243 - val_loss: 0.2009 - val_acc: 0.9295
Epoch 16/21
 - 20s - loss: 0.2006 - acc: 0.9268 - val_loss: 0.1999 - val_acc: 0.9261
Epoch 17/21
 - 20s - loss: 0.1966 - acc: 0.9285 - val_loss: 0.1649 - val_acc: 0.9433
Epoch 18/21
 - 20s - loss: 0.1890 - acc: 0.9313 - val_loss: 0.1683 - val_acc: 0.9375
Epoch 19/21
 - 20s - loss: 0.1829 - acc: 0.9353 - val_loss: 0.1687 - val_acc: 0.9396
Epoch 20/21
 - 20s - loss: 0.1786 - acc: 0.9359 - val_loss: 0.1773 - val_acc: 0.9345

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 20s - loss: 0.1693 - acc: 0.9420 - val_loss: 0.1394 - val_acc: 0.9528
Test accuracy:0.844
current auc_score ------------------> 0.950
accuracies:  [0.7939516129032258, 0.8455645161290323, 0.8400537634408602, 0.8533602150537635, 0.8327956989247312, 0.8399193548387097, 0.8151881720430108, 0.781989247311828, 0.8095430107526882, 0.8436827956989247]
aucs:  [0.9343, 0.9344, 0.918, 0.9423, 0.9407, 0.9588, 0.9437, 0.919, 0.9344, 0.95]
mean and std AUC:  0.938+/-0.012  max:   0.9588
['2-2-2', '30', '3', '16', '0.3', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5284 - acc: 0.7445 - val_loss: 0.6426 - val_acc: 0.6771
Epoch 2/21
 - 21s - loss: 0.4332 - acc: 0.7970 - val_loss: 0.6351 - val_acc: 0.6963
Epoch 3/21
 - 21s - loss: 0.3954 - acc: 0.8171 - val_loss: 0.4545 - val_acc: 0.7801
Epoch 4/21
 - 21s - loss: 0.3671 - acc: 0.8364 - val_loss: 0.3725 - val_acc: 0.8350
Epoch 5/21
 - 21s - loss: 0.3452 - acc: 0.8497 - val_loss: 0.3971 - val_acc: 0.8207
Epoch 6/21
 - 21s - loss: 0.3278 - acc: 0.8595 - val_loss: 0.3588 - val_acc: 0.8366
Epoch 7/21
 - 20s - loss: 0.3125 - acc: 0.8683 - val_loss: 0.3234 - val_acc: 0.8609
Epoch 8/21
 - 20s - loss: 0.2991 - acc: 0.8763 - val_loss: 0.3093 - val_acc: 0.8685
Epoch 9/21
 - 21s - loss: 0.2851 - acc: 0.8836 - val_loss: 0.3382 - val_acc: 0.8569
Epoch 10/21
 - 21s - loss: 0.2782 - acc: 0.8870 - val_loss: 0.5812 - val_acc: 0.7651
Epoch 11/21
 - 21s - loss: 0.2654 - acc: 0.8950 - val_loss: 0.2877 - val_acc: 0.8839
Epoch 12/21
 - 20s - loss: 0.2588 - acc: 0.8991 - val_loss: 0.2927 - val_acc: 0.8827
Epoch 13/21
 - 21s - loss: 0.2507 - acc: 0.9020 - val_loss: 0.2657 - val_acc: 0.8922
Epoch 14/21
 - 21s - loss: 0.2436 - acc: 0.9064 - val_loss: 0.2338 - val_acc: 0.9100
Epoch 15/21
 - 21s - loss: 0.2350 - acc: 0.9098 - val_loss: 0.2224 - val_acc: 0.9138
Epoch 16/21
 - 21s - loss: 0.2298 - acc: 0.9122 - val_loss: 0.2286 - val_acc: 0.9109
Epoch 17/21
 - 21s - loss: 0.2195 - acc: 0.9186 - val_loss: 0.1995 - val_acc: 0.9248
Epoch 18/21
 - 20s - loss: 0.2172 - acc: 0.9177 - val_loss: 0.2248 - val_acc: 0.9123
Epoch 19/21
 - 21s - loss: 0.2092 - acc: 0.9228 - val_loss: 0.2261 - val_acc: 0.9158
Epoch 20/21
 - 20s - loss: 0.2046 - acc: 0.9250 - val_loss: 0.2257 - val_acc: 0.9165

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 20s - loss: 0.1985 - acc: 0.9273 - val_loss: 0.1774 - val_acc: 0.9349
Test accuracy:0.836
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5281 - acc: 0.7421 - val_loss: 0.5211 - val_acc: 0.7305
Epoch 2/21
 - 20s - loss: 0.4300 - acc: 0.7948 - val_loss: 0.3941 - val_acc: 0.8117
Epoch 3/21
 - 20s - loss: 0.3948 - acc: 0.8170 - val_loss: 0.4045 - val_acc: 0.8055
Epoch 4/21
 - 20s - loss: 0.3710 - acc: 0.8321 - val_loss: 0.3510 - val_acc: 0.8412
Epoch 5/21
 - 20s - loss: 0.3527 - acc: 0.8449 - val_loss: 0.3537 - val_acc: 0.8390
Epoch 6/21
 - 20s - loss: 0.3353 - acc: 0.8550 - val_loss: 0.3024 - val_acc: 0.8672
Epoch 7/21
 - 20s - loss: 0.3203 - acc: 0.8639 - val_loss: 0.2888 - val_acc: 0.8768
Epoch 8/21
 - 20s - loss: 0.3051 - acc: 0.8709 - val_loss: 0.2977 - val_acc: 0.8686
Epoch 9/21
 - 20s - loss: 0.2941 - acc: 0.8786 - val_loss: 0.2772 - val_acc: 0.8842
Epoch 10/21
 - 20s - loss: 0.2840 - acc: 0.8839 - val_loss: 0.2621 - val_acc: 0.8893
Epoch 11/21
 - 20s - loss: 0.2725 - acc: 0.8894 - val_loss: 0.2536 - val_acc: 0.8956
Epoch 12/21
 - 20s - loss: 0.2643 - acc: 0.8940 - val_loss: 0.2535 - val_acc: 0.9027
Epoch 13/21
 - 20s - loss: 0.2556 - acc: 0.8983 - val_loss: 0.2534 - val_acc: 0.9025
Epoch 14/21
 - 20s - loss: 0.2466 - acc: 0.9034 - val_loss: 0.2161 - val_acc: 0.9160
Epoch 15/21
 - 20s - loss: 0.2380 - acc: 0.9074 - val_loss: 0.2047 - val_acc: 0.9198
Epoch 16/21
 - 20s - loss: 0.2352 - acc: 0.9097 - val_loss: 0.2088 - val_acc: 0.9191
Epoch 17/21
 - 20s - loss: 0.2258 - acc: 0.9135 - val_loss: 0.1973 - val_acc: 0.9252
Epoch 18/21
 - 20s - loss: 0.2192 - acc: 0.9175 - val_loss: 0.1767 - val_acc: 0.9367
Epoch 19/21
 - 20s - loss: 0.2167 - acc: 0.9187 - val_loss: 0.1799 - val_acc: 0.9330
Epoch 20/21
 - 20s - loss: 0.2096 - acc: 0.9226 - val_loss: 0.1761 - val_acc: 0.9350
Epoch 21/21
 - 20s - loss: 0.2028 - acc: 0.9253 - val_loss: 0.1695 - val_acc: 0.9365
Test accuracy:0.834
current auc_score ------------------> 0.915
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5157 - acc: 0.7507 - val_loss: 0.5643 - val_acc: 0.7107
Epoch 2/21
 - 21s - loss: 0.4308 - acc: 0.7976 - val_loss: 0.4552 - val_acc: 0.7831
Epoch 3/21
 - 20s - loss: 0.3961 - acc: 0.8178 - val_loss: 0.3730 - val_acc: 0.8312
Epoch 4/21
 - 21s - loss: 0.3711 - acc: 0.8346 - val_loss: 0.3681 - val_acc: 0.8379
Epoch 5/21
 - 21s - loss: 0.3522 - acc: 0.8457 - val_loss: 0.4143 - val_acc: 0.8047
Epoch 6/21
 - 21s - loss: 0.3372 - acc: 0.8532 - val_loss: 0.3171 - val_acc: 0.8662
Epoch 7/21
 - 21s - loss: 0.3239 - acc: 0.8625 - val_loss: 0.3226 - val_acc: 0.8572
Epoch 8/21
 - 21s - loss: 0.3115 - acc: 0.8686 - val_loss: 0.2957 - val_acc: 0.8784
Epoch 9/21
 - 21s - loss: 0.3001 - acc: 0.8765 - val_loss: 0.3008 - val_acc: 0.8754
Epoch 10/21
 - 21s - loss: 0.2894 - acc: 0.8819 - val_loss: 0.2665 - val_acc: 0.8912
Epoch 11/21
 - 21s - loss: 0.2795 - acc: 0.8855 - val_loss: 0.2507 - val_acc: 0.8998
Epoch 12/21
 - 21s - loss: 0.2688 - acc: 0.8914 - val_loss: 0.2504 - val_acc: 0.9001
Epoch 13/21
 - 21s - loss: 0.2591 - acc: 0.8978 - val_loss: 0.2277 - val_acc: 0.9128
Epoch 14/21
 - 21s - loss: 0.2536 - acc: 0.8995 - val_loss: 0.2604 - val_acc: 0.8966
Epoch 15/21
 - 21s - loss: 0.2426 - acc: 0.9063 - val_loss: 0.2169 - val_acc: 0.9202
Epoch 16/21
 - 21s - loss: 0.2358 - acc: 0.9091 - val_loss: 0.2155 - val_acc: 0.9173
Epoch 17/21
 - 21s - loss: 0.2286 - acc: 0.9138 - val_loss: 0.2007 - val_acc: 0.9237
Epoch 18/21
 - 21s - loss: 0.2189 - acc: 0.9176 - val_loss: 0.2066 - val_acc: 0.9231
Epoch 19/21
 - 21s - loss: 0.2173 - acc: 0.9194 - val_loss: 0.2060 - val_acc: 0.9242
Epoch 20/21
 - 21s - loss: 0.2116 - acc: 0.9223 - val_loss: 0.1874 - val_acc: 0.9316
Epoch 21/21
 - 21s - loss: 0.2046 - acc: 0.9224 - val_loss: 0.1900 - val_acc: 0.9317
Test accuracy:0.825
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5230 - acc: 0.7454 - val_loss: 0.6530 - val_acc: 0.6647
Epoch 2/21
 - 21s - loss: 0.4383 - acc: 0.7924 - val_loss: 0.6187 - val_acc: 0.7039
Epoch 3/21
 - 21s - loss: 0.4034 - acc: 0.8135 - val_loss: 0.6289 - val_acc: 0.7115
Epoch 4/21
 - 21s - loss: 0.3782 - acc: 0.8307 - val_loss: 0.4738 - val_acc: 0.7755
Epoch 5/21
 - 21s - loss: 0.3605 - acc: 0.8399 - val_loss: 0.4565 - val_acc: 0.7846
Epoch 6/21
 - 21s - loss: 0.3418 - acc: 0.8512 - val_loss: 0.4538 - val_acc: 0.7908
Epoch 7/21
 - 21s - loss: 0.3259 - acc: 0.8619 - val_loss: 0.4399 - val_acc: 0.7992
Epoch 8/21
 - 21s - loss: 0.3125 - acc: 0.8696 - val_loss: 0.3803 - val_acc: 0.8376
Epoch 9/21
 - 21s - loss: 0.2993 - acc: 0.8770 - val_loss: 0.3799 - val_acc: 0.8376
Epoch 10/21
 - 21s - loss: 0.2902 - acc: 0.8796 - val_loss: 0.3741 - val_acc: 0.8368
Epoch 11/21
 - 21s - loss: 0.2793 - acc: 0.8863 - val_loss: 0.3107 - val_acc: 0.8705
Epoch 12/21
 - 21s - loss: 0.2703 - acc: 0.8914 - val_loss: 0.4550 - val_acc: 0.8159
Epoch 13/21
 - 21s - loss: 0.2598 - acc: 0.8960 - val_loss: 0.3437 - val_acc: 0.8564
Epoch 14/21
 - 21s - loss: 0.2550 - acc: 0.9007 - val_loss: 0.2819 - val_acc: 0.8815
Epoch 15/21
 - 21s - loss: 0.2465 - acc: 0.9030 - val_loss: 0.2566 - val_acc: 0.8983
Epoch 16/21
 - 21s - loss: 0.2396 - acc: 0.9077 - val_loss: 0.2469 - val_acc: 0.9078
Epoch 17/21
 - 21s - loss: 0.2318 - acc: 0.9114 - val_loss: 0.2690 - val_acc: 0.8983
Epoch 18/21
 - 21s - loss: 0.2290 - acc: 0.9129 - val_loss: 0.2944 - val_acc: 0.8931
Epoch 19/21
 - 21s - loss: 0.2208 - acc: 0.9184 - val_loss: 0.2154 - val_acc: 0.9182
Epoch 20/21
 - 21s - loss: 0.2163 - acc: 0.9182 - val_loss: 0.2057 - val_acc: 0.9237
Epoch 21/21
 - 21s - loss: 0.2096 - acc: 0.9210 - val_loss: 0.2122 - val_acc: 0.9238
Test accuracy:0.836
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5304 - acc: 0.7446 - val_loss: 0.5472 - val_acc: 0.7144
Epoch 2/21
 - 21s - loss: 0.4453 - acc: 0.7894 - val_loss: 0.6489 - val_acc: 0.6673
Epoch 3/21
 - 21s - loss: 0.4095 - acc: 0.8093 - val_loss: 0.6137 - val_acc: 0.6878
Epoch 4/21
 - 21s - loss: 0.3842 - acc: 0.8265 - val_loss: 0.6209 - val_acc: 0.7123

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 21s - loss: 0.3684 - acc: 0.8352 - val_loss: 0.5235 - val_acc: 0.7405
Epoch 6/21
 - 20s - loss: 0.3616 - acc: 0.8399 - val_loss: 0.5753 - val_acc: 0.7262
Epoch 7/21
 - 21s - loss: 0.3543 - acc: 0.8438 - val_loss: 0.5128 - val_acc: 0.7574
Epoch 8/21
 - 20s - loss: 0.3489 - acc: 0.8469 - val_loss: 0.5161 - val_acc: 0.7508
Epoch 9/21
 - 20s - loss: 0.3420 - acc: 0.8510 - val_loss: 0.4805 - val_acc: 0.7674
Epoch 10/21
 - 20s - loss: 0.3378 - acc: 0.8543 - val_loss: 0.4803 - val_acc: 0.7682
Epoch 11/21
 - 21s - loss: 0.3339 - acc: 0.8552 - val_loss: 0.4395 - val_acc: 0.7892
Epoch 12/21
 - 20s - loss: 0.3302 - acc: 0.8583 - val_loss: 0.4279 - val_acc: 0.7935
Epoch 13/21
 - 20s - loss: 0.3250 - acc: 0.8600 - val_loss: 0.3955 - val_acc: 0.8135
Epoch 14/21
 - 20s - loss: 0.3198 - acc: 0.8663 - val_loss: 0.4193 - val_acc: 0.7992
Epoch 15/21
 - 20s - loss: 0.3162 - acc: 0.8689 - val_loss: 0.3988 - val_acc: 0.8109
Epoch 16/21
 - 20s - loss: 0.3142 - acc: 0.8681 - val_loss: 0.4572 - val_acc: 0.7853

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 17/21
 - 20s - loss: 0.3079 - acc: 0.8720 - val_loss: 0.4302 - val_acc: 0.7941
Epoch 00017: early stopping
Test accuracy:0.820
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5242 - acc: 0.7526 - val_loss: 0.5013 - val_acc: 0.7472
Epoch 2/21
 - 20s - loss: 0.4377 - acc: 0.7922 - val_loss: 0.4132 - val_acc: 0.8091
Epoch 3/21
 - 20s - loss: 0.4003 - acc: 0.8155 - val_loss: 0.4130 - val_acc: 0.8020
Epoch 4/21
 - 20s - loss: 0.3707 - acc: 0.8338 - val_loss: 0.3340 - val_acc: 0.8525
Epoch 5/21
 - 20s - loss: 0.3478 - acc: 0.8465 - val_loss: 0.3170 - val_acc: 0.8617
Epoch 6/21
 - 20s - loss: 0.3300 - acc: 0.8611 - val_loss: 0.2961 - val_acc: 0.8761
Epoch 7/21
 - 20s - loss: 0.3131 - acc: 0.8687 - val_loss: 0.2998 - val_acc: 0.8731
Epoch 8/21
 - 21s - loss: 0.3023 - acc: 0.8755 - val_loss: 0.2597 - val_acc: 0.8978
Epoch 9/21
 - 21s - loss: 0.2886 - acc: 0.8830 - val_loss: 0.2495 - val_acc: 0.9014
Epoch 10/21
 - 21s - loss: 0.2763 - acc: 0.8894 - val_loss: 0.2307 - val_acc: 0.9096
Epoch 11/21
 - 21s - loss: 0.2690 - acc: 0.8933 - val_loss: 0.2465 - val_acc: 0.9024
Epoch 12/21
 - 20s - loss: 0.2572 - acc: 0.9009 - val_loss: 0.2417 - val_acc: 0.9052
Epoch 13/21
 - 21s - loss: 0.2500 - acc: 0.9038 - val_loss: 0.2059 - val_acc: 0.9261
Epoch 14/21
 - 21s - loss: 0.2406 - acc: 0.9081 - val_loss: 0.1961 - val_acc: 0.9285
Epoch 15/21
 - 20s - loss: 0.2345 - acc: 0.9107 - val_loss: 0.2052 - val_acc: 0.9236
Epoch 16/21
 - 21s - loss: 0.2282 - acc: 0.9136 - val_loss: 0.1901 - val_acc: 0.9290
Epoch 17/21
 - 21s - loss: 0.2230 - acc: 0.9159 - val_loss: 0.1750 - val_acc: 0.9356
Epoch 18/21
 - 21s - loss: 0.2149 - acc: 0.9199 - val_loss: 0.1681 - val_acc: 0.9403
Epoch 19/21
 - 21s - loss: 0.2083 - acc: 0.9245 - val_loss: 0.1857 - val_acc: 0.9335
Epoch 20/21
 - 21s - loss: 0.2004 - acc: 0.9282 - val_loss: 0.1562 - val_acc: 0.9452
Epoch 21/21
 - 21s - loss: 0.1979 - acc: 0.9275 - val_loss: 0.1569 - val_acc: 0.9444
Test accuracy:0.850
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5137 - acc: 0.7578 - val_loss: 0.6160 - val_acc: 0.6881
Epoch 2/21
 - 21s - loss: 0.4187 - acc: 0.8062 - val_loss: 0.7407 - val_acc: 0.6722
Epoch 3/21
 - 21s - loss: 0.3845 - acc: 0.8274 - val_loss: 0.5352 - val_acc: 0.7432
Epoch 4/21
 - 21s - loss: 0.3630 - acc: 0.8382 - val_loss: 0.4314 - val_acc: 0.7978
Epoch 5/21
 - 21s - loss: 0.3439 - acc: 0.8503 - val_loss: 0.4508 - val_acc: 0.7964
Epoch 6/21
 - 21s - loss: 0.3260 - acc: 0.8604 - val_loss: 0.3387 - val_acc: 0.8527
Epoch 7/21
 - 21s - loss: 0.3105 - acc: 0.8699 - val_loss: 0.3671 - val_acc: 0.8337
Epoch 8/21
 - 21s - loss: 0.2978 - acc: 0.8760 - val_loss: 0.4170 - val_acc: 0.8254
Epoch 9/21
 - 21s - loss: 0.2864 - acc: 0.8852 - val_loss: 0.3875 - val_acc: 0.8287

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 21s - loss: 0.2744 - acc: 0.8907 - val_loss: 0.4163 - val_acc: 0.8218
Epoch 00010: early stopping
Test accuracy:0.785
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5087 - acc: 0.7592 - val_loss: 0.6596 - val_acc: 0.6526
Epoch 2/21
 - 21s - loss: 0.4354 - acc: 0.7927 - val_loss: 0.7070 - val_acc: 0.6402
Epoch 3/21
 - 21s - loss: 0.4031 - acc: 0.8109 - val_loss: 0.6641 - val_acc: 0.6542
Epoch 4/21
 - 21s - loss: 0.3791 - acc: 0.8276 - val_loss: 0.7629 - val_acc: 0.6544

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 21s - loss: 0.3627 - acc: 0.8360 - val_loss: 0.8021 - val_acc: 0.6408
Epoch 6/21
 - 21s - loss: 0.3566 - acc: 0.8428 - val_loss: 0.7314 - val_acc: 0.6672
Epoch 7/21
 - 21s - loss: 0.3499 - acc: 0.8456 - val_loss: 0.7505 - val_acc: 0.6658

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 8/21
 - 21s - loss: 0.3442 - acc: 0.8491 - val_loss: 0.7328 - val_acc: 0.6689
Epoch 9/21
 - 21s - loss: 0.3431 - acc: 0.8513 - val_loss: 0.7003 - val_acc: 0.6851
Epoch 10/21
 - 21s - loss: 0.3394 - acc: 0.8535 - val_loss: 0.7096 - val_acc: 0.6819

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 11/21
 - 21s - loss: 0.3386 - acc: 0.8547 - val_loss: 0.7185 - val_acc: 0.6793
Epoch 12/21
 - 21s - loss: 0.3384 - acc: 0.8519 - val_loss: 0.7036 - val_acc: 0.6856
Epoch 13/21
 - 21s - loss: 0.3383 - acc: 0.8521 - val_loss: 0.7303 - val_acc: 0.6762

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0006999999711449197.
Epoch 14/21
 - 21s - loss: 0.3358 - acc: 0.8568 - val_loss: 0.7213 - val_acc: 0.6782
Epoch 15/21
 - 21s - loss: 0.3372 - acc: 0.8531 - val_loss: 0.7116 - val_acc: 0.6831
Epoch 16/21
 - 20s - loss: 0.3367 - acc: 0.8557 - val_loss: 0.7161 - val_acc: 0.6806

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00022135942831891703.
Epoch 00016: early stopping
Test accuracy:0.758
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5323 - acc: 0.7396 - val_loss: 0.5624 - val_acc: 0.7078
Epoch 2/21
 - 21s - loss: 0.4384 - acc: 0.7934 - val_loss: 0.4262 - val_acc: 0.7988
Epoch 3/21
 - 21s - loss: 0.4020 - acc: 0.8144 - val_loss: 0.4042 - val_acc: 0.8129
Epoch 4/21
 - 21s - loss: 0.3746 - acc: 0.8283 - val_loss: 0.4052 - val_acc: 0.8138
Epoch 5/21
 - 21s - loss: 0.3531 - acc: 0.8431 - val_loss: 0.3410 - val_acc: 0.8424
Epoch 6/21
 - 21s - loss: 0.3365 - acc: 0.8548 - val_loss: 0.3834 - val_acc: 0.8274
Epoch 7/21
 - 21s - loss: 0.3198 - acc: 0.8644 - val_loss: 0.4419 - val_acc: 0.8006
Epoch 8/21
 - 21s - loss: 0.3097 - acc: 0.8700 - val_loss: 0.3415 - val_acc: 0.8494

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/21
 - 20s - loss: 0.2949 - acc: 0.8791 - val_loss: 0.3249 - val_acc: 0.8598
Epoch 10/21
 - 20s - loss: 0.2911 - acc: 0.8805 - val_loss: 0.2935 - val_acc: 0.8731
Epoch 11/21
 - 21s - loss: 0.2874 - acc: 0.8823 - val_loss: 0.3294 - val_acc: 0.8568
Epoch 12/21
 - 21s - loss: 0.2827 - acc: 0.8857 - val_loss: 0.3210 - val_acc: 0.8584
Epoch 13/21
 - 21s - loss: 0.2790 - acc: 0.8866 - val_loss: 0.2977 - val_acc: 0.8705

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 14/21
 - 21s - loss: 0.2740 - acc: 0.8874 - val_loss: 0.2742 - val_acc: 0.8844
Epoch 15/21
 - 21s - loss: 0.2757 - acc: 0.8880 - val_loss: 0.2768 - val_acc: 0.8818
Epoch 16/21
 - 21s - loss: 0.2748 - acc: 0.8885 - val_loss: 0.2860 - val_acc: 0.8776
Epoch 17/21
 - 21s - loss: 0.2706 - acc: 0.8919 - val_loss: 0.2797 - val_acc: 0.8808

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 18/21
 - 21s - loss: 0.2723 - acc: 0.8904 - val_loss: 0.2700 - val_acc: 0.8845
Epoch 19/21
 - 21s - loss: 0.2728 - acc: 0.8906 - val_loss: 0.2696 - val_acc: 0.8858
Epoch 20/21
 - 21s - loss: 0.2700 - acc: 0.8906 - val_loss: 0.2744 - val_acc: 0.8828
Epoch 21/21
 - 21s - loss: 0.2713 - acc: 0.8893 - val_loss: 0.2766 - val_acc: 0.8830
Test accuracy:0.851
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.3
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5108 - acc: 0.7601 - val_loss: 0.5369 - val_acc: 0.7433
Epoch 2/21
 - 20s - loss: 0.4202 - acc: 0.8039 - val_loss: 0.4938 - val_acc: 0.7713
Epoch 3/21
 - 20s - loss: 0.3870 - acc: 0.8231 - val_loss: 0.3953 - val_acc: 0.8208
Epoch 4/21
 - 21s - loss: 0.3651 - acc: 0.8377 - val_loss: 0.3364 - val_acc: 0.8523
Epoch 5/21
 - 21s - loss: 0.3472 - acc: 0.8476 - val_loss: 0.3219 - val_acc: 0.8558
Epoch 6/21
 - 21s - loss: 0.3299 - acc: 0.8570 - val_loss: 0.3198 - val_acc: 0.8560
Epoch 7/21
 - 21s - loss: 0.3126 - acc: 0.8686 - val_loss: 0.2961 - val_acc: 0.8725
Epoch 8/21
 - 20s - loss: 0.2994 - acc: 0.8735 - val_loss: 0.3076 - val_acc: 0.8701
Epoch 9/21
 - 20s - loss: 0.2867 - acc: 0.8834 - val_loss: 0.2958 - val_acc: 0.8761
Epoch 10/21
 - 20s - loss: 0.2752 - acc: 0.8878 - val_loss: 0.2533 - val_acc: 0.8966
Epoch 11/21
 - 20s - loss: 0.2633 - acc: 0.8955 - val_loss: 0.2522 - val_acc: 0.8998
Epoch 12/21
 - 20s - loss: 0.2541 - acc: 0.9006 - val_loss: 0.2658 - val_acc: 0.8924
Epoch 13/21
 - 21s - loss: 0.2442 - acc: 0.9042 - val_loss: 0.2377 - val_acc: 0.9041
Epoch 14/21
 - 21s - loss: 0.2355 - acc: 0.9091 - val_loss: 0.2346 - val_acc: 0.9076
Epoch 15/21
 - 21s - loss: 0.2282 - acc: 0.9131 - val_loss: 0.2373 - val_acc: 0.9076
Epoch 16/21
 - 21s - loss: 0.2212 - acc: 0.9164 - val_loss: 0.2246 - val_acc: 0.9135
Epoch 17/21
 - 21s - loss: 0.2148 - acc: 0.9211 - val_loss: 0.2218 - val_acc: 0.9150
Epoch 18/21
 - 21s - loss: 0.2055 - acc: 0.9245 - val_loss: 0.1928 - val_acc: 0.9288
Epoch 19/21
 - 21s - loss: 0.1999 - acc: 0.9279 - val_loss: 0.1956 - val_acc: 0.9247
Epoch 20/21
 - 21s - loss: 0.1968 - acc: 0.9291 - val_loss: 0.1904 - val_acc: 0.9291
Epoch 21/21
 - 21s - loss: 0.1907 - acc: 0.9306 - val_loss: 0.1811 - val_acc: 0.9344
Test accuracy:0.841
current auc_score ------------------> 0.932
accuracies:  [0.8358870967741936, 0.8336021505376344, 0.8247311827956989, 0.8358870967741936, 0.8204301075268817, 0.8504032258064517, 0.7849462365591398, 0.7575268817204301, 0.8513440860215054, 0.8409946236559139]
aucs:  [0.9451, 0.9148, 0.9241, 0.9301, 0.941, 0.9365, 0.9463, 0.9216, 0.9444, 0.9322]
mean and std AUC:  0.934+/-0.01  max:   0.9463
['2-2-2', '30', '3', '16', '0.4', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5379 - acc: 0.7435 - val_loss: 0.4667 - val_acc: 0.7780
Epoch 2/21
 - 20s - loss: 0.4486 - acc: 0.7859 - val_loss: 0.5363 - val_acc: 0.7558
Epoch 3/21
 - 20s - loss: 0.4183 - acc: 0.8007 - val_loss: 0.3981 - val_acc: 0.8122
Epoch 4/21
 - 20s - loss: 0.3931 - acc: 0.8156 - val_loss: 0.3898 - val_acc: 0.8180
Epoch 5/21
 - 20s - loss: 0.3756 - acc: 0.8279 - val_loss: 0.4001 - val_acc: 0.8228
Epoch 6/21
 - 20s - loss: 0.3601 - acc: 0.8386 - val_loss: 0.3457 - val_acc: 0.8407
Epoch 7/21
 - 20s - loss: 0.3449 - acc: 0.8477 - val_loss: 0.3413 - val_acc: 0.8456
Epoch 8/21
 - 20s - loss: 0.3312 - acc: 0.8561 - val_loss: 0.3298 - val_acc: 0.8512
Epoch 9/21
 - 20s - loss: 0.3174 - acc: 0.8645 - val_loss: 0.3198 - val_acc: 0.8560
Epoch 10/21
 - 20s - loss: 0.3093 - acc: 0.8699 - val_loss: 0.3142 - val_acc: 0.8652
Epoch 11/21
 - 20s - loss: 0.3009 - acc: 0.8746 - val_loss: 0.3044 - val_acc: 0.8695
Epoch 12/21
 - 20s - loss: 0.2903 - acc: 0.8818 - val_loss: 0.3124 - val_acc: 0.8638
Epoch 13/21
 - 20s - loss: 0.2790 - acc: 0.8867 - val_loss: 0.2935 - val_acc: 0.8825
Epoch 14/21
 - 20s - loss: 0.2738 - acc: 0.8891 - val_loss: 0.3273 - val_acc: 0.8616
Epoch 15/21
 - 20s - loss: 0.2649 - acc: 0.8937 - val_loss: 0.3047 - val_acc: 0.8766
Epoch 16/21
 - 20s - loss: 0.2571 - acc: 0.8988 - val_loss: 0.2669 - val_acc: 0.8917
Epoch 17/21
 - 20s - loss: 0.2509 - acc: 0.9007 - val_loss: 0.2774 - val_acc: 0.8906
Epoch 18/21
 - 20s - loss: 0.2470 - acc: 0.9029 - val_loss: 0.2328 - val_acc: 0.9127
Epoch 19/21
 - 20s - loss: 0.2359 - acc: 0.9084 - val_loss: 0.2523 - val_acc: 0.9004
Epoch 20/21
 - 20s - loss: 0.2334 - acc: 0.9112 - val_loss: 0.2259 - val_acc: 0.9109
Epoch 21/21
 - 20s - loss: 0.2272 - acc: 0.9141 - val_loss: 0.2383 - val_acc: 0.9105
Test accuracy:0.881
current auc_score ------------------> 0.956
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5337 - acc: 0.7465 - val_loss: 0.6385 - val_acc: 0.6756
Epoch 2/21
 - 20s - loss: 0.4475 - acc: 0.7846 - val_loss: 0.7190 - val_acc: 0.6814
Epoch 3/21
 - 20s - loss: 0.4165 - acc: 0.8027 - val_loss: 0.4842 - val_acc: 0.7787
Epoch 4/21
 - 20s - loss: 0.3940 - acc: 0.8153 - val_loss: 0.4775 - val_acc: 0.7814
Epoch 5/21
 - 20s - loss: 0.3757 - acc: 0.8293 - val_loss: 0.4993 - val_acc: 0.7765
Epoch 6/21
 - 20s - loss: 0.3579 - acc: 0.8411 - val_loss: 0.4895 - val_acc: 0.7941
Epoch 7/21
 - 20s - loss: 0.3453 - acc: 0.8494 - val_loss: 0.4451 - val_acc: 0.8032
Epoch 8/21
 - 20s - loss: 0.3332 - acc: 0.8582 - val_loss: 0.4321 - val_acc: 0.8254
Epoch 9/21
 - 20s - loss: 0.3210 - acc: 0.8632 - val_loss: 0.3634 - val_acc: 0.8499
Epoch 10/21
 - 20s - loss: 0.3101 - acc: 0.8718 - val_loss: 0.3144 - val_acc: 0.8676
Epoch 11/21
 - 20s - loss: 0.3001 - acc: 0.8779 - val_loss: 0.4349 - val_acc: 0.8333
Epoch 12/21
 - 20s - loss: 0.2914 - acc: 0.8797 - val_loss: 0.3464 - val_acc: 0.8577
Epoch 13/21
 - 20s - loss: 0.2806 - acc: 0.8873 - val_loss: 0.3955 - val_acc: 0.8405

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/21
 - 20s - loss: 0.2718 - acc: 0.8922 - val_loss: 0.3380 - val_acc: 0.8651
Epoch 00014: early stopping
Test accuracy:0.835
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5270 - acc: 0.7508 - val_loss: 0.7038 - val_acc: 0.6466
Epoch 2/21
 - 20s - loss: 0.4385 - acc: 0.7896 - val_loss: 0.5435 - val_acc: 0.7366
Epoch 3/21
 - 20s - loss: 0.4105 - acc: 0.8054 - val_loss: 0.5225 - val_acc: 0.7516
Epoch 4/21
 - 20s - loss: 0.3904 - acc: 0.8181 - val_loss: 0.5604 - val_acc: 0.7385
Epoch 5/21
 - 20s - loss: 0.3713 - acc: 0.8309 - val_loss: 0.5220 - val_acc: 0.7721
Epoch 6/21
 - 20s - loss: 0.3590 - acc: 0.8392 - val_loss: 0.4637 - val_acc: 0.7839
Epoch 7/21
 - 20s - loss: 0.3457 - acc: 0.8484 - val_loss: 0.4756 - val_acc: 0.7833
Epoch 8/21
 - 20s - loss: 0.3365 - acc: 0.8529 - val_loss: 0.6018 - val_acc: 0.7486
Epoch 9/21
 - 20s - loss: 0.3255 - acc: 0.8598 - val_loss: 0.6314 - val_acc: 0.7464

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 20s - loss: 0.3143 - acc: 0.8664 - val_loss: 0.5045 - val_acc: 0.7786
Epoch 00010: early stopping
Test accuracy:0.803
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5322 - acc: 0.7490 - val_loss: 0.5695 - val_acc: 0.6979
Epoch 2/21
 - 20s - loss: 0.4471 - acc: 0.7887 - val_loss: 0.5628 - val_acc: 0.7211
Epoch 3/21
 - 20s - loss: 0.4201 - acc: 0.8047 - val_loss: 0.4390 - val_acc: 0.7939
Epoch 4/21
 - 20s - loss: 0.3964 - acc: 0.8202 - val_loss: 0.4223 - val_acc: 0.8052
Epoch 5/21
 - 20s - loss: 0.3770 - acc: 0.8299 - val_loss: 0.4447 - val_acc: 0.7897
Epoch 6/21
 - 20s - loss: 0.3619 - acc: 0.8398 - val_loss: 0.3956 - val_acc: 0.8189
Epoch 7/21
 - 20s - loss: 0.3499 - acc: 0.8466 - val_loss: 0.3764 - val_acc: 0.8370
Epoch 8/21
 - 20s - loss: 0.3362 - acc: 0.8528 - val_loss: 0.3998 - val_acc: 0.8195
Epoch 9/21
 - 20s - loss: 0.3240 - acc: 0.8613 - val_loss: 0.3585 - val_acc: 0.8407
Epoch 10/21
 - 20s - loss: 0.3128 - acc: 0.8702 - val_loss: 0.2928 - val_acc: 0.8732
Epoch 11/21
 - 20s - loss: 0.3013 - acc: 0.8744 - val_loss: 0.3346 - val_acc: 0.8520
Epoch 12/21
 - 20s - loss: 0.2911 - acc: 0.8798 - val_loss: 0.3166 - val_acc: 0.8701
Epoch 13/21
 - 20s - loss: 0.2833 - acc: 0.8831 - val_loss: 0.2804 - val_acc: 0.8800
Epoch 14/21
 - 20s - loss: 0.2750 - acc: 0.8887 - val_loss: 0.2793 - val_acc: 0.8819
Epoch 15/21
 - 20s - loss: 0.2666 - acc: 0.8913 - val_loss: 0.3858 - val_acc: 0.8322
Epoch 16/21
 - 20s - loss: 0.2604 - acc: 0.8954 - val_loss: 0.2604 - val_acc: 0.8956
Epoch 17/21
 - 20s - loss: 0.2521 - acc: 0.9003 - val_loss: 0.3237 - val_acc: 0.8598
Epoch 18/21
 - 20s - loss: 0.2467 - acc: 0.9032 - val_loss: 0.2591 - val_acc: 0.8973
Epoch 19/21
 - 20s - loss: 0.2393 - acc: 0.9078 - val_loss: 0.2359 - val_acc: 0.9098
Epoch 20/21
 - 20s - loss: 0.2361 - acc: 0.9087 - val_loss: 0.2237 - val_acc: 0.9149
Epoch 21/21
 - 20s - loss: 0.2309 - acc: 0.9108 - val_loss: 0.2256 - val_acc: 0.9086
Test accuracy:0.843
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5491 - acc: 0.7343 - val_loss: 0.6209 - val_acc: 0.6552
Epoch 2/21
 - 21s - loss: 0.4590 - acc: 0.7828 - val_loss: 0.7238 - val_acc: 0.6342
Epoch 3/21
 - 22s - loss: 0.4263 - acc: 0.8002 - val_loss: 0.7424 - val_acc: 0.6408
Epoch 4/21
 - 20s - loss: 0.4007 - acc: 0.8167 - val_loss: 0.6360 - val_acc: 0.6891

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 20s - loss: 0.3827 - acc: 0.8255 - val_loss: 0.5451 - val_acc: 0.7378
Epoch 6/21
 - 20s - loss: 0.3784 - acc: 0.8284 - val_loss: 0.5500 - val_acc: 0.7364
Epoch 7/21
 - 20s - loss: 0.3723 - acc: 0.8326 - val_loss: 0.5488 - val_acc: 0.7346
Epoch 8/21
 - 20s - loss: 0.3664 - acc: 0.8359 - val_loss: 0.5888 - val_acc: 0.7254

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 9/21
 - 20s - loss: 0.3636 - acc: 0.8354 - val_loss: 0.5685 - val_acc: 0.7346
Epoch 00009: early stopping
Test accuracy:0.739
current auc_score ------------------> 0.889
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5521 - acc: 0.7359 - val_loss: 0.5790 - val_acc: 0.6857
Epoch 2/21
 - 20s - loss: 0.4551 - acc: 0.7892 - val_loss: 0.6904 - val_acc: 0.6419
Epoch 3/21
 - 20s - loss: 0.4190 - acc: 0.8078 - val_loss: 0.5443 - val_acc: 0.7172
Epoch 4/21
 - 20s - loss: 0.3930 - acc: 0.8221 - val_loss: 0.4720 - val_acc: 0.7641
Epoch 5/21
 - 20s - loss: 0.3783 - acc: 0.8312 - val_loss: 0.4643 - val_acc: 0.7697
Epoch 6/21
 - 20s - loss: 0.3622 - acc: 0.8402 - val_loss: 0.5689 - val_acc: 0.7344
Epoch 7/21
 - 20s - loss: 0.3488 - acc: 0.8465 - val_loss: 0.5105 - val_acc: 0.7598
Epoch 8/21
 - 20s - loss: 0.3363 - acc: 0.8582 - val_loss: 0.6390 - val_acc: 0.7152

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/21
 - 20s - loss: 0.3283 - acc: 0.8608 - val_loss: 0.5082 - val_acc: 0.7721
Epoch 10/21
 - 20s - loss: 0.3231 - acc: 0.8634 - val_loss: 0.5052 - val_acc: 0.7742
Epoch 11/21
 - 20s - loss: 0.3192 - acc: 0.8648 - val_loss: 0.5417 - val_acc: 0.7614

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 12/21
 - 20s - loss: 0.3158 - acc: 0.8670 - val_loss: 0.5354 - val_acc: 0.7638
Epoch 13/21
 - 20s - loss: 0.3147 - acc: 0.8668 - val_loss: 0.4949 - val_acc: 0.7809
Epoch 14/21
 - 20s - loss: 0.3155 - acc: 0.8664 - val_loss: 0.4984 - val_acc: 0.7816

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 15/21
 - 20s - loss: 0.3141 - acc: 0.8677 - val_loss: 0.5042 - val_acc: 0.7775
Epoch 16/21
 - 20s - loss: 0.3145 - acc: 0.8671 - val_loss: 0.5013 - val_acc: 0.7790
Epoch 17/21
 - 20s - loss: 0.3116 - acc: 0.8688 - val_loss: 0.4939 - val_acc: 0.7814

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006999999711449197.
Epoch 18/21
 - 20s - loss: 0.3131 - acc: 0.8690 - val_loss: 0.4818 - val_acc: 0.7856
Epoch 19/21
 - 20s - loss: 0.3126 - acc: 0.8690 - val_loss: 0.4884 - val_acc: 0.7829
Epoch 20/21
 - 20s - loss: 0.3119 - acc: 0.8690 - val_loss: 0.4875 - val_acc: 0.7835

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00022135942831891703.
Epoch 21/21
 - 20s - loss: 0.3126 - acc: 0.8683 - val_loss: 0.4999 - val_acc: 0.7796
Test accuracy:0.776
current auc_score ------------------> 0.953
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5391 - acc: 0.7431 - val_loss: 0.5262 - val_acc: 0.7477
Epoch 2/21
 - 20s - loss: 0.4519 - acc: 0.7826 - val_loss: 0.6290 - val_acc: 0.7167
Epoch 3/21
 - 20s - loss: 0.4159 - acc: 0.8008 - val_loss: 0.5818 - val_acc: 0.7435
Epoch 4/21
 - 20s - loss: 0.3939 - acc: 0.8156 - val_loss: 0.7048 - val_acc: 0.7031

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 20s - loss: 0.3783 - acc: 0.8257 - val_loss: 0.7430 - val_acc: 0.7058
Epoch 00005: early stopping
Test accuracy:0.743
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5360 - acc: 0.7433 - val_loss: 0.6745 - val_acc: 0.6595
Epoch 2/21
 - 20s - loss: 0.4538 - acc: 0.7831 - val_loss: 0.6500 - val_acc: 0.7037
Epoch 3/21
 - 20s - loss: 0.4203 - acc: 0.8019 - val_loss: 0.6821 - val_acc: 0.6977
Epoch 4/21
 - 20s - loss: 0.3947 - acc: 0.8180 - val_loss: 0.5354 - val_acc: 0.7584
Epoch 5/21
 - 20s - loss: 0.3760 - acc: 0.8312 - val_loss: 0.4804 - val_acc: 0.7830
Epoch 6/21
 - 20s - loss: 0.3588 - acc: 0.8420 - val_loss: 0.5127 - val_acc: 0.7776
Epoch 7/21
 - 20s - loss: 0.3459 - acc: 0.8496 - val_loss: 0.4440 - val_acc: 0.7981
Epoch 8/21
 - 20s - loss: 0.3315 - acc: 0.8582 - val_loss: 0.4449 - val_acc: 0.8194
Epoch 9/21
 - 20s - loss: 0.3186 - acc: 0.8657 - val_loss: 0.3628 - val_acc: 0.8480
Epoch 10/21
 - 20s - loss: 0.3068 - acc: 0.8715 - val_loss: 0.4733 - val_acc: 0.8033
Epoch 11/21
 - 20s - loss: 0.2988 - acc: 0.8772 - val_loss: 0.4571 - val_acc: 0.8131
Epoch 12/21
 - 20s - loss: 0.2896 - acc: 0.8826 - val_loss: 0.3238 - val_acc: 0.8631
Epoch 13/21
 - 20s - loss: 0.2812 - acc: 0.8862 - val_loss: 0.2736 - val_acc: 0.8887
Epoch 14/21
 - 20s - loss: 0.2712 - acc: 0.8916 - val_loss: 0.3070 - val_acc: 0.8677
Epoch 15/21
 - 20s - loss: 0.2662 - acc: 0.8950 - val_loss: 0.3161 - val_acc: 0.8691
Epoch 16/21
 - 20s - loss: 0.2577 - acc: 0.8979 - val_loss: 0.3032 - val_acc: 0.8810

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/21
 - 20s - loss: 0.2517 - acc: 0.9018 - val_loss: 0.3000 - val_acc: 0.8811
Epoch 00017: early stopping
Test accuracy:0.836
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 21s - loss: 0.5422 - acc: 0.7395 - val_loss: 0.7608 - val_acc: 0.6131
Epoch 2/21
 - 20s - loss: 0.4631 - acc: 0.7786 - val_loss: 1.0761 - val_acc: 0.5513
Epoch 3/21
 - 20s - loss: 0.4333 - acc: 0.7946 - val_loss: 0.9122 - val_acc: 0.6133
Epoch 4/21
 - 20s - loss: 0.4088 - acc: 0.8072 - val_loss: 0.8090 - val_acc: 0.6517

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 20s - loss: 0.3938 - acc: 0.8186 - val_loss: 0.8136 - val_acc: 0.6431
Epoch 6/21
 - 20s - loss: 0.3868 - acc: 0.8236 - val_loss: 0.7882 - val_acc: 0.6573
Epoch 7/21
 - 20s - loss: 0.3829 - acc: 0.8265 - val_loss: 0.8002 - val_acc: 0.6501

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 8/21
 - 20s - loss: 0.3770 - acc: 0.8286 - val_loss: 0.7148 - val_acc: 0.6844
Epoch 9/21
 - 20s - loss: 0.3762 - acc: 0.8271 - val_loss: 0.7329 - val_acc: 0.6767
Epoch 10/21
 - 20s - loss: 0.3717 - acc: 0.8329 - val_loss: 0.7100 - val_acc: 0.6847
Epoch 11/21
 - 20s - loss: 0.3709 - acc: 0.8337 - val_loss: 0.7075 - val_acc: 0.6885
Epoch 12/21
 - 20s - loss: 0.3683 - acc: 0.8332 - val_loss: 0.6996 - val_acc: 0.6916
Epoch 13/21
 - 20s - loss: 0.3681 - acc: 0.8342 - val_loss: 0.7296 - val_acc: 0.6821
Epoch 14/21
 - 20s - loss: 0.3664 - acc: 0.8366 - val_loss: 0.7210 - val_acc: 0.6837
Epoch 15/21
 - 20s - loss: 0.3669 - acc: 0.8348 - val_loss: 0.7169 - val_acc: 0.6883

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 16/21
 - 20s - loss: 0.3654 - acc: 0.8367 - val_loss: 0.6830 - val_acc: 0.6995
Epoch 17/21
 - 20s - loss: 0.3633 - acc: 0.8382 - val_loss: 0.6763 - val_acc: 0.7026
Epoch 18/21
 - 20s - loss: 0.3616 - acc: 0.8375 - val_loss: 0.6696 - val_acc: 0.7043
Epoch 19/21
 - 20s - loss: 0.3614 - acc: 0.8382 - val_loss: 0.6819 - val_acc: 0.7006
Epoch 20/21
 - 20s - loss: 0.3604 - acc: 0.8384 - val_loss: 0.6882 - val_acc: 0.6987
Epoch 21/21
 - 20s - loss: 0.3616 - acc: 0.8393 - val_loss: 0.6726 - val_acc: 0.7031

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006999999711449197.
Test accuracy:0.721
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5400 - acc: 0.7393 - val_loss: 0.4997 - val_acc: 0.7529
Epoch 2/21
 - 20s - loss: 0.4531 - acc: 0.7824 - val_loss: 0.5328 - val_acc: 0.7292
Epoch 3/21
 - 20s - loss: 0.4234 - acc: 0.7991 - val_loss: 0.5675 - val_acc: 0.7295
Epoch 4/21
 - 20s - loss: 0.4028 - acc: 0.8130 - val_loss: 0.4888 - val_acc: 0.7610
Epoch 5/21
 - 20s - loss: 0.3833 - acc: 0.8254 - val_loss: 0.4701 - val_acc: 0.7806
Epoch 6/21
 - 20s - loss: 0.3704 - acc: 0.8343 - val_loss: 0.5698 - val_acc: 0.7328
Epoch 7/21
 - 20s - loss: 0.3565 - acc: 0.8419 - val_loss: 0.4257 - val_acc: 0.8089
Epoch 8/21
 - 20s - loss: 0.3441 - acc: 0.8502 - val_loss: 0.6606 - val_acc: 0.7313
Epoch 9/21
 - 20s - loss: 0.3356 - acc: 0.8543 - val_loss: 0.4873 - val_acc: 0.7787
Epoch 10/21
 - 20s - loss: 0.3266 - acc: 0.8594 - val_loss: 0.4640 - val_acc: 0.7996

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 11/21
 - 20s - loss: 0.3170 - acc: 0.8642 - val_loss: 0.4191 - val_acc: 0.8155
Epoch 12/21
 - 20s - loss: 0.3156 - acc: 0.8660 - val_loss: 0.4682 - val_acc: 0.8003
Epoch 13/21
 - 20s - loss: 0.3107 - acc: 0.8694 - val_loss: 0.4489 - val_acc: 0.8097
Epoch 14/21
 - 20s - loss: 0.3075 - acc: 0.8707 - val_loss: 0.4306 - val_acc: 0.8120

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 15/21
 - 20s - loss: 0.3057 - acc: 0.8723 - val_loss: 0.4612 - val_acc: 0.8037
Epoch 00015: early stopping
Test accuracy:0.811
current auc_score ------------------> 0.928
accuracies:  [0.8810483870967742, 0.8353494623655914, 0.8030913978494624, 0.8434139784946236, 0.7387096774193549, 0.7762096774193549, 0.7431451612903226, 0.835752688172043, 0.7212365591397849, 0.8108870967741936]
aucs:  [0.9558, 0.9441, 0.9354, 0.9304, 0.8889, 0.9533, 0.9304, 0.919, 0.93, 0.9283]
mean and std AUC:  0.932+/-0.018  max:   0.9558
['2-2-2', '30', '3', '16', '0.5', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5571 - acc: 0.7289 - val_loss: 0.7229 - val_acc: 0.6462
Epoch 2/21
 - 21s - loss: 0.4703 - acc: 0.7798 - val_loss: 0.7543 - val_acc: 0.6723
Epoch 3/21
 - 21s - loss: 0.4410 - acc: 0.7936 - val_loss: 0.5248 - val_acc: 0.7510
Epoch 4/21
 - 21s - loss: 0.4210 - acc: 0.8025 - val_loss: 0.5476 - val_acc: 0.7641
Epoch 5/21
 - 21s - loss: 0.4041 - acc: 0.8131 - val_loss: 0.5037 - val_acc: 0.7782
Epoch 6/21
 - 21s - loss: 0.3912 - acc: 0.8175 - val_loss: 0.5191 - val_acc: 0.7790
Epoch 7/21
 - 21s - loss: 0.3780 - acc: 0.8282 - val_loss: 0.4634 - val_acc: 0.8064
Epoch 8/21
 - 21s - loss: 0.3667 - acc: 0.8347 - val_loss: 0.4727 - val_acc: 0.8110
Epoch 9/21
 - 21s - loss: 0.3579 - acc: 0.8375 - val_loss: 0.3916 - val_acc: 0.8267
Epoch 10/21
 - 21s - loss: 0.3481 - acc: 0.8462 - val_loss: 0.3783 - val_acc: 0.8367
Epoch 11/21
 - 21s - loss: 0.3392 - acc: 0.8523 - val_loss: 0.3535 - val_acc: 0.8514
Epoch 12/21
 - 21s - loss: 0.3280 - acc: 0.8566 - val_loss: 0.3319 - val_acc: 0.8593
Epoch 13/21
 - 21s - loss: 0.3163 - acc: 0.8642 - val_loss: 0.4242 - val_acc: 0.8463
Epoch 14/21
 - 21s - loss: 0.3106 - acc: 0.8681 - val_loss: 0.3717 - val_acc: 0.8553
Epoch 15/21
 - 20s - loss: 0.3026 - acc: 0.8738 - val_loss: 0.3514 - val_acc: 0.8640

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/21
 - 20s - loss: 0.2938 - acc: 0.8778 - val_loss: 0.3332 - val_acc: 0.8699
Epoch 17/21
 - 21s - loss: 0.2927 - acc: 0.8777 - val_loss: 0.3419 - val_acc: 0.8665
Epoch 18/21
 - 21s - loss: 0.2894 - acc: 0.8805 - val_loss: 0.3416 - val_acc: 0.8683

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 19/21
 - 21s - loss: 0.2868 - acc: 0.8818 - val_loss: 0.3322 - val_acc: 0.8726
Epoch 20/21
 - 21s - loss: 0.2859 - acc: 0.8828 - val_loss: 0.3140 - val_acc: 0.8770
Epoch 21/21
 - 21s - loss: 0.2858 - acc: 0.8826 - val_loss: 0.3385 - val_acc: 0.8719
Test accuracy:0.876
current auc_score ------------------> 0.951
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5573 - acc: 0.7301 - val_loss: 0.7179 - val_acc: 0.6168
Epoch 2/21
 - 20s - loss: 0.4692 - acc: 0.7798 - val_loss: 0.6515 - val_acc: 0.6724
Epoch 3/21
 - 20s - loss: 0.4410 - acc: 0.7923 - val_loss: 0.6971 - val_acc: 0.6642
Epoch 4/21
 - 20s - loss: 0.4172 - acc: 0.8035 - val_loss: 0.6601 - val_acc: 0.6842
Epoch 5/21
 - 20s - loss: 0.3994 - acc: 0.8140 - val_loss: 0.5045 - val_acc: 0.7534
Epoch 6/21
 - 20s - loss: 0.3880 - acc: 0.8214 - val_loss: 0.5870 - val_acc: 0.7223
Epoch 7/21
 - 20s - loss: 0.3733 - acc: 0.8323 - val_loss: 0.6581 - val_acc: 0.6950
Epoch 8/21
 - 20s - loss: 0.3650 - acc: 0.8365 - val_loss: 0.6919 - val_acc: 0.7022

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/21
 - 20s - loss: 0.3541 - acc: 0.8451 - val_loss: 0.6327 - val_acc: 0.7223
Epoch 00009: early stopping
Test accuracy:0.765
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5529 - acc: 0.7306 - val_loss: 0.7905 - val_acc: 0.6242
Epoch 2/21
 - 21s - loss: 0.4691 - acc: 0.7734 - val_loss: 0.6063 - val_acc: 0.7078
Epoch 3/21
 - 21s - loss: 0.4419 - acc: 0.7872 - val_loss: 0.5500 - val_acc: 0.7328
Epoch 4/21
 - 21s - loss: 0.4213 - acc: 0.7995 - val_loss: 0.6104 - val_acc: 0.7054
Epoch 5/21
 - 21s - loss: 0.4037 - acc: 0.8091 - val_loss: 0.6324 - val_acc: 0.7122
Epoch 6/21
 - 21s - loss: 0.3845 - acc: 0.8226 - val_loss: 0.5939 - val_acc: 0.7494

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 7/21
 - 21s - loss: 0.3716 - acc: 0.8309 - val_loss: 0.5368 - val_acc: 0.7646
Epoch 8/21
 - 21s - loss: 0.3686 - acc: 0.8341 - val_loss: 0.4915 - val_acc: 0.7765
Epoch 9/21
 - 21s - loss: 0.3654 - acc: 0.8362 - val_loss: 0.5539 - val_acc: 0.7567
Epoch 10/21
 - 21s - loss: 0.3632 - acc: 0.8351 - val_loss: 0.5057 - val_acc: 0.7722
Epoch 11/21
 - 21s - loss: 0.3566 - acc: 0.8419 - val_loss: 0.5165 - val_acc: 0.7718

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 12/21
 - 21s - loss: 0.3541 - acc: 0.8438 - val_loss: 0.5520 - val_acc: 0.7600
Epoch 00012: early stopping
Test accuracy:0.770
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5453 - acc: 0.7431 - val_loss: 0.6889 - val_acc: 0.6254
Epoch 2/21
 - 21s - loss: 0.4700 - acc: 0.7739 - val_loss: 0.5262 - val_acc: 0.7303
Epoch 3/21
 - 21s - loss: 0.4420 - acc: 0.7866 - val_loss: 0.4619 - val_acc: 0.7748
Epoch 4/21
 - 20s - loss: 0.4229 - acc: 0.7990 - val_loss: 0.4292 - val_acc: 0.7983
Epoch 5/21
 - 20s - loss: 0.4034 - acc: 0.8118 - val_loss: 0.3913 - val_acc: 0.8203
Epoch 6/21
 - 20s - loss: 0.3892 - acc: 0.8192 - val_loss: 0.3746 - val_acc: 0.8281
Epoch 7/21
 - 20s - loss: 0.3765 - acc: 0.8289 - val_loss: 0.4012 - val_acc: 0.8264
Epoch 8/21
 - 20s - loss: 0.3618 - acc: 0.8352 - val_loss: 0.3647 - val_acc: 0.8402
Epoch 9/21
 - 20s - loss: 0.3527 - acc: 0.8432 - val_loss: 0.3432 - val_acc: 0.8476
Epoch 10/21
 - 20s - loss: 0.3435 - acc: 0.8478 - val_loss: 0.3370 - val_acc: 0.8513
Epoch 11/21
 - 20s - loss: 0.3367 - acc: 0.8525 - val_loss: 0.3174 - val_acc: 0.8656
Epoch 12/21
 - 21s - loss: 0.3255 - acc: 0.8591 - val_loss: 0.3557 - val_acc: 0.8479
Epoch 13/21
 - 21s - loss: 0.3196 - acc: 0.8626 - val_loss: 0.3229 - val_acc: 0.8724
Epoch 14/21
 - 20s - loss: 0.3109 - acc: 0.8681 - val_loss: 0.2931 - val_acc: 0.8770
Epoch 15/21
 - 20s - loss: 0.3055 - acc: 0.8701 - val_loss: 0.3033 - val_acc: 0.8719
Epoch 16/21
 - 20s - loss: 0.2971 - acc: 0.8747 - val_loss: 0.2846 - val_acc: 0.8806
Epoch 17/21
 - 20s - loss: 0.2923 - acc: 0.8792 - val_loss: 0.2846 - val_acc: 0.8837
Epoch 18/21
 - 20s - loss: 0.2873 - acc: 0.8812 - val_loss: 0.3145 - val_acc: 0.8825
Epoch 19/21
 - 20s - loss: 0.2816 - acc: 0.8851 - val_loss: 0.3219 - val_acc: 0.8730

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 20s - loss: 0.2741 - acc: 0.8874 - val_loss: 0.2730 - val_acc: 0.8893
Epoch 21/21
 - 20s - loss: 0.2722 - acc: 0.8884 - val_loss: 0.2807 - val_acc: 0.8869
Test accuracy:0.814
current auc_score ------------------> 0.921
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5450 - acc: 0.7410 - val_loss: 1.1555 - val_acc: 0.5297
Epoch 2/21
 - 21s - loss: 0.4641 - acc: 0.7778 - val_loss: 1.0545 - val_acc: 0.5901
Epoch 3/21
 - 21s - loss: 0.4351 - acc: 0.7915 - val_loss: 0.8222 - val_acc: 0.6591
Epoch 4/21
 - 21s - loss: 0.4113 - acc: 0.8049 - val_loss: 0.8772 - val_acc: 0.6493
Epoch 5/21
 - 21s - loss: 0.4002 - acc: 0.8118 - val_loss: 1.0550 - val_acc: 0.6338
Epoch 6/21
 - 21s - loss: 0.3860 - acc: 0.8197 - val_loss: 0.9394 - val_acc: 0.6629

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 7/21
 - 21s - loss: 0.3756 - acc: 0.8267 - val_loss: 1.0294 - val_acc: 0.6445
Epoch 8/21
 - 21s - loss: 0.3721 - acc: 0.8302 - val_loss: 1.1337 - val_acc: 0.6337
Epoch 9/21
 - 21s - loss: 0.3680 - acc: 0.8315 - val_loss: 1.1576 - val_acc: 0.6350

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 10/21
 - 21s - loss: 0.3632 - acc: 0.8367 - val_loss: 1.0614 - val_acc: 0.6457
Epoch 00010: early stopping
Test accuracy:0.665
current auc_score ------------------> 0.897
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5462 - acc: 0.7362 - val_loss: 0.7230 - val_acc: 0.6386
Epoch 2/21
 - 22s - loss: 0.4582 - acc: 0.7808 - val_loss: 0.9012 - val_acc: 0.6175
Epoch 3/21
 - 22s - loss: 0.4269 - acc: 0.7948 - val_loss: 0.8642 - val_acc: 0.6472
Epoch 4/21
 - 22s - loss: 0.4057 - acc: 0.8091 - val_loss: 0.7383 - val_acc: 0.6987

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 22s - loss: 0.3916 - acc: 0.8173 - val_loss: 0.7184 - val_acc: 0.7116
Epoch 6/21
 - 22s - loss: 0.3852 - acc: 0.8222 - val_loss: 0.7081 - val_acc: 0.7126
Epoch 7/21
 - 22s - loss: 0.3810 - acc: 0.8238 - val_loss: 0.6450 - val_acc: 0.7332
Epoch 8/21
 - 22s - loss: 0.3751 - acc: 0.8286 - val_loss: 0.6895 - val_acc: 0.7226
Epoch 9/21
 - 22s - loss: 0.3719 - acc: 0.8301 - val_loss: 0.6126 - val_acc: 0.7412
Epoch 10/21
 - 22s - loss: 0.3694 - acc: 0.8325 - val_loss: 0.6230 - val_acc: 0.7421
Epoch 11/21
 - 22s - loss: 0.3634 - acc: 0.8358 - val_loss: 0.6648 - val_acc: 0.7309
Epoch 12/21
 - 22s - loss: 0.3601 - acc: 0.8384 - val_loss: 0.6346 - val_acc: 0.7421

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 13/21
 - 22s - loss: 0.3594 - acc: 0.8378 - val_loss: 0.6741 - val_acc: 0.7322
Epoch 14/21
 - 22s - loss: 0.3582 - acc: 0.8397 - val_loss: 0.6132 - val_acc: 0.7490
Epoch 15/21
 - 22s - loss: 0.3567 - acc: 0.8399 - val_loss: 0.6456 - val_acc: 0.7412

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 16/21
 - 22s - loss: 0.3580 - acc: 0.8381 - val_loss: 0.6121 - val_acc: 0.7485
Epoch 17/21
 - 22s - loss: 0.3531 - acc: 0.8433 - val_loss: 0.6086 - val_acc: 0.7504
Epoch 18/21
 - 22s - loss: 0.3551 - acc: 0.8396 - val_loss: 0.6194 - val_acc: 0.7466
Epoch 19/21
 - 22s - loss: 0.3542 - acc: 0.8409 - val_loss: 0.6517 - val_acc: 0.7371
Epoch 20/21
 - 22s - loss: 0.3527 - acc: 0.8438 - val_loss: 0.6241 - val_acc: 0.7450

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006999999711449197.
Epoch 21/21
 - 22s - loss: 0.3547 - acc: 0.8416 - val_loss: 0.6241 - val_acc: 0.7456
Epoch 00021: early stopping
Test accuracy:0.757
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5655 - acc: 0.7249 - val_loss: 0.6487 - val_acc: 0.6458
Epoch 2/21
 - 21s - loss: 0.4727 - acc: 0.7748 - val_loss: 0.7053 - val_acc: 0.6535
Epoch 3/21
 - 21s - loss: 0.4401 - acc: 0.7891 - val_loss: 0.5872 - val_acc: 0.7277
Epoch 4/21
 - 21s - loss: 0.4195 - acc: 0.8005 - val_loss: 0.5346 - val_acc: 0.7615
Epoch 5/21
 - 21s - loss: 0.4011 - acc: 0.8119 - val_loss: 0.5147 - val_acc: 0.7770
Epoch 6/21
 - 21s - loss: 0.3878 - acc: 0.8169 - val_loss: 0.5827 - val_acc: 0.7644
Epoch 7/21
 - 21s - loss: 0.3728 - acc: 0.8306 - val_loss: 0.5011 - val_acc: 0.7918
Epoch 8/21
 - 21s - loss: 0.3619 - acc: 0.8371 - val_loss: 0.3727 - val_acc: 0.8345
Epoch 9/21
 - 21s - loss: 0.3524 - acc: 0.8425 - val_loss: 0.4426 - val_acc: 0.8144
Epoch 10/21
 - 21s - loss: 0.3440 - acc: 0.8489 - val_loss: 0.4347 - val_acc: 0.8271
Epoch 11/21
 - 21s - loss: 0.3336 - acc: 0.8565 - val_loss: 0.3966 - val_acc: 0.8309

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 22s - loss: 0.3280 - acc: 0.8606 - val_loss: 0.3890 - val_acc: 0.8439
Epoch 13/21
 - 22s - loss: 0.3245 - acc: 0.8603 - val_loss: 0.3792 - val_acc: 0.8479
Epoch 14/21
 - 22s - loss: 0.3248 - acc: 0.8604 - val_loss: 0.3792 - val_acc: 0.8496

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 15/21
 - 22s - loss: 0.3185 - acc: 0.8640 - val_loss: 0.3670 - val_acc: 0.8525
Epoch 16/21
 - 22s - loss: 0.3180 - acc: 0.8644 - val_loss: 0.3813 - val_acc: 0.8499
Epoch 17/21
 - 22s - loss: 0.3188 - acc: 0.8636 - val_loss: 0.3690 - val_acc: 0.8524
Epoch 18/21
 - 22s - loss: 0.3189 - acc: 0.8639 - val_loss: 0.3706 - val_acc: 0.8505

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 19/21
 - 22s - loss: 0.3171 - acc: 0.8635 - val_loss: 0.3675 - val_acc: 0.8520
Epoch 00019: early stopping
Test accuracy:0.885
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5606 - acc: 0.7286 - val_loss: 0.6048 - val_acc: 0.6790
Epoch 2/21
 - 22s - loss: 0.4750 - acc: 0.7753 - val_loss: 0.5876 - val_acc: 0.7100
Epoch 3/21
 - 21s - loss: 0.4388 - acc: 0.7894 - val_loss: 0.4268 - val_acc: 0.7904
Epoch 4/21
 - 22s - loss: 0.4173 - acc: 0.8018 - val_loss: 0.4725 - val_acc: 0.7882
Epoch 5/21
 - 22s - loss: 0.4003 - acc: 0.8138 - val_loss: 0.4102 - val_acc: 0.8151
Epoch 6/21
 - 21s - loss: 0.3892 - acc: 0.8198 - val_loss: 0.4278 - val_acc: 0.8105
Epoch 7/21
 - 21s - loss: 0.3761 - acc: 0.8260 - val_loss: 0.3865 - val_acc: 0.8297
Epoch 8/21
 - 22s - loss: 0.3669 - acc: 0.8333 - val_loss: 0.4117 - val_acc: 0.8183
Epoch 9/21
 - 22s - loss: 0.3551 - acc: 0.8419 - val_loss: 0.3671 - val_acc: 0.8381
Epoch 10/21
 - 22s - loss: 0.3469 - acc: 0.8456 - val_loss: 0.3811 - val_acc: 0.8366
Epoch 11/21
 - 22s - loss: 0.3387 - acc: 0.8489 - val_loss: 0.3573 - val_acc: 0.8473
Epoch 12/21
 - 22s - loss: 0.3328 - acc: 0.8552 - val_loss: 0.4118 - val_acc: 0.8345
Epoch 13/21
 - 22s - loss: 0.3231 - acc: 0.8597 - val_loss: 0.3985 - val_acc: 0.8402
Epoch 14/21
 - 22s - loss: 0.3173 - acc: 0.8636 - val_loss: 0.3947 - val_acc: 0.8358

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 22s - loss: 0.3086 - acc: 0.8679 - val_loss: 0.3415 - val_acc: 0.8617
Epoch 16/21
 - 22s - loss: 0.3060 - acc: 0.8709 - val_loss: 0.3691 - val_acc: 0.8553
Epoch 17/21
 - 22s - loss: 0.3057 - acc: 0.8713 - val_loss: 0.3502 - val_acc: 0.8601
Epoch 18/21
 - 22s - loss: 0.3015 - acc: 0.8743 - val_loss: 0.3678 - val_acc: 0.8547

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 19/21
 - 22s - loss: 0.2985 - acc: 0.8747 - val_loss: 0.3571 - val_acc: 0.8569
Epoch 00019: early stopping
Test accuracy:0.817
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5705 - acc: 0.7197 - val_loss: 0.5077 - val_acc: 0.7565
Epoch 2/21
 - 21s - loss: 0.4713 - acc: 0.7736 - val_loss: 0.5199 - val_acc: 0.7559
Epoch 3/21
 - 21s - loss: 0.4398 - acc: 0.7892 - val_loss: 0.4657 - val_acc: 0.7789
Epoch 4/21
 - 21s - loss: 0.4200 - acc: 0.8029 - val_loss: 0.4813 - val_acc: 0.7828
Epoch 5/21
 - 21s - loss: 0.4022 - acc: 0.8115 - val_loss: 0.5019 - val_acc: 0.7943
Epoch 6/21
 - 21s - loss: 0.3882 - acc: 0.8199 - val_loss: 0.4298 - val_acc: 0.8144
Epoch 7/21
 - 21s - loss: 0.3762 - acc: 0.8287 - val_loss: 0.5586 - val_acc: 0.7949
Epoch 8/21
 - 21s - loss: 0.3646 - acc: 0.8358 - val_loss: 0.4294 - val_acc: 0.8240
Epoch 9/21
 - 21s - loss: 0.3517 - acc: 0.8447 - val_loss: 0.4111 - val_acc: 0.8262
Epoch 10/21
 - 21s - loss: 0.3429 - acc: 0.8499 - val_loss: 0.4044 - val_acc: 0.8288
Epoch 11/21
 - 21s - loss: 0.3338 - acc: 0.8560 - val_loss: 0.4644 - val_acc: 0.8209
Epoch 12/21
 - 21s - loss: 0.3212 - acc: 0.8626 - val_loss: 0.3687 - val_acc: 0.8504
Epoch 13/21
 - 21s - loss: 0.3168 - acc: 0.8663 - val_loss: 0.3346 - val_acc: 0.8631
Epoch 14/21
 - 21s - loss: 0.3069 - acc: 0.8708 - val_loss: 0.4011 - val_acc: 0.8475
Epoch 15/21
 - 21s - loss: 0.3019 - acc: 0.8742 - val_loss: 0.3713 - val_acc: 0.8574
Epoch 16/21
 - 21s - loss: 0.2928 - acc: 0.8789 - val_loss: 0.3088 - val_acc: 0.8758
Epoch 17/21
 - 21s - loss: 0.2879 - acc: 0.8825 - val_loss: 0.3180 - val_acc: 0.8765
Epoch 18/21
 - 21s - loss: 0.2818 - acc: 0.8857 - val_loss: 0.2921 - val_acc: 0.8860
Epoch 19/21
 - 21s - loss: 0.2766 - acc: 0.8895 - val_loss: 0.2741 - val_acc: 0.8953
Epoch 20/21
 - 21s - loss: 0.2672 - acc: 0.8945 - val_loss: 0.3248 - val_acc: 0.8823
Epoch 21/21
 - 21s - loss: 0.2629 - acc: 0.8963 - val_loss: 0.2883 - val_acc: 0.8872
Test accuracy:0.877
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.5
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5571 - acc: 0.7321 - val_loss: 0.5602 - val_acc: 0.7368
Epoch 2/21
 - 21s - loss: 0.4716 - acc: 0.7784 - val_loss: 0.6131 - val_acc: 0.7255
Epoch 3/21
 - 21s - loss: 0.4401 - acc: 0.7912 - val_loss: 0.5484 - val_acc: 0.7492
Epoch 4/21
 - 21s - loss: 0.4176 - acc: 0.8018 - val_loss: 0.5160 - val_acc: 0.7624
Epoch 5/21
 - 21s - loss: 0.3973 - acc: 0.8137 - val_loss: 0.4315 - val_acc: 0.7991
Epoch 6/21
 - 21s - loss: 0.3811 - acc: 0.8250 - val_loss: 0.6117 - val_acc: 0.7366
Epoch 7/21
 - 21s - loss: 0.3661 - acc: 0.8352 - val_loss: 0.6699 - val_acc: 0.7380
Epoch 8/21
 - 21s - loss: 0.3529 - acc: 0.8411 - val_loss: 0.5588 - val_acc: 0.7800

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/21
 - 21s - loss: 0.3432 - acc: 0.8490 - val_loss: 0.5087 - val_acc: 0.7978
Epoch 00009: early stopping
Test accuracy:0.840
current auc_score ------------------> 0.948
accuracies:  [0.8762096774193548, 0.7646505376344086, 0.7702956989247312, 0.8138440860215054, 0.6649193548387097, 0.7571236559139785, 0.8850806451612904, 0.8170698924731182, 0.876747311827957, 0.8399193548387097]
aucs:  [0.9507, 0.9331, 0.9143, 0.9213, 0.8966, 0.9105, 0.9451, 0.9138, 0.9468, 0.9484]
mean and std AUC:  0.928+/-0.018  max:   0.9507
['2-2-2', '30', '3', '16', '0.6', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5681 - acc: 0.7224 - val_loss: 0.6746 - val_acc: 0.6211
Epoch 2/21
 - 20s - loss: 0.4867 - acc: 0.7705 - val_loss: 0.5164 - val_acc: 0.7362
Epoch 3/21
 - 20s - loss: 0.4572 - acc: 0.7828 - val_loss: 0.5725 - val_acc: 0.7029
Epoch 4/21
 - 20s - loss: 0.4390 - acc: 0.7905 - val_loss: 0.5044 - val_acc: 0.7475
Epoch 5/21
 - 20s - loss: 0.4227 - acc: 0.7979 - val_loss: 0.5179 - val_acc: 0.7436
Epoch 6/21
 - 21s - loss: 0.4093 - acc: 0.8059 - val_loss: 0.6405 - val_acc: 0.6930
Epoch 7/21
 - 20s - loss: 0.3983 - acc: 0.8122 - val_loss: 0.5888 - val_acc: 0.7316

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 20s - loss: 0.3840 - acc: 0.8219 - val_loss: 0.4410 - val_acc: 0.7870
Epoch 9/21
 - 20s - loss: 0.3811 - acc: 0.8232 - val_loss: 0.4447 - val_acc: 0.7878
Epoch 10/21
 - 20s - loss: 0.3809 - acc: 0.8246 - val_loss: 0.5110 - val_acc: 0.7594
Epoch 11/21
 - 20s - loss: 0.3741 - acc: 0.8298 - val_loss: 0.4851 - val_acc: 0.7682

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 12/21
 - 20s - loss: 0.3723 - acc: 0.8291 - val_loss: 0.4428 - val_acc: 0.7932
Epoch 13/21
 - 20s - loss: 0.3727 - acc: 0.8294 - val_loss: 0.4547 - val_acc: 0.7819
Epoch 14/21
 - 20s - loss: 0.3712 - acc: 0.8303 - val_loss: 0.4432 - val_acc: 0.7892

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 15/21
 - 20s - loss: 0.3714 - acc: 0.8297 - val_loss: 0.4458 - val_acc: 0.7868
Epoch 16/21
 - 20s - loss: 0.3705 - acc: 0.8309 - val_loss: 0.4421 - val_acc: 0.7884
Epoch 00016: early stopping
Test accuracy:0.833
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5698 - acc: 0.7274 - val_loss: 0.5484 - val_acc: 0.7268
Epoch 2/21
 - 20s - loss: 0.4815 - acc: 0.7760 - val_loss: 0.4984 - val_acc: 0.7514
Epoch 3/21
 - 20s - loss: 0.4505 - acc: 0.7873 - val_loss: 0.5232 - val_acc: 0.7541
Epoch 4/21
 - 20s - loss: 0.4288 - acc: 0.8002 - val_loss: 0.5318 - val_acc: 0.7587
Epoch 5/21
 - 20s - loss: 0.4137 - acc: 0.8088 - val_loss: 0.6981 - val_acc: 0.7348

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/21
 - 20s - loss: 0.4014 - acc: 0.8167 - val_loss: 0.6468 - val_acc: 0.7383
Epoch 7/21
 - 20s - loss: 0.3981 - acc: 0.8161 - val_loss: 0.6806 - val_acc: 0.7356
Epoch 8/21
 - 20s - loss: 0.3935 - acc: 0.8179 - val_loss: 0.7262 - val_acc: 0.7203

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 00008: early stopping
Test accuracy:0.715
current auc_score ------------------> 0.953
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5634 - acc: 0.7233 - val_loss: 0.5058 - val_acc: 0.7555
Epoch 2/21
 - 20s - loss: 0.4799 - acc: 0.7730 - val_loss: 0.5029 - val_acc: 0.7486
Epoch 3/21
 - 20s - loss: 0.4548 - acc: 0.7798 - val_loss: 0.4360 - val_acc: 0.7853
Epoch 4/21
 - 20s - loss: 0.4322 - acc: 0.7950 - val_loss: 0.5048 - val_acc: 0.7617
Epoch 5/21
 - 20s - loss: 0.4173 - acc: 0.8016 - val_loss: 0.4459 - val_acc: 0.7865
Epoch 6/21
 - 20s - loss: 0.4033 - acc: 0.8103 - val_loss: 0.3803 - val_acc: 0.8140
Epoch 7/21
 - 20s - loss: 0.3889 - acc: 0.8191 - val_loss: 0.4449 - val_acc: 0.7910
Epoch 8/21
 - 20s - loss: 0.3783 - acc: 0.8273 - val_loss: 0.5077 - val_acc: 0.7750
Epoch 9/21
 - 20s - loss: 0.3708 - acc: 0.8319 - val_loss: 0.3610 - val_acc: 0.8331
Epoch 10/21
 - 20s - loss: 0.3562 - acc: 0.8409 - val_loss: 0.3733 - val_acc: 0.8302
Epoch 11/21
 - 20s - loss: 0.3502 - acc: 0.8443 - val_loss: 0.3986 - val_acc: 0.8336
Epoch 12/21
 - 20s - loss: 0.3383 - acc: 0.8491 - val_loss: 0.3518 - val_acc: 0.8496
Epoch 13/21
 - 20s - loss: 0.3341 - acc: 0.8536 - val_loss: 0.3360 - val_acc: 0.8554
Epoch 14/21
 - 20s - loss: 0.3229 - acc: 0.8593 - val_loss: 0.3923 - val_acc: 0.8427
Epoch 15/21
 - 20s - loss: 0.3170 - acc: 0.8624 - val_loss: 0.4638 - val_acc: 0.8365
Epoch 16/21
 - 20s - loss: 0.3104 - acc: 0.8653 - val_loss: 0.3542 - val_acc: 0.8671

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/21
 - 20s - loss: 0.3014 - acc: 0.8738 - val_loss: 0.3589 - val_acc: 0.8671
Epoch 18/21
 - 20s - loss: 0.2968 - acc: 0.8731 - val_loss: 0.3497 - val_acc: 0.8686
Epoch 19/21
 - 20s - loss: 0.2970 - acc: 0.8745 - val_loss: 0.3198 - val_acc: 0.8776
Epoch 20/21
 - 20s - loss: 0.2951 - acc: 0.8753 - val_loss: 0.3449 - val_acc: 0.8715
Epoch 21/21
 - 20s - loss: 0.2919 - acc: 0.8786 - val_loss: 0.3721 - val_acc: 0.8636
Test accuracy:0.837
current auc_score ------------------> 0.927
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5651 - acc: 0.7245 - val_loss: 0.6020 - val_acc: 0.6886
Epoch 2/21
 - 20s - loss: 0.4857 - acc: 0.7656 - val_loss: 0.5932 - val_acc: 0.7117
Epoch 3/21
 - 20s - loss: 0.4582 - acc: 0.7775 - val_loss: 0.6568 - val_acc: 0.6944
Epoch 4/21
 - 20s - loss: 0.4379 - acc: 0.7885 - val_loss: 0.8009 - val_acc: 0.6639
Epoch 5/21
 - 20s - loss: 0.4229 - acc: 0.7959 - val_loss: 0.8589 - val_acc: 0.6652

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/21
 - 20s - loss: 0.4115 - acc: 0.8031 - val_loss: 0.8231 - val_acc: 0.6815
Epoch 00006: early stopping
Test accuracy:0.699
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5717 - acc: 0.7249 - val_loss: 0.5196 - val_acc: 0.7497
Epoch 2/21
 - 20s - loss: 0.4898 - acc: 0.7662 - val_loss: 0.5924 - val_acc: 0.6933
Epoch 3/21
 - 20s - loss: 0.4629 - acc: 0.7754 - val_loss: 0.4971 - val_acc: 0.7529
Epoch 4/21
 - 20s - loss: 0.4421 - acc: 0.7881 - val_loss: 0.4304 - val_acc: 0.7875
Epoch 5/21
 - 20s - loss: 0.4250 - acc: 0.7960 - val_loss: 0.4060 - val_acc: 0.8026
Epoch 6/21
 - 20s - loss: 0.4120 - acc: 0.8026 - val_loss: 0.3990 - val_acc: 0.8111
Epoch 7/21
 - 20s - loss: 0.3985 - acc: 0.8153 - val_loss: 0.4745 - val_acc: 0.7840
Epoch 8/21
 - 20s - loss: 0.3869 - acc: 0.8214 - val_loss: 0.7675 - val_acc: 0.7076
Epoch 9/21
 - 21s - loss: 0.3786 - acc: 0.8290 - val_loss: 0.5370 - val_acc: 0.7741

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 21s - loss: 0.3689 - acc: 0.8331 - val_loss: 0.4154 - val_acc: 0.8194
Epoch 11/21
 - 21s - loss: 0.3661 - acc: 0.8365 - val_loss: 0.4198 - val_acc: 0.8149
Epoch 12/21
 - 20s - loss: 0.3628 - acc: 0.8359 - val_loss: 0.3782 - val_acc: 0.8348
Epoch 13/21
 - 20s - loss: 0.3588 - acc: 0.8407 - val_loss: 0.4713 - val_acc: 0.7976
Epoch 14/21
 - 21s - loss: 0.3564 - acc: 0.8402 - val_loss: 0.4288 - val_acc: 0.8180
Epoch 15/21
 - 21s - loss: 0.3558 - acc: 0.8408 - val_loss: 0.4150 - val_acc: 0.8208

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 16/21
 - 20s - loss: 0.3509 - acc: 0.8450 - val_loss: 0.4761 - val_acc: 0.8021
Epoch 00016: early stopping
Test accuracy:0.826
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5573 - acc: 0.7307 - val_loss: 0.5789 - val_acc: 0.6990
Epoch 2/21
 - 21s - loss: 0.4804 - acc: 0.7696 - val_loss: 0.7778 - val_acc: 0.6173
Epoch 3/21
 - 21s - loss: 0.4558 - acc: 0.7787 - val_loss: 1.2865 - val_acc: 0.5395
Epoch 4/21
 - 21s - loss: 0.4369 - acc: 0.7892 - val_loss: 0.9757 - val_acc: 0.6145

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 21s - loss: 0.4246 - acc: 0.7957 - val_loss: 1.2452 - val_acc: 0.5818
Epoch 00005: early stopping
Test accuracy:0.631
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5808 - acc: 0.7234 - val_loss: 0.6709 - val_acc: 0.6860
Epoch 2/21
 - 20s - loss: 0.4871 - acc: 0.7695 - val_loss: 0.4845 - val_acc: 0.7553
Epoch 3/21
 - 20s - loss: 0.4560 - acc: 0.7835 - val_loss: 0.5395 - val_acc: 0.7529
Epoch 4/21
 - 20s - loss: 0.4381 - acc: 0.7897 - val_loss: 0.4615 - val_acc: 0.7894
Epoch 5/21
 - 20s - loss: 0.4202 - acc: 0.8018 - val_loss: 0.5838 - val_acc: 0.7619
Epoch 6/21
 - 20s - loss: 0.4041 - acc: 0.8123 - val_loss: 0.6243 - val_acc: 0.7567
Epoch 7/21
 - 20s - loss: 0.3924 - acc: 0.8184 - val_loss: 0.6045 - val_acc: 0.7825

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 20s - loss: 0.3829 - acc: 0.8241 - val_loss: 0.6855 - val_acc: 0.7607
Epoch 00008: early stopping
Test accuracy:0.810
current auc_score ------------------> 0.923
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5666 - acc: 0.7323 - val_loss: 0.5600 - val_acc: 0.7179
Epoch 2/21
 - 21s - loss: 0.4785 - acc: 0.7764 - val_loss: 0.4532 - val_acc: 0.7823
Epoch 3/21
 - 20s - loss: 0.4492 - acc: 0.7872 - val_loss: 0.4402 - val_acc: 0.7885
Epoch 4/21
 - 21s - loss: 0.4264 - acc: 0.8015 - val_loss: 0.4157 - val_acc: 0.7966
Epoch 5/21
 - 20s - loss: 0.4092 - acc: 0.8112 - val_loss: 0.3979 - val_acc: 0.8139
Epoch 6/21
 - 20s - loss: 0.3990 - acc: 0.8151 - val_loss: 0.3763 - val_acc: 0.8256
Epoch 7/21
 - 20s - loss: 0.3851 - acc: 0.8260 - val_loss: 0.3794 - val_acc: 0.8277
Epoch 8/21
 - 20s - loss: 0.3737 - acc: 0.8308 - val_loss: 0.3680 - val_acc: 0.8358
Epoch 9/21
 - 20s - loss: 0.3676 - acc: 0.8356 - val_loss: 0.3554 - val_acc: 0.8426
Epoch 10/21
 - 20s - loss: 0.3591 - acc: 0.8402 - val_loss: 0.3918 - val_acc: 0.8309
Epoch 11/21
 - 20s - loss: 0.3497 - acc: 0.8473 - val_loss: 0.4510 - val_acc: 0.8025
Epoch 12/21
 - 20s - loss: 0.3424 - acc: 0.8492 - val_loss: 0.3816 - val_acc: 0.8416

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 20s - loss: 0.3354 - acc: 0.8556 - val_loss: 0.3811 - val_acc: 0.8382
Epoch 00013: early stopping
Test accuracy:0.867
current auc_score ------------------> 0.948
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5666 - acc: 0.7231 - val_loss: 0.6579 - val_acc: 0.6401
Epoch 2/21
 - 20s - loss: 0.4704 - acc: 0.7758 - val_loss: 0.5503 - val_acc: 0.7243
Epoch 3/21
 - 20s - loss: 0.4418 - acc: 0.7868 - val_loss: 0.6349 - val_acc: 0.6983
Epoch 4/21
 - 20s - loss: 0.4232 - acc: 0.7972 - val_loss: 0.6014 - val_acc: 0.7383
Epoch 5/21
 - 21s - loss: 0.4069 - acc: 0.8111 - val_loss: 0.6480 - val_acc: 0.7410

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/21
 - 20s - loss: 0.3949 - acc: 0.8155 - val_loss: 0.5521 - val_acc: 0.7595
Epoch 7/21
 - 20s - loss: 0.3908 - acc: 0.8184 - val_loss: 0.6178 - val_acc: 0.7529
Epoch 8/21
 - 20s - loss: 0.3891 - acc: 0.8211 - val_loss: 0.6874 - val_acc: 0.7354

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 9/21
 - 20s - loss: 0.3857 - acc: 0.8222 - val_loss: 0.6944 - val_acc: 0.7398
Epoch 10/21
 - 20s - loss: 0.3856 - acc: 0.8215 - val_loss: 0.6243 - val_acc: 0.7541
Epoch 00010: early stopping
Test accuracy:0.777
current auc_score ------------------> 0.894
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.6
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5752 - acc: 0.7213 - val_loss: 0.5037 - val_acc: 0.7661
Epoch 2/21
 - 20s - loss: 0.4826 - acc: 0.7724 - val_loss: 0.5944 - val_acc: 0.7321
Epoch 3/21
 - 20s - loss: 0.4536 - acc: 0.7850 - val_loss: 0.7050 - val_acc: 0.7070
Epoch 4/21
 - 20s - loss: 0.4321 - acc: 0.7963 - val_loss: 0.6316 - val_acc: 0.7244

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 20s - loss: 0.4220 - acc: 0.8012 - val_loss: 0.8379 - val_acc: 0.6807
Epoch 00005: early stopping
Test accuracy:0.753
current auc_score ------------------> 0.878
accuracies:  [0.8331989247311828, 0.7146505376344086, 0.8369623655913978, 0.698521505376344, 0.8262096774193548, 0.6310483870967742, 0.8104838709677419, 0.8674731182795699, 0.7772849462365592, 0.753494623655914]
aucs:  [0.9348, 0.9528, 0.9273, 0.9096, 0.9405, 0.9129, 0.9226, 0.9476, 0.8944, 0.8781]
mean and std AUC:  0.922+/-0.023  max:   0.9528
['2-2-2', '30', '3', '16', '0.7', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5723 - acc: 0.7260 - val_loss: 0.5321 - val_acc: 0.7460
Epoch 2/21
 - 21s - loss: 0.4940 - acc: 0.7709 - val_loss: 0.6160 - val_acc: 0.6826
Epoch 3/21
 - 21s - loss: 0.4649 - acc: 0.7783 - val_loss: 0.5724 - val_acc: 0.7090
Epoch 4/21
 - 21s - loss: 0.4467 - acc: 0.7857 - val_loss: 0.6353 - val_acc: 0.6954

Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 5/21
 - 21s - loss: 0.4368 - acc: 0.7918 - val_loss: 0.6825 - val_acc: 0.6923
Epoch 00005: early stopping
Test accuracy:0.736
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5697 - acc: 0.7235 - val_loss: 0.6863 - val_acc: 0.6264
Epoch 2/21
 - 21s - loss: 0.4923 - acc: 0.7682 - val_loss: 0.5390 - val_acc: 0.7228
Epoch 3/21
 - 21s - loss: 0.4669 - acc: 0.7781 - val_loss: 0.5633 - val_acc: 0.7117
Epoch 4/21
 - 21s - loss: 0.4491 - acc: 0.7826 - val_loss: 0.4799 - val_acc: 0.7666
Epoch 5/21
 - 21s - loss: 0.4352 - acc: 0.7903 - val_loss: 0.5274 - val_acc: 0.7500
Epoch 6/21
 - 21s - loss: 0.4228 - acc: 0.7954 - val_loss: 0.7555 - val_acc: 0.6993
Epoch 7/21
 - 21s - loss: 0.4117 - acc: 0.8050 - val_loss: 0.5866 - val_acc: 0.7545

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 21s - loss: 0.4008 - acc: 0.8102 - val_loss: 0.5710 - val_acc: 0.7649
Epoch 00008: early stopping
Test accuracy:0.816
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5814 - acc: 0.7183 - val_loss: 0.8407 - val_acc: 0.5666
Epoch 2/21
 - 21s - loss: 0.4939 - acc: 0.7687 - val_loss: 0.6873 - val_acc: 0.6542
Epoch 3/21
 - 21s - loss: 0.4653 - acc: 0.7798 - val_loss: 0.6499 - val_acc: 0.7067
Epoch 4/21
 - 21s - loss: 0.4497 - acc: 0.7862 - val_loss: 0.4689 - val_acc: 0.7839
Epoch 5/21
 - 21s - loss: 0.4361 - acc: 0.7931 - val_loss: 0.4837 - val_acc: 0.7856
Epoch 6/21
 - 21s - loss: 0.4241 - acc: 0.8026 - val_loss: 0.5027 - val_acc: 0.7870
Epoch 7/21
 - 21s - loss: 0.4135 - acc: 0.8064 - val_loss: 0.5912 - val_acc: 0.7623

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 21s - loss: 0.4071 - acc: 0.8117 - val_loss: 0.5090 - val_acc: 0.7915
Epoch 9/21
 - 21s - loss: 0.4011 - acc: 0.8135 - val_loss: 0.5313 - val_acc: 0.7902
Epoch 10/21
 - 21s - loss: 0.3977 - acc: 0.8162 - val_loss: 0.5191 - val_acc: 0.7922

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 11/21
 - 21s - loss: 0.3960 - acc: 0.8171 - val_loss: 0.5465 - val_acc: 0.7873
Epoch 12/21
 - 21s - loss: 0.3938 - acc: 0.8190 - val_loss: 0.5571 - val_acc: 0.7874
Epoch 13/21
 - 21s - loss: 0.3931 - acc: 0.8197 - val_loss: 0.5540 - val_acc: 0.7884

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 14/21
 - 21s - loss: 0.3945 - acc: 0.8148 - val_loss: 0.5478 - val_acc: 0.7897
Epoch 00014: early stopping
Test accuracy:0.844
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5885 - acc: 0.7032 - val_loss: 0.6459 - val_acc: 0.6288
Epoch 2/21
 - 22s - loss: 0.5069 - acc: 0.7572 - val_loss: 0.5820 - val_acc: 0.6994
Epoch 3/21
 - 22s - loss: 0.4754 - acc: 0.7704 - val_loss: 0.6711 - val_acc: 0.6614
Epoch 4/21
 - 22s - loss: 0.4535 - acc: 0.7833 - val_loss: 0.5952 - val_acc: 0.7267
Epoch 5/21
 - 22s - loss: 0.4384 - acc: 0.7896 - val_loss: 0.5827 - val_acc: 0.7338

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/21
 - 22s - loss: 0.4310 - acc: 0.7925 - val_loss: 0.5872 - val_acc: 0.7407
Epoch 7/21
 - 21s - loss: 0.4275 - acc: 0.7941 - val_loss: 0.5562 - val_acc: 0.7538
Epoch 8/21
 - 22s - loss: 0.4222 - acc: 0.7983 - val_loss: 0.6496 - val_acc: 0.7260
Epoch 9/21
 - 22s - loss: 0.4203 - acc: 0.7996 - val_loss: 0.6384 - val_acc: 0.7327
Epoch 10/21
 - 22s - loss: 0.4172 - acc: 0.8004 - val_loss: 0.5880 - val_acc: 0.7481

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 11/21
 - 22s - loss: 0.4140 - acc: 0.8038 - val_loss: 0.6032 - val_acc: 0.7428
Epoch 00011: early stopping
Test accuracy:0.840
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5958 - acc: 0.7018 - val_loss: 0.6899 - val_acc: 0.5761
Epoch 2/21
 - 22s - loss: 0.5096 - acc: 0.7631 - val_loss: 0.6394 - val_acc: 0.6416
Epoch 3/21
 - 22s - loss: 0.4760 - acc: 0.7726 - val_loss: 0.6072 - val_acc: 0.6672
Epoch 4/21
 - 22s - loss: 0.4557 - acc: 0.7814 - val_loss: 0.6054 - val_acc: 0.7052
Epoch 5/21
 - 22s - loss: 0.4404 - acc: 0.7921 - val_loss: 0.7025 - val_acc: 0.6491
Epoch 6/21
 - 22s - loss: 0.4258 - acc: 0.7980 - val_loss: 0.6724 - val_acc: 0.6760
Epoch 7/21
 - 22s - loss: 0.4152 - acc: 0.8040 - val_loss: 0.6339 - val_acc: 0.6918

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 21s - loss: 0.4066 - acc: 0.8101 - val_loss: 0.5702 - val_acc: 0.7284
Epoch 9/21
 - 21s - loss: 0.3997 - acc: 0.8141 - val_loss: 0.5155 - val_acc: 0.7564
Epoch 10/21
 - 21s - loss: 0.3965 - acc: 0.8174 - val_loss: 0.5764 - val_acc: 0.7218
Epoch 11/21
 - 22s - loss: 0.3934 - acc: 0.8176 - val_loss: 0.5219 - val_acc: 0.7548
Epoch 12/21
 - 22s - loss: 0.3913 - acc: 0.8191 - val_loss: 0.5556 - val_acc: 0.7374

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 13/21
 - 22s - loss: 0.3878 - acc: 0.8226 - val_loss: 0.5450 - val_acc: 0.7442
Epoch 00013: early stopping
Test accuracy:0.755
current auc_score ------------------> 0.896
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 24s - loss: 0.5941 - acc: 0.7083 - val_loss: 0.5589 - val_acc: 0.7351
Epoch 2/21
 - 22s - loss: 0.4996 - acc: 0.7630 - val_loss: 0.4815 - val_acc: 0.7764
Epoch 3/21
 - 22s - loss: 0.4681 - acc: 0.7764 - val_loss: 0.4712 - val_acc: 0.7690
Epoch 4/21
 - 22s - loss: 0.4501 - acc: 0.7832 - val_loss: 0.4620 - val_acc: 0.7741
Epoch 5/21
 - 22s - loss: 0.4334 - acc: 0.7911 - val_loss: 0.4451 - val_acc: 0.7858
Epoch 6/21
 - 22s - loss: 0.4227 - acc: 0.7959 - val_loss: 0.4095 - val_acc: 0.8005
Epoch 7/21
 - 22s - loss: 0.4097 - acc: 0.8045 - val_loss: 0.4343 - val_acc: 0.7930
Epoch 8/21
 - 22s - loss: 0.4031 - acc: 0.8092 - val_loss: 0.4760 - val_acc: 0.7830
Epoch 9/21
 - 22s - loss: 0.3914 - acc: 0.8167 - val_loss: 0.4321 - val_acc: 0.8057

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 22s - loss: 0.3844 - acc: 0.8208 - val_loss: 0.6014 - val_acc: 0.7525
Epoch 11/21
 - 22s - loss: 0.3822 - acc: 0.8244 - val_loss: 0.6541 - val_acc: 0.7425
Epoch 12/21
 - 22s - loss: 0.3774 - acc: 0.8257 - val_loss: 0.7287 - val_acc: 0.7185

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 13/21
 - 22s - loss: 0.3763 - acc: 0.8268 - val_loss: 0.6624 - val_acc: 0.7391
Epoch 00013: early stopping
Test accuracy:0.772
current auc_score ------------------> 0.950
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5983 - acc: 0.6978 - val_loss: 0.5201 - val_acc: 0.7482
Epoch 2/21
 - 21s - loss: 0.4928 - acc: 0.7705 - val_loss: 0.4604 - val_acc: 0.7740
Epoch 3/21
 - 21s - loss: 0.4633 - acc: 0.7822 - val_loss: 0.5114 - val_acc: 0.7603
Epoch 4/21
 - 21s - loss: 0.4436 - acc: 0.7911 - val_loss: 0.4481 - val_acc: 0.7826
Epoch 5/21
 - 21s - loss: 0.4288 - acc: 0.7960 - val_loss: 0.4986 - val_acc: 0.7775
Epoch 6/21
 - 21s - loss: 0.4143 - acc: 0.8049 - val_loss: 0.4081 - val_acc: 0.8090
Epoch 7/21
 - 21s - loss: 0.4020 - acc: 0.8130 - val_loss: 0.4376 - val_acc: 0.7941
Epoch 8/21
 - 21s - loss: 0.3911 - acc: 0.8172 - val_loss: 0.4732 - val_acc: 0.7976
Epoch 9/21
 - 20s - loss: 0.3814 - acc: 0.8237 - val_loss: 0.4851 - val_acc: 0.8037

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 22s - loss: 0.3757 - acc: 0.8277 - val_loss: 0.4993 - val_acc: 0.7993
Epoch 00010: early stopping
Test accuracy:0.854
current auc_score ------------------> 0.948
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5942 - acc: 0.7115 - val_loss: 0.8182 - val_acc: 0.5855
Epoch 2/21
 - 22s - loss: 0.5100 - acc: 0.7619 - val_loss: 0.5115 - val_acc: 0.7568
Epoch 3/21
 - 22s - loss: 0.4761 - acc: 0.7748 - val_loss: 0.5941 - val_acc: 0.7184
Epoch 4/21
 - 22s - loss: 0.4567 - acc: 0.7824 - val_loss: 0.8481 - val_acc: 0.6437
Epoch 5/21
 - 21s - loss: 0.4358 - acc: 0.7933 - val_loss: 0.6514 - val_acc: 0.7447

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/21
 - 22s - loss: 0.4271 - acc: 0.7989 - val_loss: 0.6723 - val_acc: 0.7304
Epoch 00006: early stopping
Test accuracy:0.776
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5799 - acc: 0.7127 - val_loss: 1.3060 - val_acc: 0.5056
Epoch 2/21
 - 21s - loss: 0.4920 - acc: 0.7650 - val_loss: 1.1032 - val_acc: 0.5595
Epoch 3/21
 - 21s - loss: 0.4707 - acc: 0.7728 - val_loss: 1.2191 - val_acc: 0.5710
Epoch 4/21
 - 21s - loss: 0.4539 - acc: 0.7801 - val_loss: 1.4388 - val_acc: 0.5456
Epoch 5/21
 - 21s - loss: 0.4408 - acc: 0.7854 - val_loss: 1.3424 - val_acc: 0.5809

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/21
 - 22s - loss: 0.4306 - acc: 0.7939 - val_loss: 1.5633 - val_acc: 0.5617
Epoch 7/21
 - 22s - loss: 0.4289 - acc: 0.7932 - val_loss: 1.3742 - val_acc: 0.5847
Epoch 8/21
 - 22s - loss: 0.4262 - acc: 0.7951 - val_loss: 1.8175 - val_acc: 0.5463

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 9/21
 - 22s - loss: 0.4217 - acc: 0.7975 - val_loss: 1.6387 - val_acc: 0.5650
Epoch 10/21
 - 22s - loss: 0.4200 - acc: 0.7988 - val_loss: 1.6495 - val_acc: 0.5634
Epoch 11/21
 - 22s - loss: 0.4200 - acc: 0.8001 - val_loss: 1.6012 - val_acc: 0.5712

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 00011: early stopping
Test accuracy:0.613
current auc_score ------------------> 0.903
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.7
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5919 - acc: 0.7079 - val_loss: 0.5432 - val_acc: 0.7417
Epoch 2/21
 - 21s - loss: 0.5085 - acc: 0.7637 - val_loss: 0.5222 - val_acc: 0.7400
Epoch 3/21
 - 21s - loss: 0.4810 - acc: 0.7740 - val_loss: 0.4916 - val_acc: 0.7617
Epoch 4/21
 - 21s - loss: 0.4608 - acc: 0.7815 - val_loss: 0.4421 - val_acc: 0.7920
Epoch 5/21
 - 21s - loss: 0.4454 - acc: 0.7882 - val_loss: 0.4507 - val_acc: 0.7864
Epoch 6/21
 - 21s - loss: 0.4313 - acc: 0.7972 - val_loss: 0.4401 - val_acc: 0.7978
Epoch 7/21
 - 21s - loss: 0.4180 - acc: 0.8065 - val_loss: 0.4127 - val_acc: 0.8079
Epoch 8/21
 - 21s - loss: 0.4082 - acc: 0.8104 - val_loss: 0.3951 - val_acc: 0.8185
Epoch 9/21
 - 21s - loss: 0.3969 - acc: 0.8185 - val_loss: 0.4168 - val_acc: 0.8140
Epoch 10/21
 - 21s - loss: 0.3884 - acc: 0.8222 - val_loss: 0.3972 - val_acc: 0.8185
Epoch 11/21
 - 21s - loss: 0.3810 - acc: 0.8281 - val_loss: 0.4205 - val_acc: 0.8193

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 22s - loss: 0.3749 - acc: 0.8330 - val_loss: 0.3886 - val_acc: 0.8253
Epoch 13/21
 - 22s - loss: 0.3709 - acc: 0.8343 - val_loss: 0.3986 - val_acc: 0.8247
Epoch 14/21
 - 22s - loss: 0.3656 - acc: 0.8369 - val_loss: 0.3946 - val_acc: 0.8223
Epoch 15/21
 - 22s - loss: 0.3656 - acc: 0.8362 - val_loss: 0.4098 - val_acc: 0.8190

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 16/21
 - 22s - loss: 0.3633 - acc: 0.8386 - val_loss: 0.3969 - val_acc: 0.8198
Epoch 00016: early stopping
Test accuracy:0.862
current auc_score ------------------> 0.951
Saved model to disk
accuracies:  [0.7358870967741935, 0.8155913978494623, 0.8440860215053764, 0.839516129032258, 0.7549731182795699, 0.7723118279569893, 0.8540322580645161, 0.7759408602150538, 0.6130376344086022, 0.8619623655913978]
aucs:  [0.9326, 0.9365, 0.936, 0.9339, 0.8956, 0.9504, 0.9482, 0.9052, 0.9033, 0.9508]
mean and std AUC:  0.929+/-0.019  max:   0.9508
['2-2-2', '30', '3', '8', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5134 - acc: 0.7547 - val_loss: 0.5037 - val_acc: 0.7538
Epoch 2/21
 - 20s - loss: 0.4322 - acc: 0.7936 - val_loss: 0.4478 - val_acc: 0.7918
Epoch 3/21
 - 20s - loss: 0.3989 - acc: 0.8148 - val_loss: 0.4421 - val_acc: 0.7849
Epoch 4/21
 - 21s - loss: 0.3719 - acc: 0.8321 - val_loss: 0.3885 - val_acc: 0.8220
Epoch 5/21
 - 20s - loss: 0.3532 - acc: 0.8441 - val_loss: 0.3543 - val_acc: 0.8404
Epoch 6/21
 - 20s - loss: 0.3352 - acc: 0.8548 - val_loss: 0.3015 - val_acc: 0.8700
Epoch 7/21
 - 20s - loss: 0.3224 - acc: 0.8607 - val_loss: 0.3184 - val_acc: 0.8557
Epoch 8/21
 - 20s - loss: 0.3062 - acc: 0.8706 - val_loss: 0.2849 - val_acc: 0.8793
Epoch 9/21
 - 20s - loss: 0.2956 - acc: 0.8766 - val_loss: 0.3152 - val_acc: 0.8567
Epoch 10/21
 - 20s - loss: 0.2824 - acc: 0.8847 - val_loss: 0.4077 - val_acc: 0.8135
Epoch 11/21
 - 20s - loss: 0.2714 - acc: 0.8891 - val_loss: 0.2856 - val_acc: 0.8775

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 20s - loss: 0.2625 - acc: 0.8935 - val_loss: 0.2800 - val_acc: 0.8790
Epoch 00012: early stopping
Test accuracy:0.864
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5293 - acc: 0.7475 - val_loss: 0.5667 - val_acc: 0.7321
Epoch 2/21
 - 20s - loss: 0.4294 - acc: 0.7990 - val_loss: 0.4024 - val_acc: 0.8081
Epoch 3/21
 - 20s - loss: 0.3850 - acc: 0.8248 - val_loss: 0.3605 - val_acc: 0.8351
Epoch 4/21
 - 20s - loss: 0.3567 - acc: 0.8418 - val_loss: 0.3319 - val_acc: 0.8473
Epoch 5/21
 - 20s - loss: 0.3352 - acc: 0.8530 - val_loss: 0.3171 - val_acc: 0.8586
Epoch 6/21
 - 20s - loss: 0.3127 - acc: 0.8661 - val_loss: 0.3073 - val_acc: 0.8676
Epoch 7/21
 - 20s - loss: 0.2981 - acc: 0.8755 - val_loss: 0.2775 - val_acc: 0.8809
Epoch 8/21
 - 21s - loss: 0.2838 - acc: 0.8826 - val_loss: 0.2566 - val_acc: 0.8936
Epoch 9/21
 - 21s - loss: 0.2730 - acc: 0.8890 - val_loss: 0.2298 - val_acc: 0.9109
Epoch 10/21
 - 20s - loss: 0.2606 - acc: 0.8953 - val_loss: 0.2481 - val_acc: 0.9037
Epoch 11/21
 - 20s - loss: 0.2472 - acc: 0.9042 - val_loss: 0.2324 - val_acc: 0.9057
Epoch 12/21
 - 21s - loss: 0.2404 - acc: 0.9060 - val_loss: 0.2434 - val_acc: 0.9012

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 21s - loss: 0.2272 - acc: 0.9134 - val_loss: 0.2350 - val_acc: 0.9069
Epoch 00013: early stopping
Test accuracy:0.872
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4985 - acc: 0.7626 - val_loss: 0.4614 - val_acc: 0.7740
Epoch 2/21
 - 20s - loss: 0.4139 - acc: 0.8047 - val_loss: 0.3826 - val_acc: 0.8209
Epoch 3/21
 - 20s - loss: 0.3787 - acc: 0.8248 - val_loss: 0.3458 - val_acc: 0.8427
Epoch 4/21
 - 20s - loss: 0.3535 - acc: 0.8421 - val_loss: 0.3552 - val_acc: 0.8438
Epoch 5/21
 - 20s - loss: 0.3369 - acc: 0.8517 - val_loss: 0.3249 - val_acc: 0.8616
Epoch 6/21
 - 20s - loss: 0.3184 - acc: 0.8622 - val_loss: 0.2872 - val_acc: 0.8803
Epoch 7/21
 - 20s - loss: 0.3008 - acc: 0.8736 - val_loss: 0.2670 - val_acc: 0.8917
Epoch 8/21
 - 20s - loss: 0.2865 - acc: 0.8808 - val_loss: 0.2634 - val_acc: 0.8961
Epoch 9/21
 - 20s - loss: 0.2738 - acc: 0.8885 - val_loss: 0.2799 - val_acc: 0.8857
Epoch 10/21
 - 20s - loss: 0.2597 - acc: 0.8956 - val_loss: 0.2322 - val_acc: 0.9095
Epoch 11/21
 - 20s - loss: 0.2513 - acc: 0.9007 - val_loss: 0.2166 - val_acc: 0.9187
Epoch 12/21
 - 20s - loss: 0.2426 - acc: 0.9059 - val_loss: 0.2083 - val_acc: 0.9196
Epoch 13/21
 - 20s - loss: 0.2311 - acc: 0.9107 - val_loss: 0.2154 - val_acc: 0.9170
Epoch 14/21
 - 20s - loss: 0.2231 - acc: 0.9142 - val_loss: 0.2063 - val_acc: 0.9213
Epoch 15/21
 - 20s - loss: 0.2151 - acc: 0.9178 - val_loss: 0.1837 - val_acc: 0.9314
Epoch 16/21
 - 20s - loss: 0.2095 - acc: 0.9208 - val_loss: 0.1927 - val_acc: 0.9281
Epoch 17/21
 - 20s - loss: 0.2030 - acc: 0.9231 - val_loss: 0.1951 - val_acc: 0.9268
Epoch 18/21
 - 20s - loss: 0.1966 - acc: 0.9267 - val_loss: 0.1604 - val_acc: 0.9404
Epoch 19/21
 - 20s - loss: 0.1911 - acc: 0.9297 - val_loss: 0.1588 - val_acc: 0.9418
Epoch 20/21
 - 20s - loss: 0.1849 - acc: 0.9320 - val_loss: 0.1698 - val_acc: 0.9391
Epoch 21/21
 - 21s - loss: 0.1795 - acc: 0.9336 - val_loss: 0.1436 - val_acc: 0.9495
Test accuracy:0.860
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5264 - acc: 0.7389 - val_loss: 0.4812 - val_acc: 0.7634
Epoch 2/21
 - 20s - loss: 0.4376 - acc: 0.7939 - val_loss: 0.4663 - val_acc: 0.7668
Epoch 3/21
 - 20s - loss: 0.4037 - acc: 0.8149 - val_loss: 0.3860 - val_acc: 0.8296
Epoch 4/21
 - 20s - loss: 0.3744 - acc: 0.8325 - val_loss: 0.3492 - val_acc: 0.8454
Epoch 5/21
 - 20s - loss: 0.3512 - acc: 0.8481 - val_loss: 0.3183 - val_acc: 0.8700
Epoch 6/21
 - 20s - loss: 0.3356 - acc: 0.8577 - val_loss: 0.3085 - val_acc: 0.8737
Epoch 7/21
 - 20s - loss: 0.3179 - acc: 0.8652 - val_loss: 0.3080 - val_acc: 0.8682
Epoch 8/21
 - 20s - loss: 0.3016 - acc: 0.8758 - val_loss: 0.2755 - val_acc: 0.8859
Epoch 9/21
 - 20s - loss: 0.2910 - acc: 0.8802 - val_loss: 0.2660 - val_acc: 0.8921
Epoch 10/21
 - 20s - loss: 0.2769 - acc: 0.8887 - val_loss: 0.2477 - val_acc: 0.8995
Epoch 11/21
 - 20s - loss: 0.2668 - acc: 0.8945 - val_loss: 0.2385 - val_acc: 0.9081
Epoch 12/21
 - 21s - loss: 0.2561 - acc: 0.8979 - val_loss: 0.2328 - val_acc: 0.9138
Epoch 13/21
 - 21s - loss: 0.2481 - acc: 0.9038 - val_loss: 0.2244 - val_acc: 0.9154
Epoch 14/21
 - 20s - loss: 0.2409 - acc: 0.9070 - val_loss: 0.2055 - val_acc: 0.9212
Epoch 15/21
 - 20s - loss: 0.2346 - acc: 0.9101 - val_loss: 0.1981 - val_acc: 0.9265
Epoch 16/21
 - 21s - loss: 0.2262 - acc: 0.9150 - val_loss: 0.2122 - val_acc: 0.9198
Epoch 17/21
 - 20s - loss: 0.2191 - acc: 0.9177 - val_loss: 0.1853 - val_acc: 0.9326
Epoch 18/21
 - 20s - loss: 0.2112 - acc: 0.9208 - val_loss: 0.1816 - val_acc: 0.9310
Epoch 19/21
 - 20s - loss: 0.2045 - acc: 0.9254 - val_loss: 0.1733 - val_acc: 0.9391
Epoch 20/21
 - 20s - loss: 0.1999 - acc: 0.9275 - val_loss: 0.1979 - val_acc: 0.9248
Epoch 21/21
 - 20s - loss: 0.1911 - acc: 0.9299 - val_loss: 0.1727 - val_acc: 0.9367
Test accuracy:0.877
current auc_score ------------------> 0.952
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5299 - acc: 0.7459 - val_loss: 0.4737 - val_acc: 0.7741
Epoch 2/21
 - 20s - loss: 0.4373 - acc: 0.7960 - val_loss: 0.3960 - val_acc: 0.8179
Epoch 3/21
 - 20s - loss: 0.4000 - acc: 0.8172 - val_loss: 0.3711 - val_acc: 0.8271
Epoch 4/21
 - 20s - loss: 0.3718 - acc: 0.8314 - val_loss: 0.3767 - val_acc: 0.8297
Epoch 5/21
 - 20s - loss: 0.3488 - acc: 0.8462 - val_loss: 0.3269 - val_acc: 0.8537
Epoch 6/21
 - 20s - loss: 0.3289 - acc: 0.8584 - val_loss: 0.3100 - val_acc: 0.8586
Epoch 7/21
 - 20s - loss: 0.3142 - acc: 0.8663 - val_loss: 0.3157 - val_acc: 0.8604
Epoch 8/21
 - 20s - loss: 0.2978 - acc: 0.8754 - val_loss: 0.2646 - val_acc: 0.8928
Epoch 9/21
 - 20s - loss: 0.2856 - acc: 0.8824 - val_loss: 0.2619 - val_acc: 0.8927
Epoch 10/21
 - 20s - loss: 0.2727 - acc: 0.8906 - val_loss: 0.2636 - val_acc: 0.8951
Epoch 11/21
 - 20s - loss: 0.2623 - acc: 0.8958 - val_loss: 0.2357 - val_acc: 0.9065
Epoch 12/21
 - 20s - loss: 0.2515 - acc: 0.9007 - val_loss: 0.2192 - val_acc: 0.9175
Epoch 13/21
 - 20s - loss: 0.2436 - acc: 0.9045 - val_loss: 0.2174 - val_acc: 0.9170
Epoch 14/21
 - 20s - loss: 0.2319 - acc: 0.9105 - val_loss: 0.2091 - val_acc: 0.9208
Epoch 15/21
 - 20s - loss: 0.2212 - acc: 0.9176 - val_loss: 0.2043 - val_acc: 0.9266
Epoch 16/21
 - 20s - loss: 0.2194 - acc: 0.9176 - val_loss: 0.1818 - val_acc: 0.9334
Epoch 17/21
 - 20s - loss: 0.2106 - acc: 0.9210 - val_loss: 0.2151 - val_acc: 0.9180
Epoch 18/21
 - 20s - loss: 0.2053 - acc: 0.9230 - val_loss: 0.1626 - val_acc: 0.9423
Epoch 19/21
 - 20s - loss: 0.1987 - acc: 0.9254 - val_loss: 0.1731 - val_acc: 0.9345
Epoch 20/21
 - 20s - loss: 0.1928 - acc: 0.9298 - val_loss: 0.1790 - val_acc: 0.9339
Epoch 21/21
 - 20s - loss: 0.1857 - acc: 0.9316 - val_loss: 0.1586 - val_acc: 0.9435
Test accuracy:0.852
current auc_score ------------------> 0.956
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5188 - acc: 0.7502 - val_loss: 0.4466 - val_acc: 0.7924
Epoch 2/21
 - 20s - loss: 0.4310 - acc: 0.7961 - val_loss: 0.4098 - val_acc: 0.8081
Epoch 3/21
 - 20s - loss: 0.3940 - acc: 0.8184 - val_loss: 0.3614 - val_acc: 0.8343
Epoch 4/21
 - 20s - loss: 0.3676 - acc: 0.8344 - val_loss: 0.3492 - val_acc: 0.8400
Epoch 5/21
 - 20s - loss: 0.3444 - acc: 0.8495 - val_loss: 0.3440 - val_acc: 0.8503
Epoch 6/21
 - 20s - loss: 0.3255 - acc: 0.8601 - val_loss: 0.3276 - val_acc: 0.8543
Epoch 7/21
 - 20s - loss: 0.3087 - acc: 0.8684 - val_loss: 0.2920 - val_acc: 0.8763
Epoch 8/21
 - 20s - loss: 0.2950 - acc: 0.8767 - val_loss: 0.2721 - val_acc: 0.8868
Epoch 9/21
 - 20s - loss: 0.2817 - acc: 0.8858 - val_loss: 0.2600 - val_acc: 0.8929
Epoch 10/21
 - 20s - loss: 0.2672 - acc: 0.8929 - val_loss: 0.2539 - val_acc: 0.8980
Epoch 11/21
 - 20s - loss: 0.2574 - acc: 0.8983 - val_loss: 0.2565 - val_acc: 0.8973
Epoch 12/21
 - 20s - loss: 0.2490 - acc: 0.9011 - val_loss: 0.2406 - val_acc: 0.9076
Epoch 13/21
 - 20s - loss: 0.2389 - acc: 0.9079 - val_loss: 0.2269 - val_acc: 0.9101
Epoch 14/21
 - 20s - loss: 0.2291 - acc: 0.9122 - val_loss: 0.2056 - val_acc: 0.9211
Epoch 15/21
 - 20s - loss: 0.2214 - acc: 0.9165 - val_loss: 0.2003 - val_acc: 0.9255
Epoch 16/21
 - 20s - loss: 0.2154 - acc: 0.9192 - val_loss: 0.2051 - val_acc: 0.9201
Epoch 17/21
 - 20s - loss: 0.2056 - acc: 0.9242 - val_loss: 0.2042 - val_acc: 0.9238
Epoch 18/21
 - 20s - loss: 0.1988 - acc: 0.9254 - val_loss: 0.1838 - val_acc: 0.9296
Epoch 19/21
 - 20s - loss: 0.1961 - acc: 0.9281 - val_loss: 0.1859 - val_acc: 0.9307
Epoch 20/21
 - 20s - loss: 0.1895 - acc: 0.9324 - val_loss: 0.1735 - val_acc: 0.9380
Epoch 21/21
 - 20s - loss: 0.1866 - acc: 0.9329 - val_loss: 0.1560 - val_acc: 0.9448
Test accuracy:0.842
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5286 - acc: 0.7404 - val_loss: 0.5121 - val_acc: 0.7390
Epoch 2/21
 - 20s - loss: 0.4301 - acc: 0.7953 - val_loss: 0.4091 - val_acc: 0.8061
Epoch 3/21
 - 20s - loss: 0.3904 - acc: 0.8188 - val_loss: 0.3656 - val_acc: 0.8337
Epoch 4/21
 - 20s - loss: 0.3620 - acc: 0.8375 - val_loss: 0.3236 - val_acc: 0.8588
Epoch 5/21
 - 20s - loss: 0.3390 - acc: 0.8532 - val_loss: 0.2940 - val_acc: 0.8785
Epoch 6/21
 - 20s - loss: 0.3185 - acc: 0.8656 - val_loss: 0.2753 - val_acc: 0.8879
Epoch 7/21
 - 20s - loss: 0.3024 - acc: 0.8759 - val_loss: 0.2600 - val_acc: 0.9006
Epoch 8/21
 - 20s - loss: 0.2860 - acc: 0.8814 - val_loss: 0.2555 - val_acc: 0.8982
Epoch 9/21
 - 20s - loss: 0.2740 - acc: 0.8894 - val_loss: 0.2673 - val_acc: 0.8951
Epoch 10/21
 - 20s - loss: 0.2636 - acc: 0.8947 - val_loss: 0.2235 - val_acc: 0.9194
Epoch 11/21
 - 21s - loss: 0.2505 - acc: 0.9024 - val_loss: 0.2188 - val_acc: 0.9178
Epoch 12/21
 - 20s - loss: 0.2426 - acc: 0.9063 - val_loss: 0.2398 - val_acc: 0.9088
Epoch 13/21
 - 20s - loss: 0.2340 - acc: 0.9101 - val_loss: 0.2273 - val_acc: 0.9143
Epoch 14/21
 - 20s - loss: 0.2251 - acc: 0.9155 - val_loss: 0.1898 - val_acc: 0.9324
Epoch 15/21
 - 20s - loss: 0.2177 - acc: 0.9179 - val_loss: 0.1831 - val_acc: 0.9327
Epoch 16/21
 - 20s - loss: 0.2100 - acc: 0.9218 - val_loss: 0.1731 - val_acc: 0.9386
Epoch 17/21
 - 20s - loss: 0.2050 - acc: 0.9239 - val_loss: 0.1626 - val_acc: 0.9445
Epoch 18/21
 - 20s - loss: 0.1990 - acc: 0.9267 - val_loss: 0.1705 - val_acc: 0.9410
Epoch 19/21
 - 20s - loss: 0.1918 - acc: 0.9291 - val_loss: 0.1559 - val_acc: 0.9458
Epoch 20/21
 - 20s - loss: 0.1846 - acc: 0.9334 - val_loss: 0.1506 - val_acc: 0.9462
Epoch 21/21
 - 20s - loss: 0.1834 - acc: 0.9344 - val_loss: 0.1634 - val_acc: 0.9442
Test accuracy:0.825
current auc_score ------------------> 0.954
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5014 - acc: 0.7592 - val_loss: 0.5118 - val_acc: 0.7506
Epoch 2/21
 - 20s - loss: 0.4262 - acc: 0.7941 - val_loss: 0.4358 - val_acc: 0.7898
Epoch 3/21
 - 20s - loss: 0.3895 - acc: 0.8164 - val_loss: 0.3983 - val_acc: 0.8151
Epoch 4/21
 - 20s - loss: 0.3614 - acc: 0.8377 - val_loss: 0.3858 - val_acc: 0.8232
Epoch 5/21
 - 20s - loss: 0.3394 - acc: 0.8531 - val_loss: 0.3040 - val_acc: 0.8696
Epoch 6/21
 - 20s - loss: 0.3218 - acc: 0.8644 - val_loss: 0.2981 - val_acc: 0.8734
Epoch 7/21
 - 20s - loss: 0.3040 - acc: 0.8739 - val_loss: 0.3999 - val_acc: 0.8286
Epoch 8/21
 - 20s - loss: 0.2909 - acc: 0.8812 - val_loss: 0.2698 - val_acc: 0.8902
Epoch 9/21
 - 20s - loss: 0.2785 - acc: 0.8880 - val_loss: 0.2526 - val_acc: 0.8981
Epoch 10/21
 - 20s - loss: 0.2674 - acc: 0.8945 - val_loss: 0.2432 - val_acc: 0.9032
Epoch 11/21
 - 20s - loss: 0.2564 - acc: 0.8994 - val_loss: 0.2315 - val_acc: 0.9079
Epoch 12/21
 - 20s - loss: 0.2460 - acc: 0.9042 - val_loss: 0.2291 - val_acc: 0.9080
Epoch 13/21
 - 20s - loss: 0.2395 - acc: 0.9079 - val_loss: 0.2026 - val_acc: 0.9247
Epoch 14/21
 - 20s - loss: 0.2300 - acc: 0.9119 - val_loss: 0.2065 - val_acc: 0.9199
Epoch 15/21
 - 20s - loss: 0.2225 - acc: 0.9158 - val_loss: 0.1993 - val_acc: 0.9242
Epoch 16/21
 - 20s - loss: 0.2174 - acc: 0.9172 - val_loss: 0.1855 - val_acc: 0.9276
Epoch 17/21
 - 20s - loss: 0.2081 - acc: 0.9217 - val_loss: 0.1822 - val_acc: 0.9297
Epoch 18/21
 - 20s - loss: 0.2049 - acc: 0.9241 - val_loss: 0.2104 - val_acc: 0.9227
Epoch 19/21
 - 20s - loss: 0.1960 - acc: 0.9286 - val_loss: 0.1846 - val_acc: 0.9317
Epoch 20/21
 - 20s - loss: 0.1918 - acc: 0.9311 - val_loss: 0.1829 - val_acc: 0.9344

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 20s - loss: 0.1829 - acc: 0.9347 - val_loss: 0.1575 - val_acc: 0.9453
Test accuracy:0.857
current auc_score ------------------> 0.951
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5362 - acc: 0.7333 - val_loss: 0.6235 - val_acc: 0.6772
Epoch 2/21
 - 20s - loss: 0.4400 - acc: 0.7878 - val_loss: 0.4902 - val_acc: 0.7577
Epoch 3/21
 - 20s - loss: 0.4044 - acc: 0.8108 - val_loss: 0.4562 - val_acc: 0.7775
Epoch 4/21
 - 20s - loss: 0.3767 - acc: 0.8272 - val_loss: 0.4449 - val_acc: 0.7943
Epoch 5/21
 - 20s - loss: 0.3569 - acc: 0.8418 - val_loss: 0.3672 - val_acc: 0.8325
Epoch 6/21
 - 20s - loss: 0.3369 - acc: 0.8537 - val_loss: 0.3364 - val_acc: 0.8512
Epoch 7/21
 - 20s - loss: 0.3245 - acc: 0.8602 - val_loss: 0.3665 - val_acc: 0.8289
Epoch 8/21
 - 20s - loss: 0.3123 - acc: 0.8674 - val_loss: 0.3036 - val_acc: 0.8700
Epoch 9/21
 - 20s - loss: 0.3009 - acc: 0.8749 - val_loss: 0.3343 - val_acc: 0.8545
Epoch 10/21
 - 20s - loss: 0.2901 - acc: 0.8810 - val_loss: 0.2931 - val_acc: 0.8737
Epoch 11/21
 - 20s - loss: 0.2769 - acc: 0.8873 - val_loss: 0.2674 - val_acc: 0.8855
Epoch 12/21
 - 20s - loss: 0.2677 - acc: 0.8926 - val_loss: 0.2374 - val_acc: 0.9096
Epoch 13/21
 - 21s - loss: 0.2589 - acc: 0.8961 - val_loss: 0.2331 - val_acc: 0.9061
Epoch 14/21
 - 20s - loss: 0.2505 - acc: 0.9023 - val_loss: 0.2389 - val_acc: 0.9071
Epoch 15/21
 - 20s - loss: 0.2419 - acc: 0.9054 - val_loss: 0.2036 - val_acc: 0.9221
Epoch 16/21
 - 20s - loss: 0.2324 - acc: 0.9099 - val_loss: 0.2045 - val_acc: 0.9226
Epoch 17/21
 - 20s - loss: 0.2250 - acc: 0.9134 - val_loss: 0.1918 - val_acc: 0.9262
Epoch 18/21
 - 20s - loss: 0.2186 - acc: 0.9174 - val_loss: 0.1829 - val_acc: 0.9332
Epoch 19/21
 - 20s - loss: 0.2154 - acc: 0.9183 - val_loss: 0.2417 - val_acc: 0.9093
Epoch 20/21
 - 20s - loss: 0.2058 - acc: 0.9220 - val_loss: 0.1853 - val_acc: 0.9303
Epoch 21/21
 - 20s - loss: 0.1983 - acc: 0.9262 - val_loss: 0.1979 - val_acc: 0.9224

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.874
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   2160        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   10260       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   9180        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   17280       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 94, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 47, 12, 12)   4418        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 47, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 47, 6, 6)     188         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 47, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     12690       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 77, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 77, 6, 6)     308         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 77, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     20790       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 107, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 107, 6, 6)    428         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 107, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 107)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            108         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 82,162
Trainable params: 81,072
Non-trainable params: 1,090
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5236 - acc: 0.7409 - val_loss: 0.4472 - val_acc: 0.7878
Epoch 2/21
 - 20s - loss: 0.4185 - acc: 0.8042 - val_loss: 0.4048 - val_acc: 0.8091
Epoch 3/21
 - 21s - loss: 0.3803 - acc: 0.8267 - val_loss: 0.3654 - val_acc: 0.8346
Epoch 4/21
 - 20s - loss: 0.3585 - acc: 0.8381 - val_loss: 0.3661 - val_acc: 0.8357
Epoch 5/21
 - 20s - loss: 0.3396 - acc: 0.8515 - val_loss: 0.3136 - val_acc: 0.8628
Epoch 6/21
 - 20s - loss: 0.3210 - acc: 0.8627 - val_loss: 0.3072 - val_acc: 0.8701
Epoch 7/21
 - 20s - loss: 0.3029 - acc: 0.8713 - val_loss: 0.2894 - val_acc: 0.8756
Epoch 8/21
 - 20s - loss: 0.2894 - acc: 0.8785 - val_loss: 0.2962 - val_acc: 0.8735
Epoch 9/21
 - 20s - loss: 0.2763 - acc: 0.8882 - val_loss: 0.2515 - val_acc: 0.8981
Epoch 10/21
 - 20s - loss: 0.2668 - acc: 0.8928 - val_loss: 0.2475 - val_acc: 0.9031
Epoch 11/21
 - 20s - loss: 0.2526 - acc: 0.8997 - val_loss: 0.2310 - val_acc: 0.9094
Epoch 12/21
 - 20s - loss: 0.2451 - acc: 0.9036 - val_loss: 0.2166 - val_acc: 0.9168
Epoch 13/21
 - 20s - loss: 0.2396 - acc: 0.9071 - val_loss: 0.2295 - val_acc: 0.9145
Epoch 14/21
 - 20s - loss: 0.2292 - acc: 0.9110 - val_loss: 0.2326 - val_acc: 0.9153
Epoch 15/21
 - 20s - loss: 0.2218 - acc: 0.9156 - val_loss: 0.2040 - val_acc: 0.9211
Epoch 16/21
 - 20s - loss: 0.2117 - acc: 0.9207 - val_loss: 0.1939 - val_acc: 0.9275
Epoch 17/21
 - 20s - loss: 0.2085 - acc: 0.9234 - val_loss: 0.2101 - val_acc: 0.9233
Epoch 18/21
 - 20s - loss: 0.2004 - acc: 0.9264 - val_loss: 0.1884 - val_acc: 0.9287
Epoch 19/21
 - 20s - loss: 0.1958 - acc: 0.9293 - val_loss: 0.1970 - val_acc: 0.9256
Epoch 20/21
 - 20s - loss: 0.1900 - acc: 0.9299 - val_loss: 0.1577 - val_acc: 0.9429
Epoch 21/21
 - 20s - loss: 0.1845 - acc: 0.9323 - val_loss: 0.2190 - val_acc: 0.9216
Test accuracy:0.846
current auc_score ------------------> 0.936
accuracies:  [0.8635752688172043, 0.8717741935483871, 0.8598118279569893, 0.8774193548387097, 0.851747311827957, 0.8416666666666667, 0.8245967741935484, 0.8565860215053763, 0.8735215053763441, 0.8456989247311828]
aucs:  [0.9385, 0.943, 0.9473, 0.9524, 0.9558, 0.9449, 0.9541, 0.9508, 0.947, 0.936]
mean and std AUC:  0.947+/-0.006  max:   0.9558
['2-2-2', '30', '3', '32', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.4994 - acc: 0.7639 - val_loss: 0.4160 - val_acc: 0.8107
Epoch 2/21
 - 21s - loss: 0.3990 - acc: 0.8214 - val_loss: 0.3790 - val_acc: 0.8348
Epoch 3/21
 - 21s - loss: 0.3578 - acc: 0.8487 - val_loss: 0.3298 - val_acc: 0.8637
Epoch 4/21
 - 21s - loss: 0.3318 - acc: 0.8640 - val_loss: 0.3005 - val_acc: 0.8827
Epoch 5/21
 - 21s - loss: 0.3065 - acc: 0.8770 - val_loss: 0.3478 - val_acc: 0.8582
Epoch 6/21
 - 21s - loss: 0.2904 - acc: 0.8862 - val_loss: 0.2812 - val_acc: 0.8870
Epoch 7/21
 - 21s - loss: 0.2770 - acc: 0.8928 - val_loss: 0.2468 - val_acc: 0.9076
Epoch 8/21
 - 21s - loss: 0.2637 - acc: 0.8998 - val_loss: 0.2476 - val_acc: 0.9078
Epoch 9/21
 - 21s - loss: 0.2458 - acc: 0.9085 - val_loss: 0.2442 - val_acc: 0.9108
Epoch 10/21
 - 21s - loss: 0.2371 - acc: 0.9131 - val_loss: 0.2103 - val_acc: 0.9224
Epoch 11/21
 - 22s - loss: 0.2261 - acc: 0.9176 - val_loss: 0.1992 - val_acc: 0.9332
Epoch 12/21
 - 22s - loss: 0.2151 - acc: 0.9234 - val_loss: 0.2002 - val_acc: 0.9307
Epoch 13/21
 - 21s - loss: 0.2098 - acc: 0.9256 - val_loss: 0.2003 - val_acc: 0.9307
Epoch 14/21
 - 21s - loss: 0.1992 - acc: 0.9308 - val_loss: 0.2367 - val_acc: 0.9128

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 22s - loss: 0.1885 - acc: 0.9356 - val_loss: 0.1720 - val_acc: 0.9413
Epoch 16/21
 - 22s - loss: 0.1836 - acc: 0.9377 - val_loss: 0.1616 - val_acc: 0.9464
Epoch 17/21
 - 22s - loss: 0.1815 - acc: 0.9394 - val_loss: 0.1619 - val_acc: 0.9445
Epoch 18/21
 - 22s - loss: 0.1765 - acc: 0.9400 - val_loss: 0.1671 - val_acc: 0.9421
Epoch 19/21
 - 22s - loss: 0.1740 - acc: 0.9421 - val_loss: 0.1691 - val_acc: 0.9420

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 20/21
 - 22s - loss: 0.1716 - acc: 0.9426 - val_loss: 0.1552 - val_acc: 0.9468
Epoch 21/21
 - 22s - loss: 0.1714 - acc: 0.9424 - val_loss: 0.1610 - val_acc: 0.9445
Test accuracy:0.860
current auc_score ------------------> 0.942
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5006 - acc: 0.7675 - val_loss: 0.4372 - val_acc: 0.8011
Epoch 2/21
 - 22s - loss: 0.3988 - acc: 0.8232 - val_loss: 0.4155 - val_acc: 0.8166
Epoch 3/21
 - 22s - loss: 0.3546 - acc: 0.8499 - val_loss: 0.3940 - val_acc: 0.8308
Epoch 4/21
 - 21s - loss: 0.3259 - acc: 0.8660 - val_loss: 0.3171 - val_acc: 0.8704
Epoch 5/21
 - 21s - loss: 0.3013 - acc: 0.8809 - val_loss: 0.3164 - val_acc: 0.8785
Epoch 6/21
 - 22s - loss: 0.2815 - acc: 0.8912 - val_loss: 0.2717 - val_acc: 0.8942
Epoch 7/21
 - 22s - loss: 0.2681 - acc: 0.8969 - val_loss: 0.2367 - val_acc: 0.9202
Epoch 8/21
 - 22s - loss: 0.2569 - acc: 0.9033 - val_loss: 0.2283 - val_acc: 0.9192
Epoch 9/21
 - 21s - loss: 0.2416 - acc: 0.9105 - val_loss: 0.2131 - val_acc: 0.9298
Epoch 10/21
 - 22s - loss: 0.2301 - acc: 0.9157 - val_loss: 0.1994 - val_acc: 0.9308
Epoch 11/21
 - 22s - loss: 0.2219 - acc: 0.9204 - val_loss: 0.2224 - val_acc: 0.9174
Epoch 12/21
 - 22s - loss: 0.2128 - acc: 0.9238 - val_loss: 0.1825 - val_acc: 0.9381
Epoch 13/21
 - 21s - loss: 0.2027 - acc: 0.9289 - val_loss: 0.1803 - val_acc: 0.9362
Epoch 14/21
 - 21s - loss: 0.1959 - acc: 0.9312 - val_loss: 0.1858 - val_acc: 0.9329
Epoch 15/21
 - 22s - loss: 0.1890 - acc: 0.9340 - val_loss: 0.1519 - val_acc: 0.9508
Epoch 16/21
 - 22s - loss: 0.1798 - acc: 0.9390 - val_loss: 0.1481 - val_acc: 0.9556
Epoch 17/21
 - 22s - loss: 0.1762 - acc: 0.9416 - val_loss: 0.1346 - val_acc: 0.9601
Epoch 18/21
 - 22s - loss: 0.1676 - acc: 0.9440 - val_loss: 0.1533 - val_acc: 0.9477
Epoch 19/21
 - 21s - loss: 0.1658 - acc: 0.9459 - val_loss: 0.1540 - val_acc: 0.9475
Epoch 20/21
 - 21s - loss: 0.1585 - acc: 0.9490 - val_loss: 0.1310 - val_acc: 0.9590
Epoch 21/21
 - 21s - loss: 0.1557 - acc: 0.9498 - val_loss: 0.1301 - val_acc: 0.9563
Epoch 00021: early stopping
Test accuracy:0.864
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5010 - acc: 0.7663 - val_loss: 0.5311 - val_acc: 0.7244
Epoch 2/21
 - 21s - loss: 0.4027 - acc: 0.8184 - val_loss: 0.4837 - val_acc: 0.7647
Epoch 3/21
 - 21s - loss: 0.3641 - acc: 0.8435 - val_loss: 0.3689 - val_acc: 0.8411
Epoch 4/21
 - 21s - loss: 0.3377 - acc: 0.8590 - val_loss: 0.3292 - val_acc: 0.8618
Epoch 5/21
 - 21s - loss: 0.3191 - acc: 0.8697 - val_loss: 0.2986 - val_acc: 0.8808
Epoch 6/21
 - 21s - loss: 0.2997 - acc: 0.8800 - val_loss: 0.3330 - val_acc: 0.8676
Epoch 7/21
 - 21s - loss: 0.2869 - acc: 0.8866 - val_loss: 0.3106 - val_acc: 0.8692
Epoch 8/21
 - 21s - loss: 0.2729 - acc: 0.8932 - val_loss: 0.2405 - val_acc: 0.9083
Epoch 9/21
 - 21s - loss: 0.2591 - acc: 0.9023 - val_loss: 0.3156 - val_acc: 0.8686
Epoch 10/21
 - 21s - loss: 0.2472 - acc: 0.9071 - val_loss: 0.2275 - val_acc: 0.9169
Epoch 11/21
 - 21s - loss: 0.2362 - acc: 0.9123 - val_loss: 0.2411 - val_acc: 0.9085
Epoch 12/21
 - 22s - loss: 0.2256 - acc: 0.9157 - val_loss: 0.2084 - val_acc: 0.9218
Epoch 13/21
 - 22s - loss: 0.2152 - acc: 0.9229 - val_loss: 0.2415 - val_acc: 0.9047
Epoch 14/21
 - 22s - loss: 0.2109 - acc: 0.9245 - val_loss: 0.2121 - val_acc: 0.9212
Epoch 15/21
 - 22s - loss: 0.2034 - acc: 0.9274 - val_loss: 0.1745 - val_acc: 0.9403
Epoch 16/21
 - 22s - loss: 0.1960 - acc: 0.9320 - val_loss: 0.1624 - val_acc: 0.9452
Epoch 17/21
 - 22s - loss: 0.1875 - acc: 0.9349 - val_loss: 0.1629 - val_acc: 0.9435
Epoch 18/21
 - 21s - loss: 0.1828 - acc: 0.9374 - val_loss: 0.1579 - val_acc: 0.9458
Epoch 19/21
 - 21s - loss: 0.1765 - acc: 0.9400 - val_loss: 0.1511 - val_acc: 0.9472
Epoch 20/21
 - 22s - loss: 0.1708 - acc: 0.9423 - val_loss: 0.1516 - val_acc: 0.9513
Epoch 21/21
 - 21s - loss: 0.1647 - acc: 0.9448 - val_loss: 0.1263 - val_acc: 0.9608
Test accuracy:0.867
current auc_score ------------------> 0.957
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5020 - acc: 0.7626 - val_loss: 0.4927 - val_acc: 0.7774
Epoch 2/21
 - 22s - loss: 0.4078 - acc: 0.8128 - val_loss: 0.5221 - val_acc: 0.7673
Epoch 3/21
 - 22s - loss: 0.3679 - acc: 0.8381 - val_loss: 0.3677 - val_acc: 0.8420
Epoch 4/21
 - 22s - loss: 0.3410 - acc: 0.8556 - val_loss: 0.3327 - val_acc: 0.8588
Epoch 5/21
 - 22s - loss: 0.3183 - acc: 0.8707 - val_loss: 0.3245 - val_acc: 0.8608
Epoch 6/21
 - 22s - loss: 0.3014 - acc: 0.8777 - val_loss: 0.2947 - val_acc: 0.8755
Epoch 7/21
 - 22s - loss: 0.2858 - acc: 0.8876 - val_loss: 0.4293 - val_acc: 0.8173
Epoch 8/21
 - 21s - loss: 0.2706 - acc: 0.8961 - val_loss: 0.2854 - val_acc: 0.8827
Epoch 9/21
 - 22s - loss: 0.2574 - acc: 0.9033 - val_loss: 0.2657 - val_acc: 0.8992
Epoch 10/21
 - 22s - loss: 0.2477 - acc: 0.9062 - val_loss: 0.2556 - val_acc: 0.8993
Epoch 11/21
 - 21s - loss: 0.2329 - acc: 0.9147 - val_loss: 0.3245 - val_acc: 0.8710
Epoch 12/21
 - 22s - loss: 0.2251 - acc: 0.9184 - val_loss: 0.3405 - val_acc: 0.8557
Epoch 13/21
 - 21s - loss: 0.2166 - acc: 0.9218 - val_loss: 0.3050 - val_acc: 0.8783

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/21
 - 21s - loss: 0.2029 - acc: 0.9294 - val_loss: 0.2006 - val_acc: 0.9290
Epoch 15/21
 - 21s - loss: 0.2010 - acc: 0.9299 - val_loss: 0.2251 - val_acc: 0.9152
Epoch 16/21
 - 21s - loss: 0.2013 - acc: 0.9302 - val_loss: 0.1896 - val_acc: 0.9360
Epoch 17/21
 - 21s - loss: 0.1955 - acc: 0.9324 - val_loss: 0.1770 - val_acc: 0.9406
Epoch 18/21
 - 22s - loss: 0.1925 - acc: 0.9343 - val_loss: 0.2075 - val_acc: 0.9239
Epoch 19/21
 - 22s - loss: 0.1919 - acc: 0.9336 - val_loss: 0.2031 - val_acc: 0.9260
Epoch 20/21
 - 21s - loss: 0.1875 - acc: 0.9363 - val_loss: 0.1879 - val_acc: 0.9325

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 21/21
 - 21s - loss: 0.1844 - acc: 0.9382 - val_loss: 0.1641 - val_acc: 0.9463
Test accuracy:0.852
current auc_score ------------------> 0.953
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5089 - acc: 0.7603 - val_loss: 0.5454 - val_acc: 0.7380
Epoch 2/21
 - 21s - loss: 0.4012 - acc: 0.8212 - val_loss: 0.3672 - val_acc: 0.8427
Epoch 3/21
 - 21s - loss: 0.3583 - acc: 0.8471 - val_loss: 0.3409 - val_acc: 0.8499
Epoch 4/21
 - 21s - loss: 0.3281 - acc: 0.8651 - val_loss: 0.3376 - val_acc: 0.8507
Epoch 5/21
 - 21s - loss: 0.3058 - acc: 0.8783 - val_loss: 0.2713 - val_acc: 0.8899
Epoch 6/21
 - 21s - loss: 0.2861 - acc: 0.8871 - val_loss: 0.2735 - val_acc: 0.8902
Epoch 7/21
 - 21s - loss: 0.2694 - acc: 0.8962 - val_loss: 0.2467 - val_acc: 0.9090
Epoch 8/21
 - 21s - loss: 0.2558 - acc: 0.9042 - val_loss: 0.2752 - val_acc: 0.8878
Epoch 9/21
 - 21s - loss: 0.2439 - acc: 0.9089 - val_loss: 0.2384 - val_acc: 0.9061
Epoch 10/21
 - 21s - loss: 0.2320 - acc: 0.9160 - val_loss: 0.2309 - val_acc: 0.9128
Epoch 11/21
 - 22s - loss: 0.2252 - acc: 0.9194 - val_loss: 0.2412 - val_acc: 0.9083
Epoch 12/21
 - 22s - loss: 0.2115 - acc: 0.9246 - val_loss: 0.2305 - val_acc: 0.9109
Epoch 13/21
 - 22s - loss: 0.2037 - acc: 0.9283 - val_loss: 0.1819 - val_acc: 0.9367
Epoch 14/21
 - 22s - loss: 0.1963 - acc: 0.9304 - val_loss: 0.1869 - val_acc: 0.9346
Epoch 15/21
 - 22s - loss: 0.1894 - acc: 0.9343 - val_loss: 0.1567 - val_acc: 0.9484
Epoch 16/21
 - 22s - loss: 0.1802 - acc: 0.9387 - val_loss: 0.1530 - val_acc: 0.9497
Epoch 17/21
 - 21s - loss: 0.1749 - acc: 0.9424 - val_loss: 0.1486 - val_acc: 0.9531
Epoch 18/21
 - 21s - loss: 0.1718 - acc: 0.9431 - val_loss: 0.1557 - val_acc: 0.9463
Epoch 19/21
 - 21s - loss: 0.1644 - acc: 0.9457 - val_loss: 0.1477 - val_acc: 0.9511
Epoch 20/21
 - 21s - loss: 0.1594 - acc: 0.9483 - val_loss: 0.1394 - val_acc: 0.9572
Epoch 21/21
 - 21s - loss: 0.1567 - acc: 0.9485 - val_loss: 0.1260 - val_acc: 0.9615
Test accuracy:0.832
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5128 - acc: 0.7538 - val_loss: 0.4617 - val_acc: 0.7855
Epoch 2/21
 - 21s - loss: 0.4092 - acc: 0.8154 - val_loss: 0.3707 - val_acc: 0.8399
Epoch 3/21
 - 22s - loss: 0.3674 - acc: 0.8415 - val_loss: 0.3440 - val_acc: 0.8549
Epoch 4/21
 - 22s - loss: 0.3409 - acc: 0.8576 - val_loss: 0.3210 - val_acc: 0.8656
Epoch 5/21
 - 22s - loss: 0.3171 - acc: 0.8691 - val_loss: 0.3042 - val_acc: 0.8778
Epoch 6/21
 - 22s - loss: 0.2988 - acc: 0.8805 - val_loss: 0.2654 - val_acc: 0.8952
Epoch 7/21
 - 22s - loss: 0.2830 - acc: 0.8889 - val_loss: 0.2552 - val_acc: 0.9049
Epoch 8/21
 - 22s - loss: 0.2678 - acc: 0.8972 - val_loss: 0.2906 - val_acc: 0.8839
Epoch 9/21
 - 22s - loss: 0.2537 - acc: 0.9040 - val_loss: 0.2477 - val_acc: 0.9041
Epoch 10/21
 - 22s - loss: 0.2404 - acc: 0.9110 - val_loss: 0.2299 - val_acc: 0.9178
Epoch 11/21
 - 22s - loss: 0.2299 - acc: 0.9170 - val_loss: 0.2199 - val_acc: 0.9231
Epoch 12/21
 - 22s - loss: 0.2207 - acc: 0.9217 - val_loss: 0.1888 - val_acc: 0.9354
Epoch 13/21
 - 21s - loss: 0.2118 - acc: 0.9246 - val_loss: 0.1987 - val_acc: 0.9308
Epoch 14/21
 - 22s - loss: 0.2002 - acc: 0.9312 - val_loss: 0.1911 - val_acc: 0.9314
Epoch 15/21
 - 22s - loss: 0.1939 - acc: 0.9337 - val_loss: 0.1624 - val_acc: 0.9472
Epoch 16/21
 - 21s - loss: 0.1884 - acc: 0.9348 - val_loss: 0.1798 - val_acc: 0.9380
Epoch 17/21
 - 22s - loss: 0.1811 - acc: 0.9380 - val_loss: 0.2243 - val_acc: 0.9169
Epoch 18/21
 - 22s - loss: 0.1783 - acc: 0.9394 - val_loss: 0.1634 - val_acc: 0.9463

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 21s - loss: 0.1645 - acc: 0.9466 - val_loss: 0.1658 - val_acc: 0.9453
Epoch 00019: early stopping
Test accuracy:0.857
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5011 - acc: 0.7636 - val_loss: 0.5944 - val_acc: 0.7156
Epoch 2/21
 - 21s - loss: 0.3967 - acc: 0.8213 - val_loss: 0.4056 - val_acc: 0.8166
Epoch 3/21
 - 21s - loss: 0.3553 - acc: 0.8475 - val_loss: 0.3390 - val_acc: 0.8572
Epoch 4/21
 - 22s - loss: 0.3292 - acc: 0.8635 - val_loss: 0.3563 - val_acc: 0.8473
Epoch 5/21
 - 22s - loss: 0.3042 - acc: 0.8783 - val_loss: 0.3455 - val_acc: 0.8591
Epoch 6/21
 - 21s - loss: 0.2850 - acc: 0.8898 - val_loss: 0.2729 - val_acc: 0.8911
Epoch 7/21
 - 22s - loss: 0.2700 - acc: 0.8960 - val_loss: 0.2355 - val_acc: 0.9111
Epoch 8/21
 - 22s - loss: 0.2582 - acc: 0.9019 - val_loss: 0.2820 - val_acc: 0.8896
Epoch 9/21
 - 21s - loss: 0.2450 - acc: 0.9094 - val_loss: 0.2452 - val_acc: 0.9074
Epoch 10/21
 - 21s - loss: 0.2334 - acc: 0.9150 - val_loss: 0.1978 - val_acc: 0.9260
Epoch 11/21
 - 21s - loss: 0.2195 - acc: 0.9204 - val_loss: 0.2361 - val_acc: 0.9116
Epoch 12/21
 - 21s - loss: 0.2121 - acc: 0.9248 - val_loss: 0.1787 - val_acc: 0.9393
Epoch 13/21
 - 21s - loss: 0.2050 - acc: 0.9273 - val_loss: 0.2291 - val_acc: 0.9129
Epoch 14/21
 - 22s - loss: 0.1942 - acc: 0.9332 - val_loss: 0.2127 - val_acc: 0.9194
Epoch 15/21
 - 22s - loss: 0.1886 - acc: 0.9355 - val_loss: 0.2174 - val_acc: 0.9172

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/21
 - 21s - loss: 0.1766 - acc: 0.9398 - val_loss: 0.2075 - val_acc: 0.9233
Epoch 00016: early stopping
Test accuracy:0.872
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5540 - acc: 0.7315 - val_loss: 0.4364 - val_acc: 0.7942
Epoch 2/21
 - 22s - loss: 0.4166 - acc: 0.8133 - val_loss: 0.3966 - val_acc: 0.8135
Epoch 3/21
 - 22s - loss: 0.3767 - acc: 0.8346 - val_loss: 0.4073 - val_acc: 0.8091
Epoch 4/21
 - 22s - loss: 0.3522 - acc: 0.8496 - val_loss: 0.4779 - val_acc: 0.7757
Epoch 5/21
 - 22s - loss: 0.3304 - acc: 0.8627 - val_loss: 0.3059 - val_acc: 0.8701
Epoch 6/21
 - 22s - loss: 0.3122 - acc: 0.8730 - val_loss: 0.3123 - val_acc: 0.8657
Epoch 7/21
 - 22s - loss: 0.2961 - acc: 0.8805 - val_loss: 0.2839 - val_acc: 0.8837
Epoch 8/21
 - 22s - loss: 0.2800 - acc: 0.8906 - val_loss: 0.2712 - val_acc: 0.8940
Epoch 9/21
 - 22s - loss: 0.2679 - acc: 0.8976 - val_loss: 0.2409 - val_acc: 0.9110
Epoch 10/21
 - 22s - loss: 0.2580 - acc: 0.9017 - val_loss: 0.2776 - val_acc: 0.8837
Epoch 11/21
 - 21s - loss: 0.2464 - acc: 0.9086 - val_loss: 0.2310 - val_acc: 0.9138
Epoch 12/21
 - 22s - loss: 0.2361 - acc: 0.9124 - val_loss: 0.2325 - val_acc: 0.9134
Epoch 13/21
 - 22s - loss: 0.2257 - acc: 0.9192 - val_loss: 0.2159 - val_acc: 0.9208
Epoch 14/21
 - 21s - loss: 0.2189 - acc: 0.9222 - val_loss: 0.2097 - val_acc: 0.9288
Epoch 15/21
 - 22s - loss: 0.2073 - acc: 0.9259 - val_loss: 0.1866 - val_acc: 0.9337
Epoch 16/21
 - 22s - loss: 0.1989 - acc: 0.9309 - val_loss: 0.1715 - val_acc: 0.9396
Epoch 17/21
 - 21s - loss: 0.1940 - acc: 0.9330 - val_loss: 0.1696 - val_acc: 0.9396
Epoch 18/21
 - 22s - loss: 0.1866 - acc: 0.9353 - val_loss: 0.1652 - val_acc: 0.9426
Epoch 19/21
 - 22s - loss: 0.1791 - acc: 0.9400 - val_loss: 0.1546 - val_acc: 0.9463
Epoch 20/21
 - 22s - loss: 0.1766 - acc: 0.9400 - val_loss: 0.1643 - val_acc: 0.9447
Epoch 21/21
 - 22s - loss: 0.1669 - acc: 0.9441 - val_loss: 0.1383 - val_acc: 0.9570
Test accuracy:0.845
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5008 - acc: 0.7693 - val_loss: 0.5874 - val_acc: 0.6935
Epoch 2/21
 - 21s - loss: 0.4028 - acc: 0.8179 - val_loss: 0.4214 - val_acc: 0.8036
Epoch 3/21
 - 22s - loss: 0.3604 - acc: 0.8460 - val_loss: 0.3429 - val_acc: 0.8540
Epoch 4/21
 - 22s - loss: 0.3297 - acc: 0.8637 - val_loss: 0.3225 - val_acc: 0.8677
Epoch 5/21
 - 22s - loss: 0.3058 - acc: 0.8775 - val_loss: 0.2867 - val_acc: 0.8876
Epoch 6/21
 - 22s - loss: 0.2883 - acc: 0.8879 - val_loss: 0.2913 - val_acc: 0.8806
Epoch 7/21
 - 22s - loss: 0.2741 - acc: 0.8943 - val_loss: 0.3131 - val_acc: 0.8655
Epoch 8/21
 - 22s - loss: 0.2554 - acc: 0.9027 - val_loss: 0.2300 - val_acc: 0.9138
Epoch 9/21
 - 22s - loss: 0.2461 - acc: 0.9089 - val_loss: 0.2180 - val_acc: 0.9165
Epoch 10/21
 - 22s - loss: 0.2388 - acc: 0.9114 - val_loss: 0.2727 - val_acc: 0.8848
Epoch 11/21
 - 21s - loss: 0.2254 - acc: 0.9171 - val_loss: 0.2295 - val_acc: 0.9148
Epoch 12/21
 - 21s - loss: 0.2138 - acc: 0.9240 - val_loss: 0.2290 - val_acc: 0.9119

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 21s - loss: 0.2061 - acc: 0.9269 - val_loss: 0.2097 - val_acc: 0.9213
Epoch 14/21
 - 21s - loss: 0.1999 - acc: 0.9306 - val_loss: 0.1742 - val_acc: 0.9379
Epoch 15/21
 - 22s - loss: 0.1961 - acc: 0.9312 - val_loss: 0.1941 - val_acc: 0.9291
Epoch 16/21
 - 22s - loss: 0.1959 - acc: 0.9331 - val_loss: 0.1906 - val_acc: 0.9303
Epoch 17/21
 - 22s - loss: 0.1888 - acc: 0.9354 - val_loss: 0.1769 - val_acc: 0.9378

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 18/21
 - 22s - loss: 0.1879 - acc: 0.9346 - val_loss: 0.1792 - val_acc: 0.9375
Epoch 00018: early stopping
Test accuracy:0.839
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   8640        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   16740       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   12420       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   20520       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 53, 12, 12)   5618        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 53, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 53, 6, 6)     212         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 53, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     14310       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 83, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 83, 6, 6)     332         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     22410       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 113, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 6, 6)    452         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 113, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 113)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            114         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 110,920
Trainable params: 109,530
Non-trainable params: 1,390
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5044 - acc: 0.7584 - val_loss: 0.4372 - val_acc: 0.7972
Epoch 2/21
 - 21s - loss: 0.4000 - acc: 0.8229 - val_loss: 0.4311 - val_acc: 0.8038
Epoch 3/21
 - 22s - loss: 0.3559 - acc: 0.8491 - val_loss: 0.3651 - val_acc: 0.8436
Epoch 4/21
 - 22s - loss: 0.3288 - acc: 0.8652 - val_loss: 0.3038 - val_acc: 0.8734
Epoch 5/21
 - 21s - loss: 0.3048 - acc: 0.8781 - val_loss: 0.2895 - val_acc: 0.8811
Epoch 6/21
 - 22s - loss: 0.2901 - acc: 0.8843 - val_loss: 0.3181 - val_acc: 0.8785
Epoch 7/21
 - 21s - loss: 0.2722 - acc: 0.8956 - val_loss: 0.2797 - val_acc: 0.8921
Epoch 8/21
 - 21s - loss: 0.2578 - acc: 0.9025 - val_loss: 0.2345 - val_acc: 0.9111
Epoch 9/21
 - 21s - loss: 0.2492 - acc: 0.9084 - val_loss: 0.2241 - val_acc: 0.9152
Epoch 10/21
 - 21s - loss: 0.2360 - acc: 0.9132 - val_loss: 0.2047 - val_acc: 0.9268
Epoch 11/21
 - 22s - loss: 0.2262 - acc: 0.9177 - val_loss: 0.2731 - val_acc: 0.8955
Epoch 12/21
 - 22s - loss: 0.2197 - acc: 0.9204 - val_loss: 0.1918 - val_acc: 0.9327
Epoch 13/21
 - 22s - loss: 0.2090 - acc: 0.9266 - val_loss: 0.2311 - val_acc: 0.9111
Epoch 14/21
 - 21s - loss: 0.2015 - acc: 0.9310 - val_loss: 0.2781 - val_acc: 0.8985
Epoch 15/21
 - 22s - loss: 0.1943 - acc: 0.9317 - val_loss: 0.2414 - val_acc: 0.9135

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/21
 - 22s - loss: 0.1832 - acc: 0.9387 - val_loss: 0.1839 - val_acc: 0.9356
Epoch 17/21
 - 21s - loss: 0.1802 - acc: 0.9389 - val_loss: 0.1896 - val_acc: 0.9315
Epoch 18/21
 - 22s - loss: 0.1767 - acc: 0.9411 - val_loss: 0.2036 - val_acc: 0.9271
Epoch 19/21
 - 22s - loss: 0.1766 - acc: 0.9414 - val_loss: 0.1839 - val_acc: 0.9365

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 20/21
 - 22s - loss: 0.1711 - acc: 0.9439 - val_loss: 0.1947 - val_acc: 0.9307
Epoch 21/21
 - 22s - loss: 0.1703 - acc: 0.9438 - val_loss: 0.1951 - val_acc: 0.9310
Test accuracy:0.878
current auc_score ------------------> 0.953
Saved model to disk
accuracies:  [0.8596774193548387, 0.8637096774193549, 0.8666666666666667, 0.8522849462365591, 0.832258064516129, 0.8565860215053763, 0.8716397849462365, 0.8446236559139785, 0.8393817204301075, 0.878494623655914]
aucs:  [0.9421, 0.9345, 0.9569, 0.9534, 0.9237, 0.9171, 0.9413, 0.9302, 0.947, 0.9532]
mean and std AUC:  0.94+/-0.013  max:   0.9569
['2-2-2', '30', '3', '64', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 24s - loss: 0.5108 - acc: 0.7647 - val_loss: 0.4383 - val_acc: 0.8030
Epoch 2/21
 - 22s - loss: 0.4065 - acc: 0.8226 - val_loss: 0.4165 - val_acc: 0.8145
Epoch 3/21
 - 22s - loss: 0.3635 - acc: 0.8507 - val_loss: 0.3485 - val_acc: 0.8581
Epoch 4/21
 - 22s - loss: 0.3295 - acc: 0.8699 - val_loss: 0.3101 - val_acc: 0.8878
Epoch 5/21
 - 22s - loss: 0.3021 - acc: 0.8846 - val_loss: 0.2996 - val_acc: 0.8891
Epoch 6/21
 - 22s - loss: 0.2799 - acc: 0.8977 - val_loss: 0.2504 - val_acc: 0.9139
Epoch 7/21
 - 22s - loss: 0.2608 - acc: 0.9075 - val_loss: 0.2374 - val_acc: 0.9216
Epoch 8/21
 - 22s - loss: 0.2454 - acc: 0.9149 - val_loss: 0.4011 - val_acc: 0.8227
Epoch 9/21
 - 22s - loss: 0.2309 - acc: 0.9214 - val_loss: 0.2119 - val_acc: 0.9291
Epoch 10/21
 - 21s - loss: 0.2176 - acc: 0.9272 - val_loss: 0.2970 - val_acc: 0.8847
Epoch 11/21
 - 22s - loss: 0.2093 - acc: 0.9299 - val_loss: 0.2150 - val_acc: 0.9252
Epoch 12/21
 - 22s - loss: 0.1988 - acc: 0.9344 - val_loss: 0.1869 - val_acc: 0.9425
Epoch 13/21
 - 22s - loss: 0.1896 - acc: 0.9391 - val_loss: 0.1866 - val_acc: 0.9381
Epoch 14/21
 - 22s - loss: 0.1809 - acc: 0.9423 - val_loss: 0.2692 - val_acc: 0.8976
Epoch 15/21
 - 22s - loss: 0.1738 - acc: 0.9463 - val_loss: 0.1605 - val_acc: 0.9523
Epoch 16/21
 - 22s - loss: 0.1672 - acc: 0.9491 - val_loss: 0.1517 - val_acc: 0.9547
Epoch 17/21
 - 22s - loss: 0.1596 - acc: 0.9522 - val_loss: 0.1878 - val_acc: 0.9383
Epoch 18/21
 - 22s - loss: 0.1540 - acc: 0.9553 - val_loss: 0.1386 - val_acc: 0.9611
Epoch 19/21
 - 22s - loss: 0.1500 - acc: 0.9561 - val_loss: 0.1500 - val_acc: 0.9543
Epoch 20/21
 - 22s - loss: 0.1435 - acc: 0.9591 - val_loss: 0.1285 - val_acc: 0.9644
Epoch 21/21
 - 22s - loss: 0.1395 - acc: 0.9611 - val_loss: 0.1385 - val_acc: 0.9597
Test accuracy:0.800
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5027 - acc: 0.7751 - val_loss: 0.4422 - val_acc: 0.8051
Epoch 2/21
 - 21s - loss: 0.4018 - acc: 0.8262 - val_loss: 0.4312 - val_acc: 0.8105
Epoch 3/21
 - 21s - loss: 0.3553 - acc: 0.8542 - val_loss: 0.3401 - val_acc: 0.8593
Epoch 4/21
 - 20s - loss: 0.3258 - acc: 0.8730 - val_loss: 0.2968 - val_acc: 0.8868
Epoch 5/21
 - 20s - loss: 0.3008 - acc: 0.8869 - val_loss: 0.3689 - val_acc: 0.8395
Epoch 6/21
 - 21s - loss: 0.2808 - acc: 0.8965 - val_loss: 0.2424 - val_acc: 0.9155
Epoch 7/21
 - 20s - loss: 0.2646 - acc: 0.9040 - val_loss: 0.2383 - val_acc: 0.9160
Epoch 8/21
 - 21s - loss: 0.2496 - acc: 0.9122 - val_loss: 0.2218 - val_acc: 0.9296
Epoch 9/21
 - 21s - loss: 0.2347 - acc: 0.9197 - val_loss: 0.2566 - val_acc: 0.9069
Epoch 10/21
 - 21s - loss: 0.2221 - acc: 0.9258 - val_loss: 0.1880 - val_acc: 0.9420
Epoch 11/21
 - 21s - loss: 0.2130 - acc: 0.9293 - val_loss: 0.2038 - val_acc: 0.9278
Epoch 12/21
 - 20s - loss: 0.2019 - acc: 0.9354 - val_loss: 0.1811 - val_acc: 0.9418
Epoch 13/21
 - 21s - loss: 0.1955 - acc: 0.9376 - val_loss: 0.2074 - val_acc: 0.9340
Epoch 14/21
 - 20s - loss: 0.1846 - acc: 0.9423 - val_loss: 0.1683 - val_acc: 0.9499
Epoch 15/21
 - 21s - loss: 0.1788 - acc: 0.9454 - val_loss: 0.1984 - val_acc: 0.9356
Epoch 16/21
 - 21s - loss: 0.1711 - acc: 0.9488 - val_loss: 0.1624 - val_acc: 0.9521
Epoch 17/21
 - 21s - loss: 0.1628 - acc: 0.9527 - val_loss: 0.1399 - val_acc: 0.9608
Epoch 18/21
 - 20s - loss: 0.1582 - acc: 0.9540 - val_loss: 0.1487 - val_acc: 0.9571
Epoch 19/21
 - 20s - loss: 0.1528 - acc: 0.9563 - val_loss: 0.1548 - val_acc: 0.9536
Epoch 20/21
 - 20s - loss: 0.1488 - acc: 0.9583 - val_loss: 0.1569 - val_acc: 0.9517

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 20s - loss: 0.1363 - acc: 0.9628 - val_loss: 0.1078 - val_acc: 0.9731
Test accuracy:0.837
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5125 - acc: 0.7574 - val_loss: 0.4730 - val_acc: 0.7839
Epoch 2/21
 - 20s - loss: 0.4082 - acc: 0.8184 - val_loss: 0.3800 - val_acc: 0.8352
Epoch 3/21
 - 20s - loss: 0.3664 - acc: 0.8473 - val_loss: 0.3342 - val_acc: 0.8648
Epoch 4/21
 - 20s - loss: 0.3350 - acc: 0.8657 - val_loss: 0.3027 - val_acc: 0.8877
Epoch 5/21
 - 20s - loss: 0.3084 - acc: 0.8806 - val_loss: 0.2770 - val_acc: 0.8986
Epoch 6/21
 - 20s - loss: 0.2864 - acc: 0.8940 - val_loss: 0.2902 - val_acc: 0.8892
Epoch 7/21
 - 21s - loss: 0.2679 - acc: 0.9040 - val_loss: 0.2302 - val_acc: 0.9173
Epoch 8/21
 - 20s - loss: 0.2486 - acc: 0.9132 - val_loss: 0.2762 - val_acc: 0.9026
Epoch 9/21
 - 20s - loss: 0.2345 - acc: 0.9192 - val_loss: 0.3145 - val_acc: 0.8798
Epoch 10/21
 - 20s - loss: 0.2220 - acc: 0.9262 - val_loss: 0.2107 - val_acc: 0.9291
Epoch 11/21
 - 20s - loss: 0.2127 - acc: 0.9299 - val_loss: 0.1950 - val_acc: 0.9347
Epoch 12/21
 - 20s - loss: 0.2011 - acc: 0.9356 - val_loss: 0.1756 - val_acc: 0.9470
Epoch 13/21
 - 20s - loss: 0.1933 - acc: 0.9392 - val_loss: 0.1776 - val_acc: 0.9445
Epoch 14/21
 - 20s - loss: 0.1844 - acc: 0.9428 - val_loss: 0.1622 - val_acc: 0.9508
Epoch 15/21
 - 20s - loss: 0.1746 - acc: 0.9470 - val_loss: 0.1506 - val_acc: 0.9577
Epoch 16/21
 - 20s - loss: 0.1690 - acc: 0.9488 - val_loss: 0.1674 - val_acc: 0.9479
Epoch 17/21
 - 21s - loss: 0.1644 - acc: 0.9507 - val_loss: 0.1336 - val_acc: 0.9645
Epoch 18/21
 - 21s - loss: 0.1592 - acc: 0.9537 - val_loss: 0.1227 - val_acc: 0.9675
Epoch 19/21
 - 20s - loss: 0.1540 - acc: 0.9560 - val_loss: 0.1174 - val_acc: 0.9728
Epoch 20/21
 - 21s - loss: 0.1491 - acc: 0.9569 - val_loss: 0.1332 - val_acc: 0.9647
Epoch 21/21
 - 21s - loss: 0.1440 - acc: 0.9583 - val_loss: 0.1177 - val_acc: 0.9700
Test accuracy:0.835
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4993 - acc: 0.7754 - val_loss: 0.4805 - val_acc: 0.7795
Epoch 2/21
 - 20s - loss: 0.4031 - acc: 0.8243 - val_loss: 0.3856 - val_acc: 0.8355
Epoch 3/21
 - 21s - loss: 0.3558 - acc: 0.8558 - val_loss: 0.3444 - val_acc: 0.8579
Epoch 4/21
 - 21s - loss: 0.3259 - acc: 0.8732 - val_loss: 0.3111 - val_acc: 0.8804
Epoch 5/21
 - 21s - loss: 0.3009 - acc: 0.8859 - val_loss: 0.2714 - val_acc: 0.9029
Epoch 6/21
 - 20s - loss: 0.2817 - acc: 0.8954 - val_loss: 0.3426 - val_acc: 0.8691
Epoch 7/21
 - 20s - loss: 0.2633 - acc: 0.9068 - val_loss: 0.2562 - val_acc: 0.9091
Epoch 8/21
 - 20s - loss: 0.2477 - acc: 0.9139 - val_loss: 0.2927 - val_acc: 0.8908
Epoch 9/21
 - 20s - loss: 0.2368 - acc: 0.9167 - val_loss: 0.2455 - val_acc: 0.9099
Epoch 10/21
 - 20s - loss: 0.2232 - acc: 0.9240 - val_loss: 0.2127 - val_acc: 0.9271
Epoch 11/21
 - 20s - loss: 0.2154 - acc: 0.9280 - val_loss: 0.2264 - val_acc: 0.9189
Epoch 12/21
 - 20s - loss: 0.2037 - acc: 0.9339 - val_loss: 0.2482 - val_acc: 0.9154
Epoch 13/21
 - 20s - loss: 0.1962 - acc: 0.9370 - val_loss: 0.1812 - val_acc: 0.9420
Epoch 14/21
 - 20s - loss: 0.1897 - acc: 0.9387 - val_loss: 0.1787 - val_acc: 0.9423
Epoch 15/21
 - 20s - loss: 0.1821 - acc: 0.9426 - val_loss: 0.1708 - val_acc: 0.9485
Epoch 16/21
 - 20s - loss: 0.1750 - acc: 0.9457 - val_loss: 0.1502 - val_acc: 0.9590
Epoch 17/21
 - 20s - loss: 0.1675 - acc: 0.9493 - val_loss: 0.2483 - val_acc: 0.9108
Epoch 18/21
 - 20s - loss: 0.1645 - acc: 0.9498 - val_loss: 0.1431 - val_acc: 0.9593
Epoch 19/21
 - 20s - loss: 0.1560 - acc: 0.9529 - val_loss: 0.1426 - val_acc: 0.9620
Epoch 20/21
 - 20s - loss: 0.1535 - acc: 0.9553 - val_loss: 0.1184 - val_acc: 0.9719
Epoch 21/21
 - 20s - loss: 0.1457 - acc: 0.9587 - val_loss: 0.1693 - val_acc: 0.9411
Test accuracy:0.849
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4943 - acc: 0.7749 - val_loss: 0.4580 - val_acc: 0.7958
Epoch 2/21
 - 21s - loss: 0.4010 - acc: 0.8259 - val_loss: 0.4018 - val_acc: 0.8252
Epoch 3/21
 - 21s - loss: 0.3569 - acc: 0.8534 - val_loss: 0.3629 - val_acc: 0.8463
Epoch 4/21
 - 21s - loss: 0.3262 - acc: 0.8733 - val_loss: 0.3119 - val_acc: 0.8776
Epoch 5/21
 - 21s - loss: 0.3020 - acc: 0.8861 - val_loss: 0.2648 - val_acc: 0.9029
Epoch 6/21
 - 21s - loss: 0.2763 - acc: 0.9001 - val_loss: 0.3349 - val_acc: 0.8763
Epoch 7/21
 - 21s - loss: 0.2607 - acc: 0.9069 - val_loss: 0.3051 - val_acc: 0.8825
Epoch 8/21
 - 20s - loss: 0.2428 - acc: 0.9150 - val_loss: 0.2455 - val_acc: 0.9119
Epoch 9/21
 - 21s - loss: 0.2285 - acc: 0.9221 - val_loss: 0.2111 - val_acc: 0.9296
Epoch 10/21
 - 21s - loss: 0.2172 - acc: 0.9273 - val_loss: 0.1978 - val_acc: 0.9354
Epoch 11/21
 - 21s - loss: 0.2089 - acc: 0.9314 - val_loss: 0.1892 - val_acc: 0.9396
Epoch 12/21
 - 21s - loss: 0.1960 - acc: 0.9373 - val_loss: 0.2196 - val_acc: 0.9276
Epoch 13/21
 - 21s - loss: 0.1880 - acc: 0.9403 - val_loss: 0.1652 - val_acc: 0.9521
Epoch 14/21
 - 20s - loss: 0.1807 - acc: 0.9433 - val_loss: 0.1541 - val_acc: 0.9518
Epoch 15/21
 - 21s - loss: 0.1725 - acc: 0.9469 - val_loss: 0.1755 - val_acc: 0.9421
Epoch 16/21
 - 20s - loss: 0.1665 - acc: 0.9506 - val_loss: 0.1395 - val_acc: 0.9612
Epoch 17/21
 - 21s - loss: 0.1617 - acc: 0.9522 - val_loss: 0.1909 - val_acc: 0.9361
Epoch 18/21
 - 21s - loss: 0.1553 - acc: 0.9547 - val_loss: 0.1329 - val_acc: 0.9613
Epoch 19/21
 - 20s - loss: 0.1471 - acc: 0.9584 - val_loss: 0.1262 - val_acc: 0.9671
Epoch 20/21
 - 20s - loss: 0.1444 - acc: 0.9593 - val_loss: 0.1122 - val_acc: 0.9740
Epoch 21/21
 - 20s - loss: 0.1377 - acc: 0.9620 - val_loss: 0.1061 - val_acc: 0.9753
Test accuracy:0.875
current auc_score ------------------> 0.951
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5078 - acc: 0.7640 - val_loss: 0.4348 - val_acc: 0.8031
Epoch 2/21
 - 20s - loss: 0.4013 - acc: 0.8275 - val_loss: 0.3921 - val_acc: 0.8333
Epoch 3/21
 - 21s - loss: 0.3594 - acc: 0.8525 - val_loss: 0.4191 - val_acc: 0.8158
Epoch 4/21
 - 21s - loss: 0.3275 - acc: 0.8707 - val_loss: 0.3279 - val_acc: 0.8709
Epoch 5/21
 - 21s - loss: 0.3027 - acc: 0.8847 - val_loss: 0.3075 - val_acc: 0.8835
Epoch 6/21
 - 20s - loss: 0.2830 - acc: 0.8940 - val_loss: 0.2464 - val_acc: 0.9147
Epoch 7/21
 - 21s - loss: 0.2666 - acc: 0.9036 - val_loss: 0.2269 - val_acc: 0.9234
Epoch 8/21
 - 21s - loss: 0.2506 - acc: 0.9111 - val_loss: 0.2264 - val_acc: 0.9196
Epoch 9/21
 - 21s - loss: 0.2385 - acc: 0.9177 - val_loss: 0.2022 - val_acc: 0.9362
Epoch 10/21
 - 21s - loss: 0.2249 - acc: 0.9251 - val_loss: 0.1942 - val_acc: 0.9388
Epoch 11/21
 - 21s - loss: 0.2147 - acc: 0.9281 - val_loss: 0.1867 - val_acc: 0.9379
Epoch 12/21
 - 21s - loss: 0.2050 - acc: 0.9322 - val_loss: 0.1842 - val_acc: 0.9419
Epoch 13/21
 - 20s - loss: 0.1960 - acc: 0.9375 - val_loss: 0.1741 - val_acc: 0.9442
Epoch 14/21
 - 21s - loss: 0.1865 - acc: 0.9416 - val_loss: 0.1855 - val_acc: 0.9399
Epoch 15/21
 - 20s - loss: 0.1813 - acc: 0.9415 - val_loss: 0.1535 - val_acc: 0.9533
Epoch 16/21
 - 20s - loss: 0.1717 - acc: 0.9479 - val_loss: 0.1536 - val_acc: 0.9509
Epoch 17/21
 - 21s - loss: 0.1680 - acc: 0.9492 - val_loss: 0.1543 - val_acc: 0.9528
Epoch 18/21
 - 21s - loss: 0.1587 - acc: 0.9531 - val_loss: 0.1231 - val_acc: 0.9690
Epoch 19/21
 - 20s - loss: 0.1559 - acc: 0.9530 - val_loss: 0.2454 - val_acc: 0.9140
Epoch 20/21
 - 20s - loss: 0.1514 - acc: 0.9556 - val_loss: 0.1300 - val_acc: 0.9639
Epoch 21/21
 - 20s - loss: 0.1446 - acc: 0.9583 - val_loss: 0.1452 - val_acc: 0.9552

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.863
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4900 - acc: 0.7733 - val_loss: 0.4036 - val_acc: 0.8198
Epoch 2/21
 - 20s - loss: 0.3902 - acc: 0.8328 - val_loss: 0.3465 - val_acc: 0.8619
Epoch 3/21
 - 20s - loss: 0.3443 - acc: 0.8585 - val_loss: 0.3340 - val_acc: 0.8627
Epoch 4/21
 - 20s - loss: 0.3193 - acc: 0.8742 - val_loss: 0.3429 - val_acc: 0.8614
Epoch 5/21
 - 20s - loss: 0.2949 - acc: 0.8883 - val_loss: 0.2827 - val_acc: 0.8914
Epoch 6/21
 - 20s - loss: 0.2737 - acc: 0.9013 - val_loss: 0.3590 - val_acc: 0.8584
Epoch 7/21
 - 20s - loss: 0.2564 - acc: 0.9076 - val_loss: 0.2438 - val_acc: 0.9149
Epoch 8/21
 - 20s - loss: 0.2392 - acc: 0.9182 - val_loss: 0.2087 - val_acc: 0.9326
Epoch 9/21
 - 20s - loss: 0.2269 - acc: 0.9229 - val_loss: 0.2157 - val_acc: 0.9293
Epoch 10/21
 - 20s - loss: 0.2148 - acc: 0.9296 - val_loss: 0.1976 - val_acc: 0.9354
Epoch 11/21
 - 20s - loss: 0.2030 - acc: 0.9346 - val_loss: 0.2334 - val_acc: 0.9159
Epoch 12/21
 - 20s - loss: 0.1961 - acc: 0.9372 - val_loss: 0.2359 - val_acc: 0.9160
Epoch 13/21
 - 20s - loss: 0.1839 - acc: 0.9424 - val_loss: 0.1774 - val_acc: 0.9424
Epoch 14/21
 - 20s - loss: 0.1780 - acc: 0.9445 - val_loss: 0.1585 - val_acc: 0.9576
Epoch 15/21
 - 20s - loss: 0.1690 - acc: 0.9490 - val_loss: 0.1449 - val_acc: 0.9600
Epoch 16/21
 - 20s - loss: 0.1634 - acc: 0.9513 - val_loss: 0.1299 - val_acc: 0.9684
Epoch 17/21
 - 21s - loss: 0.1574 - acc: 0.9539 - val_loss: 0.1229 - val_acc: 0.9677
Epoch 18/21
 - 21s - loss: 0.1496 - acc: 0.9569 - val_loss: 0.1209 - val_acc: 0.9721
Epoch 19/21
 - 21s - loss: 0.1456 - acc: 0.9586 - val_loss: 0.1518 - val_acc: 0.9529
Epoch 20/21
 - 21s - loss: 0.1405 - acc: 0.9611 - val_loss: 0.1171 - val_acc: 0.9736
Epoch 21/21
 - 21s - loss: 0.1356 - acc: 0.9619 - val_loss: 0.1212 - val_acc: 0.9690
Test accuracy:0.788
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.4956 - acc: 0.7778 - val_loss: 0.6017 - val_acc: 0.7164
Epoch 2/21
 - 20s - loss: 0.3951 - acc: 0.8305 - val_loss: 0.4414 - val_acc: 0.7948
Epoch 3/21
 - 20s - loss: 0.3541 - acc: 0.8534 - val_loss: 0.3532 - val_acc: 0.8470
Epoch 4/21
 - 20s - loss: 0.3265 - acc: 0.8715 - val_loss: 0.3225 - val_acc: 0.8662
Epoch 5/21
 - 21s - loss: 0.3020 - acc: 0.8844 - val_loss: 0.3738 - val_acc: 0.8396
Epoch 6/21
 - 21s - loss: 0.2813 - acc: 0.8959 - val_loss: 0.2544 - val_acc: 0.9105
Epoch 7/21
 - 20s - loss: 0.2603 - acc: 0.9055 - val_loss: 0.2370 - val_acc: 0.9157
Epoch 8/21
 - 21s - loss: 0.2473 - acc: 0.9132 - val_loss: 0.2302 - val_acc: 0.9185
Epoch 9/21
 - 21s - loss: 0.2343 - acc: 0.9193 - val_loss: 0.3349 - val_acc: 0.8730
Epoch 10/21
 - 21s - loss: 0.2212 - acc: 0.9245 - val_loss: 0.3280 - val_acc: 0.8658
Epoch 11/21
 - 21s - loss: 0.2120 - acc: 0.9306 - val_loss: 0.2444 - val_acc: 0.9081

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 21s - loss: 0.1982 - acc: 0.9378 - val_loss: 0.1995 - val_acc: 0.9376
Epoch 13/21
 - 21s - loss: 0.1931 - acc: 0.9394 - val_loss: 0.1953 - val_acc: 0.9386
Epoch 14/21
 - 21s - loss: 0.1884 - acc: 0.9412 - val_loss: 0.2107 - val_acc: 0.9263
Epoch 15/21
 - 20s - loss: 0.1869 - acc: 0.9421 - val_loss: 0.1871 - val_acc: 0.9404
Epoch 16/21
 - 20s - loss: 0.1842 - acc: 0.9428 - val_loss: 0.2006 - val_acc: 0.9326
Epoch 17/21
 - 21s - loss: 0.1833 - acc: 0.9431 - val_loss: 0.2026 - val_acc: 0.9301
Epoch 18/21
 - 20s - loss: 0.1782 - acc: 0.9456 - val_loss: 0.1668 - val_acc: 0.9493
Epoch 19/21
 - 20s - loss: 0.1764 - acc: 0.9459 - val_loss: 0.1544 - val_acc: 0.9571
Epoch 20/21
 - 21s - loss: 0.1727 - acc: 0.9482 - val_loss: 0.1674 - val_acc: 0.9502
Epoch 21/21
 - 20s - loss: 0.1693 - acc: 0.9498 - val_loss: 0.1856 - val_acc: 0.9384
Test accuracy:0.752
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5066 - acc: 0.7622 - val_loss: 0.4699 - val_acc: 0.7765
Epoch 2/21
 - 20s - loss: 0.4023 - acc: 0.8271 - val_loss: 0.4202 - val_acc: 0.8166
Epoch 3/21
 - 21s - loss: 0.3630 - acc: 0.8490 - val_loss: 0.3316 - val_acc: 0.8642
Epoch 4/21
 - 21s - loss: 0.3348 - acc: 0.8656 - val_loss: 0.3150 - val_acc: 0.8741
Epoch 5/21
 - 21s - loss: 0.3134 - acc: 0.8777 - val_loss: 0.3021 - val_acc: 0.8850
Epoch 6/21
 - 21s - loss: 0.2942 - acc: 0.8879 - val_loss: 0.2764 - val_acc: 0.8985
Epoch 7/21
 - 21s - loss: 0.2774 - acc: 0.8972 - val_loss: 0.2744 - val_acc: 0.9016
Epoch 8/21
 - 21s - loss: 0.2601 - acc: 0.9061 - val_loss: 0.4284 - val_acc: 0.8194
Epoch 9/21
 - 20s - loss: 0.2475 - acc: 0.9121 - val_loss: 0.2708 - val_acc: 0.8958
Epoch 10/21
 - 21s - loss: 0.2356 - acc: 0.9167 - val_loss: 0.2375 - val_acc: 0.9185
Epoch 11/21
 - 20s - loss: 0.2235 - acc: 0.9250 - val_loss: 0.2465 - val_acc: 0.9189
Epoch 12/21
 - 20s - loss: 0.2141 - acc: 0.9274 - val_loss: 0.3004 - val_acc: 0.8898
Epoch 13/21
 - 21s - loss: 0.2059 - acc: 0.9322 - val_loss: 0.2628 - val_acc: 0.9054

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/21
 - 21s - loss: 0.1867 - acc: 0.9414 - val_loss: 0.2000 - val_acc: 0.9347
Epoch 15/21
 - 20s - loss: 0.1864 - acc: 0.9418 - val_loss: 0.2223 - val_acc: 0.9177
Epoch 16/21
 - 20s - loss: 0.1810 - acc: 0.9441 - val_loss: 0.1826 - val_acc: 0.9442
Epoch 17/21
 - 20s - loss: 0.1767 - acc: 0.9460 - val_loss: 0.1624 - val_acc: 0.9565
Epoch 18/21
 - 20s - loss: 0.1765 - acc: 0.9456 - val_loss: 0.1912 - val_acc: 0.9410
Epoch 19/21
 - 21s - loss: 0.1733 - acc: 0.9476 - val_loss: 0.2379 - val_acc: 0.9120
Epoch 20/21
 - 21s - loss: 0.1693 - acc: 0.9488 - val_loss: 0.1978 - val_acc: 0.9380

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 21/21
 - 20s - loss: 0.1661 - acc: 0.9506 - val_loss: 0.1872 - val_acc: 0.9413
Epoch 00021: early stopping
Test accuracy:0.807
current auc_score ------------------> 0.940
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   17280       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   25380       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   16740       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   24840       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 122, 12, 12)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 61, 12, 12)   7442        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 61, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 61, 6, 6)     244         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 61, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     16470       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 91, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 91, 6, 6)     364         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 91, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     24570       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 121, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 121, 6, 6)    484         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 121, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 121)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            122         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 150,384
Trainable params: 148,594
Non-trainable params: 1,790
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5029 - acc: 0.7676 - val_loss: 0.4653 - val_acc: 0.7892
Epoch 2/21
 - 20s - loss: 0.3985 - acc: 0.8302 - val_loss: 0.4816 - val_acc: 0.7810
Epoch 3/21
 - 20s - loss: 0.3541 - acc: 0.8556 - val_loss: 0.3507 - val_acc: 0.8582
Epoch 4/21
 - 20s - loss: 0.3223 - acc: 0.8756 - val_loss: 0.3362 - val_acc: 0.8678
Epoch 5/21
 - 20s - loss: 0.2981 - acc: 0.8882 - val_loss: 0.2965 - val_acc: 0.8781
Epoch 6/21
 - 20s - loss: 0.2776 - acc: 0.8981 - val_loss: 0.2616 - val_acc: 0.9069
Epoch 7/21
 - 20s - loss: 0.2614 - acc: 0.9076 - val_loss: 0.2293 - val_acc: 0.9185
Epoch 8/21
 - 21s - loss: 0.2460 - acc: 0.9138 - val_loss: 0.2125 - val_acc: 0.9251
Epoch 9/21
 - 20s - loss: 0.2340 - acc: 0.9206 - val_loss: 0.2714 - val_acc: 0.9005
Epoch 10/21
 - 20s - loss: 0.2232 - acc: 0.9239 - val_loss: 0.2057 - val_acc: 0.9300
Epoch 11/21
 - 20s - loss: 0.2121 - acc: 0.9296 - val_loss: 0.2224 - val_acc: 0.9194
Epoch 12/21
 - 20s - loss: 0.2037 - acc: 0.9327 - val_loss: 0.2310 - val_acc: 0.9158
Epoch 13/21
 - 21s - loss: 0.1943 - acc: 0.9366 - val_loss: 0.1737 - val_acc: 0.9440
Epoch 14/21
 - 20s - loss: 0.1856 - acc: 0.9412 - val_loss: 0.2430 - val_acc: 0.9135
Epoch 15/21
 - 20s - loss: 0.1787 - acc: 0.9456 - val_loss: 0.1599 - val_acc: 0.9501
Epoch 16/21
 - 20s - loss: 0.1719 - acc: 0.9479 - val_loss: 0.1644 - val_acc: 0.9485
Epoch 17/21
 - 21s - loss: 0.1665 - acc: 0.9498 - val_loss: 0.1555 - val_acc: 0.9526
Epoch 18/21
 - 21s - loss: 0.1591 - acc: 0.9534 - val_loss: 0.1327 - val_acc: 0.9636
Epoch 19/21
 - 21s - loss: 0.1555 - acc: 0.9545 - val_loss: 0.1626 - val_acc: 0.9477
Epoch 20/21
 - 20s - loss: 0.1512 - acc: 0.9568 - val_loss: 0.1627 - val_acc: 0.9498
Epoch 21/21
 - 21s - loss: 0.1439 - acc: 0.9594 - val_loss: 0.1479 - val_acc: 0.9548

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.792
current auc_score ------------------> 0.890
accuracies:  [0.8001344086021506, 0.837231182795699, 0.8348118279569893, 0.8489247311827957, 0.875, 0.8627688172043011, 0.7883064516129032, 0.7520161290322581, 0.8065860215053764, 0.7922043010752688]
aucs:  [0.9046, 0.9134, 0.934, 0.9441, 0.9506, 0.9452, 0.9197, 0.9348, 0.9401, 0.8899]
mean and std AUC:  0.928+/-0.019  max:   0.9506
['2-2-2', '18', '3', '8', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 22s - loss: 0.5502 - acc: 0.7206 - val_loss: 0.9055 - val_acc: 0.5959
Epoch 2/21
 - 20s - loss: 0.4479 - acc: 0.7829 - val_loss: 0.7474 - val_acc: 0.6788
Epoch 3/21
 - 20s - loss: 0.4168 - acc: 0.8007 - val_loss: 0.7290 - val_acc: 0.6723
Epoch 4/21
 - 20s - loss: 0.3970 - acc: 0.8110 - val_loss: 0.5587 - val_acc: 0.7556
Epoch 5/21
 - 20s - loss: 0.3832 - acc: 0.8207 - val_loss: 0.5272 - val_acc: 0.7669
Epoch 6/21
 - 20s - loss: 0.3687 - acc: 0.8268 - val_loss: 0.4886 - val_acc: 0.7785
Epoch 7/21
 - 20s - loss: 0.3568 - acc: 0.8351 - val_loss: 0.4607 - val_acc: 0.7879
Epoch 8/21
 - 20s - loss: 0.3462 - acc: 0.8440 - val_loss: 0.4487 - val_acc: 0.7922
Epoch 9/21
 - 20s - loss: 0.3369 - acc: 0.8505 - val_loss: 0.3618 - val_acc: 0.8366
Epoch 10/21
 - 20s - loss: 0.3263 - acc: 0.8542 - val_loss: 0.3566 - val_acc: 0.8405
Epoch 11/21
 - 20s - loss: 0.3203 - acc: 0.8580 - val_loss: 0.3189 - val_acc: 0.8611
Epoch 12/21
 - 20s - loss: 0.3083 - acc: 0.8681 - val_loss: 0.3270 - val_acc: 0.8568
Epoch 13/21
 - 20s - loss: 0.3003 - acc: 0.8709 - val_loss: 0.2713 - val_acc: 0.8844
Epoch 14/21
 - 20s - loss: 0.2919 - acc: 0.8742 - val_loss: 0.2688 - val_acc: 0.8869
Epoch 15/21
 - 20s - loss: 0.2858 - acc: 0.8790 - val_loss: 0.2606 - val_acc: 0.8907
Epoch 16/21
 - 20s - loss: 0.2792 - acc: 0.8843 - val_loss: 0.2575 - val_acc: 0.8966
Epoch 17/21
 - 20s - loss: 0.2687 - acc: 0.8894 - val_loss: 0.2351 - val_acc: 0.9075
Epoch 18/21
 - 20s - loss: 0.2679 - acc: 0.8896 - val_loss: 0.2361 - val_acc: 0.9052
Epoch 19/21
 - 20s - loss: 0.2618 - acc: 0.8945 - val_loss: 0.2398 - val_acc: 0.9019
Epoch 20/21
 - 20s - loss: 0.2547 - acc: 0.8958 - val_loss: 0.2183 - val_acc: 0.9147
Epoch 21/21
 - 20s - loss: 0.2522 - acc: 0.8976 - val_loss: 0.2199 - val_acc: 0.9137
Test accuracy:0.858
current auc_score ------------------> 0.954
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5424 - acc: 0.7342 - val_loss: 0.6484 - val_acc: 0.6862
Epoch 2/21
 - 22s - loss: 0.4431 - acc: 0.7867 - val_loss: 0.4289 - val_acc: 0.7884
Epoch 3/21
 - 21s - loss: 0.4118 - acc: 0.8058 - val_loss: 0.4002 - val_acc: 0.8075
Epoch 4/21
 - 21s - loss: 0.3885 - acc: 0.8186 - val_loss: 0.4196 - val_acc: 0.8017
Epoch 5/21
 - 21s - loss: 0.3734 - acc: 0.8274 - val_loss: 0.3739 - val_acc: 0.8287
Epoch 6/21
 - 21s - loss: 0.3552 - acc: 0.8399 - val_loss: 0.3505 - val_acc: 0.8435
Epoch 7/21
 - 22s - loss: 0.3405 - acc: 0.8507 - val_loss: 0.3485 - val_acc: 0.8481
Epoch 8/21
 - 22s - loss: 0.3278 - acc: 0.8589 - val_loss: 0.3067 - val_acc: 0.8655
Epoch 9/21
 - 22s - loss: 0.3160 - acc: 0.8657 - val_loss: 0.2807 - val_acc: 0.8828
Epoch 10/21
 - 21s - loss: 0.3068 - acc: 0.8709 - val_loss: 0.3169 - val_acc: 0.8660
Epoch 11/21
 - 21s - loss: 0.2964 - acc: 0.8747 - val_loss: 0.2821 - val_acc: 0.8786
Epoch 12/21
 - 21s - loss: 0.2872 - acc: 0.8808 - val_loss: 0.2861 - val_acc: 0.8785

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 22s - loss: 0.2764 - acc: 0.8870 - val_loss: 0.2715 - val_acc: 0.8805
Epoch 00013: early stopping
Test accuracy:0.860
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5394 - acc: 0.7341 - val_loss: 0.4751 - val_acc: 0.7693
Epoch 2/21
 - 22s - loss: 0.4464 - acc: 0.7854 - val_loss: 0.4429 - val_acc: 0.7844
Epoch 3/21
 - 21s - loss: 0.4175 - acc: 0.8015 - val_loss: 0.4355 - val_acc: 0.7890
Epoch 4/21
 - 22s - loss: 0.3915 - acc: 0.8167 - val_loss: 0.3641 - val_acc: 0.8384
Epoch 5/21
 - 22s - loss: 0.3692 - acc: 0.8306 - val_loss: 0.3611 - val_acc: 0.8410
Epoch 6/21
 - 21s - loss: 0.3514 - acc: 0.8439 - val_loss: 0.3224 - val_acc: 0.8617
Epoch 7/21
 - 21s - loss: 0.3346 - acc: 0.8524 - val_loss: 0.3185 - val_acc: 0.8650
Epoch 8/21
 - 21s - loss: 0.3254 - acc: 0.8584 - val_loss: 0.3049 - val_acc: 0.8707
Epoch 9/21
 - 21s - loss: 0.3123 - acc: 0.8638 - val_loss: 0.2901 - val_acc: 0.8780
Epoch 10/21
 - 21s - loss: 0.3021 - acc: 0.8705 - val_loss: 0.3213 - val_acc: 0.8645
Epoch 11/21
 - 22s - loss: 0.2940 - acc: 0.8758 - val_loss: 0.2696 - val_acc: 0.8933
Epoch 12/21
 - 22s - loss: 0.2869 - acc: 0.8803 - val_loss: 0.2756 - val_acc: 0.8886
Epoch 13/21
 - 22s - loss: 0.2789 - acc: 0.8843 - val_loss: 0.2710 - val_acc: 0.8893
Epoch 14/21
 - 21s - loss: 0.2747 - acc: 0.8873 - val_loss: 0.2504 - val_acc: 0.9006
Epoch 15/21
 - 21s - loss: 0.2661 - acc: 0.8917 - val_loss: 0.2413 - val_acc: 0.9060
Epoch 16/21
 - 21s - loss: 0.2601 - acc: 0.8937 - val_loss: 0.2503 - val_acc: 0.8986
Epoch 17/21
 - 21s - loss: 0.2552 - acc: 0.8980 - val_loss: 0.2299 - val_acc: 0.9110
Epoch 18/21
 - 21s - loss: 0.2483 - acc: 0.9002 - val_loss: 0.2223 - val_acc: 0.9113
Epoch 19/21
 - 21s - loss: 0.2442 - acc: 0.9021 - val_loss: 0.2144 - val_acc: 0.9180
Epoch 20/21
 - 21s - loss: 0.2388 - acc: 0.9046 - val_loss: 0.2180 - val_acc: 0.9192
Epoch 21/21
 - 21s - loss: 0.2349 - acc: 0.9086 - val_loss: 0.2131 - val_acc: 0.9172
Test accuracy:0.859
current auc_score ------------------> 0.955
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5461 - acc: 0.7383 - val_loss: 0.4841 - val_acc: 0.7692
Epoch 2/21
 - 21s - loss: 0.4572 - acc: 0.7811 - val_loss: 0.4357 - val_acc: 0.7858
Epoch 3/21
 - 21s - loss: 0.4269 - acc: 0.7938 - val_loss: 0.4171 - val_acc: 0.7952
Epoch 4/21
 - 21s - loss: 0.4037 - acc: 0.8057 - val_loss: 0.4220 - val_acc: 0.7897
Epoch 5/21
 - 21s - loss: 0.3857 - acc: 0.8159 - val_loss: 0.3675 - val_acc: 0.8269
Epoch 6/21
 - 21s - loss: 0.3713 - acc: 0.8267 - val_loss: 0.3477 - val_acc: 0.8375
Epoch 7/21
 - 21s - loss: 0.3557 - acc: 0.8368 - val_loss: 0.3409 - val_acc: 0.8440
Epoch 8/21
 - 21s - loss: 0.3454 - acc: 0.8429 - val_loss: 0.3179 - val_acc: 0.8601
Epoch 9/21
 - 22s - loss: 0.3338 - acc: 0.8507 - val_loss: 0.3169 - val_acc: 0.8638
Epoch 10/21
 - 22s - loss: 0.3253 - acc: 0.8545 - val_loss: 0.2987 - val_acc: 0.8729
Epoch 11/21
 - 21s - loss: 0.3139 - acc: 0.8608 - val_loss: 0.2827 - val_acc: 0.8809
Epoch 12/21
 - 21s - loss: 0.3043 - acc: 0.8667 - val_loss: 0.2950 - val_acc: 0.8704
Epoch 13/21
 - 21s - loss: 0.2994 - acc: 0.8706 - val_loss: 0.2766 - val_acc: 0.8835
Epoch 14/21
 - 22s - loss: 0.2933 - acc: 0.8748 - val_loss: 0.2646 - val_acc: 0.8881
Epoch 15/21
 - 22s - loss: 0.2859 - acc: 0.8773 - val_loss: 0.2501 - val_acc: 0.8968
Epoch 16/21
 - 22s - loss: 0.2783 - acc: 0.8818 - val_loss: 0.2477 - val_acc: 0.8980
Epoch 17/21
 - 22s - loss: 0.2757 - acc: 0.8827 - val_loss: 0.2564 - val_acc: 0.8926
Epoch 18/21
 - 22s - loss: 0.2704 - acc: 0.8877 - val_loss: 0.2349 - val_acc: 0.9073
Epoch 19/21
 - 22s - loss: 0.2603 - acc: 0.8921 - val_loss: 0.2353 - val_acc: 0.9068
Epoch 20/21
 - 22s - loss: 0.2559 - acc: 0.8952 - val_loss: 0.2248 - val_acc: 0.9121
Epoch 21/21
 - 22s - loss: 0.2490 - acc: 0.8994 - val_loss: 0.2240 - val_acc: 0.9130
Test accuracy:0.854
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5327 - acc: 0.7455 - val_loss: 0.4866 - val_acc: 0.7533
Epoch 2/21
 - 21s - loss: 0.4563 - acc: 0.7804 - val_loss: 0.4867 - val_acc: 0.7501
Epoch 3/21
 - 21s - loss: 0.4232 - acc: 0.7946 - val_loss: 0.4484 - val_acc: 0.7780
Epoch 4/21
 - 21s - loss: 0.3991 - acc: 0.8089 - val_loss: 0.4821 - val_acc: 0.7560
Epoch 5/21
 - 21s - loss: 0.3793 - acc: 0.8219 - val_loss: 0.4247 - val_acc: 0.7953
Epoch 6/21
 - 21s - loss: 0.3629 - acc: 0.8331 - val_loss: 0.3707 - val_acc: 0.8269
Epoch 7/21
 - 21s - loss: 0.3511 - acc: 0.8403 - val_loss: 0.3889 - val_acc: 0.8151
Epoch 8/21
 - 21s - loss: 0.3378 - acc: 0.8493 - val_loss: 0.3774 - val_acc: 0.8186
Epoch 9/21
 - 21s - loss: 0.3291 - acc: 0.8542 - val_loss: 0.3202 - val_acc: 0.8550
Epoch 10/21
 - 21s - loss: 0.3187 - acc: 0.8599 - val_loss: 0.3227 - val_acc: 0.8559
Epoch 11/21
 - 21s - loss: 0.3099 - acc: 0.8646 - val_loss: 0.3196 - val_acc: 0.8589
Epoch 12/21
 - 21s - loss: 0.3015 - acc: 0.8704 - val_loss: 0.3136 - val_acc: 0.8591
Epoch 13/21
 - 21s - loss: 0.2957 - acc: 0.8744 - val_loss: 0.3223 - val_acc: 0.8538
Epoch 14/21
 - 21s - loss: 0.2891 - acc: 0.8780 - val_loss: 0.3405 - val_acc: 0.8439
Epoch 15/21
 - 21s - loss: 0.2799 - acc: 0.8806 - val_loss: 0.3117 - val_acc: 0.8597
Epoch 16/21
 - 21s - loss: 0.2752 - acc: 0.8853 - val_loss: 0.2632 - val_acc: 0.8892
Epoch 17/21
 - 21s - loss: 0.2707 - acc: 0.8882 - val_loss: 0.2992 - val_acc: 0.8648
Epoch 18/21
 - 21s - loss: 0.2636 - acc: 0.8920 - val_loss: 0.3134 - val_acc: 0.8623
Epoch 19/21
 - 21s - loss: 0.2587 - acc: 0.8942 - val_loss: 0.2657 - val_acc: 0.8882

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 21s - loss: 0.2559 - acc: 0.8969 - val_loss: 0.2582 - val_acc: 0.8921
Epoch 21/21
 - 21s - loss: 0.2513 - acc: 0.8991 - val_loss: 0.2467 - val_acc: 0.8981
Test accuracy:0.818
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5399 - acc: 0.7295 - val_loss: 0.5155 - val_acc: 0.7385
Epoch 2/21
 - 21s - loss: 0.4421 - acc: 0.7859 - val_loss: 0.5172 - val_acc: 0.7462
Epoch 3/21
 - 22s - loss: 0.4125 - acc: 0.7996 - val_loss: 0.4592 - val_acc: 0.7769
Epoch 4/21
 - 21s - loss: 0.3944 - acc: 0.8107 - val_loss: 0.4055 - val_acc: 0.8060
Epoch 5/21
 - 21s - loss: 0.3761 - acc: 0.8254 - val_loss: 0.4257 - val_acc: 0.7946
Epoch 6/21
 - 21s - loss: 0.3618 - acc: 0.8336 - val_loss: 0.3583 - val_acc: 0.8426
Epoch 7/21
 - 21s - loss: 0.3502 - acc: 0.8409 - val_loss: 0.3733 - val_acc: 0.8261
Epoch 8/21
 - 21s - loss: 0.3379 - acc: 0.8487 - val_loss: 0.3268 - val_acc: 0.8560
Epoch 9/21
 - 21s - loss: 0.3267 - acc: 0.8572 - val_loss: 0.3520 - val_acc: 0.8431
Epoch 10/21
 - 21s - loss: 0.3174 - acc: 0.8622 - val_loss: 0.3262 - val_acc: 0.8578
Epoch 11/21
 - 21s - loss: 0.3086 - acc: 0.8677 - val_loss: 0.3088 - val_acc: 0.8685
Epoch 12/21
 - 21s - loss: 0.2998 - acc: 0.8727 - val_loss: 0.3190 - val_acc: 0.8606
Epoch 13/21
 - 21s - loss: 0.2925 - acc: 0.8770 - val_loss: 0.3577 - val_acc: 0.8488
Epoch 14/21
 - 21s - loss: 0.2828 - acc: 0.8816 - val_loss: 0.3297 - val_acc: 0.8599

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 21s - loss: 0.2761 - acc: 0.8861 - val_loss: 0.3168 - val_acc: 0.8657
Epoch 00015: early stopping
Test accuracy:0.835
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5283 - acc: 0.7472 - val_loss: 0.4546 - val_acc: 0.7781
Epoch 2/21
 - 21s - loss: 0.4403 - acc: 0.7867 - val_loss: 0.4126 - val_acc: 0.7968
Epoch 3/21
 - 21s - loss: 0.4049 - acc: 0.8057 - val_loss: 0.3944 - val_acc: 0.8067
Epoch 4/21
 - 21s - loss: 0.3839 - acc: 0.8178 - val_loss: 0.3735 - val_acc: 0.8179
Epoch 5/21
 - 21s - loss: 0.3652 - acc: 0.8283 - val_loss: 0.3515 - val_acc: 0.8379
Epoch 6/21
 - 21s - loss: 0.3522 - acc: 0.8390 - val_loss: 0.3574 - val_acc: 0.8330
Epoch 7/21
 - 21s - loss: 0.3396 - acc: 0.8457 - val_loss: 0.3210 - val_acc: 0.8547
Epoch 8/21
 - 22s - loss: 0.3283 - acc: 0.8548 - val_loss: 0.3211 - val_acc: 0.8581
Epoch 9/21
 - 21s - loss: 0.3165 - acc: 0.8622 - val_loss: 0.3257 - val_acc: 0.8555
Epoch 10/21
 - 21s - loss: 0.3087 - acc: 0.8653 - val_loss: 0.2917 - val_acc: 0.8700
Epoch 11/21
 - 21s - loss: 0.2997 - acc: 0.8707 - val_loss: 0.2793 - val_acc: 0.8794
Epoch 12/21
 - 21s - loss: 0.2945 - acc: 0.8759 - val_loss: 0.2740 - val_acc: 0.8818
Epoch 13/21
 - 21s - loss: 0.2874 - acc: 0.8784 - val_loss: 0.2587 - val_acc: 0.8926
Epoch 14/21
 - 21s - loss: 0.2792 - acc: 0.8819 - val_loss: 0.2520 - val_acc: 0.8914
Epoch 15/21
 - 21s - loss: 0.2720 - acc: 0.8862 - val_loss: 0.2680 - val_acc: 0.8877
Epoch 16/21
 - 22s - loss: 0.2642 - acc: 0.8911 - val_loss: 0.2748 - val_acc: 0.8830
Epoch 17/21
 - 21s - loss: 0.2604 - acc: 0.8940 - val_loss: 0.2472 - val_acc: 0.8985
Epoch 18/21
 - 21s - loss: 0.2549 - acc: 0.8967 - val_loss: 0.2608 - val_acc: 0.8926
Epoch 19/21
 - 21s - loss: 0.2495 - acc: 0.8985 - val_loss: 0.2473 - val_acc: 0.8982
Epoch 20/21
 - 21s - loss: 0.2435 - acc: 0.9025 - val_loss: 0.2369 - val_acc: 0.9049
Epoch 21/21
 - 21s - loss: 0.2388 - acc: 0.9041 - val_loss: 0.2298 - val_acc: 0.9055
Test accuracy:0.872
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5208 - acc: 0.7500 - val_loss: 0.4771 - val_acc: 0.7590
Epoch 2/21
 - 21s - loss: 0.4511 - acc: 0.7773 - val_loss: 0.4658 - val_acc: 0.7760
Epoch 3/21
 - 21s - loss: 0.4220 - acc: 0.7928 - val_loss: 0.4740 - val_acc: 0.7716
Epoch 4/21
 - 21s - loss: 0.3997 - acc: 0.8061 - val_loss: 0.4448 - val_acc: 0.7865
Epoch 5/21
 - 21s - loss: 0.3830 - acc: 0.8169 - val_loss: 0.4666 - val_acc: 0.7706
Epoch 6/21
 - 22s - loss: 0.3675 - acc: 0.8274 - val_loss: 0.3750 - val_acc: 0.8230
Epoch 7/21
 - 22s - loss: 0.3542 - acc: 0.8364 - val_loss: 0.4022 - val_acc: 0.8166
Epoch 8/21
 - 21s - loss: 0.3407 - acc: 0.8459 - val_loss: 0.3518 - val_acc: 0.8373
Epoch 9/21
 - 22s - loss: 0.3328 - acc: 0.8503 - val_loss: 0.4522 - val_acc: 0.7805
Epoch 10/21
 - 22s - loss: 0.3212 - acc: 0.8576 - val_loss: 0.3429 - val_acc: 0.8427
Epoch 11/21
 - 21s - loss: 0.3140 - acc: 0.8612 - val_loss: 0.4100 - val_acc: 0.8028
Epoch 12/21
 - 21s - loss: 0.3035 - acc: 0.8681 - val_loss: 0.3367 - val_acc: 0.8438
Epoch 13/21
 - 21s - loss: 0.2974 - acc: 0.8732 - val_loss: 0.3609 - val_acc: 0.8306
Epoch 14/21
 - 21s - loss: 0.2914 - acc: 0.8751 - val_loss: 0.3364 - val_acc: 0.8459
Epoch 15/21
 - 21s - loss: 0.2835 - acc: 0.8802 - val_loss: 0.3365 - val_acc: 0.8470
Epoch 16/21
 - 21s - loss: 0.2767 - acc: 0.8826 - val_loss: 0.2574 - val_acc: 0.8899
Epoch 17/21
 - 21s - loss: 0.2695 - acc: 0.8859 - val_loss: 0.3240 - val_acc: 0.8519
Epoch 18/21
 - 21s - loss: 0.2643 - acc: 0.8917 - val_loss: 0.2523 - val_acc: 0.8921
Epoch 19/21
 - 21s - loss: 0.2586 - acc: 0.8946 - val_loss: 0.2818 - val_acc: 0.8780
Epoch 20/21
 - 21s - loss: 0.2536 - acc: 0.8975 - val_loss: 0.2551 - val_acc: 0.8918
Epoch 21/21
 - 21s - loss: 0.2483 - acc: 0.9006 - val_loss: 0.2700 - val_acc: 0.8822

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.810
current auc_score ------------------> 0.940
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5501 - acc: 0.7284 - val_loss: 0.4758 - val_acc: 0.7676
Epoch 2/21
 - 21s - loss: 0.4480 - acc: 0.7873 - val_loss: 0.4397 - val_acc: 0.7791
Epoch 3/21
 - 21s - loss: 0.4125 - acc: 0.8053 - val_loss: 0.3916 - val_acc: 0.8213
Epoch 4/21
 - 21s - loss: 0.3912 - acc: 0.8173 - val_loss: 0.3722 - val_acc: 0.8327
Epoch 5/21
 - 21s - loss: 0.3730 - acc: 0.8293 - val_loss: 0.3368 - val_acc: 0.8471
Epoch 6/21
 - 22s - loss: 0.3550 - acc: 0.8388 - val_loss: 0.3307 - val_acc: 0.8569
Epoch 7/21
 - 21s - loss: 0.3421 - acc: 0.8483 - val_loss: 0.3050 - val_acc: 0.8642
Epoch 8/21
 - 21s - loss: 0.3299 - acc: 0.8547 - val_loss: 0.3056 - val_acc: 0.8632
Epoch 9/21
 - 21s - loss: 0.3176 - acc: 0.8605 - val_loss: 0.2902 - val_acc: 0.8766
Epoch 10/21
 - 21s - loss: 0.3110 - acc: 0.8659 - val_loss: 0.2762 - val_acc: 0.8827
Epoch 11/21
 - 21s - loss: 0.3044 - acc: 0.8707 - val_loss: 0.2731 - val_acc: 0.8828
Epoch 12/21
 - 21s - loss: 0.2947 - acc: 0.8737 - val_loss: 0.2533 - val_acc: 0.8951
Epoch 13/21
 - 21s - loss: 0.2878 - acc: 0.8790 - val_loss: 0.2540 - val_acc: 0.8922
Epoch 14/21
 - 21s - loss: 0.2800 - acc: 0.8827 - val_loss: 0.2393 - val_acc: 0.9017
Epoch 15/21
 - 21s - loss: 0.2731 - acc: 0.8869 - val_loss: 0.2382 - val_acc: 0.9022
Epoch 16/21
 - 21s - loss: 0.2689 - acc: 0.8887 - val_loss: 0.2280 - val_acc: 0.9089
Epoch 17/21
 - 21s - loss: 0.2641 - acc: 0.8923 - val_loss: 0.2383 - val_acc: 0.9021
Epoch 18/21
 - 21s - loss: 0.2585 - acc: 0.8938 - val_loss: 0.2168 - val_acc: 0.9124
Epoch 19/21
 - 21s - loss: 0.2535 - acc: 0.8961 - val_loss: 0.2205 - val_acc: 0.9119
Epoch 20/21
 - 21s - loss: 0.2472 - acc: 0.9005 - val_loss: 0.2211 - val_acc: 0.9128
Epoch 21/21
 - 21s - loss: 0.2433 - acc: 0.9014 - val_loss: 0.2110 - val_acc: 0.9187
Test accuracy:0.881
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   1296        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   4212        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   3564        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   6480        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 58, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 29, 12, 12)   1682        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 29, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 29, 6, 6)     116         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 29, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     4698        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 47, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 47, 6, 6)     188         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 47, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7614        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 65, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 65, 6, 6)     260         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 65, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 65)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            66          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 32,752
Trainable params: 32,058
Non-trainable params: 694
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5558 - acc: 0.7188 - val_loss: 0.4850 - val_acc: 0.7626
Epoch 2/21
 - 21s - loss: 0.4521 - acc: 0.7853 - val_loss: 0.4558 - val_acc: 0.7841
Epoch 3/21
 - 21s - loss: 0.4170 - acc: 0.8008 - val_loss: 0.4023 - val_acc: 0.8046
Epoch 4/21
 - 21s - loss: 0.3907 - acc: 0.8161 - val_loss: 0.3663 - val_acc: 0.8296
Epoch 5/21
 - 21s - loss: 0.3726 - acc: 0.8259 - val_loss: 0.3792 - val_acc: 0.8217
Epoch 6/21
 - 21s - loss: 0.3542 - acc: 0.8384 - val_loss: 0.3574 - val_acc: 0.8304
Epoch 7/21
 - 21s - loss: 0.3427 - acc: 0.8460 - val_loss: 0.3605 - val_acc: 0.8315
Epoch 8/21
 - 21s - loss: 0.3313 - acc: 0.8529 - val_loss: 0.3351 - val_acc: 0.8463
Epoch 9/21
 - 21s - loss: 0.3229 - acc: 0.8581 - val_loss: 0.3172 - val_acc: 0.8606
Epoch 10/21
 - 21s - loss: 0.3138 - acc: 0.8629 - val_loss: 0.2987 - val_acc: 0.8695
Epoch 11/21
 - 21s - loss: 0.3047 - acc: 0.8683 - val_loss: 0.2703 - val_acc: 0.8898
Epoch 12/21
 - 22s - loss: 0.2954 - acc: 0.8726 - val_loss: 0.2823 - val_acc: 0.8764
Epoch 13/21
 - 21s - loss: 0.2869 - acc: 0.8796 - val_loss: 0.2571 - val_acc: 0.8973
Epoch 14/21
 - 22s - loss: 0.2813 - acc: 0.8809 - val_loss: 0.2593 - val_acc: 0.8951
Epoch 15/21
 - 22s - loss: 0.2777 - acc: 0.8838 - val_loss: 0.2426 - val_acc: 0.9068
Epoch 16/21
 - 21s - loss: 0.2689 - acc: 0.8891 - val_loss: 0.2625 - val_acc: 0.8886
Epoch 17/21
 - 21s - loss: 0.2650 - acc: 0.8912 - val_loss: 0.2271 - val_acc: 0.9137
Epoch 18/21
 - 22s - loss: 0.2605 - acc: 0.8926 - val_loss: 0.2519 - val_acc: 0.8975
Epoch 19/21
 - 22s - loss: 0.2569 - acc: 0.8955 - val_loss: 0.2560 - val_acc: 0.8966
Epoch 20/21
 - 22s - loss: 0.2496 - acc: 0.8987 - val_loss: 0.2225 - val_acc: 0.9148
Epoch 21/21
 - 21s - loss: 0.2462 - acc: 0.9014 - val_loss: 0.2108 - val_acc: 0.9202
Test accuracy:0.849
current auc_score ------------------> 0.932
accuracies:  [0.8584677419354839, 0.8595430107526881, 0.858736559139785, 0.8541666666666666, 0.8181451612903226, 0.8350806451612903, 0.871505376344086, 0.8098118279569892, 0.8814516129032258, 0.8493279569892473]
aucs:  [0.9544, 0.9446, 0.9553, 0.9462, 0.9144, 0.9195, 0.9491, 0.9398, 0.9488, 0.9324]
mean and std AUC:  0.94+/-0.013  max:   0.9553
['2-2-2', '18', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5382 - acc: 0.7343 - val_loss: 0.4805 - val_acc: 0.7644
Epoch 2/21
 - 21s - loss: 0.4393 - acc: 0.7893 - val_loss: 0.4252 - val_acc: 0.7979
Epoch 3/21
 - 21s - loss: 0.4089 - acc: 0.8079 - val_loss: 0.3909 - val_acc: 0.8126
Epoch 4/21
 - 21s - loss: 0.3854 - acc: 0.8222 - val_loss: 0.3696 - val_acc: 0.8249
Epoch 5/21
 - 21s - loss: 0.3667 - acc: 0.8328 - val_loss: 0.3445 - val_acc: 0.8449
Epoch 6/21
 - 21s - loss: 0.3509 - acc: 0.8434 - val_loss: 0.3442 - val_acc: 0.8471
Epoch 7/21
 - 22s - loss: 0.3380 - acc: 0.8509 - val_loss: 0.3324 - val_acc: 0.8486
Epoch 8/21
 - 21s - loss: 0.3275 - acc: 0.8561 - val_loss: 0.3148 - val_acc: 0.8562
Epoch 9/21
 - 22s - loss: 0.3145 - acc: 0.8638 - val_loss: 0.2967 - val_acc: 0.8721
Epoch 10/21
 - 22s - loss: 0.3046 - acc: 0.8694 - val_loss: 0.2835 - val_acc: 0.8795
Epoch 11/21
 - 22s - loss: 0.2951 - acc: 0.8741 - val_loss: 0.2716 - val_acc: 0.8854
Epoch 12/21
 - 22s - loss: 0.2892 - acc: 0.8774 - val_loss: 0.2952 - val_acc: 0.8665
Epoch 13/21
 - 22s - loss: 0.2809 - acc: 0.8821 - val_loss: 0.2554 - val_acc: 0.8952
Epoch 14/21
 - 22s - loss: 0.2734 - acc: 0.8864 - val_loss: 0.2592 - val_acc: 0.8904
Epoch 15/21
 - 22s - loss: 0.2670 - acc: 0.8880 - val_loss: 0.2275 - val_acc: 0.9096
Epoch 16/21
 - 22s - loss: 0.2598 - acc: 0.8918 - val_loss: 0.2840 - val_acc: 0.8739
Epoch 17/21
 - 21s - loss: 0.2542 - acc: 0.8970 - val_loss: 0.2265 - val_acc: 0.9114
Epoch 18/21
 - 21s - loss: 0.2484 - acc: 0.8988 - val_loss: 0.2213 - val_acc: 0.9130
Epoch 19/21
 - 21s - loss: 0.2433 - acc: 0.9018 - val_loss: 0.2336 - val_acc: 0.9074
Epoch 20/21
 - 21s - loss: 0.2360 - acc: 0.9043 - val_loss: 0.2062 - val_acc: 0.9223
Epoch 21/21
 - 21s - loss: 0.2334 - acc: 0.9077 - val_loss: 0.2049 - val_acc: 0.9253
Test accuracy:0.866
current auc_score ------------------> 0.937
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5377 - acc: 0.7304 - val_loss: 0.4784 - val_acc: 0.7647
Epoch 2/21
 - 21s - loss: 0.4466 - acc: 0.7796 - val_loss: 0.4827 - val_acc: 0.7558
Epoch 3/21
 - 21s - loss: 0.4143 - acc: 0.7985 - val_loss: 0.6397 - val_acc: 0.6909
Epoch 4/21
 - 22s - loss: 0.3905 - acc: 0.8146 - val_loss: 0.4528 - val_acc: 0.7715
Epoch 5/21
 - 21s - loss: 0.3728 - acc: 0.8278 - val_loss: 0.4154 - val_acc: 0.7968
Epoch 6/21
 - 21s - loss: 0.3538 - acc: 0.8376 - val_loss: 0.3780 - val_acc: 0.8219
Epoch 7/21
 - 22s - loss: 0.3418 - acc: 0.8480 - val_loss: 0.3813 - val_acc: 0.8197
Epoch 8/21
 - 22s - loss: 0.3299 - acc: 0.8548 - val_loss: 0.3528 - val_acc: 0.8471
Epoch 9/21
 - 21s - loss: 0.3182 - acc: 0.8606 - val_loss: 0.3107 - val_acc: 0.8672
Epoch 10/21
 - 21s - loss: 0.3065 - acc: 0.8689 - val_loss: 0.3062 - val_acc: 0.8715
Epoch 11/21
 - 22s - loss: 0.3004 - acc: 0.8731 - val_loss: 0.3279 - val_acc: 0.8559
Epoch 12/21
 - 22s - loss: 0.2906 - acc: 0.8787 - val_loss: 0.3632 - val_acc: 0.8385
Epoch 13/21
 - 22s - loss: 0.2824 - acc: 0.8817 - val_loss: 0.3233 - val_acc: 0.8564

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/21
 - 21s - loss: 0.2728 - acc: 0.8858 - val_loss: 0.2848 - val_acc: 0.8806
Epoch 15/21
 - 21s - loss: 0.2712 - acc: 0.8882 - val_loss: 0.2839 - val_acc: 0.8796
Epoch 16/21
 - 21s - loss: 0.2679 - acc: 0.8894 - val_loss: 0.2860 - val_acc: 0.8798
Epoch 17/21
 - 22s - loss: 0.2652 - acc: 0.8923 - val_loss: 0.2915 - val_acc: 0.8731
Epoch 18/21
 - 22s - loss: 0.2646 - acc: 0.8918 - val_loss: 0.2839 - val_acc: 0.8794

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 00018: early stopping
Test accuracy:0.773
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5230 - acc: 0.7531 - val_loss: 0.4935 - val_acc: 0.7560
Epoch 2/21
 - 22s - loss: 0.4299 - acc: 0.7957 - val_loss: 0.4558 - val_acc: 0.7764
Epoch 3/21
 - 22s - loss: 0.3937 - acc: 0.8172 - val_loss: 0.3925 - val_acc: 0.8156
Epoch 4/21
 - 22s - loss: 0.3697 - acc: 0.8318 - val_loss: 0.3724 - val_acc: 0.8281
Epoch 5/21
 - 21s - loss: 0.3542 - acc: 0.8402 - val_loss: 0.3639 - val_acc: 0.8301
Epoch 6/21
 - 22s - loss: 0.3387 - acc: 0.8510 - val_loss: 0.3720 - val_acc: 0.8239
Epoch 7/21
 - 22s - loss: 0.3245 - acc: 0.8573 - val_loss: 0.3696 - val_acc: 0.8284
Epoch 8/21
 - 22s - loss: 0.3141 - acc: 0.8641 - val_loss: 0.3221 - val_acc: 0.8576
Epoch 9/21
 - 22s - loss: 0.3011 - acc: 0.8738 - val_loss: 0.3263 - val_acc: 0.8469
Epoch 10/21
 - 22s - loss: 0.2866 - acc: 0.8812 - val_loss: 0.2864 - val_acc: 0.8720
Epoch 11/21
 - 22s - loss: 0.2793 - acc: 0.8839 - val_loss: 0.2978 - val_acc: 0.8622
Epoch 12/21
 - 22s - loss: 0.2708 - acc: 0.8895 - val_loss: 0.2561 - val_acc: 0.8937
Epoch 13/21
 - 22s - loss: 0.2638 - acc: 0.8927 - val_loss: 0.3641 - val_acc: 0.8350
Epoch 14/21
 - 22s - loss: 0.2531 - acc: 0.8978 - val_loss: 0.2524 - val_acc: 0.8912
Epoch 15/21
 - 22s - loss: 0.2474 - acc: 0.9019 - val_loss: 0.2413 - val_acc: 0.8978
Epoch 16/21
 - 22s - loss: 0.2398 - acc: 0.9050 - val_loss: 0.2686 - val_acc: 0.8837
Epoch 17/21
 - 22s - loss: 0.2331 - acc: 0.9092 - val_loss: 0.2757 - val_acc: 0.8852
Epoch 18/21
 - 22s - loss: 0.2279 - acc: 0.9105 - val_loss: 0.2597 - val_acc: 0.8940

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 22s - loss: 0.2206 - acc: 0.9138 - val_loss: 0.2217 - val_acc: 0.9098
Epoch 20/21
 - 22s - loss: 0.2175 - acc: 0.9164 - val_loss: 0.2041 - val_acc: 0.9177
Epoch 21/21
 - 22s - loss: 0.2151 - acc: 0.9163 - val_loss: 0.2045 - val_acc: 0.9193
Test accuracy:0.822
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5314 - acc: 0.7319 - val_loss: 0.4810 - val_acc: 0.7541
Epoch 2/21
 - 22s - loss: 0.4303 - acc: 0.7936 - val_loss: 0.4065 - val_acc: 0.8015
Epoch 3/21
 - 22s - loss: 0.3966 - acc: 0.8131 - val_loss: 0.3770 - val_acc: 0.8212
Epoch 4/21
 - 22s - loss: 0.3708 - acc: 0.8298 - val_loss: 0.3705 - val_acc: 0.8292
Epoch 5/21
 - 22s - loss: 0.3541 - acc: 0.8393 - val_loss: 0.3642 - val_acc: 0.8326
Epoch 6/21
 - 21s - loss: 0.3358 - acc: 0.8517 - val_loss: 0.3332 - val_acc: 0.8500
Epoch 7/21
 - 22s - loss: 0.3233 - acc: 0.8583 - val_loss: 0.3677 - val_acc: 0.8245
Epoch 8/21
 - 22s - loss: 0.3140 - acc: 0.8642 - val_loss: 0.3285 - val_acc: 0.8533
Epoch 9/21
 - 22s - loss: 0.3013 - acc: 0.8710 - val_loss: 0.3180 - val_acc: 0.8574
Epoch 10/21
 - 22s - loss: 0.2915 - acc: 0.8769 - val_loss: 0.3107 - val_acc: 0.8635
Epoch 11/21
 - 22s - loss: 0.2832 - acc: 0.8827 - val_loss: 0.3402 - val_acc: 0.8515
Epoch 12/21
 - 21s - loss: 0.2768 - acc: 0.8863 - val_loss: 0.2920 - val_acc: 0.8793
Epoch 13/21
 - 21s - loss: 0.2652 - acc: 0.8915 - val_loss: 0.2958 - val_acc: 0.8763
Epoch 14/21
 - 21s - loss: 0.2602 - acc: 0.8935 - val_loss: 0.2751 - val_acc: 0.8913
Epoch 15/21
 - 21s - loss: 0.2515 - acc: 0.8988 - val_loss: 0.3190 - val_acc: 0.8630
Epoch 16/21
 - 21s - loss: 0.2471 - acc: 0.9002 - val_loss: 0.2608 - val_acc: 0.8924
Epoch 17/21
 - 21s - loss: 0.2386 - acc: 0.9045 - val_loss: 0.2333 - val_acc: 0.9085
Epoch 18/21
 - 21s - loss: 0.2344 - acc: 0.9072 - val_loss: 0.2359 - val_acc: 0.9069
Epoch 19/21
 - 21s - loss: 0.2271 - acc: 0.9122 - val_loss: 0.2062 - val_acc: 0.9227
Epoch 20/21
 - 21s - loss: 0.2246 - acc: 0.9124 - val_loss: 0.2485 - val_acc: 0.9005
Epoch 21/21
 - 21s - loss: 0.2179 - acc: 0.9154 - val_loss: 0.2166 - val_acc: 0.9193
Test accuracy:0.798
current auc_score ------------------> 0.952
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5380 - acc: 0.7358 - val_loss: 0.5204 - val_acc: 0.7361
Epoch 2/21
 - 22s - loss: 0.4407 - acc: 0.7870 - val_loss: 0.4197 - val_acc: 0.7978
Epoch 3/21
 - 22s - loss: 0.4047 - acc: 0.8078 - val_loss: 0.3953 - val_acc: 0.8070
Epoch 4/21
 - 21s - loss: 0.3806 - acc: 0.8209 - val_loss: 0.3598 - val_acc: 0.8258
Epoch 5/21
 - 22s - loss: 0.3620 - acc: 0.8340 - val_loss: 0.3381 - val_acc: 0.8441
Epoch 6/21
 - 21s - loss: 0.3482 - acc: 0.8434 - val_loss: 0.3198 - val_acc: 0.8581
Epoch 7/21
 - 21s - loss: 0.3344 - acc: 0.8537 - val_loss: 0.3262 - val_acc: 0.8512
Epoch 8/21
 - 21s - loss: 0.3194 - acc: 0.8636 - val_loss: 0.3179 - val_acc: 0.8567
Epoch 9/21
 - 21s - loss: 0.3099 - acc: 0.8664 - val_loss: 0.2808 - val_acc: 0.8806
Epoch 10/21
 - 21s - loss: 0.2983 - acc: 0.8759 - val_loss: 0.2788 - val_acc: 0.8824
Epoch 11/21
 - 21s - loss: 0.2876 - acc: 0.8789 - val_loss: 0.2830 - val_acc: 0.8734
Epoch 12/21
 - 22s - loss: 0.2817 - acc: 0.8855 - val_loss: 0.2881 - val_acc: 0.8763
Epoch 13/21
 - 21s - loss: 0.2733 - acc: 0.8895 - val_loss: 0.2503 - val_acc: 0.8932
Epoch 14/21
 - 21s - loss: 0.2652 - acc: 0.8923 - val_loss: 0.2419 - val_acc: 0.9029
Epoch 15/21
 - 21s - loss: 0.2605 - acc: 0.8938 - val_loss: 0.2393 - val_acc: 0.9021
Epoch 16/21
 - 21s - loss: 0.2515 - acc: 0.8984 - val_loss: 0.2300 - val_acc: 0.9110
Epoch 17/21
 - 21s - loss: 0.2445 - acc: 0.9031 - val_loss: 0.2207 - val_acc: 0.9153
Epoch 18/21
 - 21s - loss: 0.2401 - acc: 0.9055 - val_loss: 0.2195 - val_acc: 0.9108
Epoch 19/21
 - 21s - loss: 0.2337 - acc: 0.9081 - val_loss: 0.2059 - val_acc: 0.9219
Epoch 20/21
 - 21s - loss: 0.2283 - acc: 0.9108 - val_loss: 0.2011 - val_acc: 0.9234
Epoch 21/21
 - 21s - loss: 0.2243 - acc: 0.9120 - val_loss: 0.2427 - val_acc: 0.9024
Test accuracy:0.893
current auc_score ------------------> 0.960
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5212 - acc: 0.7497 - val_loss: 0.4481 - val_acc: 0.7846
Epoch 2/21
 - 21s - loss: 0.4303 - acc: 0.7942 - val_loss: 0.4054 - val_acc: 0.8085
Epoch 3/21
 - 21s - loss: 0.3969 - acc: 0.8148 - val_loss: 0.3825 - val_acc: 0.8252
Epoch 4/21
 - 21s - loss: 0.3735 - acc: 0.8272 - val_loss: 0.3505 - val_acc: 0.8435
Epoch 5/21
 - 21s - loss: 0.3561 - acc: 0.8394 - val_loss: 0.3428 - val_acc: 0.8509
Epoch 6/21
 - 22s - loss: 0.3379 - acc: 0.8494 - val_loss: 0.3196 - val_acc: 0.8628
Epoch 7/21
 - 21s - loss: 0.3265 - acc: 0.8569 - val_loss: 0.3443 - val_acc: 0.8507
Epoch 8/21
 - 21s - loss: 0.3142 - acc: 0.8655 - val_loss: 0.3005 - val_acc: 0.8724
Epoch 9/21
 - 21s - loss: 0.3055 - acc: 0.8706 - val_loss: 0.2950 - val_acc: 0.8823
Epoch 10/21
 - 21s - loss: 0.2965 - acc: 0.8761 - val_loss: 0.2800 - val_acc: 0.8835
Epoch 11/21
 - 21s - loss: 0.2868 - acc: 0.8779 - val_loss: 0.2569 - val_acc: 0.8956
Epoch 12/21
 - 21s - loss: 0.2796 - acc: 0.8831 - val_loss: 0.2575 - val_acc: 0.8928
Epoch 13/21
 - 22s - loss: 0.2738 - acc: 0.8876 - val_loss: 0.2547 - val_acc: 0.8966
Epoch 14/21
 - 21s - loss: 0.2675 - acc: 0.8902 - val_loss: 0.2833 - val_acc: 0.8832
Epoch 15/21
 - 21s - loss: 0.2606 - acc: 0.8940 - val_loss: 0.2370 - val_acc: 0.9096
Epoch 16/21
 - 21s - loss: 0.2525 - acc: 0.8971 - val_loss: 0.2216 - val_acc: 0.9202
Epoch 17/21
 - 21s - loss: 0.2463 - acc: 0.9022 - val_loss: 0.2817 - val_acc: 0.8822
Epoch 18/21
 - 21s - loss: 0.2399 - acc: 0.9058 - val_loss: 0.2396 - val_acc: 0.9046
Epoch 19/21
 - 21s - loss: 0.2377 - acc: 0.9057 - val_loss: 0.2255 - val_acc: 0.9104

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 21s - loss: 0.2302 - acc: 0.9088 - val_loss: 0.2221 - val_acc: 0.9123
Epoch 00020: early stopping
Test accuracy:0.883
current auc_score ------------------> 0.954
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5380 - acc: 0.7389 - val_loss: 0.5110 - val_acc: 0.7560
Epoch 2/21
 - 21s - loss: 0.4486 - acc: 0.7814 - val_loss: 0.4986 - val_acc: 0.7481
Epoch 3/21
 - 21s - loss: 0.4199 - acc: 0.7973 - val_loss: 0.4198 - val_acc: 0.7961
Epoch 4/21
 - 22s - loss: 0.3987 - acc: 0.8117 - val_loss: 0.4228 - val_acc: 0.7964
Epoch 5/21
 - 21s - loss: 0.3790 - acc: 0.8248 - val_loss: 0.4088 - val_acc: 0.8041
Epoch 6/21
 - 21s - loss: 0.3610 - acc: 0.8366 - val_loss: 0.3637 - val_acc: 0.8336
Epoch 7/21
 - 21s - loss: 0.3441 - acc: 0.8469 - val_loss: 0.3215 - val_acc: 0.8558
Epoch 8/21
 - 22s - loss: 0.3303 - acc: 0.8536 - val_loss: 0.3380 - val_acc: 0.8469
Epoch 9/21
 - 22s - loss: 0.3191 - acc: 0.8623 - val_loss: 0.3125 - val_acc: 0.8658
Epoch 10/21
 - 22s - loss: 0.3081 - acc: 0.8670 - val_loss: 0.3227 - val_acc: 0.8584
Epoch 11/21
 - 22s - loss: 0.2993 - acc: 0.8735 - val_loss: 0.2857 - val_acc: 0.8832
Epoch 12/21
 - 22s - loss: 0.2888 - acc: 0.8787 - val_loss: 0.2690 - val_acc: 0.8896
Epoch 13/21
 - 22s - loss: 0.2819 - acc: 0.8817 - val_loss: 0.2637 - val_acc: 0.8917
Epoch 14/21
 - 21s - loss: 0.2774 - acc: 0.8863 - val_loss: 0.2408 - val_acc: 0.9027
Epoch 15/21
 - 21s - loss: 0.2690 - acc: 0.8885 - val_loss: 0.2398 - val_acc: 0.9052
Epoch 16/21
 - 21s - loss: 0.2587 - acc: 0.8949 - val_loss: 0.2346 - val_acc: 0.9066
Epoch 17/21
 - 22s - loss: 0.2528 - acc: 0.8970 - val_loss: 0.2226 - val_acc: 0.9144
Epoch 18/21
 - 21s - loss: 0.2461 - acc: 0.9020 - val_loss: 0.2140 - val_acc: 0.9189
Epoch 19/21
 - 22s - loss: 0.2412 - acc: 0.9045 - val_loss: 0.2244 - val_acc: 0.9118
Epoch 20/21
 - 22s - loss: 0.2403 - acc: 0.9049 - val_loss: 0.2019 - val_acc: 0.9204
Epoch 21/21
 - 22s - loss: 0.2322 - acc: 0.9090 - val_loss: 0.2292 - val_acc: 0.9073
Test accuracy:0.831
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5241 - acc: 0.7493 - val_loss: 0.5036 - val_acc: 0.7521
Epoch 2/21
 - 21s - loss: 0.4385 - acc: 0.7900 - val_loss: 0.4107 - val_acc: 0.7915
Epoch 3/21
 - 21s - loss: 0.4050 - acc: 0.8080 - val_loss: 0.4030 - val_acc: 0.8027
Epoch 4/21
 - 21s - loss: 0.3798 - acc: 0.8223 - val_loss: 0.3729 - val_acc: 0.8243
Epoch 5/21
 - 21s - loss: 0.3605 - acc: 0.8359 - val_loss: 0.3859 - val_acc: 0.8210
Epoch 6/21
 - 21s - loss: 0.3452 - acc: 0.8442 - val_loss: 0.3760 - val_acc: 0.8258
Epoch 7/21
 - 22s - loss: 0.3340 - acc: 0.8495 - val_loss: 0.3300 - val_acc: 0.8537
Epoch 8/21
 - 21s - loss: 0.3228 - acc: 0.8576 - val_loss: 0.3157 - val_acc: 0.8607
Epoch 9/21
 - 22s - loss: 0.3103 - acc: 0.8639 - val_loss: 0.3257 - val_acc: 0.8583
Epoch 10/21
 - 21s - loss: 0.3018 - acc: 0.8690 - val_loss: 0.3197 - val_acc: 0.8576
Epoch 11/21
 - 22s - loss: 0.2936 - acc: 0.8753 - val_loss: 0.3248 - val_acc: 0.8564

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 21s - loss: 0.2821 - acc: 0.8807 - val_loss: 0.2885 - val_acc: 0.8768
Epoch 13/21
 - 21s - loss: 0.2798 - acc: 0.8833 - val_loss: 0.2863 - val_acc: 0.8785
Epoch 14/21
 - 21s - loss: 0.2780 - acc: 0.8832 - val_loss: 0.2818 - val_acc: 0.8840
Epoch 15/21
 - 22s - loss: 0.2742 - acc: 0.8846 - val_loss: 0.2825 - val_acc: 0.8845
Epoch 16/21
 - 22s - loss: 0.2730 - acc: 0.8866 - val_loss: 0.2762 - val_acc: 0.8819
Epoch 17/21
 - 21s - loss: 0.2682 - acc: 0.8891 - val_loss: 0.3030 - val_acc: 0.8714
Epoch 18/21
 - 22s - loss: 0.2695 - acc: 0.8872 - val_loss: 0.2794 - val_acc: 0.8840
Epoch 19/21
 - 21s - loss: 0.2666 - acc: 0.8884 - val_loss: 0.2622 - val_acc: 0.8913
Epoch 20/21
 - 21s - loss: 0.2628 - acc: 0.8925 - val_loss: 0.2796 - val_acc: 0.8847
Epoch 21/21
 - 21s - loss: 0.2629 - acc: 0.8907 - val_loss: 0.2906 - val_acc: 0.8805
Test accuracy:0.857
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5047 - acc: 0.7603 - val_loss: 0.5706 - val_acc: 0.7063
Epoch 2/21
 - 22s - loss: 0.4249 - acc: 0.7981 - val_loss: 0.5887 - val_acc: 0.7093
Epoch 3/21
 - 22s - loss: 0.3977 - acc: 0.8136 - val_loss: 0.5293 - val_acc: 0.7423
Epoch 4/21
 - 22s - loss: 0.3773 - acc: 0.8262 - val_loss: 0.4502 - val_acc: 0.7776
Epoch 5/21
 - 21s - loss: 0.3597 - acc: 0.8376 - val_loss: 0.4169 - val_acc: 0.7893
Epoch 6/21
 - 22s - loss: 0.3414 - acc: 0.8515 - val_loss: 0.3291 - val_acc: 0.8529
Epoch 7/21
 - 21s - loss: 0.3297 - acc: 0.8587 - val_loss: 0.3110 - val_acc: 0.8645
Epoch 8/21
 - 22s - loss: 0.3185 - acc: 0.8643 - val_loss: 0.3784 - val_acc: 0.8209
Epoch 9/21
 - 22s - loss: 0.3063 - acc: 0.8700 - val_loss: 0.3178 - val_acc: 0.8589
Epoch 10/21
 - 22s - loss: 0.2981 - acc: 0.8770 - val_loss: 0.3437 - val_acc: 0.8417

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 11/21
 - 23s - loss: 0.2888 - acc: 0.8805 - val_loss: 0.3012 - val_acc: 0.8709
Epoch 12/21
 - 23s - loss: 0.2850 - acc: 0.8842 - val_loss: 0.3057 - val_acc: 0.8642
Epoch 13/21
 - 22s - loss: 0.2853 - acc: 0.8835 - val_loss: 0.3111 - val_acc: 0.8648
Epoch 14/21
 - 22s - loss: 0.2784 - acc: 0.8855 - val_loss: 0.2800 - val_acc: 0.8815
Epoch 15/21
 - 22s - loss: 0.2780 - acc: 0.8869 - val_loss: 0.3197 - val_acc: 0.8583
Epoch 16/21
 - 21s - loss: 0.2753 - acc: 0.8880 - val_loss: 0.2805 - val_acc: 0.8814
Epoch 17/21
 - 21s - loss: 0.2732 - acc: 0.8913 - val_loss: 0.3113 - val_acc: 0.8636

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 18/21
 - 21s - loss: 0.2693 - acc: 0.8924 - val_loss: 0.2805 - val_acc: 0.8813
Epoch 00018: early stopping
Test accuracy:0.855
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 31, 12, 12)   1922        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 31, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 31, 6, 6)     124         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 31, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5022        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 49, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 6, 6)     196         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 49, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     7938        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 67, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 67, 6, 6)     268         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 67, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 67)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            68          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 38,898
Trainable params: 38,104
Non-trainable params: 794
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5413 - acc: 0.7335 - val_loss: 0.4906 - val_acc: 0.7653
Epoch 2/21
 - 21s - loss: 0.4407 - acc: 0.7865 - val_loss: 0.4655 - val_acc: 0.7627
Epoch 3/21
 - 21s - loss: 0.4095 - acc: 0.8048 - val_loss: 0.4012 - val_acc: 0.8048
Epoch 4/21
 - 21s - loss: 0.3886 - acc: 0.8184 - val_loss: 0.4058 - val_acc: 0.8005
Epoch 5/21
 - 22s - loss: 0.3713 - acc: 0.8284 - val_loss: 0.3468 - val_acc: 0.8435
Epoch 6/21
 - 22s - loss: 0.3541 - acc: 0.8408 - val_loss: 0.3438 - val_acc: 0.8405
Epoch 7/21
 - 21s - loss: 0.3420 - acc: 0.8477 - val_loss: 0.3388 - val_acc: 0.8445
Epoch 8/21
 - 21s - loss: 0.3319 - acc: 0.8525 - val_loss: 0.3181 - val_acc: 0.8630
Epoch 9/21
 - 21s - loss: 0.3213 - acc: 0.8605 - val_loss: 0.3035 - val_acc: 0.8714
Epoch 10/21
 - 21s - loss: 0.3109 - acc: 0.8660 - val_loss: 0.3581 - val_acc: 0.8396
Epoch 11/21
 - 21s - loss: 0.3024 - acc: 0.8697 - val_loss: 0.3232 - val_acc: 0.8550
Epoch 12/21
 - 22s - loss: 0.2955 - acc: 0.8748 - val_loss: 0.2865 - val_acc: 0.8801
Epoch 13/21
 - 21s - loss: 0.2881 - acc: 0.8779 - val_loss: 0.2951 - val_acc: 0.8750
Epoch 14/21
 - 22s - loss: 0.2793 - acc: 0.8843 - val_loss: 0.2652 - val_acc: 0.8926
Epoch 15/21
 - 22s - loss: 0.2742 - acc: 0.8873 - val_loss: 0.2736 - val_acc: 0.8833
Epoch 16/21
 - 21s - loss: 0.2687 - acc: 0.8897 - val_loss: 0.2447 - val_acc: 0.9020
Epoch 17/21
 - 21s - loss: 0.2618 - acc: 0.8941 - val_loss: 0.2712 - val_acc: 0.8848
Epoch 18/21
 - 21s - loss: 0.2573 - acc: 0.8957 - val_loss: 0.2267 - val_acc: 0.9119
Epoch 19/21
 - 21s - loss: 0.2506 - acc: 0.9006 - val_loss: 0.2236 - val_acc: 0.9142
Epoch 20/21
 - 21s - loss: 0.2448 - acc: 0.9029 - val_loss: 0.2401 - val_acc: 0.9071
Epoch 21/21
 - 21s - loss: 0.2392 - acc: 0.9054 - val_loss: 0.2387 - val_acc: 0.9080
Test accuracy:0.867
current auc_score ------------------> 0.940
accuracies:  [0.8658602150537634, 0.7733870967741936, 0.8219086021505376, 0.7979838709677419, 0.8926075268817204, 0.8833333333333333, 0.8307795698924731, 0.8565860215053763, 0.8547043010752688, 0.8672043010752688]
aucs:  [0.9368, 0.917, 0.9431, 0.9518, 0.9596, 0.9542, 0.9337, 0.9389, 0.946, 0.9404]
mean and std AUC:  0.942+/-0.011  max:   0.9596
['2-2-2', '18', '3', '32', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5346 - acc: 0.7458 - val_loss: 0.4835 - val_acc: 0.7666
Epoch 2/21
 - 21s - loss: 0.4305 - acc: 0.8008 - val_loss: 0.4226 - val_acc: 0.8023
Epoch 3/21
 - 21s - loss: 0.3890 - acc: 0.8233 - val_loss: 0.3711 - val_acc: 0.8355
Epoch 4/21
 - 22s - loss: 0.3624 - acc: 0.8386 - val_loss: 0.3436 - val_acc: 0.8564
Epoch 5/21
 - 22s - loss: 0.3439 - acc: 0.8484 - val_loss: 0.3220 - val_acc: 0.8721
Epoch 6/21
 - 22s - loss: 0.3274 - acc: 0.8592 - val_loss: 0.3556 - val_acc: 0.8451
Epoch 7/21
 - 22s - loss: 0.3102 - acc: 0.8699 - val_loss: 0.2913 - val_acc: 0.8817
Epoch 8/21
 - 22s - loss: 0.2977 - acc: 0.8776 - val_loss: 0.2912 - val_acc: 0.8747
Epoch 9/21
 - 22s - loss: 0.2897 - acc: 0.8822 - val_loss: 0.2672 - val_acc: 0.8893
Epoch 10/21
 - 21s - loss: 0.2769 - acc: 0.8890 - val_loss: 0.2563 - val_acc: 0.9037
Epoch 11/21
 - 22s - loss: 0.2688 - acc: 0.8920 - val_loss: 0.2420 - val_acc: 0.9024
Epoch 12/21
 - 22s - loss: 0.2575 - acc: 0.8990 - val_loss: 0.2313 - val_acc: 0.9158
Epoch 13/21
 - 22s - loss: 0.2511 - acc: 0.9021 - val_loss: 0.2181 - val_acc: 0.9246
Epoch 14/21
 - 21s - loss: 0.2418 - acc: 0.9072 - val_loss: 0.2304 - val_acc: 0.9124
Epoch 15/21
 - 22s - loss: 0.2337 - acc: 0.9125 - val_loss: 0.1990 - val_acc: 0.9321
Epoch 16/21
 - 21s - loss: 0.2286 - acc: 0.9144 - val_loss: 0.2066 - val_acc: 0.9255
Epoch 17/21
 - 22s - loss: 0.2200 - acc: 0.9181 - val_loss: 0.1901 - val_acc: 0.9305
Epoch 18/21
 - 22s - loss: 0.2154 - acc: 0.9196 - val_loss: 0.1853 - val_acc: 0.9335
Epoch 19/21
 - 21s - loss: 0.2096 - acc: 0.9233 - val_loss: 0.1924 - val_acc: 0.9315
Epoch 20/21
 - 21s - loss: 0.2021 - acc: 0.9259 - val_loss: 0.1867 - val_acc: 0.9317
Epoch 21/21
 - 22s - loss: 0.1994 - acc: 0.9276 - val_loss: 0.1736 - val_acc: 0.9400
Test accuracy:0.846
current auc_score ------------------> 0.950
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5189 - acc: 0.7467 - val_loss: 0.5147 - val_acc: 0.7546
Epoch 2/21
 - 21s - loss: 0.4250 - acc: 0.7973 - val_loss: 0.4293 - val_acc: 0.7910
Epoch 3/21
 - 21s - loss: 0.3880 - acc: 0.8214 - val_loss: 0.3524 - val_acc: 0.8380
Epoch 4/21
 - 22s - loss: 0.3647 - acc: 0.8363 - val_loss: 0.4266 - val_acc: 0.8143
Epoch 5/21
 - 22s - loss: 0.3451 - acc: 0.8479 - val_loss: 0.3167 - val_acc: 0.8586
Epoch 6/21
 - 22s - loss: 0.3308 - acc: 0.8576 - val_loss: 0.3664 - val_acc: 0.8365
Epoch 7/21
 - 22s - loss: 0.3151 - acc: 0.8682 - val_loss: 0.2948 - val_acc: 0.8712
Epoch 8/21
 - 22s - loss: 0.3056 - acc: 0.8732 - val_loss: 0.2872 - val_acc: 0.8761
Epoch 9/21
 - 22s - loss: 0.2980 - acc: 0.8761 - val_loss: 0.2647 - val_acc: 0.8883
Epoch 10/21
 - 22s - loss: 0.2874 - acc: 0.8823 - val_loss: 0.2529 - val_acc: 0.9001
Epoch 11/21
 - 21s - loss: 0.2802 - acc: 0.8864 - val_loss: 0.2825 - val_acc: 0.8781
Epoch 12/21
 - 21s - loss: 0.2742 - acc: 0.8888 - val_loss: 0.2710 - val_acc: 0.8852
Epoch 13/21
 - 21s - loss: 0.2636 - acc: 0.8958 - val_loss: 0.2423 - val_acc: 0.9051
Epoch 14/21
 - 21s - loss: 0.2569 - acc: 0.8985 - val_loss: 0.2433 - val_acc: 0.8993
Epoch 15/21
 - 22s - loss: 0.2513 - acc: 0.9003 - val_loss: 0.2320 - val_acc: 0.9083
Epoch 16/21
 - 22s - loss: 0.2420 - acc: 0.9058 - val_loss: 0.2240 - val_acc: 0.9113
Epoch 17/21
 - 21s - loss: 0.2371 - acc: 0.9094 - val_loss: 0.2247 - val_acc: 0.9149
Epoch 18/21
 - 22s - loss: 0.2326 - acc: 0.9116 - val_loss: 0.2144 - val_acc: 0.9147
Epoch 19/21
 - 21s - loss: 0.2252 - acc: 0.9148 - val_loss: 0.2852 - val_acc: 0.8806
Epoch 20/21
 - 21s - loss: 0.2201 - acc: 0.9165 - val_loss: 0.2266 - val_acc: 0.9095
Epoch 21/21
 - 21s - loss: 0.2128 - acc: 0.9214 - val_loss: 0.1886 - val_acc: 0.9265
Test accuracy:0.858
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5100 - acc: 0.7636 - val_loss: 0.4662 - val_acc: 0.7737
Epoch 2/21
 - 21s - loss: 0.4243 - acc: 0.8015 - val_loss: 0.3971 - val_acc: 0.8179
Epoch 3/21
 - 22s - loss: 0.3834 - acc: 0.8254 - val_loss: 0.4516 - val_acc: 0.7854
Epoch 4/21
 - 22s - loss: 0.3556 - acc: 0.8454 - val_loss: 0.3375 - val_acc: 0.8508
Epoch 5/21
 - 22s - loss: 0.3338 - acc: 0.8578 - val_loss: 0.3384 - val_acc: 0.8529
Epoch 6/21
 - 22s - loss: 0.3163 - acc: 0.8678 - val_loss: 0.2950 - val_acc: 0.8749
Epoch 7/21
 - 21s - loss: 0.3021 - acc: 0.8747 - val_loss: 0.2807 - val_acc: 0.8884
Epoch 8/21
 - 22s - loss: 0.2910 - acc: 0.8814 - val_loss: 0.2922 - val_acc: 0.8790
Epoch 9/21
 - 21s - loss: 0.2773 - acc: 0.8883 - val_loss: 0.2646 - val_acc: 0.8958
Epoch 10/21
 - 22s - loss: 0.2672 - acc: 0.8945 - val_loss: 0.2413 - val_acc: 0.9080
Epoch 11/21
 - 21s - loss: 0.2560 - acc: 0.8998 - val_loss: 0.2629 - val_acc: 0.8981
Epoch 12/21
 - 22s - loss: 0.2479 - acc: 0.9039 - val_loss: 0.2648 - val_acc: 0.8918
Epoch 13/21
 - 22s - loss: 0.2414 - acc: 0.9072 - val_loss: 0.2302 - val_acc: 0.9170
Epoch 14/21
 - 22s - loss: 0.2320 - acc: 0.9122 - val_loss: 0.2191 - val_acc: 0.9208
Epoch 15/21
 - 22s - loss: 0.2264 - acc: 0.9135 - val_loss: 0.2197 - val_acc: 0.9187
Epoch 16/21
 - 22s - loss: 0.2206 - acc: 0.9169 - val_loss: 0.2133 - val_acc: 0.9221
Epoch 17/21
 - 22s - loss: 0.2131 - acc: 0.9208 - val_loss: 0.1980 - val_acc: 0.9244
Epoch 18/21
 - 22s - loss: 0.2105 - acc: 0.9232 - val_loss: 0.1802 - val_acc: 0.9344
Epoch 19/21
 - 22s - loss: 0.2016 - acc: 0.9274 - val_loss: 0.2189 - val_acc: 0.9173
Epoch 20/21
 - 22s - loss: 0.1971 - acc: 0.9275 - val_loss: 0.1722 - val_acc: 0.9414
Epoch 21/21
 - 22s - loss: 0.1956 - acc: 0.9285 - val_loss: 0.1571 - val_acc: 0.9463
Test accuracy:0.851
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5290 - acc: 0.7457 - val_loss: 0.4620 - val_acc: 0.7820
Epoch 2/21
 - 22s - loss: 0.4343 - acc: 0.7936 - val_loss: 0.4345 - val_acc: 0.7913
Epoch 3/21
 - 22s - loss: 0.3994 - acc: 0.8171 - val_loss: 0.3779 - val_acc: 0.8328
Epoch 4/21
 - 22s - loss: 0.3713 - acc: 0.8340 - val_loss: 0.3706 - val_acc: 0.8307
Epoch 5/21
 - 22s - loss: 0.3512 - acc: 0.8473 - val_loss: 0.3181 - val_acc: 0.8596
Epoch 6/21
 - 22s - loss: 0.3311 - acc: 0.8589 - val_loss: 0.3112 - val_acc: 0.8653
Epoch 7/21
 - 22s - loss: 0.3181 - acc: 0.8646 - val_loss: 0.3106 - val_acc: 0.8685
Epoch 8/21
 - 22s - loss: 0.3047 - acc: 0.8731 - val_loss: 0.2921 - val_acc: 0.8771
Epoch 9/21
 - 21s - loss: 0.2928 - acc: 0.8781 - val_loss: 0.2818 - val_acc: 0.8835
Epoch 10/21
 - 22s - loss: 0.2829 - acc: 0.8861 - val_loss: 0.2675 - val_acc: 0.9009
Epoch 11/21
 - 22s - loss: 0.2716 - acc: 0.8912 - val_loss: 0.2778 - val_acc: 0.8808
Epoch 12/21
 - 22s - loss: 0.2638 - acc: 0.8963 - val_loss: 0.2471 - val_acc: 0.9052
Epoch 13/21
 - 22s - loss: 0.2556 - acc: 0.9004 - val_loss: 0.2258 - val_acc: 0.9219
Epoch 14/21
 - 22s - loss: 0.2475 - acc: 0.9040 - val_loss: 0.2191 - val_acc: 0.9172
Epoch 15/21
 - 22s - loss: 0.2378 - acc: 0.9096 - val_loss: 0.2084 - val_acc: 0.9237
Epoch 16/21
 - 22s - loss: 0.2298 - acc: 0.9139 - val_loss: 0.2077 - val_acc: 0.9242
Epoch 17/21
 - 22s - loss: 0.2224 - acc: 0.9167 - val_loss: 0.2451 - val_acc: 0.8931
Epoch 18/21
 - 22s - loss: 0.2195 - acc: 0.9175 - val_loss: 0.1861 - val_acc: 0.9336
Epoch 19/21
 - 22s - loss: 0.2121 - acc: 0.9230 - val_loss: 0.2003 - val_acc: 0.9216
Epoch 20/21
 - 22s - loss: 0.2088 - acc: 0.9232 - val_loss: 0.1905 - val_acc: 0.9306
Epoch 21/21
 - 22s - loss: 0.2032 - acc: 0.9247 - val_loss: 0.1768 - val_acc: 0.9374
Test accuracy:0.839
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5225 - acc: 0.7456 - val_loss: 0.5116 - val_acc: 0.7513
Epoch 2/21
 - 22s - loss: 0.4283 - acc: 0.7946 - val_loss: 0.4422 - val_acc: 0.7959
Epoch 3/21
 - 21s - loss: 0.3893 - acc: 0.8206 - val_loss: 0.5992 - val_acc: 0.7312
Epoch 4/21
 - 21s - loss: 0.3649 - acc: 0.8370 - val_loss: 0.3555 - val_acc: 0.8443
Epoch 5/21
 - 22s - loss: 0.3456 - acc: 0.8509 - val_loss: 0.5069 - val_acc: 0.7779
Epoch 6/21
 - 22s - loss: 0.3316 - acc: 0.8596 - val_loss: 0.3030 - val_acc: 0.8706
Epoch 7/21
 - 22s - loss: 0.3169 - acc: 0.8684 - val_loss: 0.3102 - val_acc: 0.8646
Epoch 8/21
 - 22s - loss: 0.3070 - acc: 0.8732 - val_loss: 0.3159 - val_acc: 0.8622
Epoch 9/21
 - 22s - loss: 0.2938 - acc: 0.8791 - val_loss: 0.3393 - val_acc: 0.8534

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 22s - loss: 0.2827 - acc: 0.8872 - val_loss: 0.2628 - val_acc: 0.8968
Epoch 11/21
 - 22s - loss: 0.2775 - acc: 0.8882 - val_loss: 0.2721 - val_acc: 0.8896
Epoch 12/21
 - 22s - loss: 0.2739 - acc: 0.8902 - val_loss: 0.2951 - val_acc: 0.8755
Epoch 13/21
 - 22s - loss: 0.2718 - acc: 0.8933 - val_loss: 0.3209 - val_acc: 0.8574

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 14/21
 - 21s - loss: 0.2693 - acc: 0.8922 - val_loss: 0.2607 - val_acc: 0.8958
Epoch 00014: early stopping
Test accuracy:0.838
current auc_score ------------------> 0.956
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5293 - acc: 0.7439 - val_loss: 0.4665 - val_acc: 0.7777
Epoch 2/21
 - 22s - loss: 0.4336 - acc: 0.7963 - val_loss: 0.4098 - val_acc: 0.8033
Epoch 3/21
 - 21s - loss: 0.3933 - acc: 0.8195 - val_loss: 0.3791 - val_acc: 0.8340
Epoch 4/21
 - 22s - loss: 0.3640 - acc: 0.8386 - val_loss: 0.3774 - val_acc: 0.8249
Epoch 5/21
 - 21s - loss: 0.3420 - acc: 0.8533 - val_loss: 0.3195 - val_acc: 0.8640
Epoch 6/21
 - 22s - loss: 0.3251 - acc: 0.8625 - val_loss: 0.3023 - val_acc: 0.8768
Epoch 7/21
 - 22s - loss: 0.3082 - acc: 0.8718 - val_loss: 0.3320 - val_acc: 0.8588
Epoch 8/21
 - 22s - loss: 0.2962 - acc: 0.8802 - val_loss: 0.2879 - val_acc: 0.8859
Epoch 9/21
 - 22s - loss: 0.2834 - acc: 0.8854 - val_loss: 0.2730 - val_acc: 0.8924
Epoch 10/21
 - 22s - loss: 0.2728 - acc: 0.8906 - val_loss: 0.2563 - val_acc: 0.9009
Epoch 11/21
 - 22s - loss: 0.2628 - acc: 0.8972 - val_loss: 0.2829 - val_acc: 0.8827
Epoch 12/21
 - 22s - loss: 0.2523 - acc: 0.9022 - val_loss: 0.2322 - val_acc: 0.9150
Epoch 13/21
 - 22s - loss: 0.2427 - acc: 0.9070 - val_loss: 0.2192 - val_acc: 0.9198
Epoch 14/21
 - 22s - loss: 0.2366 - acc: 0.9107 - val_loss: 0.2154 - val_acc: 0.9202
Epoch 15/21
 - 22s - loss: 0.2294 - acc: 0.9140 - val_loss: 0.2317 - val_acc: 0.9106
Epoch 16/21
 - 22s - loss: 0.2205 - acc: 0.9179 - val_loss: 0.1950 - val_acc: 0.9288
Epoch 17/21
 - 22s - loss: 0.2171 - acc: 0.9197 - val_loss: 0.2435 - val_acc: 0.9064
Epoch 18/21
 - 22s - loss: 0.2123 - acc: 0.9222 - val_loss: 0.1873 - val_acc: 0.9359
Epoch 19/21
 - 22s - loss: 0.2056 - acc: 0.9246 - val_loss: 0.2025 - val_acc: 0.9232
Epoch 20/21
 - 21s - loss: 0.2031 - acc: 0.9259 - val_loss: 0.1721 - val_acc: 0.9414
Epoch 21/21
 - 22s - loss: 0.1976 - acc: 0.9289 - val_loss: 0.1641 - val_acc: 0.9452
Test accuracy:0.836
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5099 - acc: 0.7642 - val_loss: 0.6231 - val_acc: 0.6964
Epoch 2/21
 - 22s - loss: 0.4171 - acc: 0.8046 - val_loss: 0.4312 - val_acc: 0.7879
Epoch 3/21
 - 22s - loss: 0.3830 - acc: 0.8270 - val_loss: 0.4934 - val_acc: 0.7629
Epoch 4/21
 - 22s - loss: 0.3590 - acc: 0.8410 - val_loss: 0.4900 - val_acc: 0.7686
Epoch 5/21
 - 21s - loss: 0.3403 - acc: 0.8535 - val_loss: 0.4243 - val_acc: 0.7928
Epoch 6/21
 - 22s - loss: 0.3224 - acc: 0.8636 - val_loss: 0.4582 - val_acc: 0.7834
Epoch 7/21
 - 21s - loss: 0.3102 - acc: 0.8717 - val_loss: 0.3999 - val_acc: 0.8033
Epoch 8/21
 - 21s - loss: 0.3009 - acc: 0.8769 - val_loss: 0.3743 - val_acc: 0.8267
Epoch 9/21
 - 21s - loss: 0.2904 - acc: 0.8836 - val_loss: 0.3228 - val_acc: 0.8598
Epoch 10/21
 - 21s - loss: 0.2786 - acc: 0.8874 - val_loss: 0.3494 - val_acc: 0.8407
Epoch 11/21
 - 21s - loss: 0.2694 - acc: 0.8935 - val_loss: 0.3875 - val_acc: 0.8279
Epoch 12/21
 - 21s - loss: 0.2596 - acc: 0.8989 - val_loss: 0.3266 - val_acc: 0.8502

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 13/21
 - 21s - loss: 0.2510 - acc: 0.9017 - val_loss: 0.3390 - val_acc: 0.8483
Epoch 00013: early stopping
Test accuracy:0.811
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5143 - acc: 0.7626 - val_loss: 0.4660 - val_acc: 0.7757
Epoch 2/21
 - 22s - loss: 0.4215 - acc: 0.8027 - val_loss: 0.4679 - val_acc: 0.7677
Epoch 3/21
 - 22s - loss: 0.3871 - acc: 0.8235 - val_loss: 0.3740 - val_acc: 0.8332
Epoch 4/21
 - 22s - loss: 0.3610 - acc: 0.8395 - val_loss: 0.3475 - val_acc: 0.8444
Epoch 5/21
 - 22s - loss: 0.3417 - acc: 0.8530 - val_loss: 0.3260 - val_acc: 0.8594
Epoch 6/21
 - 22s - loss: 0.3236 - acc: 0.8635 - val_loss: 0.3088 - val_acc: 0.8764
Epoch 7/21
 - 21s - loss: 0.3089 - acc: 0.8713 - val_loss: 0.3201 - val_acc: 0.8704
Epoch 8/21
 - 22s - loss: 0.2948 - acc: 0.8810 - val_loss: 0.3128 - val_acc: 0.8630
Epoch 9/21
 - 22s - loss: 0.2819 - acc: 0.8865 - val_loss: 0.2628 - val_acc: 0.9026
Epoch 10/21
 - 22s - loss: 0.2718 - acc: 0.8932 - val_loss: 0.2651 - val_acc: 0.8996
Epoch 11/21
 - 21s - loss: 0.2623 - acc: 0.8973 - val_loss: 0.2597 - val_acc: 0.8966
Epoch 12/21
 - 22s - loss: 0.2519 - acc: 0.9027 - val_loss: 0.2520 - val_acc: 0.9027
Epoch 13/21
 - 22s - loss: 0.2437 - acc: 0.9065 - val_loss: 0.2722 - val_acc: 0.8904
Epoch 14/21
 - 21s - loss: 0.2396 - acc: 0.9076 - val_loss: 0.2677 - val_acc: 0.8897
Epoch 15/21
 - 22s - loss: 0.2300 - acc: 0.9116 - val_loss: 0.2204 - val_acc: 0.9159
Epoch 16/21
 - 22s - loss: 0.2215 - acc: 0.9171 - val_loss: 0.2663 - val_acc: 0.8934
Epoch 17/21
 - 22s - loss: 0.2158 - acc: 0.9202 - val_loss: 0.1932 - val_acc: 0.9326
Epoch 18/21
 - 21s - loss: 0.2106 - acc: 0.9225 - val_loss: 0.2228 - val_acc: 0.9133
Epoch 19/21
 - 21s - loss: 0.2031 - acc: 0.9255 - val_loss: 0.1916 - val_acc: 0.9296
Epoch 20/21
 - 22s - loss: 0.1984 - acc: 0.9278 - val_loss: 0.1991 - val_acc: 0.9224
Epoch 21/21
 - 21s - loss: 0.1922 - acc: 0.9315 - val_loss: 0.2075 - val_acc: 0.9216
Epoch 00021: early stopping
Test accuracy:0.835
current auc_score ------------------> 0.952
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5307 - acc: 0.7533 - val_loss: 0.4599 - val_acc: 0.7809
Epoch 2/21
 - 22s - loss: 0.4407 - acc: 0.7915 - val_loss: 0.4228 - val_acc: 0.7966
Epoch 3/21
 - 21s - loss: 0.4044 - acc: 0.8109 - val_loss: 0.4459 - val_acc: 0.7929
Epoch 4/21
 - 21s - loss: 0.3796 - acc: 0.8275 - val_loss: 0.4174 - val_acc: 0.8070
Epoch 5/21
 - 22s - loss: 0.3569 - acc: 0.8433 - val_loss: 0.3497 - val_acc: 0.8478
Epoch 6/21
 - 22s - loss: 0.3416 - acc: 0.8548 - val_loss: 0.4333 - val_acc: 0.7948
Epoch 7/21
 - 22s - loss: 0.3265 - acc: 0.8631 - val_loss: 0.3984 - val_acc: 0.8160
Epoch 8/21
 - 22s - loss: 0.3119 - acc: 0.8694 - val_loss: 0.3254 - val_acc: 0.8612
Epoch 9/21
 - 22s - loss: 0.3016 - acc: 0.8764 - val_loss: 0.3666 - val_acc: 0.8373
Epoch 10/21
 - 22s - loss: 0.2929 - acc: 0.8801 - val_loss: 0.3877 - val_acc: 0.8244
Epoch 11/21
 - 22s - loss: 0.2810 - acc: 0.8875 - val_loss: 0.2835 - val_acc: 0.8864
Epoch 12/21
 - 22s - loss: 0.2762 - acc: 0.8893 - val_loss: 0.3405 - val_acc: 0.8498
Epoch 13/21
 - 22s - loss: 0.2655 - acc: 0.8949 - val_loss: 0.3329 - val_acc: 0.8525
Epoch 14/21
 - 22s - loss: 0.2577 - acc: 0.8982 - val_loss: 0.3134 - val_acc: 0.8627

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 22s - loss: 0.2484 - acc: 0.9051 - val_loss: 0.3156 - val_acc: 0.8589
Epoch 00015: early stopping
Test accuracy:0.816
current auc_score ------------------> 0.934
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5201 - acc: 0.7491 - val_loss: 0.4737 - val_acc: 0.7671
Epoch 2/21
 - 22s - loss: 0.4301 - acc: 0.7965 - val_loss: 0.4251 - val_acc: 0.7969
Epoch 3/21
 - 22s - loss: 0.3940 - acc: 0.8183 - val_loss: 0.4586 - val_acc: 0.7692
Epoch 4/21
 - 22s - loss: 0.3676 - acc: 0.8364 - val_loss: 0.3493 - val_acc: 0.8406
Epoch 5/21
 - 22s - loss: 0.3495 - acc: 0.8459 - val_loss: 0.4129 - val_acc: 0.8071
Epoch 6/21
 - 21s - loss: 0.3321 - acc: 0.8577 - val_loss: 0.3108 - val_acc: 0.8716
Epoch 7/21
 - 21s - loss: 0.3176 - acc: 0.8662 - val_loss: 0.2952 - val_acc: 0.8813
Epoch 8/21
 - 21s - loss: 0.3027 - acc: 0.8764 - val_loss: 0.2986 - val_acc: 0.8731
Epoch 9/21
 - 22s - loss: 0.2901 - acc: 0.8823 - val_loss: 0.2718 - val_acc: 0.8956
Epoch 10/21
 - 21s - loss: 0.2813 - acc: 0.8868 - val_loss: 0.2609 - val_acc: 0.9011
Epoch 11/21
 - 21s - loss: 0.2715 - acc: 0.8914 - val_loss: 0.2470 - val_acc: 0.9074
Epoch 12/21
 - 21s - loss: 0.2629 - acc: 0.8952 - val_loss: 0.2421 - val_acc: 0.9090
Epoch 13/21
 - 21s - loss: 0.2515 - acc: 0.9017 - val_loss: 0.2303 - val_acc: 0.9148
Epoch 14/21
 - 21s - loss: 0.2411 - acc: 0.9063 - val_loss: 0.2131 - val_acc: 0.9229
Epoch 15/21
 - 21s - loss: 0.2378 - acc: 0.9086 - val_loss: 0.2116 - val_acc: 0.9206
Epoch 16/21
 - 21s - loss: 0.2308 - acc: 0.9120 - val_loss: 0.2351 - val_acc: 0.9130
Epoch 17/21
 - 21s - loss: 0.2242 - acc: 0.9162 - val_loss: 0.1981 - val_acc: 0.9278
Epoch 18/21
 - 21s - loss: 0.2172 - acc: 0.9186 - val_loss: 0.2049 - val_acc: 0.9243
Epoch 19/21
 - 22s - loss: 0.2113 - acc: 0.9225 - val_loss: 0.1900 - val_acc: 0.9315
Epoch 20/21
 - 21s - loss: 0.2057 - acc: 0.9244 - val_loss: 0.1865 - val_acc: 0.9316
Epoch 21/21
 - 22s - loss: 0.2017 - acc: 0.9264 - val_loss: 0.2027 - val_acc: 0.9221
Test accuracy:0.883
current auc_score ------------------> 0.953
Saved model to disk
accuracies:  [0.8462365591397849, 0.8579301075268817, 0.8508064516129032, 0.8388440860215054, 0.8381720430107527, 0.835752688172043, 0.8110215053763441, 0.8350806451612903, 0.8157258064516129, 0.8830645161290323]
aucs:  [0.95, 0.9451, 0.9446, 0.9383, 0.956, 0.9486, 0.9433, 0.9516, 0.9336, 0.9527]
mean and std AUC:  0.946+/-0.006  max:   0.956
['2-2-2', '18', '3', '64', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5185 - acc: 0.7665 - val_loss: 0.4882 - val_acc: 0.7764
Epoch 2/21
 - 21s - loss: 0.4272 - acc: 0.8092 - val_loss: 0.4887 - val_acc: 0.7677
Epoch 3/21
 - 21s - loss: 0.3859 - acc: 0.8344 - val_loss: 0.3560 - val_acc: 0.8505
Epoch 4/21
 - 21s - loss: 0.3566 - acc: 0.8508 - val_loss: 0.4398 - val_acc: 0.8026
Epoch 5/21
 - 21s - loss: 0.3346 - acc: 0.8644 - val_loss: 0.4052 - val_acc: 0.8268
Epoch 6/21
 - 21s - loss: 0.3154 - acc: 0.8759 - val_loss: 0.2986 - val_acc: 0.8801
Epoch 7/21
 - 22s - loss: 0.2975 - acc: 0.8864 - val_loss: 0.3386 - val_acc: 0.8660
Epoch 8/21
 - 21s - loss: 0.2831 - acc: 0.8933 - val_loss: 0.3076 - val_acc: 0.8788
Epoch 9/21
 - 21s - loss: 0.2707 - acc: 0.9003 - val_loss: 0.3239 - val_acc: 0.8731

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/21
 - 21s - loss: 0.2558 - acc: 0.9084 - val_loss: 0.2789 - val_acc: 0.8932
Epoch 11/21
 - 21s - loss: 0.2509 - acc: 0.9104 - val_loss: 0.2530 - val_acc: 0.9051
Epoch 12/21
 - 21s - loss: 0.2474 - acc: 0.9107 - val_loss: 0.3254 - val_acc: 0.8719
Epoch 13/21
 - 21s - loss: 0.2401 - acc: 0.9160 - val_loss: 0.2408 - val_acc: 0.9114
Epoch 14/21
 - 21s - loss: 0.2404 - acc: 0.9158 - val_loss: 0.2292 - val_acc: 0.9169
Epoch 15/21
 - 22s - loss: 0.2362 - acc: 0.9165 - val_loss: 0.2298 - val_acc: 0.9175
Epoch 16/21
 - 21s - loss: 0.2330 - acc: 0.9195 - val_loss: 0.2410 - val_acc: 0.9098
Epoch 17/21
 - 22s - loss: 0.2290 - acc: 0.9205 - val_loss: 0.2484 - val_acc: 0.9051

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 18/21
 - 21s - loss: 0.2230 - acc: 0.9240 - val_loss: 0.2451 - val_acc: 0.9073
Epoch 19/21
 - 21s - loss: 0.2258 - acc: 0.9221 - val_loss: 0.2300 - val_acc: 0.9169
Epoch 00019: early stopping
Test accuracy:0.858
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5066 - acc: 0.7668 - val_loss: 0.4602 - val_acc: 0.7839
Epoch 2/21
 - 21s - loss: 0.4220 - acc: 0.8104 - val_loss: 0.4650 - val_acc: 0.7692
Epoch 3/21
 - 22s - loss: 0.3881 - acc: 0.8308 - val_loss: 0.3713 - val_acc: 0.8401
Epoch 4/21
 - 22s - loss: 0.3574 - acc: 0.8491 - val_loss: 0.4081 - val_acc: 0.8140
Epoch 5/21
 - 22s - loss: 0.3347 - acc: 0.8652 - val_loss: 0.3435 - val_acc: 0.8543
Epoch 6/21
 - 22s - loss: 0.3161 - acc: 0.8744 - val_loss: 0.4092 - val_acc: 0.8038
Epoch 7/21
 - 22s - loss: 0.2989 - acc: 0.8832 - val_loss: 0.5515 - val_acc: 0.7278
Epoch 8/21
 - 22s - loss: 0.2828 - acc: 0.8924 - val_loss: 0.2949 - val_acc: 0.8844
Epoch 9/21
 - 22s - loss: 0.2710 - acc: 0.8983 - val_loss: 0.3131 - val_acc: 0.8784
Epoch 10/21
 - 22s - loss: 0.2560 - acc: 0.9068 - val_loss: 0.4058 - val_acc: 0.8279
Epoch 11/21
 - 22s - loss: 0.2458 - acc: 0.9126 - val_loss: 0.3776 - val_acc: 0.8282

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 22s - loss: 0.2325 - acc: 0.9176 - val_loss: 0.2975 - val_acc: 0.8764
Epoch 00012: early stopping
Test accuracy:0.791
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5284 - acc: 0.7472 - val_loss: 0.4590 - val_acc: 0.7935
Epoch 2/21
 - 22s - loss: 0.4314 - acc: 0.8043 - val_loss: 0.5254 - val_acc: 0.7416
Epoch 3/21
 - 22s - loss: 0.3902 - acc: 0.8292 - val_loss: 0.3645 - val_acc: 0.8485
Epoch 4/21
 - 22s - loss: 0.3623 - acc: 0.8471 - val_loss: 0.3798 - val_acc: 0.8261
Epoch 5/21
 - 22s - loss: 0.3409 - acc: 0.8594 - val_loss: 0.3311 - val_acc: 0.8623
Epoch 6/21
 - 22s - loss: 0.3241 - acc: 0.8684 - val_loss: 0.4156 - val_acc: 0.8100
Epoch 7/21
 - 22s - loss: 0.3083 - acc: 0.8771 - val_loss: 0.2868 - val_acc: 0.8869
Epoch 8/21
 - 22s - loss: 0.2943 - acc: 0.8852 - val_loss: 0.3156 - val_acc: 0.8754
Epoch 9/21
 - 22s - loss: 0.2815 - acc: 0.8914 - val_loss: 0.2688 - val_acc: 0.8978
Epoch 10/21
 - 22s - loss: 0.2679 - acc: 0.8984 - val_loss: 0.2490 - val_acc: 0.9090
Epoch 11/21
 - 22s - loss: 0.2591 - acc: 0.9037 - val_loss: 0.2362 - val_acc: 0.9184
Epoch 12/21
 - 22s - loss: 0.2482 - acc: 0.9089 - val_loss: 0.2495 - val_acc: 0.9045
Epoch 13/21
 - 22s - loss: 0.2379 - acc: 0.9144 - val_loss: 0.2110 - val_acc: 0.9302
Epoch 14/21
 - 22s - loss: 0.2320 - acc: 0.9175 - val_loss: 0.2279 - val_acc: 0.9204
Epoch 15/21
 - 22s - loss: 0.2228 - acc: 0.9216 - val_loss: 0.1912 - val_acc: 0.9366
Epoch 16/21
 - 22s - loss: 0.2158 - acc: 0.9246 - val_loss: 0.2319 - val_acc: 0.9120
Epoch 17/21
 - 22s - loss: 0.2083 - acc: 0.9286 - val_loss: 0.2096 - val_acc: 0.9223
Epoch 18/21
 - 22s - loss: 0.2019 - acc: 0.9319 - val_loss: 0.1927 - val_acc: 0.9302

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 22s - loss: 0.1901 - acc: 0.9372 - val_loss: 0.1687 - val_acc: 0.9475
Epoch 20/21
 - 22s - loss: 0.1881 - acc: 0.9374 - val_loss: 0.1640 - val_acc: 0.9495
Epoch 21/21
 - 22s - loss: 0.1845 - acc: 0.9397 - val_loss: 0.1601 - val_acc: 0.9523
Test accuracy:0.866
current auc_score ------------------> 0.948
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5174 - acc: 0.7674 - val_loss: 0.5323 - val_acc: 0.7331
Epoch 2/21
 - 22s - loss: 0.4157 - acc: 0.8169 - val_loss: 0.3984 - val_acc: 0.8233
Epoch 3/21
 - 22s - loss: 0.3730 - acc: 0.8420 - val_loss: 0.3657 - val_acc: 0.8461
Epoch 4/21
 - 22s - loss: 0.3436 - acc: 0.8601 - val_loss: 0.4517 - val_acc: 0.7914
Epoch 5/21
 - 22s - loss: 0.3214 - acc: 0.8734 - val_loss: 0.3360 - val_acc: 0.8618
Epoch 6/21
 - 21s - loss: 0.3043 - acc: 0.8824 - val_loss: 0.3997 - val_acc: 0.8328
Epoch 7/21
 - 22s - loss: 0.2889 - acc: 0.8916 - val_loss: 0.2680 - val_acc: 0.9019
Epoch 8/21
 - 22s - loss: 0.2776 - acc: 0.8962 - val_loss: 0.3058 - val_acc: 0.8795
Epoch 9/21
 - 21s - loss: 0.2648 - acc: 0.9017 - val_loss: 0.2407 - val_acc: 0.9163
Epoch 10/21
 - 21s - loss: 0.2554 - acc: 0.9068 - val_loss: 0.2272 - val_acc: 0.9174
Epoch 11/21
 - 22s - loss: 0.2447 - acc: 0.9123 - val_loss: 0.2440 - val_acc: 0.9070
Epoch 12/21
 - 21s - loss: 0.2373 - acc: 0.9159 - val_loss: 0.2313 - val_acc: 0.9180
Epoch 13/21
 - 21s - loss: 0.2289 - acc: 0.9204 - val_loss: 0.2126 - val_acc: 0.9260
Epoch 14/21
 - 21s - loss: 0.2198 - acc: 0.9235 - val_loss: 0.1976 - val_acc: 0.9301
Epoch 15/21
 - 22s - loss: 0.2121 - acc: 0.9278 - val_loss: 0.2167 - val_acc: 0.9222
Epoch 16/21
 - 21s - loss: 0.2072 - acc: 0.9282 - val_loss: 0.1855 - val_acc: 0.9434
Epoch 17/21
 - 21s - loss: 0.2028 - acc: 0.9311 - val_loss: 0.1783 - val_acc: 0.9389
Epoch 18/21
 - 21s - loss: 0.1993 - acc: 0.9330 - val_loss: 0.1964 - val_acc: 0.9282
Epoch 19/21
 - 21s - loss: 0.1910 - acc: 0.9373 - val_loss: 0.1867 - val_acc: 0.9366
Epoch 20/21
 - 21s - loss: 0.1868 - acc: 0.9387 - val_loss: 0.1638 - val_acc: 0.9482
Epoch 21/21
 - 21s - loss: 0.1828 - acc: 0.9401 - val_loss: 0.1588 - val_acc: 0.9485
Test accuracy:0.864
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5238 - acc: 0.7617 - val_loss: 0.5746 - val_acc: 0.7065
Epoch 2/21
 - 22s - loss: 0.4275 - acc: 0.8099 - val_loss: 0.4116 - val_acc: 0.8175
Epoch 3/21
 - 22s - loss: 0.3846 - acc: 0.8365 - val_loss: 0.4507 - val_acc: 0.7966
Epoch 4/21
 - 22s - loss: 0.3578 - acc: 0.8522 - val_loss: 0.3961 - val_acc: 0.8331
Epoch 5/21
 - 22s - loss: 0.3372 - acc: 0.8636 - val_loss: 0.3506 - val_acc: 0.8563
Epoch 6/21
 - 21s - loss: 0.3175 - acc: 0.8749 - val_loss: 0.3543 - val_acc: 0.8478
Epoch 7/21
 - 22s - loss: 0.3034 - acc: 0.8822 - val_loss: 0.2938 - val_acc: 0.8873
Epoch 8/21
 - 22s - loss: 0.2915 - acc: 0.8874 - val_loss: 0.3195 - val_acc: 0.8712
Epoch 9/21
 - 22s - loss: 0.2804 - acc: 0.8927 - val_loss: 0.2874 - val_acc: 0.8932
Epoch 10/21
 - 22s - loss: 0.2656 - acc: 0.9014 - val_loss: 0.2614 - val_acc: 0.8940
Epoch 11/21
 - 22s - loss: 0.2593 - acc: 0.9015 - val_loss: 0.2528 - val_acc: 0.9078
Epoch 12/21
 - 22s - loss: 0.2486 - acc: 0.9082 - val_loss: 0.3978 - val_acc: 0.8266
Epoch 13/21
 - 22s - loss: 0.2386 - acc: 0.9149 - val_loss: 0.2730 - val_acc: 0.8904
Epoch 14/21
 - 22s - loss: 0.2294 - acc: 0.9172 - val_loss: 0.2967 - val_acc: 0.8827

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/21
 - 22s - loss: 0.2194 - acc: 0.9230 - val_loss: 0.2101 - val_acc: 0.9297
Epoch 16/21
 - 22s - loss: 0.2149 - acc: 0.9263 - val_loss: 0.2106 - val_acc: 0.9249
Epoch 17/21
 - 22s - loss: 0.2138 - acc: 0.9262 - val_loss: 0.2369 - val_acc: 0.9109
Epoch 18/21
 - 22s - loss: 0.2084 - acc: 0.9281 - val_loss: 0.2108 - val_acc: 0.9256

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 19/21
 - 22s - loss: 0.2054 - acc: 0.9310 - val_loss: 0.2023 - val_acc: 0.9290
Epoch 00019: early stopping
Test accuracy:0.828
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5332 - acc: 0.7480 - val_loss: 0.4596 - val_acc: 0.7893
Epoch 2/21
 - 21s - loss: 0.4251 - acc: 0.8099 - val_loss: 0.3966 - val_acc: 0.8180
Epoch 3/21
 - 21s - loss: 0.3853 - acc: 0.8338 - val_loss: 0.4916 - val_acc: 0.7607
Epoch 4/21
 - 21s - loss: 0.3573 - acc: 0.8517 - val_loss: 0.3893 - val_acc: 0.8202
Epoch 5/21
 - 21s - loss: 0.3354 - acc: 0.8648 - val_loss: 0.3198 - val_acc: 0.8689
Epoch 6/21
 - 21s - loss: 0.3166 - acc: 0.8742 - val_loss: 0.3129 - val_acc: 0.8719
Epoch 7/21
 - 21s - loss: 0.3005 - acc: 0.8841 - val_loss: 0.2671 - val_acc: 0.9040
Epoch 8/21
 - 22s - loss: 0.2876 - acc: 0.8883 - val_loss: 0.3045 - val_acc: 0.8749
Epoch 9/21
 - 22s - loss: 0.2720 - acc: 0.8974 - val_loss: 0.3414 - val_acc: 0.8558
Epoch 10/21
 - 22s - loss: 0.2623 - acc: 0.9029 - val_loss: 0.2650 - val_acc: 0.8978
Epoch 11/21
 - 22s - loss: 0.2544 - acc: 0.9084 - val_loss: 0.2157 - val_acc: 0.9276
Epoch 12/21
 - 22s - loss: 0.2422 - acc: 0.9140 - val_loss: 0.2165 - val_acc: 0.9212
Epoch 13/21
 - 22s - loss: 0.2345 - acc: 0.9170 - val_loss: 0.2190 - val_acc: 0.9256
Epoch 14/21
 - 22s - loss: 0.2288 - acc: 0.9202 - val_loss: 0.2006 - val_acc: 0.9303
Epoch 15/21
 - 22s - loss: 0.2183 - acc: 0.9242 - val_loss: 0.1837 - val_acc: 0.9440
Epoch 16/21
 - 21s - loss: 0.2111 - acc: 0.9290 - val_loss: 0.1861 - val_acc: 0.9362
Epoch 17/21
 - 21s - loss: 0.2071 - acc: 0.9292 - val_loss: 0.1663 - val_acc: 0.9472
Epoch 18/21
 - 21s - loss: 0.2021 - acc: 0.9310 - val_loss: 0.1760 - val_acc: 0.9431
Epoch 19/21
 - 21s - loss: 0.1947 - acc: 0.9354 - val_loss: 0.1740 - val_acc: 0.9428
Epoch 20/21
 - 21s - loss: 0.1887 - acc: 0.9384 - val_loss: 0.1917 - val_acc: 0.9361

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 21/21
 - 21s - loss: 0.1798 - acc: 0.9429 - val_loss: 0.1498 - val_acc: 0.9578
Test accuracy:0.844
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5145 - acc: 0.7581 - val_loss: 0.4452 - val_acc: 0.7922
Epoch 2/21
 - 22s - loss: 0.4172 - acc: 0.8116 - val_loss: 0.4396 - val_acc: 0.7888
Epoch 3/21
 - 21s - loss: 0.3780 - acc: 0.8377 - val_loss: 0.3857 - val_acc: 0.8253
Epoch 4/21
 - 21s - loss: 0.3535 - acc: 0.8519 - val_loss: 0.3542 - val_acc: 0.8456
Epoch 5/21
 - 21s - loss: 0.3355 - acc: 0.8630 - val_loss: 0.3148 - val_acc: 0.8702
Epoch 6/21
 - 21s - loss: 0.3211 - acc: 0.8699 - val_loss: 0.3210 - val_acc: 0.8660
Epoch 7/21
 - 21s - loss: 0.3031 - acc: 0.8808 - val_loss: 0.3526 - val_acc: 0.8608
Epoch 8/21
 - 21s - loss: 0.2937 - acc: 0.8858 - val_loss: 0.2717 - val_acc: 0.8982
Epoch 9/21
 - 21s - loss: 0.2814 - acc: 0.8926 - val_loss: 0.2719 - val_acc: 0.8904
Epoch 10/21
 - 21s - loss: 0.2719 - acc: 0.8969 - val_loss: 0.2783 - val_acc: 0.8912
Epoch 11/21
 - 21s - loss: 0.2606 - acc: 0.9025 - val_loss: 0.2910 - val_acc: 0.8889

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 21s - loss: 0.2490 - acc: 0.9110 - val_loss: 0.2380 - val_acc: 0.9089
Epoch 13/21
 - 22s - loss: 0.2461 - acc: 0.9107 - val_loss: 0.2216 - val_acc: 0.9198
Epoch 14/21
 - 22s - loss: 0.2421 - acc: 0.9123 - val_loss: 0.2213 - val_acc: 0.9184
Epoch 15/21
 - 21s - loss: 0.2395 - acc: 0.9142 - val_loss: 0.2107 - val_acc: 0.9252
Epoch 16/21
 - 21s - loss: 0.2375 - acc: 0.9146 - val_loss: 0.2150 - val_acc: 0.9208
Epoch 17/21
 - 21s - loss: 0.2326 - acc: 0.9178 - val_loss: 0.2285 - val_acc: 0.9129
Epoch 18/21
 - 21s - loss: 0.2323 - acc: 0.9178 - val_loss: 0.2082 - val_acc: 0.9251
Epoch 19/21
 - 22s - loss: 0.2261 - acc: 0.9215 - val_loss: 0.2055 - val_acc: 0.9273
Epoch 20/21
 - 22s - loss: 0.2243 - acc: 0.9212 - val_loss: 0.2152 - val_acc: 0.9218
Epoch 21/21
 - 21s - loss: 0.2228 - acc: 0.9209 - val_loss: 0.2276 - val_acc: 0.9165
Test accuracy:0.857
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5240 - acc: 0.7591 - val_loss: 0.4655 - val_acc: 0.7900
Epoch 2/21
 - 22s - loss: 0.4219 - acc: 0.8126 - val_loss: 0.4009 - val_acc: 0.8251
Epoch 3/21
 - 22s - loss: 0.3814 - acc: 0.8362 - val_loss: 0.3759 - val_acc: 0.8454
Epoch 4/21
 - 22s - loss: 0.3585 - acc: 0.8489 - val_loss: 0.4182 - val_acc: 0.8072
Epoch 5/21
 - 22s - loss: 0.3377 - acc: 0.8602 - val_loss: 0.3222 - val_acc: 0.8716
Epoch 6/21
 - 22s - loss: 0.3209 - acc: 0.8715 - val_loss: 0.3157 - val_acc: 0.8819
Epoch 7/21
 - 22s - loss: 0.3043 - acc: 0.8810 - val_loss: 0.2877 - val_acc: 0.8980
Epoch 8/21
 - 22s - loss: 0.2918 - acc: 0.8878 - val_loss: 0.2791 - val_acc: 0.8958
Epoch 9/21
 - 22s - loss: 0.2806 - acc: 0.8926 - val_loss: 0.2658 - val_acc: 0.9007
Epoch 10/21
 - 22s - loss: 0.2653 - acc: 0.9015 - val_loss: 0.2514 - val_acc: 0.9167
Epoch 11/21
 - 22s - loss: 0.2558 - acc: 0.9065 - val_loss: 0.2503 - val_acc: 0.9119
Epoch 12/21
 - 22s - loss: 0.2458 - acc: 0.9110 - val_loss: 0.2574 - val_acc: 0.9055
Epoch 13/21
 - 22s - loss: 0.2385 - acc: 0.9147 - val_loss: 0.2159 - val_acc: 0.9275
Epoch 14/21
 - 22s - loss: 0.2285 - acc: 0.9205 - val_loss: 0.3168 - val_acc: 0.8760
Epoch 15/21
 - 22s - loss: 0.2197 - acc: 0.9236 - val_loss: 0.1856 - val_acc: 0.9406
Epoch 16/21
 - 22s - loss: 0.2123 - acc: 0.9271 - val_loss: 0.1761 - val_acc: 0.9453
Epoch 17/21
 - 22s - loss: 0.2051 - acc: 0.9313 - val_loss: 0.2565 - val_acc: 0.9016
Epoch 18/21
 - 22s - loss: 0.1998 - acc: 0.9323 - val_loss: 0.1999 - val_acc: 0.9288
Epoch 19/21
 - 22s - loss: 0.1911 - acc: 0.9381 - val_loss: 0.1660 - val_acc: 0.9445
Epoch 20/21
 - 22s - loss: 0.1901 - acc: 0.9376 - val_loss: 0.1860 - val_acc: 0.9400
Epoch 00020: early stopping
Test accuracy:0.859
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5480 - acc: 0.7346 - val_loss: 0.4655 - val_acc: 0.7825
Epoch 2/21
 - 22s - loss: 0.4332 - acc: 0.8007 - val_loss: 0.4184 - val_acc: 0.8045
Epoch 3/21
 - 22s - loss: 0.3964 - acc: 0.8230 - val_loss: 0.4574 - val_acc: 0.7963
Epoch 4/21
 - 21s - loss: 0.3636 - acc: 0.8438 - val_loss: 0.3650 - val_acc: 0.8397
Epoch 5/21
 - 22s - loss: 0.3413 - acc: 0.8572 - val_loss: 0.3371 - val_acc: 0.8611
Epoch 6/21
 - 22s - loss: 0.3217 - acc: 0.8687 - val_loss: 0.3628 - val_acc: 0.8429
Epoch 7/21
 - 22s - loss: 0.3049 - acc: 0.8771 - val_loss: 0.2944 - val_acc: 0.8877
Epoch 8/21
 - 22s - loss: 0.2922 - acc: 0.8841 - val_loss: 0.2655 - val_acc: 0.8997
Epoch 9/21
 - 22s - loss: 0.2810 - acc: 0.8911 - val_loss: 0.2628 - val_acc: 0.9045
Epoch 10/21
 - 22s - loss: 0.2672 - acc: 0.8989 - val_loss: 0.2484 - val_acc: 0.9108
Epoch 11/21
 - 22s - loss: 0.2591 - acc: 0.9025 - val_loss: 0.3036 - val_acc: 0.8823
Epoch 12/21
 - 22s - loss: 0.2487 - acc: 0.9075 - val_loss: 0.2645 - val_acc: 0.9096
Epoch 13/21
 - 22s - loss: 0.2403 - acc: 0.9123 - val_loss: 0.2429 - val_acc: 0.9060
Epoch 14/21
 - 21s - loss: 0.2313 - acc: 0.9165 - val_loss: 0.2261 - val_acc: 0.9228
Epoch 15/21
 - 21s - loss: 0.2236 - acc: 0.9202 - val_loss: 0.2457 - val_acc: 0.9086
Epoch 16/21
 - 21s - loss: 0.2182 - acc: 0.9221 - val_loss: 0.2224 - val_acc: 0.9169
Epoch 17/21
 - 21s - loss: 0.2108 - acc: 0.9270 - val_loss: 0.2011 - val_acc: 0.9280
Epoch 18/21
 - 21s - loss: 0.2039 - acc: 0.9291 - val_loss: 0.2246 - val_acc: 0.9247
Epoch 19/21
 - 21s - loss: 0.1978 - acc: 0.9329 - val_loss: 0.2145 - val_acc: 0.9218
Epoch 20/21
 - 22s - loss: 0.1948 - acc: 0.9334 - val_loss: 0.1750 - val_acc: 0.9463
Epoch 21/21
 - 22s - loss: 0.1899 - acc: 0.9355 - val_loss: 0.1667 - val_acc: 0.9487
Test accuracy:0.835
current auc_score ------------------> 0.951
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   6272        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   10368       activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   13284       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   8100        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11016       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 86, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 43, 12, 12)   3698        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 43, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 43, 6, 6)     172         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 43, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     6966        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 61, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 6, 6)     244         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 61, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     9882        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 79, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 79, 6, 6)     316         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 79, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 79)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            80          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 77,454
Trainable params: 76,060
Non-trainable params: 1,394
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 23s - loss: 0.5169 - acc: 0.7582 - val_loss: 0.4599 - val_acc: 0.7885
Epoch 2/21
 - 22s - loss: 0.4158 - acc: 0.8133 - val_loss: 0.4131 - val_acc: 0.8104
Epoch 3/21
 - 22s - loss: 0.3759 - acc: 0.8382 - val_loss: 0.4659 - val_acc: 0.7784
Epoch 4/21
 - 22s - loss: 0.3482 - acc: 0.8556 - val_loss: 0.3241 - val_acc: 0.8727
Epoch 5/21
 - 22s - loss: 0.3253 - acc: 0.8707 - val_loss: 0.3437 - val_acc: 0.8663
Epoch 6/21
 - 22s - loss: 0.3097 - acc: 0.8774 - val_loss: 0.2868 - val_acc: 0.8958
Epoch 7/21
 - 22s - loss: 0.2977 - acc: 0.8841 - val_loss: 0.2855 - val_acc: 0.8894
Epoch 8/21
 - 22s - loss: 0.2798 - acc: 0.8972 - val_loss: 0.2646 - val_acc: 0.8975
Epoch 9/21
 - 22s - loss: 0.2713 - acc: 0.8974 - val_loss: 0.3441 - val_acc: 0.8632
Epoch 10/21
 - 22s - loss: 0.2606 - acc: 0.9059 - val_loss: 0.3061 - val_acc: 0.8829
Epoch 11/21
 - 22s - loss: 0.2489 - acc: 0.9105 - val_loss: 0.2695 - val_acc: 0.8962

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/21
 - 21s - loss: 0.2342 - acc: 0.9176 - val_loss: 0.2347 - val_acc: 0.9133
Epoch 13/21
 - 21s - loss: 0.2302 - acc: 0.9199 - val_loss: 0.2320 - val_acc: 0.9163
Epoch 14/21
 - 22s - loss: 0.2262 - acc: 0.9208 - val_loss: 0.2216 - val_acc: 0.9211
Epoch 15/21
 - 22s - loss: 0.2246 - acc: 0.9213 - val_loss: 0.2244 - val_acc: 0.9204
Epoch 16/21
 - 22s - loss: 0.2247 - acc: 0.9209 - val_loss: 0.2071 - val_acc: 0.9319
Epoch 17/21
 - 22s - loss: 0.2168 - acc: 0.9264 - val_loss: 0.1903 - val_acc: 0.9384
Epoch 18/21
 - 22s - loss: 0.2156 - acc: 0.9267 - val_loss: 0.2008 - val_acc: 0.9316
Epoch 19/21
 - 22s - loss: 0.2127 - acc: 0.9275 - val_loss: 0.2395 - val_acc: 0.9105
Epoch 20/21
 - 22s - loss: 0.2101 - acc: 0.9296 - val_loss: 0.2020 - val_acc: 0.9327

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 21/21
 - 22s - loss: 0.2057 - acc: 0.9314 - val_loss: 0.2315 - val_acc: 0.9148
Epoch 00021: early stopping
Test accuracy:0.890
current auc_score ------------------> 0.951
Saved model to disk
accuracies:  [0.8577956989247312, 0.790994623655914, 0.8658602150537634, 0.8638440860215054, 0.828494623655914, 0.844489247311828, 0.8573924731182796, 0.8594086021505376, 0.8349462365591398, 0.8897849462365591]
aucs:  [0.9351, 0.9245, 0.9483, 0.9458, 0.9456, 0.9471, 0.9376, 0.9425, 0.9507, 0.9509]
mean and std AUC:  0.943+/-0.008  max:   0.9509
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0', 'FALSE', '64', 'avg'], '0.942+/-0.014', 0.962)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.2', 'FALSE', '64', 'avg'], '0.929+/-0.012', 0.942)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.3', 'FALSE', '64', 'avg'], '0.939+/-0.017', 0.958)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.7', 'FALSE', '64', 'avg'], '0.939+/-0.008', 0.949)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0', 'TRUE', '64', 'avg'], '0.922+/-0.01', 0.937)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.2', 'TRUE', '64', 'avg'], '0.926+/-0.011', 0.943)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.3', 'TRUE', '64', 'avg'], '0.921+/-0.016', 0.943)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'TRUE', '64', 'avg'], '0.927+/-0.016', 0.941)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.7', 'TRUE', '64', 'avg'], '0.924+/-0.009', 0.938)
(['2-2-2', '30', '3', '16', '0', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.916+/-0.011', 0.936)
(['2-2-2', '30', '3', '16', '0.1', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.932+/-0.015', 0.948)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.938+/-0.012', 0.959)
(['2-2-2', '30', '3', '16', '0.3', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.934+/-0.01', 0.946)
(['2-2-2', '30', '3', '16', '0.4', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.932+/-0.018', 0.956)
(['2-2-2', '30', '3', '16', '0.5', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.928+/-0.018', 0.951)
(['2-2-2', '30', '3', '16', '0.6', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.922+/-0.023', 0.953)
(['2-2-2', '30', '3', '16', '0.7', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.929+/-0.019', 0.951)
(['2-2-2', '30', '3', '8', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.947+/-0.006', 0.956)
(['2-2-2', '30', '3', '32', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.94+/-0.013', 0.957)
(['2-2-2', '30', '3', '64', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.928+/-0.019', 0.951)
(['2-2-2', '18', '3', '8', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.94+/-0.013', 0.955)
(['2-2-2', '18', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.942+/-0.011', 0.96)
(['2-2-2', '18', '3', '32', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.946+/-0.006', 0.956)
(['2-2-2', '18', '3', '64', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'avg'], '0.943+/-0.008', 0.951)
