python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, fc_dropout, fc_filter, fc_layers
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 25s - loss: 0.4216 - acc: 0.8199 - val_loss: 0.2350 - val_acc: 0.9160
Epoch 2/12
 - 19s - loss: 0.1894 - acc: 0.9336 - val_loss: 0.1300 - val_acc: 0.9641
Epoch 3/12
 - 19s - loss: 0.1236 - acc: 0.9620 - val_loss: 0.0869 - val_acc: 0.9838
Epoch 4/12
 - 19s - loss: 0.0853 - acc: 0.9771 - val_loss: 0.0570 - val_acc: 0.9898
Epoch 5/12
 - 19s - loss: 0.0639 - acc: 0.9848 - val_loss: 0.0435 - val_acc: 0.9923
Epoch 6/12
 - 19s - loss: 0.0475 - acc: 0.9900 - val_loss: 0.0333 - val_acc: 0.9957
Epoch 7/12
 - 19s - loss: 0.0411 - acc: 0.9915 - val_loss: 0.0281 - val_acc: 0.9961
Epoch 8/12
 - 19s - loss: 0.0357 - acc: 0.9939 - val_loss: 0.0287 - val_acc: 0.9966
Epoch 9/12
 - 19s - loss: 0.0310 - acc: 0.9950 - val_loss: 0.0241 - val_acc: 0.9975
Epoch 10/12
 - 19s - loss: 0.0277 - acc: 0.9955 - val_loss: 0.0199 - val_acc: 0.9980
Epoch 11/12
 - 19s - loss: 0.0265 - acc: 0.9956 - val_loss: 0.0184 - val_acc: 0.9979
Epoch 12/12
 - 19s - loss: 0.0229 - acc: 0.9972 - val_loss: 0.0170 - val_acc: 0.9977
Test accuracy:0.709
current auc_score ------------------> 0.861
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4242 - acc: 0.8176 - val_loss: 0.2302 - val_acc: 0.9183
Epoch 2/12
 - 20s - loss: 0.1965 - acc: 0.9290 - val_loss: 0.1311 - val_acc: 0.9636
Epoch 3/12
 - 19s - loss: 0.1244 - acc: 0.9607 - val_loss: 0.0799 - val_acc: 0.9822
Epoch 4/12
 - 19s - loss: 0.0867 - acc: 0.9762 - val_loss: 0.0561 - val_acc: 0.9883
Epoch 5/12
 - 20s - loss: 0.0642 - acc: 0.9849 - val_loss: 0.0485 - val_acc: 0.9931
Epoch 6/12
 - 20s - loss: 0.0490 - acc: 0.9899 - val_loss: 0.0358 - val_acc: 0.9946
Epoch 7/12
 - 19s - loss: 0.0379 - acc: 0.9939 - val_loss: 0.0267 - val_acc: 0.9967
Epoch 8/12
 - 19s - loss: 0.0325 - acc: 0.9945 - val_loss: 0.0236 - val_acc: 0.9969
Epoch 9/12
 - 19s - loss: 0.0296 - acc: 0.9952 - val_loss: 0.0206 - val_acc: 0.9970
Epoch 10/12
 - 20s - loss: 0.0264 - acc: 0.9962 - val_loss: 0.0192 - val_acc: 0.9971
Epoch 11/12
 - 20s - loss: 0.0249 - acc: 0.9962 - val_loss: 0.0178 - val_acc: 0.9974
Epoch 12/12
 - 20s - loss: 0.0226 - acc: 0.9971 - val_loss: 0.0158 - val_acc: 0.9979
Test accuracy:0.694
current auc_score ------------------> 0.850
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4326 - acc: 0.8165 - val_loss: 0.2295 - val_acc: 0.9178
Epoch 2/12
 - 19s - loss: 0.2005 - acc: 0.9263 - val_loss: 0.1237 - val_acc: 0.9649
Epoch 3/12
 - 19s - loss: 0.1242 - acc: 0.9611 - val_loss: 0.0800 - val_acc: 0.9809
Epoch 4/12
 - 19s - loss: 0.0885 - acc: 0.9754 - val_loss: 0.0624 - val_acc: 0.9859
Epoch 5/12
 - 19s - loss: 0.0659 - acc: 0.9842 - val_loss: 0.0427 - val_acc: 0.9921
Epoch 6/12
 - 19s - loss: 0.0522 - acc: 0.9882 - val_loss: 0.0397 - val_acc: 0.9933
Epoch 7/12
 - 19s - loss: 0.0406 - acc: 0.9926 - val_loss: 0.0279 - val_acc: 0.9950
Epoch 8/12
 - 19s - loss: 0.0340 - acc: 0.9943 - val_loss: 0.0246 - val_acc: 0.9967
Epoch 9/12
 - 19s - loss: 0.0324 - acc: 0.9945 - val_loss: 0.0253 - val_acc: 0.9971
Epoch 10/12
 - 20s - loss: 0.0283 - acc: 0.9954 - val_loss: 0.0247 - val_acc: 0.9974
Epoch 11/12
 - 19s - loss: 0.0260 - acc: 0.9961 - val_loss: 0.0190 - val_acc: 0.9971
Epoch 12/12
 - 19s - loss: 0.0231 - acc: 0.9966 - val_loss: 0.0163 - val_acc: 0.9982
Test accuracy:0.689
current auc_score ------------------> 0.863
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4260 - acc: 0.8146 - val_loss: 0.2298 - val_acc: 0.9153
Epoch 2/12
 - 20s - loss: 0.2049 - acc: 0.9233 - val_loss: 0.1386 - val_acc: 0.9596
Epoch 3/12
 - 19s - loss: 0.1353 - acc: 0.9570 - val_loss: 0.1035 - val_acc: 0.9775
Epoch 4/12
 - 19s - loss: 0.0972 - acc: 0.9737 - val_loss: 0.0846 - val_acc: 0.9800
Epoch 5/12
 - 19s - loss: 0.0725 - acc: 0.9821 - val_loss: 0.0509 - val_acc: 0.9907
Epoch 6/12
 - 19s - loss: 0.0558 - acc: 0.9884 - val_loss: 0.0421 - val_acc: 0.9930
Epoch 7/12
 - 19s - loss: 0.0455 - acc: 0.9913 - val_loss: 0.0380 - val_acc: 0.9939
Epoch 8/12
 - 19s - loss: 0.0385 - acc: 0.9928 - val_loss: 0.0316 - val_acc: 0.9959
Epoch 9/12
 - 19s - loss: 0.0366 - acc: 0.9934 - val_loss: 0.0263 - val_acc: 0.9970
Epoch 10/12
 - 19s - loss: 0.0323 - acc: 0.9949 - val_loss: 0.0225 - val_acc: 0.9981
Epoch 11/12
 - 19s - loss: 0.0280 - acc: 0.9956 - val_loss: 0.0264 - val_acc: 0.9981
Epoch 12/12
 - 19s - loss: 0.0264 - acc: 0.9959 - val_loss: 0.0182 - val_acc: 0.9979
Test accuracy:0.668
current auc_score ------------------> 0.874
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 21s - loss: 0.4128 - acc: 0.8240 - val_loss: 0.2481 - val_acc: 0.9079
Epoch 2/12
 - 19s - loss: 0.2004 - acc: 0.9260 - val_loss: 0.1518 - val_acc: 0.9571
Epoch 3/12
 - 19s - loss: 0.1277 - acc: 0.9597 - val_loss: 0.0972 - val_acc: 0.9803
Epoch 4/12
 - 19s - loss: 0.0887 - acc: 0.9747 - val_loss: 0.0595 - val_acc: 0.9872
Epoch 5/12
 - 19s - loss: 0.0647 - acc: 0.9840 - val_loss: 0.0462 - val_acc: 0.9907
Epoch 6/12
 - 19s - loss: 0.0524 - acc: 0.9885 - val_loss: 0.0411 - val_acc: 0.9940
Epoch 7/12
 - 19s - loss: 0.0396 - acc: 0.9932 - val_loss: 0.0294 - val_acc: 0.9955
Epoch 8/12
 - 19s - loss: 0.0345 - acc: 0.9938 - val_loss: 0.0245 - val_acc: 0.9957
Epoch 9/12
 - 19s - loss: 0.0302 - acc: 0.9955 - val_loss: 0.0213 - val_acc: 0.9971
Epoch 10/12
 - 19s - loss: 0.0270 - acc: 0.9960 - val_loss: 0.0200 - val_acc: 0.9961
Epoch 11/12
 - 19s - loss: 0.0242 - acc: 0.9970 - val_loss: 0.0181 - val_acc: 0.9982
Epoch 12/12
 - 19s - loss: 0.0224 - acc: 0.9973 - val_loss: 0.0171 - val_acc: 0.9980
Test accuracy:0.679
current auc_score ------------------> 0.876
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 21s - loss: 0.4243 - acc: 0.8187 - val_loss: 0.2165 - val_acc: 0.9244
Epoch 2/12
 - 19s - loss: 0.2057 - acc: 0.9218 - val_loss: 0.1364 - val_acc: 0.9620
Epoch 3/12
 - 19s - loss: 0.1320 - acc: 0.9567 - val_loss: 0.0793 - val_acc: 0.9813
Epoch 4/12
 - 19s - loss: 0.0902 - acc: 0.9741 - val_loss: 0.0697 - val_acc: 0.9852
Epoch 5/12
 - 18s - loss: 0.0669 - acc: 0.9836 - val_loss: 0.0556 - val_acc: 0.9905
Epoch 6/12
 - 18s - loss: 0.0551 - acc: 0.9875 - val_loss: 0.0421 - val_acc: 0.9950
Epoch 7/12
 - 19s - loss: 0.0464 - acc: 0.9906 - val_loss: 0.0343 - val_acc: 0.9955
Epoch 8/12
 - 18s - loss: 0.0366 - acc: 0.9928 - val_loss: 0.0239 - val_acc: 0.9966
Epoch 9/12
 - 19s - loss: 0.0321 - acc: 0.9950 - val_loss: 0.0241 - val_acc: 0.9966
Epoch 10/12
 - 19s - loss: 0.0277 - acc: 0.9957 - val_loss: 0.0192 - val_acc: 0.9977
Epoch 11/12
 - 19s - loss: 0.0273 - acc: 0.9955 - val_loss: 0.0202 - val_acc: 0.9977
Epoch 12/12
 - 19s - loss: 0.0227 - acc: 0.9971 - val_loss: 0.0186 - val_acc: 0.9982
Test accuracy:0.691
current auc_score ------------------> 0.900
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4545 - acc: 0.8024 - val_loss: 0.2539 - val_acc: 0.9078
Epoch 2/12
 - 19s - loss: 0.2237 - acc: 0.9147 - val_loss: 0.1327 - val_acc: 0.9610
Epoch 3/12
 - 19s - loss: 0.1423 - acc: 0.9539 - val_loss: 0.0870 - val_acc: 0.9775
Epoch 4/12
 - 19s - loss: 0.0976 - acc: 0.9723 - val_loss: 0.0696 - val_acc: 0.9831
Epoch 5/12
 - 19s - loss: 0.0733 - acc: 0.9822 - val_loss: 0.0503 - val_acc: 0.9907
Epoch 6/12
 - 19s - loss: 0.0537 - acc: 0.9885 - val_loss: 0.0403 - val_acc: 0.9931
Epoch 7/12
 - 19s - loss: 0.0449 - acc: 0.9913 - val_loss: 0.0302 - val_acc: 0.9954
Epoch 8/12
 - 19s - loss: 0.0381 - acc: 0.9929 - val_loss: 0.0241 - val_acc: 0.9955
Epoch 9/12
 - 19s - loss: 0.0316 - acc: 0.9947 - val_loss: 0.0220 - val_acc: 0.9981
Epoch 10/12
 - 20s - loss: 0.0291 - acc: 0.9953 - val_loss: 0.0198 - val_acc: 0.9980
Epoch 11/12
 - 20s - loss: 0.0276 - acc: 0.9957 - val_loss: 0.0176 - val_acc: 0.9987
Epoch 12/12
 - 20s - loss: 0.0241 - acc: 0.9969 - val_loss: 0.0161 - val_acc: 0.9985
Test accuracy:0.689
current auc_score ------------------> 0.830
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4288 - acc: 0.8164 - val_loss: 0.2345 - val_acc: 0.9153
Epoch 2/12
 - 19s - loss: 0.2015 - acc: 0.9265 - val_loss: 0.1357 - val_acc: 0.9621
Epoch 3/12
 - 19s - loss: 0.1288 - acc: 0.9591 - val_loss: 0.0986 - val_acc: 0.9762
Epoch 4/12
 - 19s - loss: 0.0903 - acc: 0.9762 - val_loss: 0.0653 - val_acc: 0.9838
Epoch 5/12
 - 19s - loss: 0.0691 - acc: 0.9835 - val_loss: 0.0553 - val_acc: 0.9917
Epoch 6/12
 - 20s - loss: 0.0534 - acc: 0.9887 - val_loss: 0.0381 - val_acc: 0.9937
Epoch 7/12
 - 20s - loss: 0.0432 - acc: 0.9920 - val_loss: 0.0350 - val_acc: 0.9945
Epoch 8/12
 - 20s - loss: 0.0387 - acc: 0.9927 - val_loss: 0.0292 - val_acc: 0.9950
Epoch 9/12
 - 19s - loss: 0.0335 - acc: 0.9945 - val_loss: 0.0262 - val_acc: 0.9955
Epoch 10/12
 - 20s - loss: 0.0278 - acc: 0.9961 - val_loss: 0.0249 - val_acc: 0.9962
Epoch 11/12
 - 20s - loss: 0.0266 - acc: 0.9959 - val_loss: 0.0216 - val_acc: 0.9966
Epoch 12/12
 - 20s - loss: 0.0242 - acc: 0.9964 - val_loss: 0.0212 - val_acc: 0.9964
Test accuracy:0.671
current auc_score ------------------> 0.843
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4205 - acc: 0.8224 - val_loss: 0.2064 - val_acc: 0.9255
Epoch 2/12
 - 20s - loss: 0.1921 - acc: 0.9304 - val_loss: 0.1085 - val_acc: 0.9716
Epoch 3/12
 - 19s - loss: 0.1190 - acc: 0.9642 - val_loss: 0.0737 - val_acc: 0.9854
Epoch 4/12
 - 19s - loss: 0.0828 - acc: 0.9794 - val_loss: 0.0549 - val_acc: 0.9880
Epoch 5/12
 - 19s - loss: 0.0640 - acc: 0.9853 - val_loss: 0.0425 - val_acc: 0.9913
Epoch 6/12
 - 19s - loss: 0.0493 - acc: 0.9896 - val_loss: 0.0373 - val_acc: 0.9947
Epoch 7/12
 - 19s - loss: 0.0401 - acc: 0.9927 - val_loss: 0.0265 - val_acc: 0.9957
Epoch 8/12
 - 19s - loss: 0.0339 - acc: 0.9942 - val_loss: 0.0256 - val_acc: 0.9964
Epoch 9/12
 - 19s - loss: 0.0317 - acc: 0.9941 - val_loss: 0.0242 - val_acc: 0.9961
Epoch 10/12
 - 20s - loss: 0.0286 - acc: 0.9953 - val_loss: 0.0185 - val_acc: 0.9982
Epoch 11/12
 - 19s - loss: 0.0244 - acc: 0.9967 - val_loss: 0.0172 - val_acc: 0.9977
Epoch 12/12
 - 19s - loss: 0.0230 - acc: 0.9970 - val_loss: 0.0168 - val_acc: 0.9980
Test accuracy:0.742
current auc_score ------------------> 0.859
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4279 - acc: 0.8170 - val_loss: 0.2344 - val_acc: 0.9075
Epoch 2/12
 - 20s - loss: 0.2007 - acc: 0.9256 - val_loss: 0.1303 - val_acc: 0.9549
Epoch 3/12
 - 20s - loss: 0.1286 - acc: 0.9584 - val_loss: 0.0861 - val_acc: 0.9790
Epoch 4/12
 - 20s - loss: 0.0862 - acc: 0.9769 - val_loss: 0.0666 - val_acc: 0.9863
Epoch 5/12
 - 19s - loss: 0.0661 - acc: 0.9848 - val_loss: 0.0437 - val_acc: 0.9928
Epoch 6/12
 - 19s - loss: 0.0550 - acc: 0.9876 - val_loss: 0.0349 - val_acc: 0.9941
Epoch 7/12
 - 19s - loss: 0.0459 - acc: 0.9906 - val_loss: 0.0367 - val_acc: 0.9949
Epoch 8/12
 - 19s - loss: 0.0367 - acc: 0.9939 - val_loss: 0.0254 - val_acc: 0.9956
Epoch 9/12
 - 19s - loss: 0.0326 - acc: 0.9943 - val_loss: 0.0234 - val_acc: 0.9960
Epoch 10/12
 - 19s - loss: 0.0282 - acc: 0.9952 - val_loss: 0.0223 - val_acc: 0.9965
Epoch 11/12
 - 19s - loss: 0.0277 - acc: 0.9955 - val_loss: 0.0203 - val_acc: 0.9962
Epoch 12/12
 - 19s - loss: 0.0236 - acc: 0.9969 - val_loss: 0.0188 - val_acc: 0.9976
Test accuracy:0.675
current auc_score ------------------> 0.911
accuracies:  [0.7091397849462365, 0.6936827956989248, 0.6889784946236559, 0.6676075268817204, 0.6788978494623656, 0.6912634408602151, 0.6893817204301075, 0.6713709677419355, 0.7420698924731183, 0.6745967741935484]
aucs:  [0.861, 0.8504, 0.8627, 0.8739, 0.8765, 0.9002, 0.83, 0.8431, 0.8585, 0.9107]
mean and std AUC:  0.867+/-0.023  max:   0.9107
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4075 - acc: 0.8261 - val_loss: 0.2011 - val_acc: 0.9285
Epoch 2/12
 - 19s - loss: 0.1854 - acc: 0.9337 - val_loss: 0.1328 - val_acc: 0.9641
Epoch 3/12
 - 19s - loss: 0.1140 - acc: 0.9671 - val_loss: 0.0745 - val_acc: 0.9848
Epoch 4/12
 - 19s - loss: 0.0780 - acc: 0.9816 - val_loss: 0.0473 - val_acc: 0.9922
Epoch 5/12
 - 19s - loss: 0.0591 - acc: 0.9878 - val_loss: 0.0394 - val_acc: 0.9946
Epoch 6/12
 - 19s - loss: 0.0465 - acc: 0.9915 - val_loss: 0.0311 - val_acc: 0.9965
Epoch 7/12
 - 19s - loss: 0.0389 - acc: 0.9941 - val_loss: 0.0263 - val_acc: 0.9967
Epoch 8/12
 - 19s - loss: 0.0318 - acc: 0.9957 - val_loss: 0.0208 - val_acc: 0.9982
Epoch 9/12
 - 19s - loss: 0.0304 - acc: 0.9953 - val_loss: 0.0206 - val_acc: 0.9979
Epoch 10/12
 - 19s - loss: 0.0262 - acc: 0.9967 - val_loss: 0.0193 - val_acc: 0.9987
Epoch 11/12
 - 19s - loss: 0.0254 - acc: 0.9966 - val_loss: 0.0182 - val_acc: 0.9982
Epoch 12/12
 - 19s - loss: 0.0206 - acc: 0.9981 - val_loss: 0.0155 - val_acc: 0.9987
Test accuracy:0.722
current auc_score ------------------> 0.838
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4380 - acc: 0.8089 - val_loss: 0.2375 - val_acc: 0.9162
Epoch 2/12
 - 20s - loss: 0.2146 - acc: 0.9207 - val_loss: 0.1348 - val_acc: 0.9632
Epoch 3/12
 - 20s - loss: 0.1352 - acc: 0.9582 - val_loss: 0.0905 - val_acc: 0.9780
Epoch 4/12
 - 20s - loss: 0.0938 - acc: 0.9750 - val_loss: 0.0634 - val_acc: 0.9882
Epoch 5/12
 - 19s - loss: 0.0695 - acc: 0.9831 - val_loss: 0.0482 - val_acc: 0.9935
Epoch 6/12
 - 20s - loss: 0.0558 - acc: 0.9890 - val_loss: 0.0467 - val_acc: 0.9926
Epoch 7/12
 - 19s - loss: 0.0471 - acc: 0.9913 - val_loss: 0.0347 - val_acc: 0.9946
Epoch 8/12
 - 20s - loss: 0.0390 - acc: 0.9939 - val_loss: 0.0296 - val_acc: 0.9977
Epoch 9/12
 - 20s - loss: 0.0358 - acc: 0.9944 - val_loss: 0.0251 - val_acc: 0.9979
Epoch 10/12
 - 20s - loss: 0.0319 - acc: 0.9955 - val_loss: 0.0204 - val_acc: 0.9981
Epoch 11/12
 - 20s - loss: 0.0280 - acc: 0.9964 - val_loss: 0.0195 - val_acc: 0.9980
Epoch 12/12
 - 20s - loss: 0.0285 - acc: 0.9961 - val_loss: 0.0191 - val_acc: 0.9982
Test accuracy:0.739
current auc_score ------------------> 0.888
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4650 - acc: 0.7958 - val_loss: 0.2722 - val_acc: 0.8919
Epoch 2/12
 - 19s - loss: 0.2258 - acc: 0.9156 - val_loss: 0.1459 - val_acc: 0.9608
Epoch 3/12
 - 19s - loss: 0.1423 - acc: 0.9549 - val_loss: 0.0988 - val_acc: 0.9783
Epoch 4/12
 - 19s - loss: 0.0995 - acc: 0.9734 - val_loss: 0.0627 - val_acc: 0.9872
Epoch 5/12
 - 19s - loss: 0.0757 - acc: 0.9820 - val_loss: 0.0527 - val_acc: 0.9928
Epoch 6/12
 - 20s - loss: 0.0589 - acc: 0.9877 - val_loss: 0.0428 - val_acc: 0.9945
Epoch 7/12
 - 20s - loss: 0.0472 - acc: 0.9914 - val_loss: 0.0335 - val_acc: 0.9960
Epoch 8/12
 - 19s - loss: 0.0390 - acc: 0.9941 - val_loss: 0.0253 - val_acc: 0.9970
Epoch 9/12
 - 20s - loss: 0.0352 - acc: 0.9939 - val_loss: 0.0244 - val_acc: 0.9974
Epoch 10/12
 - 19s - loss: 0.0335 - acc: 0.9946 - val_loss: 0.0269 - val_acc: 0.9972
Epoch 11/12
 - 19s - loss: 0.0296 - acc: 0.9961 - val_loss: 0.0194 - val_acc: 0.9982
Epoch 12/12
 - 19s - loss: 0.0256 - acc: 0.9971 - val_loss: 0.0181 - val_acc: 0.9989
Test accuracy:0.668
current auc_score ------------------> 0.920
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4310 - acc: 0.8125 - val_loss: 0.2444 - val_acc: 0.9128
Epoch 2/12
 - 20s - loss: 0.2063 - acc: 0.9272 - val_loss: 0.1474 - val_acc: 0.9637
Epoch 3/12
 - 20s - loss: 0.1261 - acc: 0.9627 - val_loss: 0.0971 - val_acc: 0.9833
Epoch 4/12
 - 20s - loss: 0.0844 - acc: 0.9790 - val_loss: 0.0673 - val_acc: 0.9892
Epoch 5/12
 - 20s - loss: 0.0650 - acc: 0.9851 - val_loss: 0.0430 - val_acc: 0.9935
Epoch 6/12
 - 20s - loss: 0.0514 - acc: 0.9890 - val_loss: 0.0382 - val_acc: 0.9949
Epoch 7/12
 - 20s - loss: 0.0423 - acc: 0.9923 - val_loss: 0.0339 - val_acc: 0.9971
Epoch 8/12
 - 20s - loss: 0.0352 - acc: 0.9947 - val_loss: 0.0295 - val_acc: 0.9951
Epoch 9/12
 - 20s - loss: 0.0317 - acc: 0.9958 - val_loss: 0.0264 - val_acc: 0.9970
Epoch 10/12
 - 19s - loss: 0.0288 - acc: 0.9959 - val_loss: 0.0306 - val_acc: 0.9972
Epoch 11/12
 - 20s - loss: 0.0254 - acc: 0.9965 - val_loss: 0.0201 - val_acc: 0.9979
Epoch 12/12
 - 20s - loss: 0.0220 - acc: 0.9979 - val_loss: 0.0176 - val_acc: 0.9992
Test accuracy:0.674
current auc_score ------------------> 0.889
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4240 - acc: 0.8196 - val_loss: 0.2161 - val_acc: 0.9298
Epoch 2/12
 - 20s - loss: 0.2009 - acc: 0.9283 - val_loss: 0.1307 - val_acc: 0.9686
Epoch 3/12
 - 20s - loss: 0.1279 - acc: 0.9601 - val_loss: 0.0907 - val_acc: 0.9813
Epoch 4/12
 - 20s - loss: 0.0909 - acc: 0.9773 - val_loss: 0.0696 - val_acc: 0.9876
Epoch 5/12
 - 20s - loss: 0.0713 - acc: 0.9830 - val_loss: 0.0588 - val_acc: 0.9903
Epoch 6/12
 - 20s - loss: 0.0593 - acc: 0.9871 - val_loss: 0.0463 - val_acc: 0.9935
Epoch 7/12
 - 20s - loss: 0.0491 - acc: 0.9907 - val_loss: 0.0324 - val_acc: 0.9961
Epoch 8/12
 - 20s - loss: 0.0411 - acc: 0.9928 - val_loss: 0.0262 - val_acc: 0.9965
Epoch 9/12
 - 20s - loss: 0.0352 - acc: 0.9942 - val_loss: 0.0248 - val_acc: 0.9981
Epoch 10/12
 - 20s - loss: 0.0331 - acc: 0.9951 - val_loss: 0.0214 - val_acc: 0.9984
Epoch 11/12
 - 20s - loss: 0.0300 - acc: 0.9957 - val_loss: 0.0207 - val_acc: 0.9982
Epoch 12/12
 - 20s - loss: 0.0271 - acc: 0.9963 - val_loss: 0.0183 - val_acc: 0.9984
Test accuracy:0.685
current auc_score ------------------> 0.897
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4459 - acc: 0.8045 - val_loss: 0.2494 - val_acc: 0.9090
Epoch 2/12
 - 20s - loss: 0.2189 - acc: 0.9179 - val_loss: 0.1496 - val_acc: 0.9603
Epoch 3/12
 - 19s - loss: 0.1349 - acc: 0.9587 - val_loss: 0.0906 - val_acc: 0.9802
Epoch 4/12
 - 19s - loss: 0.0936 - acc: 0.9755 - val_loss: 0.0693 - val_acc: 0.9881
Epoch 5/12
 - 19s - loss: 0.0693 - acc: 0.9839 - val_loss: 0.0509 - val_acc: 0.9910
Epoch 6/12
 - 19s - loss: 0.0544 - acc: 0.9890 - val_loss: 0.0350 - val_acc: 0.9970
Epoch 7/12
 - 19s - loss: 0.0426 - acc: 0.9932 - val_loss: 0.0318 - val_acc: 0.9952
Epoch 8/12
 - 19s - loss: 0.0400 - acc: 0.9929 - val_loss: 0.0266 - val_acc: 0.9962
Epoch 9/12
 - 20s - loss: 0.0345 - acc: 0.9946 - val_loss: 0.0226 - val_acc: 0.9982
Epoch 10/12
 - 19s - loss: 0.0295 - acc: 0.9959 - val_loss: 0.0183 - val_acc: 0.9987
Epoch 11/12
 - 19s - loss: 0.0261 - acc: 0.9964 - val_loss: 0.0178 - val_acc: 0.9984
Epoch 12/12
 - 19s - loss: 0.0241 - acc: 0.9971 - val_loss: 0.0180 - val_acc: 0.9996
Test accuracy:0.612
current auc_score ------------------> 0.879
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 21s - loss: 0.4356 - acc: 0.8105 - val_loss: 0.2352 - val_acc: 0.9211
Epoch 2/12
 - 19s - loss: 0.2120 - acc: 0.9229 - val_loss: 0.1489 - val_acc: 0.9595
Epoch 3/12
 - 19s - loss: 0.1338 - acc: 0.9596 - val_loss: 0.0918 - val_acc: 0.9794
Epoch 4/12
 - 19s - loss: 0.0955 - acc: 0.9748 - val_loss: 0.0632 - val_acc: 0.9903
Epoch 5/12
 - 19s - loss: 0.0686 - acc: 0.9847 - val_loss: 0.0542 - val_acc: 0.9932
Epoch 6/12
 - 19s - loss: 0.0557 - acc: 0.9880 - val_loss: 0.0398 - val_acc: 0.9950
Epoch 7/12
 - 19s - loss: 0.0440 - acc: 0.9921 - val_loss: 0.0354 - val_acc: 0.9952
Epoch 8/12
 - 19s - loss: 0.0386 - acc: 0.9939 - val_loss: 0.0269 - val_acc: 0.9965
Epoch 9/12
 - 20s - loss: 0.0337 - acc: 0.9949 - val_loss: 0.0245 - val_acc: 0.9979
Epoch 10/12
 - 19s - loss: 0.0289 - acc: 0.9958 - val_loss: 0.0210 - val_acc: 0.9979
Epoch 11/12
 - 20s - loss: 0.0252 - acc: 0.9971 - val_loss: 0.0166 - val_acc: 0.9986
Epoch 12/12
 - 19s - loss: 0.0233 - acc: 0.9976 - val_loss: 0.0169 - val_acc: 0.9990
Test accuracy:0.711
current auc_score ------------------> 0.877
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4550 - acc: 0.8037 - val_loss: 0.2685 - val_acc: 0.8962
Epoch 2/12
 - 19s - loss: 0.2190 - acc: 0.9192 - val_loss: 0.1743 - val_acc: 0.9464
Epoch 3/12
 - 19s - loss: 0.1446 - acc: 0.9535 - val_loss: 0.1123 - val_acc: 0.9785
Epoch 4/12
 - 19s - loss: 0.0994 - acc: 0.9731 - val_loss: 0.0638 - val_acc: 0.9854
Epoch 5/12
 - 20s - loss: 0.0786 - acc: 0.9818 - val_loss: 0.0500 - val_acc: 0.9902
Epoch 6/12
 - 19s - loss: 0.0584 - acc: 0.9877 - val_loss: 0.0390 - val_acc: 0.9949
Epoch 7/12
 - 19s - loss: 0.0465 - acc: 0.9914 - val_loss: 0.0355 - val_acc: 0.9964
Epoch 8/12
 - 19s - loss: 0.0405 - acc: 0.9930 - val_loss: 0.0259 - val_acc: 0.9981
Epoch 9/12
 - 19s - loss: 0.0329 - acc: 0.9950 - val_loss: 0.0226 - val_acc: 0.9984
Epoch 10/12
 - 19s - loss: 0.0293 - acc: 0.9960 - val_loss: 0.0202 - val_acc: 0.9984
Epoch 11/12
 - 20s - loss: 0.0257 - acc: 0.9967 - val_loss: 0.0200 - val_acc: 0.9972
Epoch 12/12
 - 20s - loss: 0.0267 - acc: 0.9962 - val_loss: 0.0234 - val_acc: 0.9970
Test accuracy:0.724
current auc_score ------------------> 0.898
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4474 - acc: 0.8053 - val_loss: 0.2495 - val_acc: 0.9096
Epoch 2/12
 - 20s - loss: 0.2184 - acc: 0.9167 - val_loss: 0.1489 - val_acc: 0.9654
Epoch 3/12
 - 20s - loss: 0.1379 - acc: 0.9554 - val_loss: 0.0994 - val_acc: 0.9792
Epoch 4/12
 - 19s - loss: 0.0973 - acc: 0.9728 - val_loss: 0.0663 - val_acc: 0.9885
Epoch 5/12
 - 20s - loss: 0.0743 - acc: 0.9827 - val_loss: 0.0494 - val_acc: 0.9925
Epoch 6/12
 - 19s - loss: 0.0577 - acc: 0.9881 - val_loss: 0.0373 - val_acc: 0.9952
Epoch 7/12
 - 19s - loss: 0.0450 - acc: 0.9921 - val_loss: 0.0283 - val_acc: 0.9970
Epoch 8/12
 - 19s - loss: 0.0399 - acc: 0.9927 - val_loss: 0.0296 - val_acc: 0.9966
Epoch 9/12
 - 19s - loss: 0.0337 - acc: 0.9946 - val_loss: 0.0222 - val_acc: 0.9975
Epoch 10/12
 - 20s - loss: 0.0297 - acc: 0.9955 - val_loss: 0.0243 - val_acc: 0.9972
Epoch 11/12
 - 20s - loss: 0.0264 - acc: 0.9967 - val_loss: 0.0192 - val_acc: 0.9982
Epoch 12/12
 - 19s - loss: 0.0252 - acc: 0.9968 - val_loss: 0.0195 - val_acc: 0.9984
Test accuracy:0.699
current auc_score ------------------> 0.852
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4501 - acc: 0.8032 - val_loss: 0.2390 - val_acc: 0.9123
Epoch 2/12
 - 20s - loss: 0.2223 - acc: 0.9176 - val_loss: 0.1600 - val_acc: 0.9585
Epoch 3/12
 - 20s - loss: 0.1405 - acc: 0.9564 - val_loss: 0.1010 - val_acc: 0.9736
Epoch 4/12
 - 20s - loss: 0.1017 - acc: 0.9714 - val_loss: 0.0674 - val_acc: 0.9862
Epoch 5/12
 - 20s - loss: 0.0735 - acc: 0.9832 - val_loss: 0.0527 - val_acc: 0.9913
Epoch 6/12
 - 20s - loss: 0.0570 - acc: 0.9880 - val_loss: 0.0365 - val_acc: 0.9957
Epoch 7/12
 - 20s - loss: 0.0440 - acc: 0.9924 - val_loss: 0.0282 - val_acc: 0.9961
Epoch 8/12
 - 20s - loss: 0.0398 - acc: 0.9935 - val_loss: 0.0291 - val_acc: 0.9961
Epoch 9/12
 - 20s - loss: 0.0343 - acc: 0.9951 - val_loss: 0.0216 - val_acc: 0.9975
Epoch 10/12
 - 20s - loss: 0.0302 - acc: 0.9957 - val_loss: 0.0215 - val_acc: 0.9971
Epoch 11/12
 - 20s - loss: 0.0267 - acc: 0.9967 - val_loss: 0.0220 - val_acc: 0.9966
Epoch 12/12
 - 20s - loss: 0.0261 - acc: 0.9965 - val_loss: 0.0199 - val_acc: 0.9974
Test accuracy:0.733
current auc_score ------------------> 0.867
accuracies:  [0.7221774193548387, 0.739247311827957, 0.668010752688172, 0.673521505376344, 0.6854838709677419, 0.6123655913978494, 0.7110215053763441, 0.7236559139784946, 0.6986559139784946, 0.7333333333333333]
aucs:  [0.8383, 0.8883, 0.9205, 0.8894, 0.897, 0.8789, 0.877, 0.8979, 0.8516, 0.8671]
mean and std AUC:  0.881+/-0.023  max:   0.9205
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4280 - acc: 0.8153 - val_loss: 0.2612 - val_acc: 0.9214
Epoch 2/12
 - 19s - loss: 0.2099 - acc: 0.9271 - val_loss: 0.1490 - val_acc: 0.9613
Epoch 3/12
 - 20s - loss: 0.1400 - acc: 0.9588 - val_loss: 0.1112 - val_acc: 0.9782
Epoch 4/12
 - 19s - loss: 0.0949 - acc: 0.9764 - val_loss: 0.0717 - val_acc: 0.9888
Epoch 5/12
 - 19s - loss: 0.0750 - acc: 0.9836 - val_loss: 0.0484 - val_acc: 0.9947
Epoch 6/12
 - 19s - loss: 0.0597 - acc: 0.9894 - val_loss: 0.0477 - val_acc: 0.9954
Epoch 7/12
 - 19s - loss: 0.0495 - acc: 0.9916 - val_loss: 0.0345 - val_acc: 0.9964
Epoch 8/12
 - 20s - loss: 0.0426 - acc: 0.9936 - val_loss: 0.0319 - val_acc: 0.9970
Epoch 9/12
 - 19s - loss: 0.0350 - acc: 0.9953 - val_loss: 0.0276 - val_acc: 0.9967
Epoch 10/12
 - 19s - loss: 0.0352 - acc: 0.9958 - val_loss: 0.0227 - val_acc: 0.9977
Epoch 11/12
 - 19s - loss: 0.0300 - acc: 0.9965 - val_loss: 0.0202 - val_acc: 0.9987
Epoch 12/12
 - 20s - loss: 0.0281 - acc: 0.9971 - val_loss: 0.0212 - val_acc: 0.9986
Test accuracy:0.744
current auc_score ------------------> 0.900
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.3758 - acc: 0.8441 - val_loss: 0.2209 - val_acc: 0.9261
Epoch 2/12
 - 20s - loss: 0.1785 - acc: 0.9404 - val_loss: 0.1421 - val_acc: 0.9667
Epoch 3/12
 - 20s - loss: 0.1180 - acc: 0.9664 - val_loss: 0.0877 - val_acc: 0.9843
Epoch 4/12
 - 19s - loss: 0.0829 - acc: 0.9812 - val_loss: 0.0653 - val_acc: 0.9902
Epoch 5/12
 - 19s - loss: 0.0604 - acc: 0.9888 - val_loss: 0.0453 - val_acc: 0.9939
Epoch 6/12
 - 19s - loss: 0.0498 - acc: 0.9912 - val_loss: 0.0330 - val_acc: 0.9956
Epoch 7/12
 - 20s - loss: 0.0412 - acc: 0.9937 - val_loss: 0.0307 - val_acc: 0.9965
Epoch 8/12
 - 19s - loss: 0.0325 - acc: 0.9966 - val_loss: 0.0247 - val_acc: 0.9975
Epoch 9/12
 - 19s - loss: 0.0304 - acc: 0.9967 - val_loss: 0.0255 - val_acc: 0.9981
Epoch 10/12
 - 19s - loss: 0.0321 - acc: 0.9960 - val_loss: 0.0218 - val_acc: 0.9986
Epoch 11/12
 - 19s - loss: 0.0264 - acc: 0.9975 - val_loss: 0.0230 - val_acc: 0.9970
Epoch 12/12
 - 19s - loss: 0.0270 - acc: 0.9969 - val_loss: 0.0218 - val_acc: 0.9975
Test accuracy:0.698
current auc_score ------------------> 0.909
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 23s - loss: 0.4018 - acc: 0.8334 - val_loss: 0.2282 - val_acc: 0.9277
Epoch 2/12
 - 20s - loss: 0.1995 - acc: 0.9295 - val_loss: 0.1336 - val_acc: 0.9661
Epoch 3/12
 - 20s - loss: 0.1287 - acc: 0.9622 - val_loss: 0.0857 - val_acc: 0.9822
Epoch 4/12
 - 20s - loss: 0.0883 - acc: 0.9793 - val_loss: 0.0737 - val_acc: 0.9886
Epoch 5/12
 - 20s - loss: 0.0666 - acc: 0.9867 - val_loss: 0.0492 - val_acc: 0.9951
Epoch 6/12
 - 20s - loss: 0.0565 - acc: 0.9899 - val_loss: 0.0471 - val_acc: 0.9947
Epoch 7/12
 - 20s - loss: 0.0459 - acc: 0.9921 - val_loss: 0.0312 - val_acc: 0.9979
Epoch 8/12
 - 20s - loss: 0.0373 - acc: 0.9956 - val_loss: 0.0247 - val_acc: 0.9985
Epoch 9/12
 - 19s - loss: 0.0358 - acc: 0.9946 - val_loss: 0.0239 - val_acc: 0.9989
Epoch 10/12
 - 20s - loss: 0.0323 - acc: 0.9960 - val_loss: 0.0245 - val_acc: 0.9974
Epoch 11/12
 - 20s - loss: 0.0306 - acc: 0.9965 - val_loss: 0.0290 - val_acc: 0.9984
Epoch 12/12
 - 20s - loss: 0.0272 - acc: 0.9973 - val_loss: 0.0195 - val_acc: 0.9992
Test accuracy:0.694
current auc_score ------------------> 0.876
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4234 - acc: 0.8210 - val_loss: 0.2396 - val_acc: 0.9208
Epoch 2/12
 - 20s - loss: 0.2015 - acc: 0.9301 - val_loss: 0.1593 - val_acc: 0.9590
Epoch 3/12
 - 20s - loss: 0.1297 - acc: 0.9648 - val_loss: 0.1068 - val_acc: 0.9746
Epoch 4/12
 - 20s - loss: 0.0880 - acc: 0.9794 - val_loss: 0.0553 - val_acc: 0.9916
Epoch 5/12
 - 19s - loss: 0.0657 - acc: 0.9877 - val_loss: 0.0491 - val_acc: 0.9927
Epoch 6/12
 - 19s - loss: 0.0548 - acc: 0.9904 - val_loss: 0.0371 - val_acc: 0.9947
Epoch 7/12
 - 20s - loss: 0.0476 - acc: 0.9922 - val_loss: 0.0372 - val_acc: 0.9962
Epoch 8/12
 - 19s - loss: 0.0407 - acc: 0.9940 - val_loss: 0.0283 - val_acc: 0.9979
Epoch 9/12
 - 20s - loss: 0.0343 - acc: 0.9958 - val_loss: 0.0304 - val_acc: 0.9980
Epoch 10/12
 - 20s - loss: 0.0307 - acc: 0.9968 - val_loss: 0.0222 - val_acc: 0.9979
Epoch 11/12
 - 20s - loss: 0.0288 - acc: 0.9971 - val_loss: 0.0206 - val_acc: 0.9987
Epoch 12/12
 - 20s - loss: 0.0282 - acc: 0.9971 - val_loss: 0.0202 - val_acc: 0.9987
Test accuracy:0.631
current auc_score ------------------> 0.910
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4497 - acc: 0.8061 - val_loss: 0.2575 - val_acc: 0.9104
Epoch 2/12
 - 20s - loss: 0.2156 - acc: 0.9224 - val_loss: 0.1652 - val_acc: 0.9570
Epoch 3/12
 - 20s - loss: 0.1328 - acc: 0.9630 - val_loss: 0.1052 - val_acc: 0.9824
Epoch 4/12
 - 20s - loss: 0.0922 - acc: 0.9783 - val_loss: 0.0644 - val_acc: 0.9915
Epoch 5/12
 - 20s - loss: 0.0704 - acc: 0.9855 - val_loss: 0.0521 - val_acc: 0.9930
Epoch 6/12
 - 19s - loss: 0.0557 - acc: 0.9905 - val_loss: 0.0452 - val_acc: 0.9939
Epoch 7/12
 - 19s - loss: 0.0490 - acc: 0.9916 - val_loss: 0.0449 - val_acc: 0.9941
Epoch 8/12
 - 19s - loss: 0.0387 - acc: 0.9947 - val_loss: 0.0311 - val_acc: 0.9975
Epoch 9/12
 - 19s - loss: 0.0363 - acc: 0.9952 - val_loss: 0.0283 - val_acc: 0.9982
Epoch 10/12
 - 19s - loss: 0.0334 - acc: 0.9962 - val_loss: 0.0246 - val_acc: 0.9987
Epoch 11/12
 - 20s - loss: 0.0294 - acc: 0.9971 - val_loss: 0.0241 - val_acc: 0.9985
Epoch 12/12
 - 19s - loss: 0.0293 - acc: 0.9965 - val_loss: 0.0210 - val_acc: 0.9984
Test accuracy:0.729
current auc_score ------------------> 0.878
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 23s - loss: 0.4407 - acc: 0.8118 - val_loss: 0.2759 - val_acc: 0.9022
Epoch 2/12
 - 20s - loss: 0.2165 - acc: 0.9240 - val_loss: 0.1590 - val_acc: 0.9659
Epoch 3/12
 - 20s - loss: 0.1415 - acc: 0.9581 - val_loss: 0.0991 - val_acc: 0.9804
Epoch 4/12
 - 20s - loss: 0.1000 - acc: 0.9760 - val_loss: 0.0717 - val_acc: 0.9896
Epoch 5/12
 - 20s - loss: 0.0746 - acc: 0.9838 - val_loss: 0.0614 - val_acc: 0.9935
Epoch 6/12
 - 20s - loss: 0.0603 - acc: 0.9893 - val_loss: 0.0413 - val_acc: 0.9959
Epoch 7/12
 - 20s - loss: 0.0484 - acc: 0.9917 - val_loss: 0.0348 - val_acc: 0.9971
Epoch 8/12
 - 20s - loss: 0.0397 - acc: 0.9942 - val_loss: 0.0288 - val_acc: 0.9974
Epoch 9/12
 - 20s - loss: 0.0346 - acc: 0.9958 - val_loss: 0.0269 - val_acc: 0.9976
Epoch 10/12
 - 20s - loss: 0.0319 - acc: 0.9960 - val_loss: 0.0246 - val_acc: 0.9979
Epoch 11/12
 - 20s - loss: 0.0289 - acc: 0.9971 - val_loss: 0.0232 - val_acc: 0.9985
Epoch 12/12
 - 19s - loss: 0.0290 - acc: 0.9967 - val_loss: 0.0245 - val_acc: 0.9991
Test accuracy:0.703
current auc_score ------------------> 0.866
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4232 - acc: 0.8177 - val_loss: 0.2210 - val_acc: 0.9295
Epoch 2/12
 - 19s - loss: 0.2018 - acc: 0.9312 - val_loss: 0.1322 - val_acc: 0.9681
Epoch 3/12
 - 19s - loss: 0.1337 - acc: 0.9601 - val_loss: 0.0982 - val_acc: 0.9829
Epoch 4/12
 - 18s - loss: 0.0937 - acc: 0.9774 - val_loss: 0.0713 - val_acc: 0.9908
Epoch 5/12
 - 18s - loss: 0.0712 - acc: 0.9854 - val_loss: 0.0589 - val_acc: 0.9925
Epoch 6/12
 - 18s - loss: 0.0563 - acc: 0.9910 - val_loss: 0.0357 - val_acc: 0.9969
Epoch 7/12
 - 18s - loss: 0.0484 - acc: 0.9918 - val_loss: 0.0333 - val_acc: 0.9970
Epoch 8/12
 - 18s - loss: 0.0412 - acc: 0.9943 - val_loss: 0.0281 - val_acc: 0.9977
Epoch 9/12
 - 18s - loss: 0.0369 - acc: 0.9953 - val_loss: 0.0310 - val_acc: 0.9979
Epoch 10/12
 - 18s - loss: 0.0341 - acc: 0.9956 - val_loss: 0.0222 - val_acc: 0.9986
Epoch 11/12
 - 18s - loss: 0.0306 - acc: 0.9970 - val_loss: 0.0226 - val_acc: 0.9981
Epoch 12/12
 - 18s - loss: 0.0304 - acc: 0.9961 - val_loss: 0.0206 - val_acc: 0.9986
Test accuracy:0.667
current auc_score ------------------> 0.905
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 21s - loss: 0.4218 - acc: 0.8219 - val_loss: 0.2301 - val_acc: 0.9306
Epoch 2/12
 - 19s - loss: 0.1971 - acc: 0.9349 - val_loss: 0.1723 - val_acc: 0.9570
Epoch 3/12
 - 18s - loss: 0.1252 - acc: 0.9661 - val_loss: 0.0894 - val_acc: 0.9872
Epoch 4/12
 - 18s - loss: 0.0870 - acc: 0.9800 - val_loss: 0.0587 - val_acc: 0.9911
Epoch 5/12
 - 19s - loss: 0.0664 - acc: 0.9874 - val_loss: 0.0515 - val_acc: 0.9947
Epoch 6/12
 - 18s - loss: 0.0550 - acc: 0.9899 - val_loss: 0.0368 - val_acc: 0.9959
Epoch 7/12
 - 19s - loss: 0.0434 - acc: 0.9940 - val_loss: 0.0307 - val_acc: 0.9962
Epoch 8/12
 - 18s - loss: 0.0386 - acc: 0.9951 - val_loss: 0.0300 - val_acc: 0.9977
Epoch 9/12
 - 18s - loss: 0.0338 - acc: 0.9960 - val_loss: 0.0250 - val_acc: 0.9980
Epoch 10/12
 - 18s - loss: 0.0300 - acc: 0.9970 - val_loss: 0.0236 - val_acc: 0.9970
Epoch 11/12
 - 18s - loss: 0.0290 - acc: 0.9968 - val_loss: 0.0202 - val_acc: 0.9986
Epoch 12/12
 - 19s - loss: 0.0272 - acc: 0.9970 - val_loss: 0.0206 - val_acc: 0.9986
Test accuracy:0.635
current auc_score ------------------> 0.822
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4119 - acc: 0.8260 - val_loss: 0.2455 - val_acc: 0.9192
Epoch 2/12
 - 20s - loss: 0.1885 - acc: 0.9356 - val_loss: 0.1318 - val_acc: 0.9682
Epoch 3/12
 - 20s - loss: 0.1235 - acc: 0.9654 - val_loss: 0.1074 - val_acc: 0.9799
Epoch 4/12
 - 20s - loss: 0.0871 - acc: 0.9804 - val_loss: 0.0665 - val_acc: 0.9911
Epoch 5/12
 - 19s - loss: 0.0647 - acc: 0.9876 - val_loss: 0.0458 - val_acc: 0.9952
Epoch 6/12
 - 19s - loss: 0.0540 - acc: 0.9912 - val_loss: 0.0373 - val_acc: 0.9952
Epoch 7/12
 - 19s - loss: 0.0432 - acc: 0.9938 - val_loss: 0.0362 - val_acc: 0.9966
Epoch 8/12
 - 19s - loss: 0.0389 - acc: 0.9946 - val_loss: 0.0351 - val_acc: 0.9962
Epoch 9/12
 - 19s - loss: 0.0349 - acc: 0.9956 - val_loss: 0.0273 - val_acc: 0.9972
Epoch 10/12
 - 19s - loss: 0.0298 - acc: 0.9968 - val_loss: 0.0233 - val_acc: 0.9979
Epoch 11/12
 - 19s - loss: 0.0301 - acc: 0.9962 - val_loss: 0.0229 - val_acc: 0.9986
Epoch 12/12
 - 19s - loss: 0.0263 - acc: 0.9971 - val_loss: 0.0286 - val_acc: 0.9962
Test accuracy:0.655
current auc_score ------------------> 0.830
Epochs  12  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 22s - loss: 0.4173 - acc: 0.8269 - val_loss: 0.2364 - val_acc: 0.9211
Epoch 2/12
 - 19s - loss: 0.2019 - acc: 0.9287 - val_loss: 0.1467 - val_acc: 0.9646
Epoch 3/12
 - 19s - loss: 0.1298 - acc: 0.9632 - val_loss: 0.1009 - val_acc: 0.9814
Epoch 4/12
 - 19s - loss: 0.0932 - acc: 0.9771 - val_loss: 0.0686 - val_acc: 0.9891
Epoch 5/12
 - 19s - loss: 0.0684 - acc: 0.9868 - val_loss: 0.0492 - val_acc: 0.9935
Epoch 6/12
 - 19s - loss: 0.0530 - acc: 0.9912 - val_loss: 0.0356 - val_acc: 0.9959
Epoch 7/12
 - 19s - loss: 0.0453 - acc: 0.9933 - val_loss: 0.0349 - val_acc: 0.9974
Epoch 8/12
 - 19s - loss: 0.0405 - acc: 0.9944 - val_loss: 0.0269 - val_acc: 0.9974
Epoch 9/12
 - 19s - loss: 0.0348 - acc: 0.9956 - val_loss: 0.0244 - val_acc: 0.9977
Epoch 10/12
 - 19s - loss: 0.0325 - acc: 0.9959 - val_loss: 0.0265 - val_acc: 0.9981
Epoch 11/12
 - 19s - loss: 0.0306 - acc: 0.9964 - val_loss: 0.0203 - val_acc: 0.9987
Epoch 12/12
 - 19s - loss: 0.0274 - acc: 0.9971 - val_loss: 0.0189 - val_acc: 0.9992
Test accuracy:0.671
current auc_score ------------------> 0.889
accuracies:  [0.744489247311828, 0.6975806451612904, 0.6943548387096774, 0.6311827956989248, 0.7286290322580645, 0.7030913978494624, 0.6666666666666666, 0.6349462365591397, 0.655241935483871, 0.6706989247311828]
aucs:  [0.8997, 0.9092, 0.8765, 0.9103, 0.8779, 0.866, 0.9047, 0.8217, 0.8298, 0.8894]
mean and std AUC:  0.879+/-0.03  max:   0.9103
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4796 - acc: 0.7908 - val_loss: 0.2739 - val_acc: 0.8973
Epoch 2/10
 - 18s - loss: 0.2481 - acc: 0.9025 - val_loss: 0.1932 - val_acc: 0.9364
Epoch 3/10
 - 18s - loss: 0.1636 - acc: 0.9443 - val_loss: 0.1112 - val_acc: 0.9715
Epoch 4/10
 - 18s - loss: 0.1195 - acc: 0.9639 - val_loss: 0.0798 - val_acc: 0.9816
Epoch 5/10
 - 18s - loss: 0.0845 - acc: 0.9783 - val_loss: 0.0580 - val_acc: 0.9878
Epoch 6/10
 - 18s - loss: 0.0665 - acc: 0.9838 - val_loss: 0.0557 - val_acc: 0.9869
Epoch 7/10
 - 18s - loss: 0.0568 - acc: 0.9870 - val_loss: 0.0405 - val_acc: 0.9912
Epoch 8/10
 - 17s - loss: 0.0468 - acc: 0.9901 - val_loss: 0.0340 - val_acc: 0.9935
Epoch 9/10
 - 18s - loss: 0.0394 - acc: 0.9922 - val_loss: 0.0264 - val_acc: 0.9959
Epoch 10/10
 - 18s - loss: 0.0351 - acc: 0.9938 - val_loss: 0.0232 - val_acc: 0.9966
Test accuracy:0.675
current auc_score ------------------> 0.884
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4912 - acc: 0.7820 - val_loss: 0.2924 - val_acc: 0.8960
Epoch 2/10
 - 19s - loss: 0.2643 - acc: 0.8954 - val_loss: 0.1910 - val_acc: 0.9413
Epoch 3/10
 - 19s - loss: 0.1725 - acc: 0.9388 - val_loss: 0.1331 - val_acc: 0.9627
Epoch 4/10
 - 19s - loss: 0.1269 - acc: 0.9602 - val_loss: 0.1032 - val_acc: 0.9798
Epoch 5/10
 - 19s - loss: 0.0958 - acc: 0.9722 - val_loss: 0.0756 - val_acc: 0.9863
Epoch 6/10
 - 19s - loss: 0.0757 - acc: 0.9812 - val_loss: 0.0591 - val_acc: 0.9908
Epoch 7/10
 - 19s - loss: 0.0620 - acc: 0.9854 - val_loss: 0.0443 - val_acc: 0.9939
Epoch 8/10
 - 19s - loss: 0.0516 - acc: 0.9883 - val_loss: 0.0448 - val_acc: 0.9936
Epoch 9/10
 - 19s - loss: 0.0449 - acc: 0.9914 - val_loss: 0.0312 - val_acc: 0.9959
Epoch 10/10
 - 19s - loss: 0.0409 - acc: 0.9913 - val_loss: 0.0259 - val_acc: 0.9960
Test accuracy:0.693
current auc_score ------------------> 0.923
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 22s - loss: 0.4679 - acc: 0.7989 - val_loss: 0.2519 - val_acc: 0.9052
Epoch 2/10
 - 19s - loss: 0.2385 - acc: 0.9073 - val_loss: 0.1453 - val_acc: 0.9558
Epoch 3/10
 - 19s - loss: 0.1572 - acc: 0.9482 - val_loss: 0.0956 - val_acc: 0.9768
Epoch 4/10
 - 19s - loss: 0.1120 - acc: 0.9654 - val_loss: 0.0690 - val_acc: 0.9812
Epoch 5/10
 - 19s - loss: 0.0866 - acc: 0.9770 - val_loss: 0.0532 - val_acc: 0.9896
Epoch 6/10
 - 19s - loss: 0.0672 - acc: 0.9832 - val_loss: 0.0457 - val_acc: 0.9916
Epoch 7/10
 - 19s - loss: 0.0558 - acc: 0.9869 - val_loss: 0.0336 - val_acc: 0.9937
Epoch 8/10
 - 19s - loss: 0.0447 - acc: 0.9908 - val_loss: 0.0261 - val_acc: 0.9961
Epoch 9/10
 - 19s - loss: 0.0373 - acc: 0.9930 - val_loss: 0.0223 - val_acc: 0.9965
Epoch 10/10
 - 19s - loss: 0.0348 - acc: 0.9936 - val_loss: 0.0229 - val_acc: 0.9969
Test accuracy:0.672
current auc_score ------------------> 0.876
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4867 - acc: 0.7925 - val_loss: 0.2744 - val_acc: 0.9045
Epoch 2/10
 - 18s - loss: 0.2598 - acc: 0.8979 - val_loss: 0.2070 - val_acc: 0.9378
Epoch 3/10
 - 19s - loss: 0.1790 - acc: 0.9356 - val_loss: 0.1439 - val_acc: 0.9620
Epoch 4/10
 - 19s - loss: 0.1300 - acc: 0.9585 - val_loss: 0.1078 - val_acc: 0.9750
Epoch 5/10
 - 19s - loss: 0.1002 - acc: 0.9712 - val_loss: 0.0682 - val_acc: 0.9854
Epoch 6/10
 - 19s - loss: 0.0780 - acc: 0.9788 - val_loss: 0.0520 - val_acc: 0.9908
Epoch 7/10
 - 19s - loss: 0.0625 - acc: 0.9852 - val_loss: 0.0499 - val_acc: 0.9913
Epoch 8/10
 - 19s - loss: 0.0526 - acc: 0.9885 - val_loss: 0.0353 - val_acc: 0.9950
Epoch 9/10
 - 19s - loss: 0.0450 - acc: 0.9902 - val_loss: 0.0303 - val_acc: 0.9954
Epoch 10/10
 - 19s - loss: 0.0367 - acc: 0.9934 - val_loss: 0.0264 - val_acc: 0.9961
Test accuracy:0.615
current auc_score ------------------> 0.875
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4863 - acc: 0.7851 - val_loss: 0.3131 - val_acc: 0.8609
Epoch 2/10
 - 19s - loss: 0.2566 - acc: 0.8997 - val_loss: 0.2272 - val_acc: 0.9262
Epoch 3/10
 - 19s - loss: 0.1669 - acc: 0.9432 - val_loss: 0.1579 - val_acc: 0.9603
Epoch 4/10
 - 19s - loss: 0.1270 - acc: 0.9606 - val_loss: 0.0937 - val_acc: 0.9819
Epoch 5/10
 - 18s - loss: 0.0921 - acc: 0.9741 - val_loss: 0.0847 - val_acc: 0.9858
Epoch 6/10
 - 19s - loss: 0.0728 - acc: 0.9813 - val_loss: 0.0558 - val_acc: 0.9916
Epoch 7/10
 - 18s - loss: 0.0592 - acc: 0.9863 - val_loss: 0.0496 - val_acc: 0.9921
Epoch 8/10
 - 19s - loss: 0.0508 - acc: 0.9886 - val_loss: 0.0347 - val_acc: 0.9947
Epoch 9/10
 - 18s - loss: 0.0403 - acc: 0.9922 - val_loss: 0.0327 - val_acc: 0.9962
Epoch 10/10
 - 19s - loss: 0.0370 - acc: 0.9927 - val_loss: 0.0270 - val_acc: 0.9967
Test accuracy:0.647
current auc_score ------------------> 0.886
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5018 - acc: 0.7817 - val_loss: 0.3948 - val_acc: 0.7989
Epoch 2/10
 - 19s - loss: 0.2620 - acc: 0.8957 - val_loss: 0.2276 - val_acc: 0.9262
Epoch 3/10
 - 19s - loss: 0.1700 - acc: 0.9415 - val_loss: 0.1582 - val_acc: 0.9567
Epoch 4/10
 - 18s - loss: 0.1223 - acc: 0.9618 - val_loss: 0.1250 - val_acc: 0.9705
Epoch 5/10
 - 19s - loss: 0.0890 - acc: 0.9759 - val_loss: 0.0845 - val_acc: 0.9838
Epoch 6/10
 - 19s - loss: 0.0687 - acc: 0.9828 - val_loss: 0.0593 - val_acc: 0.9891
Epoch 7/10
 - 19s - loss: 0.0547 - acc: 0.9870 - val_loss: 0.0441 - val_acc: 0.9911
Epoch 8/10
 - 19s - loss: 0.0473 - acc: 0.9898 - val_loss: 0.0385 - val_acc: 0.9937
Epoch 9/10
 - 19s - loss: 0.0417 - acc: 0.9912 - val_loss: 0.0297 - val_acc: 0.9957
Epoch 10/10
 - 19s - loss: 0.0357 - acc: 0.9932 - val_loss: 0.0262 - val_acc: 0.9960
Test accuracy:0.663
current auc_score ------------------> 0.847
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4894 - acc: 0.7843 - val_loss: 0.2777 - val_acc: 0.9044
Epoch 2/10
 - 19s - loss: 0.2489 - acc: 0.9036 - val_loss: 0.1858 - val_acc: 0.9460
Epoch 3/10
 - 19s - loss: 0.1658 - acc: 0.9420 - val_loss: 0.1278 - val_acc: 0.9680
Epoch 4/10
 - 19s - loss: 0.1165 - acc: 0.9642 - val_loss: 0.0839 - val_acc: 0.9829
Epoch 5/10
 - 19s - loss: 0.0879 - acc: 0.9756 - val_loss: 0.0623 - val_acc: 0.9871
Epoch 6/10
 - 19s - loss: 0.0709 - acc: 0.9815 - val_loss: 0.0513 - val_acc: 0.9918
Epoch 7/10
 - 18s - loss: 0.0597 - acc: 0.9854 - val_loss: 0.0368 - val_acc: 0.9950
Epoch 8/10
 - 19s - loss: 0.0456 - acc: 0.9900 - val_loss: 0.0394 - val_acc: 0.9939
Epoch 9/10
 - 19s - loss: 0.0379 - acc: 0.9933 - val_loss: 0.0278 - val_acc: 0.9955
Epoch 10/10
 - 19s - loss: 0.0326 - acc: 0.9942 - val_loss: 0.0223 - val_acc: 0.9971
Test accuracy:0.672
current auc_score ------------------> 0.862
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 20s - loss: 0.5037 - acc: 0.7766 - val_loss: 0.2780 - val_acc: 0.9027
Epoch 2/10
 - 18s - loss: 0.2634 - acc: 0.8957 - val_loss: 0.1989 - val_acc: 0.9345
Epoch 3/10
 - 18s - loss: 0.1774 - acc: 0.9360 - val_loss: 0.1251 - val_acc: 0.9693
Epoch 4/10
 - 18s - loss: 0.1267 - acc: 0.9594 - val_loss: 0.0940 - val_acc: 0.9785
Epoch 5/10
 - 18s - loss: 0.0973 - acc: 0.9727 - val_loss: 0.0686 - val_acc: 0.9873
Epoch 6/10
 - 18s - loss: 0.0784 - acc: 0.9800 - val_loss: 0.0511 - val_acc: 0.9905
Epoch 7/10
 - 18s - loss: 0.0602 - acc: 0.9865 - val_loss: 0.0426 - val_acc: 0.9939
Epoch 8/10
 - 18s - loss: 0.0513 - acc: 0.9888 - val_loss: 0.0377 - val_acc: 0.9928
Epoch 9/10
 - 18s - loss: 0.0451 - acc: 0.9905 - val_loss: 0.0280 - val_acc: 0.9950
Epoch 10/10
 - 18s - loss: 0.0399 - acc: 0.9920 - val_loss: 0.0305 - val_acc: 0.9939
Test accuracy:0.689
current auc_score ------------------> 0.872
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5194 - acc: 0.7688 - val_loss: 0.3023 - val_acc: 0.8810
Epoch 2/10
 - 19s - loss: 0.2726 - acc: 0.8892 - val_loss: 0.1912 - val_acc: 0.9378
Epoch 3/10
 - 19s - loss: 0.1816 - acc: 0.9383 - val_loss: 0.1374 - val_acc: 0.9640
Epoch 4/10
 - 19s - loss: 0.1257 - acc: 0.9613 - val_loss: 0.0945 - val_acc: 0.9789
Epoch 5/10
 - 19s - loss: 0.0905 - acc: 0.9758 - val_loss: 0.0732 - val_acc: 0.9873
Epoch 6/10
 - 19s - loss: 0.0737 - acc: 0.9821 - val_loss: 0.0482 - val_acc: 0.9910
Epoch 7/10
 - 19s - loss: 0.0583 - acc: 0.9869 - val_loss: 0.0383 - val_acc: 0.9918
Epoch 8/10
 - 19s - loss: 0.0437 - acc: 0.9914 - val_loss: 0.0283 - val_acc: 0.9962
Epoch 9/10
 - 19s - loss: 0.0386 - acc: 0.9933 - val_loss: 0.0243 - val_acc: 0.9974
Epoch 10/10
 - 19s - loss: 0.0342 - acc: 0.9942 - val_loss: 0.0206 - val_acc: 0.9970
Test accuracy:0.619
current auc_score ------------------> 0.893
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 28, 24, 24)   1120        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3024        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4320        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 52, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 52, 12, 12)   208         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 52, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 7488)         0           activation_7[0][0]               
==================================================================================================
Total params: 14,880
Trainable params: 14,440
Non-trainable params: 440
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         14880       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 7,685,665
Trainable params: 7,684,201
Non-trainable params: 1,464
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4695 - acc: 0.8004 - val_loss: 0.3088 - val_acc: 0.8727
Epoch 2/10
 - 18s - loss: 0.2358 - acc: 0.9090 - val_loss: 0.2255 - val_acc: 0.9194
Epoch 3/10
 - 18s - loss: 0.1593 - acc: 0.9459 - val_loss: 0.1691 - val_acc: 0.9462
Epoch 4/10
 - 19s - loss: 0.1155 - acc: 0.9653 - val_loss: 0.1243 - val_acc: 0.9654
Epoch 5/10
 - 19s - loss: 0.0929 - acc: 0.9738 - val_loss: 0.0823 - val_acc: 0.9810
Epoch 6/10
 - 18s - loss: 0.0696 - acc: 0.9824 - val_loss: 0.0637 - val_acc: 0.9863
Epoch 7/10
 - 19s - loss: 0.0579 - acc: 0.9856 - val_loss: 0.0455 - val_acc: 0.9922
Epoch 8/10
 - 19s - loss: 0.0502 - acc: 0.9885 - val_loss: 0.0420 - val_acc: 0.9927
Epoch 9/10
 - 19s - loss: 0.0440 - acc: 0.9907 - val_loss: 0.0291 - val_acc: 0.9962
Epoch 10/10
 - 19s - loss: 0.0381 - acc: 0.9928 - val_loss: 0.0273 - val_acc: 0.9957
Test accuracy:0.726
current auc_score ------------------> 0.856
accuracies:  [0.6751344086021506, 0.6932795698924731, 0.6720430107526881, 0.6146505376344086, 0.6470430107526882, 0.6633064516129032, 0.6717741935483871, 0.6885752688172043, 0.619489247311828, 0.7263440860215054]
aucs:  [0.8844, 0.9232, 0.8763, 0.8749, 0.8861, 0.8473, 0.8622, 0.872, 0.8932, 0.8556]
mean and std AUC:  0.878+/-0.02  max:   0.9232
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4664 - acc: 0.7992 - val_loss: 0.2986 - val_acc: 0.8951
Epoch 2/10
 - 19s - loss: 0.2433 - acc: 0.9074 - val_loss: 0.2105 - val_acc: 0.9434
Epoch 3/10
 - 19s - loss: 0.1627 - acc: 0.9454 - val_loss: 0.1441 - val_acc: 0.9635
Epoch 4/10
 - 19s - loss: 0.1203 - acc: 0.9643 - val_loss: 0.1172 - val_acc: 0.9743
Epoch 5/10
 - 19s - loss: 0.0923 - acc: 0.9756 - val_loss: 0.0845 - val_acc: 0.9836
Epoch 6/10
 - 19s - loss: 0.0717 - acc: 0.9829 - val_loss: 0.0565 - val_acc: 0.9907
Epoch 7/10
 - 19s - loss: 0.0617 - acc: 0.9858 - val_loss: 0.0568 - val_acc: 0.9926
Epoch 8/10
 - 19s - loss: 0.0522 - acc: 0.9896 - val_loss: 0.0426 - val_acc: 0.9930
Epoch 9/10
 - 19s - loss: 0.0425 - acc: 0.9918 - val_loss: 0.0346 - val_acc: 0.9947
Epoch 10/10
 - 19s - loss: 0.0399 - acc: 0.9926 - val_loss: 0.0314 - val_acc: 0.9939
Test accuracy:0.667
current auc_score ------------------> 0.902
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5481 - acc: 0.7546 - val_loss: 0.3322 - val_acc: 0.8727
Epoch 2/10
 - 18s - loss: 0.2958 - acc: 0.8808 - val_loss: 0.2927 - val_acc: 0.8795
Epoch 3/10
 - 18s - loss: 0.1990 - acc: 0.9287 - val_loss: 0.1569 - val_acc: 0.9608
Epoch 4/10
 - 19s - loss: 0.1410 - acc: 0.9557 - val_loss: 0.1125 - val_acc: 0.9764
Epoch 5/10
 - 19s - loss: 0.1074 - acc: 0.9709 - val_loss: 0.1070 - val_acc: 0.9768
Epoch 6/10
 - 19s - loss: 0.0874 - acc: 0.9773 - val_loss: 0.0939 - val_acc: 0.9803
Epoch 7/10
 - 19s - loss: 0.0717 - acc: 0.9830 - val_loss: 0.0574 - val_acc: 0.9911
Epoch 8/10
 - 19s - loss: 0.0595 - acc: 0.9870 - val_loss: 0.0538 - val_acc: 0.9903
Epoch 9/10
 - 19s - loss: 0.0524 - acc: 0.9891 - val_loss: 0.0406 - val_acc: 0.9954
Epoch 10/10
 - 18s - loss: 0.0464 - acc: 0.9914 - val_loss: 0.0254 - val_acc: 0.9971
Test accuracy:0.668
current auc_score ------------------> 0.886
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5200 - acc: 0.7703 - val_loss: 0.3110 - val_acc: 0.8845
Epoch 2/10
 - 18s - loss: 0.2676 - acc: 0.8950 - val_loss: 0.1977 - val_acc: 0.9444
Epoch 3/10
 - 18s - loss: 0.1751 - acc: 0.9418 - val_loss: 0.1318 - val_acc: 0.9710
Epoch 4/10
 - 19s - loss: 0.1265 - acc: 0.9616 - val_loss: 0.1049 - val_acc: 0.9790
Epoch 5/10
 - 18s - loss: 0.0934 - acc: 0.9746 - val_loss: 0.0647 - val_acc: 0.9896
Epoch 6/10
 - 18s - loss: 0.0758 - acc: 0.9816 - val_loss: 0.0622 - val_acc: 0.9916
Epoch 7/10
 - 18s - loss: 0.0656 - acc: 0.9852 - val_loss: 0.0477 - val_acc: 0.9928
Epoch 8/10
 - 18s - loss: 0.0526 - acc: 0.9891 - val_loss: 0.0344 - val_acc: 0.9946
Epoch 9/10
 - 18s - loss: 0.0441 - acc: 0.9920 - val_loss: 0.0303 - val_acc: 0.9974
Epoch 10/10
 - 18s - loss: 0.0394 - acc: 0.9928 - val_loss: 0.0266 - val_acc: 0.9970
Test accuracy:0.632
current auc_score ------------------> 0.885
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4292 - acc: 0.8151 - val_loss: 0.2554 - val_acc: 0.9116
Epoch 2/10
 - 19s - loss: 0.2156 - acc: 0.9223 - val_loss: 0.1537 - val_acc: 0.9548
Epoch 3/10
 - 19s - loss: 0.1391 - acc: 0.9569 - val_loss: 0.1160 - val_acc: 0.9765
Epoch 4/10
 - 19s - loss: 0.1012 - acc: 0.9712 - val_loss: 0.0823 - val_acc: 0.9843
Epoch 5/10
 - 19s - loss: 0.0785 - acc: 0.9807 - val_loss: 0.0685 - val_acc: 0.9891
Epoch 6/10
 - 19s - loss: 0.0656 - acc: 0.9849 - val_loss: 0.0557 - val_acc: 0.9937
Epoch 7/10
 - 19s - loss: 0.0534 - acc: 0.9886 - val_loss: 0.0350 - val_acc: 0.9952
Epoch 8/10
 - 19s - loss: 0.0434 - acc: 0.9918 - val_loss: 0.0340 - val_acc: 0.9965
Epoch 9/10
 - 19s - loss: 0.0397 - acc: 0.9928 - val_loss: 0.0255 - val_acc: 0.9972
Epoch 10/10
 - 19s - loss: 0.0350 - acc: 0.9941 - val_loss: 0.0261 - val_acc: 0.9962
Test accuracy:0.675
current auc_score ------------------> 0.890
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4751 - acc: 0.7965 - val_loss: 0.2751 - val_acc: 0.8926
Epoch 2/10
 - 19s - loss: 0.2503 - acc: 0.9022 - val_loss: 0.1904 - val_acc: 0.9439
Epoch 3/10
 - 18s - loss: 0.1636 - acc: 0.9460 - val_loss: 0.1190 - val_acc: 0.9672
Epoch 4/10
 - 18s - loss: 0.1187 - acc: 0.9644 - val_loss: 0.0930 - val_acc: 0.9716
Epoch 5/10
 - 18s - loss: 0.0921 - acc: 0.9764 - val_loss: 0.0707 - val_acc: 0.9849
Epoch 6/10
 - 18s - loss: 0.0693 - acc: 0.9835 - val_loss: 0.0491 - val_acc: 0.9901
Epoch 7/10
 - 18s - loss: 0.0608 - acc: 0.9858 - val_loss: 0.0462 - val_acc: 0.9916
Epoch 8/10
 - 18s - loss: 0.0526 - acc: 0.9899 - val_loss: 0.0357 - val_acc: 0.9941
Epoch 9/10
 - 18s - loss: 0.0444 - acc: 0.9912 - val_loss: 0.0350 - val_acc: 0.9941
Epoch 10/10
 - 18s - loss: 0.0380 - acc: 0.9928 - val_loss: 0.0274 - val_acc: 0.9960
Test accuracy:0.642
current auc_score ------------------> 0.876
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 20s - loss: 0.5727 - acc: 0.7399 - val_loss: 0.3713 - val_acc: 0.8485
Epoch 2/10
 - 19s - loss: 0.3295 - acc: 0.8637 - val_loss: 0.2821 - val_acc: 0.8898
Epoch 3/10
 - 18s - loss: 0.2259 - acc: 0.9169 - val_loss: 0.1935 - val_acc: 0.9458
Epoch 4/10
 - 19s - loss: 0.1642 - acc: 0.9442 - val_loss: 0.1172 - val_acc: 0.9726
Epoch 5/10
 - 18s - loss: 0.1207 - acc: 0.9646 - val_loss: 0.0946 - val_acc: 0.9807
Epoch 6/10
 - 18s - loss: 0.1036 - acc: 0.9709 - val_loss: 0.0842 - val_acc: 0.9854
Epoch 7/10
 - 19s - loss: 0.0805 - acc: 0.9798 - val_loss: 0.0538 - val_acc: 0.9908
Epoch 8/10
 - 19s - loss: 0.0674 - acc: 0.9840 - val_loss: 0.0555 - val_acc: 0.9921
Epoch 9/10
 - 18s - loss: 0.0595 - acc: 0.9869 - val_loss: 0.0407 - val_acc: 0.9952
Epoch 10/10
 - 19s - loss: 0.0487 - acc: 0.9907 - val_loss: 0.0385 - val_acc: 0.9940
Test accuracy:0.672
current auc_score ------------------> 0.908
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5169 - acc: 0.7692 - val_loss: 0.3217 - val_acc: 0.8700
Epoch 2/10
 - 19s - loss: 0.2703 - acc: 0.8924 - val_loss: 0.1968 - val_acc: 0.9383
Epoch 3/10
 - 19s - loss: 0.1792 - acc: 0.9400 - val_loss: 0.1425 - val_acc: 0.9647
Epoch 4/10
 - 19s - loss: 0.1322 - acc: 0.9615 - val_loss: 0.1014 - val_acc: 0.9784
Epoch 5/10
 - 19s - loss: 0.1025 - acc: 0.9720 - val_loss: 0.0870 - val_acc: 0.9810
Epoch 6/10
 - 19s - loss: 0.0814 - acc: 0.9795 - val_loss: 0.0594 - val_acc: 0.9895
Epoch 7/10
 - 19s - loss: 0.0663 - acc: 0.9847 - val_loss: 0.0475 - val_acc: 0.9928
Epoch 8/10
 - 19s - loss: 0.0574 - acc: 0.9872 - val_loss: 0.0427 - val_acc: 0.9942
Epoch 9/10
 - 19s - loss: 0.0488 - acc: 0.9904 - val_loss: 0.0363 - val_acc: 0.9952
Epoch 10/10
 - 19s - loss: 0.0442 - acc: 0.9914 - val_loss: 0.0338 - val_acc: 0.9956
Test accuracy:0.666
current auc_score ------------------> 0.883
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5094 - acc: 0.7732 - val_loss: 0.3079 - val_acc: 0.8891
Epoch 2/10
 - 19s - loss: 0.2676 - acc: 0.8937 - val_loss: 0.1973 - val_acc: 0.9354
Epoch 3/10
 - 19s - loss: 0.1761 - acc: 0.9403 - val_loss: 0.1713 - val_acc: 0.9517
Epoch 4/10
 - 19s - loss: 0.1259 - acc: 0.9628 - val_loss: 0.1037 - val_acc: 0.9745
Epoch 5/10
 - 19s - loss: 0.0950 - acc: 0.9742 - val_loss: 0.0734 - val_acc: 0.9881
Epoch 6/10
 - 19s - loss: 0.0778 - acc: 0.9808 - val_loss: 0.0524 - val_acc: 0.9907
Epoch 7/10
 - 19s - loss: 0.0625 - acc: 0.9859 - val_loss: 0.0506 - val_acc: 0.9926
Epoch 8/10
 - 19s - loss: 0.0550 - acc: 0.9882 - val_loss: 0.0406 - val_acc: 0.9946
Epoch 9/10
 - 19s - loss: 0.0491 - acc: 0.9909 - val_loss: 0.0333 - val_acc: 0.9957
Epoch 10/10
 - 19s - loss: 0.0433 - acc: 0.9916 - val_loss: 0.0301 - val_acc: 0.9959
Test accuracy:0.693
current auc_score ------------------> 0.900
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4603 - acc: 0.8035 - val_loss: 0.2758 - val_acc: 0.8934
Epoch 2/10
 - 18s - loss: 0.2334 - acc: 0.9121 - val_loss: 0.1565 - val_acc: 0.9581
Epoch 3/10
 - 18s - loss: 0.1549 - acc: 0.9491 - val_loss: 0.0948 - val_acc: 0.9778
Epoch 4/10
 - 18s - loss: 0.1135 - acc: 0.9654 - val_loss: 0.0762 - val_acc: 0.9862
Epoch 5/10
 - 18s - loss: 0.0865 - acc: 0.9762 - val_loss: 0.0733 - val_acc: 0.9876
Epoch 6/10
 - 18s - loss: 0.0688 - acc: 0.9833 - val_loss: 0.0544 - val_acc: 0.9905
Epoch 7/10
 - 18s - loss: 0.0551 - acc: 0.9883 - val_loss: 0.0437 - val_acc: 0.9940
Epoch 8/10
 - 18s - loss: 0.0472 - acc: 0.9902 - val_loss: 0.0319 - val_acc: 0.9966
Epoch 9/10
 - 18s - loss: 0.0421 - acc: 0.9916 - val_loss: 0.0374 - val_acc: 0.9941
Epoch 10/10
 - 18s - loss: 0.0370 - acc: 0.9929 - val_loss: 0.0284 - val_acc: 0.9961
Test accuracy:0.675
current auc_score ------------------> 0.876
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 12, 12)   144         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 36, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 54, 12, 12)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8748        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 72, 12, 12)   288         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 72, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10368)        0           activation_7[0][0]               
==================================================================================================
Total params: 26,456
Trainable params: 25,896
Non-trainable params: 560
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10368)        26456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20736)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10617344    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,646,361
Trainable params: 10,644,777
Non-trainable params: 1,584
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4683 - acc: 0.7941 - val_loss: 0.2974 - val_acc: 0.8924
Epoch 2/10
 - 19s - loss: 0.2437 - acc: 0.9060 - val_loss: 0.2047 - val_acc: 0.9430
Epoch 3/10
 - 18s - loss: 0.1658 - acc: 0.9463 - val_loss: 0.1233 - val_acc: 0.9711
Epoch 4/10
 - 19s - loss: 0.1223 - acc: 0.9639 - val_loss: 0.0955 - val_acc: 0.9787
Epoch 5/10
 - 18s - loss: 0.0966 - acc: 0.9748 - val_loss: 0.0763 - val_acc: 0.9880
Epoch 6/10
 - 18s - loss: 0.0760 - acc: 0.9818 - val_loss: 0.0572 - val_acc: 0.9931
Epoch 7/10
 - 18s - loss: 0.0598 - acc: 0.9869 - val_loss: 0.0415 - val_acc: 0.9939
Epoch 8/10
 - 18s - loss: 0.0523 - acc: 0.9896 - val_loss: 0.0329 - val_acc: 0.9951
Epoch 9/10
 - 18s - loss: 0.0436 - acc: 0.9922 - val_loss: 0.0268 - val_acc: 0.9971
Epoch 10/10
 - 18s - loss: 0.0382 - acc: 0.9932 - val_loss: 0.0276 - val_acc: 0.9962
Test accuracy:0.699
current auc_score ------------------> 0.899
accuracies:  [0.6668010752688172, 0.6684139784946237, 0.6321236559139785, 0.6747311827956989, 0.6423387096774194, 0.6721774193548387, 0.6663978494623656, 0.6928763440860215, 0.6747311827956989, 0.6991935483870968]
aucs:  [0.9023, 0.8865, 0.885, 0.8901, 0.8764, 0.9085, 0.8827, 0.9002, 0.8764, 0.8986]
mean and std AUC:  0.891+/-0.011  max:   0.9085
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4748 - acc: 0.7941 - val_loss: 0.3612 - val_acc: 0.8405
Epoch 2/10
 - 19s - loss: 0.2506 - acc: 0.9069 - val_loss: 0.1880 - val_acc: 0.9537
Epoch 3/10
 - 19s - loss: 0.1689 - acc: 0.9452 - val_loss: 0.1628 - val_acc: 0.9592
Epoch 4/10
 - 19s - loss: 0.1255 - acc: 0.9647 - val_loss: 0.1013 - val_acc: 0.9773
Epoch 5/10
 - 19s - loss: 0.0977 - acc: 0.9748 - val_loss: 0.0647 - val_acc: 0.9910
Epoch 6/10
 - 19s - loss: 0.0752 - acc: 0.9830 - val_loss: 0.0703 - val_acc: 0.9893
Epoch 7/10
 - 19s - loss: 0.0651 - acc: 0.9867 - val_loss: 0.0418 - val_acc: 0.9945
Epoch 8/10
 - 19s - loss: 0.0538 - acc: 0.9899 - val_loss: 0.0398 - val_acc: 0.9961
Epoch 9/10
 - 19s - loss: 0.0441 - acc: 0.9933 - val_loss: 0.0305 - val_acc: 0.9970
Epoch 10/10
 - 19s - loss: 0.0401 - acc: 0.9942 - val_loss: 0.0300 - val_acc: 0.9970
Test accuracy:0.626
current auc_score ------------------> 0.888
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4606 - acc: 0.8027 - val_loss: 0.3510 - val_acc: 0.8574
Epoch 2/10
 - 18s - loss: 0.2383 - acc: 0.9139 - val_loss: 0.2014 - val_acc: 0.9474
Epoch 3/10
 - 18s - loss: 0.1641 - acc: 0.9472 - val_loss: 0.1553 - val_acc: 0.9612
Epoch 4/10
 - 18s - loss: 0.1153 - acc: 0.9682 - val_loss: 0.0895 - val_acc: 0.9841
Epoch 5/10
 - 18s - loss: 0.0894 - acc: 0.9787 - val_loss: 0.0815 - val_acc: 0.9880
Epoch 6/10
 - 18s - loss: 0.0757 - acc: 0.9837 - val_loss: 0.0625 - val_acc: 0.9923
Epoch 7/10
 - 19s - loss: 0.0629 - acc: 0.9871 - val_loss: 0.0427 - val_acc: 0.9949
Epoch 8/10
 - 19s - loss: 0.0557 - acc: 0.9897 - val_loss: 0.0372 - val_acc: 0.9955
Epoch 9/10
 - 18s - loss: 0.0493 - acc: 0.9909 - val_loss: 0.0296 - val_acc: 0.9976
Epoch 10/10
 - 18s - loss: 0.0393 - acc: 0.9937 - val_loss: 0.0288 - val_acc: 0.9971
Test accuracy:0.697
current auc_score ------------------> 0.904
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4939 - acc: 0.7836 - val_loss: 0.4112 - val_acc: 0.7974
Epoch 2/10
 - 19s - loss: 0.2639 - acc: 0.9007 - val_loss: 0.2208 - val_acc: 0.9420
Epoch 3/10
 - 19s - loss: 0.1788 - acc: 0.9429 - val_loss: 0.1457 - val_acc: 0.9723
Epoch 4/10
 - 19s - loss: 0.1293 - acc: 0.9638 - val_loss: 0.0982 - val_acc: 0.9823
Epoch 5/10
 - 19s - loss: 0.1004 - acc: 0.9746 - val_loss: 0.0783 - val_acc: 0.9871
Epoch 6/10
 - 19s - loss: 0.0789 - acc: 0.9821 - val_loss: 0.0724 - val_acc: 0.9890
Epoch 7/10
 - 19s - loss: 0.0627 - acc: 0.9873 - val_loss: 0.0473 - val_acc: 0.9949
Epoch 8/10
 - 19s - loss: 0.0542 - acc: 0.9897 - val_loss: 0.0415 - val_acc: 0.9966
Epoch 9/10
 - 19s - loss: 0.0495 - acc: 0.9909 - val_loss: 0.0340 - val_acc: 0.9975
Epoch 10/10
 - 19s - loss: 0.0412 - acc: 0.9940 - val_loss: 0.0286 - val_acc: 0.9972
Test accuracy:0.707
current auc_score ------------------> 0.880
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4435 - acc: 0.8129 - val_loss: 0.4015 - val_acc: 0.8133
Epoch 2/10
 - 19s - loss: 0.2303 - acc: 0.9160 - val_loss: 0.2595 - val_acc: 0.9005
Epoch 3/10
 - 19s - loss: 0.1618 - acc: 0.9488 - val_loss: 0.2161 - val_acc: 0.9273
Epoch 4/10
 - 19s - loss: 0.1159 - acc: 0.9683 - val_loss: 0.1189 - val_acc: 0.9765
Epoch 5/10
 - 19s - loss: 0.0857 - acc: 0.9795 - val_loss: 0.0924 - val_acc: 0.9831
Epoch 6/10
 - 19s - loss: 0.0725 - acc: 0.9837 - val_loss: 0.0720 - val_acc: 0.9880
Epoch 7/10
 - 19s - loss: 0.0613 - acc: 0.9872 - val_loss: 0.0573 - val_acc: 0.9920
Epoch 8/10
 - 19s - loss: 0.0526 - acc: 0.9899 - val_loss: 0.0422 - val_acc: 0.9944
Epoch 9/10
 - 19s - loss: 0.0467 - acc: 0.9919 - val_loss: 0.0297 - val_acc: 0.9984
Epoch 10/10
 - 19s - loss: 0.0395 - acc: 0.9934 - val_loss: 0.0322 - val_acc: 0.9970
Test accuracy:0.599
current auc_score ------------------> 0.837
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4311 - acc: 0.8166 - val_loss: 0.3080 - val_acc: 0.8924
Epoch 2/10
 - 19s - loss: 0.2162 - acc: 0.9244 - val_loss: 0.2062 - val_acc: 0.9445
Epoch 3/10
 - 19s - loss: 0.1509 - acc: 0.9541 - val_loss: 0.1418 - val_acc: 0.9710
Epoch 4/10
 - 18s - loss: 0.1125 - acc: 0.9700 - val_loss: 0.1079 - val_acc: 0.9713
Epoch 5/10
 - 19s - loss: 0.0847 - acc: 0.9811 - val_loss: 0.0925 - val_acc: 0.9804
Epoch 6/10
 - 18s - loss: 0.0696 - acc: 0.9860 - val_loss: 0.0652 - val_acc: 0.9893
Epoch 7/10
 - 18s - loss: 0.0585 - acc: 0.9879 - val_loss: 0.0404 - val_acc: 0.9954
Epoch 8/10
 - 18s - loss: 0.0475 - acc: 0.9917 - val_loss: 0.0461 - val_acc: 0.9932
Epoch 9/10
 - 18s - loss: 0.0413 - acc: 0.9934 - val_loss: 0.0318 - val_acc: 0.9974
Epoch 10/10
 - 18s - loss: 0.0375 - acc: 0.9949 - val_loss: 0.0304 - val_acc: 0.9964
Test accuracy:0.696
current auc_score ------------------> 0.906
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4840 - acc: 0.7905 - val_loss: 0.3396 - val_acc: 0.8571
Epoch 2/10
 - 19s - loss: 0.2534 - acc: 0.9052 - val_loss: 0.2093 - val_acc: 0.9375
Epoch 3/10
 - 19s - loss: 0.1723 - acc: 0.9439 - val_loss: 0.1518 - val_acc: 0.9615
Epoch 4/10
 - 19s - loss: 0.1244 - acc: 0.9652 - val_loss: 0.1259 - val_acc: 0.9729
Epoch 5/10
 - 19s - loss: 0.0955 - acc: 0.9761 - val_loss: 0.0858 - val_acc: 0.9828
Epoch 6/10
 - 19s - loss: 0.0766 - acc: 0.9826 - val_loss: 0.0735 - val_acc: 0.9838
Epoch 7/10
 - 19s - loss: 0.0627 - acc: 0.9873 - val_loss: 0.0770 - val_acc: 0.9832
Epoch 8/10
 - 19s - loss: 0.0528 - acc: 0.9901 - val_loss: 0.0427 - val_acc: 0.9951
Epoch 9/10
 - 19s - loss: 0.0492 - acc: 0.9911 - val_loss: 0.0445 - val_acc: 0.9923
Epoch 10/10
 - 19s - loss: 0.0427 - acc: 0.9922 - val_loss: 0.0393 - val_acc: 0.9945
Test accuracy:0.632
current auc_score ------------------> 0.920
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.5272 - acc: 0.7677 - val_loss: 0.2999 - val_acc: 0.8919
Epoch 2/10
 - 19s - loss: 0.2790 - acc: 0.8899 - val_loss: 0.2134 - val_acc: 0.9350
Epoch 3/10
 - 19s - loss: 0.1851 - acc: 0.9387 - val_loss: 0.1610 - val_acc: 0.9602
Epoch 4/10
 - 19s - loss: 0.1322 - acc: 0.9629 - val_loss: 0.1080 - val_acc: 0.9805
Epoch 5/10
 - 19s - loss: 0.1024 - acc: 0.9743 - val_loss: 0.0733 - val_acc: 0.9876
Epoch 6/10
 - 19s - loss: 0.0829 - acc: 0.9810 - val_loss: 0.0737 - val_acc: 0.9891
Epoch 7/10
 - 19s - loss: 0.0701 - acc: 0.9850 - val_loss: 0.0514 - val_acc: 0.9928
Epoch 8/10
 - 18s - loss: 0.0588 - acc: 0.9887 - val_loss: 0.0391 - val_acc: 0.9956
Epoch 9/10
 - 19s - loss: 0.0502 - acc: 0.9910 - val_loss: 0.0335 - val_acc: 0.9960
Epoch 10/10
 - 19s - loss: 0.0416 - acc: 0.9934 - val_loss: 0.0319 - val_acc: 0.9969
Test accuracy:0.702
current auc_score ------------------> 0.866
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 22s - loss: 0.4659 - acc: 0.8004 - val_loss: 0.4856 - val_acc: 0.7476
Epoch 2/10
 - 19s - loss: 0.2329 - acc: 0.9147 - val_loss: 0.2278 - val_acc: 0.9291
Epoch 3/10
 - 19s - loss: 0.1606 - acc: 0.9494 - val_loss: 0.1554 - val_acc: 0.9630
Epoch 4/10
 - 19s - loss: 0.1177 - acc: 0.9664 - val_loss: 0.1430 - val_acc: 0.9630
Epoch 5/10
 - 19s - loss: 0.0969 - acc: 0.9754 - val_loss: 0.1048 - val_acc: 0.9797
Epoch 6/10
 - 19s - loss: 0.0810 - acc: 0.9809 - val_loss: 0.0825 - val_acc: 0.9868
Epoch 7/10
 - 19s - loss: 0.0637 - acc: 0.9866 - val_loss: 0.0581 - val_acc: 0.9915
Epoch 8/10
 - 19s - loss: 0.0512 - acc: 0.9905 - val_loss: 0.0398 - val_acc: 0.9966
Epoch 9/10
 - 19s - loss: 0.0464 - acc: 0.9917 - val_loss: 0.0420 - val_acc: 0.9944
Epoch 10/10
 - 18s - loss: 0.0420 - acc: 0.9928 - val_loss: 0.0337 - val_acc: 0.9969
Test accuracy:0.656
current auc_score ------------------> 0.904
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4304 - acc: 0.8157 - val_loss: 0.3124 - val_acc: 0.8906
Epoch 2/10
 - 18s - loss: 0.2224 - acc: 0.9199 - val_loss: 0.2310 - val_acc: 0.9344
Epoch 3/10
 - 18s - loss: 0.1483 - acc: 0.9548 - val_loss: 0.1946 - val_acc: 0.9443
Epoch 4/10
 - 18s - loss: 0.1096 - acc: 0.9708 - val_loss: 0.1433 - val_acc: 0.9659
Epoch 5/10
 - 18s - loss: 0.0821 - acc: 0.9806 - val_loss: 0.0851 - val_acc: 0.9873
Epoch 6/10
 - 18s - loss: 0.0680 - acc: 0.9855 - val_loss: 0.0647 - val_acc: 0.9905
Epoch 7/10
 - 18s - loss: 0.0527 - acc: 0.9904 - val_loss: 0.0465 - val_acc: 0.9961
Epoch 8/10
 - 18s - loss: 0.0470 - acc: 0.9924 - val_loss: 0.0361 - val_acc: 0.9959
Epoch 9/10
 - 18s - loss: 0.0412 - acc: 0.9933 - val_loss: 0.0330 - val_acc: 0.9972
Epoch 10/10
 - 18s - loss: 0.0379 - acc: 0.9937 - val_loss: 0.0335 - val_acc: 0.9971
Test accuracy:0.681
current auc_score ------------------> 0.892
Epochs  10  batch_size:  64  lr:  0.0001  optimizer:  nadam
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   14310       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   22410       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_7[0][0]               
==================================================================================================
Total params: 59,884
Trainable params: 59,078
Non-trainable params: 806
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        59884       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,725,485
Trainable params: 16,723,655
Non-trainable params: 1,830
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/10
 - 21s - loss: 0.4402 - acc: 0.8117 - val_loss: 0.2751 - val_acc: 0.9152
Epoch 2/10
 - 18s - loss: 0.2305 - acc: 0.9167 - val_loss: 0.2161 - val_acc: 0.9457
Epoch 3/10
 - 18s - loss: 0.1555 - acc: 0.9514 - val_loss: 0.1245 - val_acc: 0.9764
Epoch 4/10
 - 19s - loss: 0.1124 - acc: 0.9694 - val_loss: 0.0933 - val_acc: 0.9831
Epoch 5/10
 - 19s - loss: 0.0845 - acc: 0.9805 - val_loss: 0.0721 - val_acc: 0.9896
Epoch 6/10
 - 19s - loss: 0.0656 - acc: 0.9871 - val_loss: 0.0424 - val_acc: 0.9951
Epoch 7/10
 - 19s - loss: 0.0532 - acc: 0.9902 - val_loss: 0.0374 - val_acc: 0.9947
Epoch 8/10
 - 18s - loss: 0.0452 - acc: 0.9929 - val_loss: 0.0340 - val_acc: 0.9969
Epoch 9/10
 - 19s - loss: 0.0433 - acc: 0.9928 - val_loss: 0.0296 - val_acc: 0.9974
Epoch 10/10
 - 18s - loss: 0.0384 - acc: 0.9936 - val_loss: 0.0274 - val_acc: 0.9977
Test accuracy:0.704
current auc_score ------------------> 0.901
accuracies:  [0.6262096774193548, 0.6969086021505376, 0.7071236559139785, 0.5986559139784946, 0.6959677419354838, 0.6323924731182796, 0.7020161290322581, 0.6561827956989247, 0.6806451612903226, 0.7040322580645161]
aucs:  [0.8881, 0.904, 0.8802, 0.837, 0.9056, 0.9199, 0.8656, 0.9041, 0.8922, 0.9013]
mean and std AUC:  0.89+/-0.023  max:   0.9199
(['2-2', '12', '2', '16', '0.2', '0.0001', '12', 'nadam', '0.3', 'FALSE', '64', '0.5', '512', '1'], '0.867+/-0.023', 0.911)
(['2-2', '18', '2', '16', '0.2', '0.0001', '12', 'nadam', '0.3', 'FALSE', '64', '0.5', '512', '1'], '0.881+/-0.023', 0.92)
(['2-2', '30', '2', '16', '0.2', '0.0001', '12', 'nadam', '0.3', 'FALSE', '64', '0.5', '512', '1'], '0.879+/-0.03', 0.91)
(['2-2', '12', '2', '16', '0.4', '0.0001', '10', 'nadam', '0.3', 'FALSE', '64', '0.5', '512', '1'], '0.878+/-0.02', 0.923)
(['2-2', '18', '2', '16', '0.4', '0.0001', '10', 'nadam', '0.3', 'FALSE', '64', '0.5', '512', '1'], '0.891+/-0.011', 0.908)
(['2-2', '30', '2', '16', '0.4', '0.0001', '10', 'nadam', '0.3', 'FALSE', '64', '0.5', '512', '1'], '0.89+/-0.023', 0.92)
