python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
python custom_gridsearch_dn_siamese_layers.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, pooling
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '32', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 43s - loss: 0.4467 - acc: 0.7942 - val_loss: 0.3473 - val_acc: 0.8514
Epoch 2/21
 - 39s - loss: 0.3264 - acc: 0.8648 - val_loss: 0.2787 - val_acc: 0.8914
Epoch 3/21
 - 39s - loss: 0.2808 - acc: 0.8919 - val_loss: 0.2397 - val_acc: 0.9128
Epoch 4/21
 - 39s - loss: 0.2440 - acc: 0.9082 - val_loss: 0.1996 - val_acc: 0.9321
Epoch 5/21
 - 39s - loss: 0.2149 - acc: 0.9227 - val_loss: 0.1738 - val_acc: 0.9442
Epoch 6/21
 - 38s - loss: 0.1948 - acc: 0.9323 - val_loss: 0.1558 - val_acc: 0.9492
Epoch 7/21
 - 38s - loss: 0.1778 - acc: 0.9391 - val_loss: 0.1407 - val_acc: 0.9565
Epoch 8/21
 - 39s - loss: 0.1631 - acc: 0.9456 - val_loss: 0.1243 - val_acc: 0.9611
Epoch 9/21
 - 38s - loss: 0.1494 - acc: 0.9533 - val_loss: 0.1139 - val_acc: 0.9657
Epoch 10/21
 - 39s - loss: 0.1397 - acc: 0.9556 - val_loss: 0.1133 - val_acc: 0.9637
Epoch 11/21
 - 39s - loss: 0.1304 - acc: 0.9598 - val_loss: 0.0989 - val_acc: 0.9684
Epoch 12/21
 - 39s - loss: 0.1226 - acc: 0.9629 - val_loss: 0.1014 - val_acc: 0.9677
Epoch 13/21
 - 37s - loss: 0.1176 - acc: 0.9642 - val_loss: 0.0800 - val_acc: 0.9787
Epoch 14/21
 - 39s - loss: 0.1098 - acc: 0.9677 - val_loss: 0.0881 - val_acc: 0.9725
Epoch 15/21
 - 39s - loss: 0.1055 - acc: 0.9696 - val_loss: 0.0784 - val_acc: 0.9777
Epoch 16/21
 - 39s - loss: 0.1006 - acc: 0.9709 - val_loss: 0.0668 - val_acc: 0.9827
Epoch 17/21
 - 39s - loss: 0.0948 - acc: 0.9733 - val_loss: 0.0632 - val_acc: 0.9857
Epoch 18/21
 - 39s - loss: 0.0906 - acc: 0.9742 - val_loss: 0.0630 - val_acc: 0.9854
Epoch 19/21
 - 39s - loss: 0.0874 - acc: 0.9758 - val_loss: 0.0554 - val_acc: 0.9881
Epoch 20/21
 - 39s - loss: 0.0847 - acc: 0.9773 - val_loss: 0.0606 - val_acc: 0.9858
Epoch 21/21
 - 39s - loss: 0.0800 - acc: 0.9790 - val_loss: 0.0549 - val_acc: 0.9871
Test accuracy:0.816
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 41s - loss: 0.4696 - acc: 0.7790 - val_loss: 0.4130 - val_acc: 0.8033
Epoch 2/21
 - 40s - loss: 0.3371 - acc: 0.8590 - val_loss: 0.2940 - val_acc: 0.8815
Epoch 3/21
 - 39s - loss: 0.2813 - acc: 0.8899 - val_loss: 0.2661 - val_acc: 0.8931
Epoch 4/21
 - 40s - loss: 0.2460 - acc: 0.9063 - val_loss: 0.2179 - val_acc: 0.9196
Epoch 5/21
 - 40s - loss: 0.2176 - acc: 0.9226 - val_loss: 0.1900 - val_acc: 0.9357
Epoch 6/21
 - 39s - loss: 0.1929 - acc: 0.9317 - val_loss: 0.1615 - val_acc: 0.9465
Epoch 7/21
 - 39s - loss: 0.1755 - acc: 0.9394 - val_loss: 0.1415 - val_acc: 0.9568
Epoch 8/21
 - 40s - loss: 0.1616 - acc: 0.9449 - val_loss: 0.1314 - val_acc: 0.9580
Epoch 9/21
 - 39s - loss: 0.1479 - acc: 0.9517 - val_loss: 0.1152 - val_acc: 0.9646
Epoch 10/21
 - 39s - loss: 0.1364 - acc: 0.9566 - val_loss: 0.1154 - val_acc: 0.9671
Epoch 11/21
 - 38s - loss: 0.1262 - acc: 0.9605 - val_loss: 0.1031 - val_acc: 0.9714
Epoch 12/21
 - 39s - loss: 0.1179 - acc: 0.9637 - val_loss: 0.0948 - val_acc: 0.9738
Epoch 13/21
 - 38s - loss: 0.1120 - acc: 0.9672 - val_loss: 0.0993 - val_acc: 0.9724
Epoch 14/21
 - 38s - loss: 0.1035 - acc: 0.9699 - val_loss: 0.0882 - val_acc: 0.9768
Epoch 15/21
 - 38s - loss: 0.0984 - acc: 0.9713 - val_loss: 0.0833 - val_acc: 0.9770
Epoch 16/21
 - 39s - loss: 0.0930 - acc: 0.9739 - val_loss: 0.0647 - val_acc: 0.9829
Epoch 17/21
 - 38s - loss: 0.0889 - acc: 0.9754 - val_loss: 0.0613 - val_acc: 0.9858
Epoch 18/21
 - 38s - loss: 0.0843 - acc: 0.9766 - val_loss: 0.0531 - val_acc: 0.9890
Epoch 19/21
 - 38s - loss: 0.0819 - acc: 0.9780 - val_loss: 0.0533 - val_acc: 0.9867
Epoch 20/21
 - 38s - loss: 0.0771 - acc: 0.9795 - val_loss: 0.0504 - val_acc: 0.9895
Epoch 21/21
 - 37s - loss: 0.0734 - acc: 0.9809 - val_loss: 0.0487 - val_acc: 0.9891
Test accuracy:0.791
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4489 - acc: 0.7962 - val_loss: 0.3874 - val_acc: 0.8156
Epoch 2/21
 - 38s - loss: 0.3202 - acc: 0.8707 - val_loss: 0.2710 - val_acc: 0.8897
Epoch 3/21
 - 37s - loss: 0.2694 - acc: 0.8946 - val_loss: 0.2935 - val_acc: 0.8700
Epoch 4/21
 - 37s - loss: 0.2334 - acc: 0.9134 - val_loss: 0.2223 - val_acc: 0.9144
Epoch 5/21
 - 37s - loss: 0.2080 - acc: 0.9254 - val_loss: 0.1685 - val_acc: 0.9426
Epoch 6/21
 - 37s - loss: 0.1863 - acc: 0.9349 - val_loss: 0.1513 - val_acc: 0.9521
Epoch 7/21
 - 38s - loss: 0.1675 - acc: 0.9428 - val_loss: 0.1304 - val_acc: 0.9590
Epoch 8/21
 - 38s - loss: 0.1551 - acc: 0.9481 - val_loss: 0.1223 - val_acc: 0.9650
Epoch 9/21
 - 37s - loss: 0.1442 - acc: 0.9542 - val_loss: 0.1203 - val_acc: 0.9634
Epoch 10/21
 - 37s - loss: 0.1327 - acc: 0.9577 - val_loss: 0.1115 - val_acc: 0.9674
Epoch 11/21
 - 41s - loss: 0.1224 - acc: 0.9625 - val_loss: 0.0908 - val_acc: 0.9759
Epoch 12/21
 - 39s - loss: 0.1161 - acc: 0.9639 - val_loss: 0.0853 - val_acc: 0.9787
Epoch 13/21
 - 39s - loss: 0.1111 - acc: 0.9674 - val_loss: 0.0760 - val_acc: 0.9834
Epoch 14/21
 - 40s - loss: 0.1043 - acc: 0.9691 - val_loss: 0.0725 - val_acc: 0.9851
Epoch 15/21
 - 40s - loss: 0.0986 - acc: 0.9714 - val_loss: 0.0774 - val_acc: 0.9812
Epoch 16/21
 - 39s - loss: 0.0935 - acc: 0.9737 - val_loss: 0.0662 - val_acc: 0.9857
Epoch 17/21
 - 39s - loss: 0.0908 - acc: 0.9736 - val_loss: 0.0671 - val_acc: 0.9839
Epoch 18/21
 - 39s - loss: 0.0843 - acc: 0.9781 - val_loss: 0.0612 - val_acc: 0.9866
Epoch 19/21
 - 39s - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0545 - val_acc: 0.9897
Epoch 20/21
 - 39s - loss: 0.0778 - acc: 0.9790 - val_loss: 0.0628 - val_acc: 0.9861
Epoch 21/21
 - 40s - loss: 0.0765 - acc: 0.9798 - val_loss: 0.0454 - val_acc: 0.9915
Test accuracy:0.822
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 42s - loss: 0.4470 - acc: 0.7942 - val_loss: 0.3139 - val_acc: 0.8799
Epoch 2/21
 - 41s - loss: 0.3195 - acc: 0.8675 - val_loss: 0.2620 - val_acc: 0.9009
Epoch 3/21
 - 40s - loss: 0.2697 - acc: 0.8950 - val_loss: 0.2189 - val_acc: 0.9211
Epoch 4/21
 - 40s - loss: 0.2370 - acc: 0.9139 - val_loss: 0.1854 - val_acc: 0.9390
Epoch 5/21
 - 40s - loss: 0.2129 - acc: 0.9234 - val_loss: 0.1660 - val_acc: 0.9429
Epoch 6/21
 - 40s - loss: 0.1926 - acc: 0.9326 - val_loss: 0.1488 - val_acc: 0.9549
Epoch 7/21
 - 39s - loss: 0.1769 - acc: 0.9405 - val_loss: 0.1351 - val_acc: 0.9568
Epoch 8/21
 - 39s - loss: 0.1624 - acc: 0.9462 - val_loss: 0.1259 - val_acc: 0.9612
Epoch 9/21
 - 39s - loss: 0.1501 - acc: 0.9510 - val_loss: 0.1157 - val_acc: 0.9654
Epoch 10/21
 - 39s - loss: 0.1403 - acc: 0.9548 - val_loss: 0.1005 - val_acc: 0.9709
Epoch 11/21
 - 39s - loss: 0.1310 - acc: 0.9589 - val_loss: 0.0912 - val_acc: 0.9746
Epoch 12/21
 - 39s - loss: 0.1225 - acc: 0.9614 - val_loss: 0.0902 - val_acc: 0.9769
Epoch 13/21
 - 39s - loss: 0.1153 - acc: 0.9654 - val_loss: 0.0824 - val_acc: 0.9783
Epoch 14/21
 - 40s - loss: 0.1079 - acc: 0.9684 - val_loss: 0.0746 - val_acc: 0.9804
Epoch 15/21
 - 40s - loss: 0.1030 - acc: 0.9694 - val_loss: 0.0758 - val_acc: 0.9800
Epoch 16/21
 - 41s - loss: 0.0979 - acc: 0.9720 - val_loss: 0.0643 - val_acc: 0.9846
Epoch 17/21
 - 40s - loss: 0.0927 - acc: 0.9743 - val_loss: 0.0651 - val_acc: 0.9849
Epoch 18/21
 - 39s - loss: 0.0868 - acc: 0.9760 - val_loss: 0.0653 - val_acc: 0.9832
Epoch 19/21
 - 39s - loss: 0.0841 - acc: 0.9779 - val_loss: 0.0576 - val_acc: 0.9862
Epoch 20/21
 - 39s - loss: 0.0786 - acc: 0.9795 - val_loss: 0.0554 - val_acc: 0.9873
Epoch 21/21
 - 39s - loss: 0.0777 - acc: 0.9793 - val_loss: 0.0565 - val_acc: 0.9871
Test accuracy:0.840
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 42s - loss: 0.4698 - acc: 0.7814 - val_loss: 0.3426 - val_acc: 0.8552
Epoch 2/21
 - 39s - loss: 0.3313 - acc: 0.8640 - val_loss: 0.3010 - val_acc: 0.8686
Epoch 3/21
 - 39s - loss: 0.2776 - acc: 0.8893 - val_loss: 0.2217 - val_acc: 0.9184
Epoch 4/21
 - 39s - loss: 0.2435 - acc: 0.9075 - val_loss: 0.1945 - val_acc: 0.9297
Epoch 5/21
 - 39s - loss: 0.2203 - acc: 0.9196 - val_loss: 0.1749 - val_acc: 0.9395
Epoch 6/21
 - 39s - loss: 0.1977 - acc: 0.9298 - val_loss: 0.1533 - val_acc: 0.9498
Epoch 7/21
 - 39s - loss: 0.1810 - acc: 0.9369 - val_loss: 0.1344 - val_acc: 0.9600
Epoch 8/21
 - 39s - loss: 0.1665 - acc: 0.9443 - val_loss: 0.1367 - val_acc: 0.9562
Epoch 9/21
 - 39s - loss: 0.1537 - acc: 0.9489 - val_loss: 0.1164 - val_acc: 0.9646
Epoch 10/21
 - 39s - loss: 0.1421 - acc: 0.9544 - val_loss: 0.1057 - val_acc: 0.9699
Epoch 11/21
 - 39s - loss: 0.1333 - acc: 0.9574 - val_loss: 0.0944 - val_acc: 0.9759
Epoch 12/21
 - 40s - loss: 0.1275 - acc: 0.9618 - val_loss: 0.0867 - val_acc: 0.9783
Epoch 13/21
 - 39s - loss: 0.1198 - acc: 0.9632 - val_loss: 0.0870 - val_acc: 0.9762
Epoch 14/21
 - 39s - loss: 0.1123 - acc: 0.9658 - val_loss: 0.0755 - val_acc: 0.9821
Epoch 15/21
 - 39s - loss: 0.1078 - acc: 0.9692 - val_loss: 0.0755 - val_acc: 0.9808
Epoch 16/21
 - 39s - loss: 0.1023 - acc: 0.9709 - val_loss: 0.0688 - val_acc: 0.9837
Epoch 17/21
 - 39s - loss: 0.0957 - acc: 0.9725 - val_loss: 0.0621 - val_acc: 0.9876
Epoch 18/21
 - 39s - loss: 0.0925 - acc: 0.9750 - val_loss: 0.0634 - val_acc: 0.9851
Epoch 19/21
 - 39s - loss: 0.0893 - acc: 0.9748 - val_loss: 0.0549 - val_acc: 0.9888
Epoch 20/21
 - 39s - loss: 0.0849 - acc: 0.9771 - val_loss: 0.0568 - val_acc: 0.9885
Epoch 21/21
 - 39s - loss: 0.0812 - acc: 0.9786 - val_loss: 0.0601 - val_acc: 0.9859
Test accuracy:0.832
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 41s - loss: 0.4643 - acc: 0.7847 - val_loss: 0.3421 - val_acc: 0.8582
Epoch 2/21
 - 39s - loss: 0.3311 - acc: 0.8640 - val_loss: 0.3259 - val_acc: 0.8552
Epoch 3/21
 - 39s - loss: 0.2806 - acc: 0.8909 - val_loss: 0.2350 - val_acc: 0.9162
Epoch 4/21
 - 39s - loss: 0.2468 - acc: 0.9073 - val_loss: 0.1957 - val_acc: 0.9344
Epoch 5/21
 - 39s - loss: 0.2200 - acc: 0.9195 - val_loss: 0.1745 - val_acc: 0.9443
Epoch 6/21
 - 39s - loss: 0.1972 - acc: 0.9310 - val_loss: 0.1574 - val_acc: 0.9482
Epoch 7/21
 - 39s - loss: 0.1825 - acc: 0.9371 - val_loss: 0.1417 - val_acc: 0.9553
Epoch 8/21
 - 40s - loss: 0.1655 - acc: 0.9442 - val_loss: 0.1288 - val_acc: 0.9593
Epoch 9/21
 - 41s - loss: 0.1548 - acc: 0.9491 - val_loss: 0.1127 - val_acc: 0.9694
Epoch 10/21
 - 41s - loss: 0.1433 - acc: 0.9539 - val_loss: 0.1109 - val_acc: 0.9682
Epoch 11/21
 - 40s - loss: 0.1358 - acc: 0.9569 - val_loss: 0.0961 - val_acc: 0.9750
Epoch 12/21
 - 39s - loss: 0.1271 - acc: 0.9610 - val_loss: 0.0896 - val_acc: 0.9764
Epoch 13/21
 - 39s - loss: 0.1195 - acc: 0.9638 - val_loss: 0.0821 - val_acc: 0.9790
Epoch 14/21
 - 40s - loss: 0.1142 - acc: 0.9653 - val_loss: 0.0847 - val_acc: 0.9748
Epoch 15/21
 - 41s - loss: 0.1066 - acc: 0.9689 - val_loss: 0.0726 - val_acc: 0.9821
Epoch 16/21
 - 39s - loss: 0.1016 - acc: 0.9709 - val_loss: 0.0751 - val_acc: 0.9789
Epoch 17/21
 - 40s - loss: 0.0976 - acc: 0.9714 - val_loss: 0.0716 - val_acc: 0.9803
Epoch 18/21
 - 40s - loss: 0.0915 - acc: 0.9730 - val_loss: 0.0600 - val_acc: 0.9863
Epoch 19/21
 - 40s - loss: 0.0892 - acc: 0.9748 - val_loss: 0.0612 - val_acc: 0.9844
Epoch 20/21
 - 39s - loss: 0.0856 - acc: 0.9764 - val_loss: 0.0554 - val_acc: 0.9878
Epoch 21/21
 - 39s - loss: 0.0820 - acc: 0.9775 - val_loss: 0.0490 - val_acc: 0.9907
Test accuracy:0.777
current auc_score ------------------> 0.899
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 43s - loss: 0.4519 - acc: 0.7932 - val_loss: 0.3452 - val_acc: 0.8532
Epoch 2/21
 - 39s - loss: 0.3276 - acc: 0.8667 - val_loss: 0.2745 - val_acc: 0.8902
Epoch 3/21
 - 39s - loss: 0.2795 - acc: 0.8916 - val_loss: 0.2270 - val_acc: 0.9199
Epoch 4/21
 - 37s - loss: 0.2428 - acc: 0.9098 - val_loss: 0.1925 - val_acc: 0.9344
Epoch 5/21
 - 38s - loss: 0.2151 - acc: 0.9218 - val_loss: 0.1623 - val_acc: 0.9469
Epoch 6/21
 - 38s - loss: 0.1942 - acc: 0.9318 - val_loss: 0.1505 - val_acc: 0.9502
Epoch 7/21
 - 38s - loss: 0.1757 - acc: 0.9395 - val_loss: 0.1348 - val_acc: 0.9577
Epoch 8/21
 - 39s - loss: 0.1641 - acc: 0.9448 - val_loss: 0.1299 - val_acc: 0.9561
Epoch 9/21
 - 39s - loss: 0.1511 - acc: 0.9510 - val_loss: 0.1187 - val_acc: 0.9611
Epoch 10/21
 - 38s - loss: 0.1379 - acc: 0.9574 - val_loss: 0.1125 - val_acc: 0.9629
Epoch 11/21
 - 39s - loss: 0.1300 - acc: 0.9590 - val_loss: 0.1131 - val_acc: 0.9632
Epoch 12/21
 - 39s - loss: 0.1249 - acc: 0.9617 - val_loss: 0.1097 - val_acc: 0.9617
Epoch 13/21
 - 39s - loss: 0.1152 - acc: 0.9655 - val_loss: 0.0890 - val_acc: 0.9743
Epoch 14/21
 - 39s - loss: 0.1086 - acc: 0.9679 - val_loss: 0.0739 - val_acc: 0.9813
Epoch 15/21
 - 39s - loss: 0.1037 - acc: 0.9702 - val_loss: 0.0814 - val_acc: 0.9757
Epoch 16/21
 - 38s - loss: 0.0964 - acc: 0.9724 - val_loss: 0.0758 - val_acc: 0.9787
Epoch 17/21
 - 37s - loss: 0.0928 - acc: 0.9744 - val_loss: 0.0763 - val_acc: 0.9784

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 18/21
 - 38s - loss: 0.0861 - acc: 0.9771 - val_loss: 0.0685 - val_acc: 0.9824
Epoch 19/21
 - 39s - loss: 0.0829 - acc: 0.9775 - val_loss: 0.0652 - val_acc: 0.9829
Epoch 20/21
 - 38s - loss: 0.0809 - acc: 0.9780 - val_loss: 0.0686 - val_acc: 0.9810
Epoch 21/21
 - 39s - loss: 0.0811 - acc: 0.9786 - val_loss: 0.0600 - val_acc: 0.9852
Test accuracy:0.841
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4494 - acc: 0.7992 - val_loss: 0.3441 - val_acc: 0.8594
Epoch 2/21
 - 38s - loss: 0.3237 - acc: 0.8678 - val_loss: 0.2620 - val_acc: 0.8985
Epoch 3/21
 - 38s - loss: 0.2671 - acc: 0.8968 - val_loss: 0.2138 - val_acc: 0.9213
Epoch 4/21
 - 37s - loss: 0.2306 - acc: 0.9159 - val_loss: 0.1943 - val_acc: 0.9272
Epoch 5/21
 - 38s - loss: 0.2044 - acc: 0.9276 - val_loss: 0.1712 - val_acc: 0.9435
Epoch 6/21
 - 38s - loss: 0.1827 - acc: 0.9390 - val_loss: 0.1414 - val_acc: 0.9514
Epoch 7/21
 - 38s - loss: 0.1655 - acc: 0.9450 - val_loss: 0.1407 - val_acc: 0.9511
Epoch 8/21
 - 38s - loss: 0.1517 - acc: 0.9503 - val_loss: 0.1141 - val_acc: 0.9646
Epoch 9/21
 - 38s - loss: 0.1399 - acc: 0.9566 - val_loss: 0.1042 - val_acc: 0.9691
Epoch 10/21
 - 39s - loss: 0.1297 - acc: 0.9601 - val_loss: 0.0931 - val_acc: 0.9725
Epoch 11/21
 - 39s - loss: 0.1206 - acc: 0.9631 - val_loss: 0.0808 - val_acc: 0.9782
Epoch 12/21
 - 39s - loss: 0.1128 - acc: 0.9661 - val_loss: 0.0887 - val_acc: 0.9720
Epoch 13/21
 - 38s - loss: 0.1059 - acc: 0.9697 - val_loss: 0.0843 - val_acc: 0.9767
Epoch 14/21
 - 39s - loss: 0.1013 - acc: 0.9706 - val_loss: 0.0710 - val_acc: 0.9809
Epoch 15/21
 - 38s - loss: 0.0956 - acc: 0.9737 - val_loss: 0.0820 - val_acc: 0.9741
Epoch 16/21
 - 38s - loss: 0.0893 - acc: 0.9762 - val_loss: 0.0615 - val_acc: 0.9859
Epoch 17/21
 - 38s - loss: 0.0874 - acc: 0.9762 - val_loss: 0.0567 - val_acc: 0.9880
Epoch 18/21
 - 37s - loss: 0.0815 - acc: 0.9773 - val_loss: 0.0569 - val_acc: 0.9878
Epoch 19/21
 - 38s - loss: 0.0789 - acc: 0.9791 - val_loss: 0.0539 - val_acc: 0.9885
Epoch 20/21
 - 37s - loss: 0.0769 - acc: 0.9796 - val_loss: 0.0513 - val_acc: 0.9886
Epoch 21/21
 - 38s - loss: 0.0714 - acc: 0.9820 - val_loss: 0.0449 - val_acc: 0.9927
Test accuracy:0.838
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4550 - acc: 0.7912 - val_loss: 0.3856 - val_acc: 0.8243
Epoch 2/21
 - 38s - loss: 0.3378 - acc: 0.8597 - val_loss: 0.2892 - val_acc: 0.8844
Epoch 3/21
 - 43s - loss: 0.2884 - acc: 0.8865 - val_loss: 0.2544 - val_acc: 0.9051
Epoch 4/21
 - 40s - loss: 0.2554 - acc: 0.9034 - val_loss: 0.2234 - val_acc: 0.9223
Epoch 5/21
 - 40s - loss: 0.2274 - acc: 0.9186 - val_loss: 0.1842 - val_acc: 0.9395
Epoch 6/21
 - 40s - loss: 0.2077 - acc: 0.9261 - val_loss: 0.1667 - val_acc: 0.9440
Epoch 7/21
 - 40s - loss: 0.1885 - acc: 0.9338 - val_loss: 0.1506 - val_acc: 0.9529
Epoch 8/21
 - 40s - loss: 0.1751 - acc: 0.9397 - val_loss: 0.1381 - val_acc: 0.9588
Epoch 9/21
 - 40s - loss: 0.1638 - acc: 0.9449 - val_loss: 0.1231 - val_acc: 0.9635
Epoch 10/21
 - 40s - loss: 0.1501 - acc: 0.9515 - val_loss: 0.1093 - val_acc: 0.9691
Epoch 11/21
 - 40s - loss: 0.1415 - acc: 0.9548 - val_loss: 0.1088 - val_acc: 0.9667
Epoch 12/21
 - 39s - loss: 0.1309 - acc: 0.9597 - val_loss: 0.0958 - val_acc: 0.9739
Epoch 13/21
 - 39s - loss: 0.1243 - acc: 0.9613 - val_loss: 0.0848 - val_acc: 0.9782
Epoch 14/21
 - 39s - loss: 0.1172 - acc: 0.9643 - val_loss: 0.0856 - val_acc: 0.9777
Epoch 15/21
 - 39s - loss: 0.1120 - acc: 0.9671 - val_loss: 0.0814 - val_acc: 0.9784
Epoch 16/21
 - 39s - loss: 0.1038 - acc: 0.9695 - val_loss: 0.0777 - val_acc: 0.9778
Epoch 17/21
 - 40s - loss: 0.0993 - acc: 0.9720 - val_loss: 0.0746 - val_acc: 0.9789
Epoch 18/21
 - 40s - loss: 0.0964 - acc: 0.9727 - val_loss: 0.0611 - val_acc: 0.9859
Epoch 19/21
 - 39s - loss: 0.0926 - acc: 0.9737 - val_loss: 0.0607 - val_acc: 0.9869
Epoch 20/21
 - 39s - loss: 0.0867 - acc: 0.9766 - val_loss: 0.0610 - val_acc: 0.9852
Epoch 21/21
 - 39s - loss: 0.0832 - acc: 0.9778 - val_loss: 0.0612 - val_acc: 0.9842
Test accuracy:0.830
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 43s - loss: 0.4583 - acc: 0.7881 - val_loss: 0.3464 - val_acc: 0.8539
Epoch 2/21
 - 40s - loss: 0.3265 - acc: 0.8664 - val_loss: 0.2590 - val_acc: 0.8977
Epoch 3/21
 - 40s - loss: 0.2742 - acc: 0.8932 - val_loss: 0.2368 - val_acc: 0.9086
Epoch 4/21
 - 39s - loss: 0.2413 - acc: 0.9092 - val_loss: 0.1981 - val_acc: 0.9283
Epoch 5/21
 - 39s - loss: 0.2139 - acc: 0.9232 - val_loss: 0.1717 - val_acc: 0.9421
Epoch 6/21
 - 40s - loss: 0.1943 - acc: 0.9317 - val_loss: 0.1606 - val_acc: 0.9439
Epoch 7/21
 - 39s - loss: 0.1737 - acc: 0.9420 - val_loss: 0.1407 - val_acc: 0.9517
Epoch 8/21
 - 39s - loss: 0.1601 - acc: 0.9477 - val_loss: 0.1266 - val_acc: 0.9580
Epoch 9/21
 - 38s - loss: 0.1500 - acc: 0.9508 - val_loss: 0.1174 - val_acc: 0.9635
Epoch 10/21
 - 39s - loss: 0.1386 - acc: 0.9560 - val_loss: 0.1038 - val_acc: 0.9670
Epoch 11/21
 - 40s - loss: 0.1300 - acc: 0.9598 - val_loss: 0.0919 - val_acc: 0.9750
Epoch 12/21
 - 40s - loss: 0.1227 - acc: 0.9628 - val_loss: 0.0891 - val_acc: 0.9745
Epoch 13/21
 - 39s - loss: 0.1162 - acc: 0.9649 - val_loss: 0.0864 - val_acc: 0.9760
Epoch 14/21
 - 40s - loss: 0.1089 - acc: 0.9684 - val_loss: 0.0725 - val_acc: 0.9839
Epoch 15/21
 - 40s - loss: 0.1036 - acc: 0.9701 - val_loss: 0.0725 - val_acc: 0.9812
Epoch 16/21
 - 42s - loss: 0.0973 - acc: 0.9721 - val_loss: 0.0628 - val_acc: 0.9856
Epoch 17/21
 - 40s - loss: 0.0932 - acc: 0.9739 - val_loss: 0.0629 - val_acc: 0.9847
Epoch 18/21
 - 41s - loss: 0.0883 - acc: 0.9749 - val_loss: 0.0574 - val_acc: 0.9887
Epoch 19/21
 - 38s - loss: 0.0856 - acc: 0.9774 - val_loss: 0.0548 - val_acc: 0.9882
Epoch 20/21
 - 38s - loss: 0.0823 - acc: 0.9775 - val_loss: 0.0607 - val_acc: 0.9844
Epoch 21/21
 - 38s - loss: 0.0791 - acc: 0.9789 - val_loss: 0.0493 - val_acc: 0.9893
Test accuracy:0.848
current auc_score ------------------> 0.935
accuracies:  [0.8162634408602151, 0.7911290322580645, 0.8221774193548387, 0.839516129032258, 0.832258064516129, 0.7772849462365592, 0.8407258064516129, 0.8384408602150538, 0.8299731182795699, 0.8477150537634408]
aucs:  [0.9166, 0.9144, 0.9055, 0.9286, 0.9164, 0.8989, 0.9294, 0.9413, 0.9197, 0.9348]
mean and std AUC:  0.921+/-0.012  max:   0.9413
['2-2-2', '30', '3', '16', '0.2', '0.07', '22', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 31s - loss: 0.4887 - acc: 0.7708 - val_loss: 0.3762 - val_acc: 0.8335
Epoch 2/22
 - 28s - loss: 0.3565 - acc: 0.8487 - val_loss: 0.3478 - val_acc: 0.8456
Epoch 3/22
 - 29s - loss: 0.3030 - acc: 0.8782 - val_loss: 0.3217 - val_acc: 0.8554
Epoch 4/22
 - 29s - loss: 0.2684 - acc: 0.8949 - val_loss: 0.3253 - val_acc: 0.8498
Epoch 5/22
 - 29s - loss: 0.2466 - acc: 0.9079 - val_loss: 0.2108 - val_acc: 0.9223
Epoch 6/22
 - 29s - loss: 0.2246 - acc: 0.9158 - val_loss: 0.2597 - val_acc: 0.8919
Epoch 7/22
 - 28s - loss: 0.2071 - acc: 0.9258 - val_loss: 0.2233 - val_acc: 0.9168
Epoch 8/22
 - 28s - loss: 0.1938 - acc: 0.9323 - val_loss: 0.1819 - val_acc: 0.9341
Epoch 9/22
 - 28s - loss: 0.1800 - acc: 0.9374 - val_loss: 0.1591 - val_acc: 0.9464
Epoch 10/22
 - 29s - loss: 0.1675 - acc: 0.9434 - val_loss: 0.1611 - val_acc: 0.9460
Epoch 11/22
 - 28s - loss: 0.1583 - acc: 0.9472 - val_loss: 0.1285 - val_acc: 0.9588
Epoch 12/22
 - 28s - loss: 0.1477 - acc: 0.9526 - val_loss: 0.1111 - val_acc: 0.9681
Epoch 13/22
 - 28s - loss: 0.1396 - acc: 0.9546 - val_loss: 0.1122 - val_acc: 0.9676
Epoch 14/22
 - 28s - loss: 0.1350 - acc: 0.9578 - val_loss: 0.1027 - val_acc: 0.9705
Epoch 15/22
 - 28s - loss: 0.1272 - acc: 0.9617 - val_loss: 0.0903 - val_acc: 0.9752
Epoch 16/22
 - 29s - loss: 0.1219 - acc: 0.9628 - val_loss: 0.0914 - val_acc: 0.9759
Epoch 17/22
 - 29s - loss: 0.1162 - acc: 0.9651 - val_loss: 0.0935 - val_acc: 0.9740
Epoch 18/22
 - 29s - loss: 0.1108 - acc: 0.9668 - val_loss: 0.0745 - val_acc: 0.9823
Epoch 19/22
 - 28s - loss: 0.1086 - acc: 0.9673 - val_loss: 0.0792 - val_acc: 0.9807
Epoch 20/22
 - 30s - loss: 0.1033 - acc: 0.9693 - val_loss: 0.0765 - val_acc: 0.9818
Epoch 21/22
 - 29s - loss: 0.0976 - acc: 0.9721 - val_loss: 0.0725 - val_acc: 0.9829
Epoch 22/22
 - 31s - loss: 0.0934 - acc: 0.9742 - val_loss: 0.0638 - val_acc: 0.9868
Test accuracy:0.792
current auc_score ------------------> 0.918
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.4920 - acc: 0.7670 - val_loss: 0.3866 - val_acc: 0.8337
Epoch 2/22
 - 29s - loss: 0.3620 - acc: 0.8451 - val_loss: 0.3133 - val_acc: 0.8710
Epoch 3/22
 - 30s - loss: 0.3084 - acc: 0.8730 - val_loss: 0.2711 - val_acc: 0.8942
Epoch 4/22
 - 30s - loss: 0.2745 - acc: 0.8932 - val_loss: 0.2456 - val_acc: 0.9109
Epoch 5/22
 - 30s - loss: 0.2487 - acc: 0.9073 - val_loss: 0.2165 - val_acc: 0.9249
Epoch 6/22
 - 30s - loss: 0.2290 - acc: 0.9147 - val_loss: 0.1917 - val_acc: 0.9322
Epoch 7/22
 - 30s - loss: 0.2100 - acc: 0.9241 - val_loss: 0.1737 - val_acc: 0.9447
Epoch 8/22
 - 30s - loss: 0.1962 - acc: 0.9306 - val_loss: 0.1559 - val_acc: 0.9497
Epoch 9/22
 - 30s - loss: 0.1826 - acc: 0.9355 - val_loss: 0.1410 - val_acc: 0.9562
Epoch 10/22
 - 30s - loss: 0.1718 - acc: 0.9420 - val_loss: 0.1382 - val_acc: 0.9577
Epoch 11/22
 - 30s - loss: 0.1622 - acc: 0.9459 - val_loss: 0.1247 - val_acc: 0.9652
Epoch 12/22
 - 30s - loss: 0.1537 - acc: 0.9492 - val_loss: 0.1135 - val_acc: 0.9675
Epoch 13/22
 - 29s - loss: 0.1462 - acc: 0.9526 - val_loss: 0.1120 - val_acc: 0.9677
Epoch 14/22
 - 30s - loss: 0.1376 - acc: 0.9569 - val_loss: 0.1071 - val_acc: 0.9664
Epoch 15/22
 - 30s - loss: 0.1303 - acc: 0.9594 - val_loss: 0.1049 - val_acc: 0.9675
Epoch 16/22
 - 30s - loss: 0.1234 - acc: 0.9617 - val_loss: 0.0902 - val_acc: 0.9757
Epoch 17/22
 - 30s - loss: 0.1195 - acc: 0.9633 - val_loss: 0.0857 - val_acc: 0.9790
Epoch 18/22
 - 30s - loss: 0.1135 - acc: 0.9658 - val_loss: 0.0792 - val_acc: 0.9800
Epoch 19/22
 - 30s - loss: 0.1100 - acc: 0.9667 - val_loss: 0.1185 - val_acc: 0.9598
Epoch 20/22
 - 30s - loss: 0.1042 - acc: 0.9696 - val_loss: 0.0719 - val_acc: 0.9827
Epoch 21/22
 - 30s - loss: 0.1023 - acc: 0.9703 - val_loss: 0.0667 - val_acc: 0.9854
Epoch 22/22
 - 30s - loss: 0.0985 - acc: 0.9728 - val_loss: 0.0667 - val_acc: 0.9853
Test accuracy:0.817
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.4872 - acc: 0.7719 - val_loss: 0.3874 - val_acc: 0.8276
Epoch 2/22
 - 30s - loss: 0.3618 - acc: 0.8453 - val_loss: 0.3261 - val_acc: 0.8555
Epoch 3/22
 - 29s - loss: 0.3118 - acc: 0.8723 - val_loss: 0.2693 - val_acc: 0.8922
Epoch 4/22
 - 29s - loss: 0.2776 - acc: 0.8903 - val_loss: 0.2647 - val_acc: 0.8898
Epoch 5/22
 - 29s - loss: 0.2518 - acc: 0.9052 - val_loss: 0.2193 - val_acc: 0.9157
Epoch 6/22
 - 30s - loss: 0.2277 - acc: 0.9144 - val_loss: 0.2279 - val_acc: 0.9100
Epoch 7/22
 - 30s - loss: 0.2094 - acc: 0.9248 - val_loss: 0.1716 - val_acc: 0.9420
Epoch 8/22
 - 30s - loss: 0.1974 - acc: 0.9305 - val_loss: 0.1601 - val_acc: 0.9435
Epoch 9/22
 - 30s - loss: 0.1816 - acc: 0.9386 - val_loss: 0.1411 - val_acc: 0.9563
Epoch 10/22
 - 30s - loss: 0.1705 - acc: 0.9420 - val_loss: 0.1324 - val_acc: 0.9585
Epoch 11/22
 - 29s - loss: 0.1594 - acc: 0.9473 - val_loss: 0.1273 - val_acc: 0.9623
Epoch 12/22
 - 29s - loss: 0.1527 - acc: 0.9500 - val_loss: 0.1204 - val_acc: 0.9640
Epoch 13/22
 - 30s - loss: 0.1410 - acc: 0.9551 - val_loss: 0.1092 - val_acc: 0.9659
Epoch 14/22
 - 30s - loss: 0.1364 - acc: 0.9566 - val_loss: 0.1002 - val_acc: 0.9746
Epoch 15/22
 - 29s - loss: 0.1271 - acc: 0.9605 - val_loss: 0.0983 - val_acc: 0.9709
Epoch 16/22
 - 30s - loss: 0.1222 - acc: 0.9623 - val_loss: 0.0918 - val_acc: 0.9738
Epoch 17/22
 - 30s - loss: 0.1153 - acc: 0.9651 - val_loss: 0.0843 - val_acc: 0.9754
Epoch 18/22
 - 30s - loss: 0.1103 - acc: 0.9675 - val_loss: 0.0750 - val_acc: 0.9819
Epoch 19/22
 - 30s - loss: 0.1053 - acc: 0.9694 - val_loss: 0.0778 - val_acc: 0.9790
Epoch 20/22
 - 30s - loss: 0.1002 - acc: 0.9716 - val_loss: 0.0741 - val_acc: 0.9805
Epoch 21/22
 - 30s - loss: 0.0976 - acc: 0.9718 - val_loss: 0.0652 - val_acc: 0.9857
Epoch 22/22
 - 30s - loss: 0.0926 - acc: 0.9742 - val_loss: 0.0628 - val_acc: 0.9856
Test accuracy:0.819
current auc_score ------------------> 0.921
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.4888 - acc: 0.7710 - val_loss: 0.3789 - val_acc: 0.8363
Epoch 2/22
 - 30s - loss: 0.3624 - acc: 0.8475 - val_loss: 0.3226 - val_acc: 0.8631
Epoch 3/22
 - 30s - loss: 0.3116 - acc: 0.8747 - val_loss: 0.2691 - val_acc: 0.8966
Epoch 4/22
 - 29s - loss: 0.2786 - acc: 0.8923 - val_loss: 0.2518 - val_acc: 0.9050
Epoch 5/22
 - 30s - loss: 0.2516 - acc: 0.9051 - val_loss: 0.2315 - val_acc: 0.9133
Epoch 6/22
 - 30s - loss: 0.2292 - acc: 0.9153 - val_loss: 0.2063 - val_acc: 0.9290
Epoch 7/22
 - 30s - loss: 0.2128 - acc: 0.9235 - val_loss: 0.1864 - val_acc: 0.9346
Epoch 8/22
 - 30s - loss: 0.1947 - acc: 0.9326 - val_loss: 0.1648 - val_acc: 0.9435
Epoch 9/22
 - 30s - loss: 0.1845 - acc: 0.9378 - val_loss: 0.1494 - val_acc: 0.9506
Epoch 10/22
 - 30s - loss: 0.1725 - acc: 0.9406 - val_loss: 0.1365 - val_acc: 0.9567
Epoch 11/22
 - 30s - loss: 0.1600 - acc: 0.9477 - val_loss: 0.1248 - val_acc: 0.9611
Epoch 12/22
 - 30s - loss: 0.1505 - acc: 0.9508 - val_loss: 0.1175 - val_acc: 0.9646
Epoch 13/22
 - 30s - loss: 0.1422 - acc: 0.9545 - val_loss: 0.1123 - val_acc: 0.9661
Epoch 14/22
 - 30s - loss: 0.1361 - acc: 0.9576 - val_loss: 0.1052 - val_acc: 0.9682
Epoch 15/22
 - 30s - loss: 0.1271 - acc: 0.9610 - val_loss: 0.0952 - val_acc: 0.9738
Epoch 16/22
 - 29s - loss: 0.1221 - acc: 0.9632 - val_loss: 0.0895 - val_acc: 0.9745
Epoch 17/22
 - 30s - loss: 0.1151 - acc: 0.9656 - val_loss: 0.0937 - val_acc: 0.9723
Epoch 18/22
 - 30s - loss: 0.1118 - acc: 0.9674 - val_loss: 0.0811 - val_acc: 0.9784
Epoch 19/22
 - 30s - loss: 0.1065 - acc: 0.9690 - val_loss: 0.0813 - val_acc: 0.9787
Epoch 20/22
 - 29s - loss: 0.1024 - acc: 0.9696 - val_loss: 0.0715 - val_acc: 0.9841
Epoch 21/22
 - 30s - loss: 0.0969 - acc: 0.9725 - val_loss: 0.0674 - val_acc: 0.9859
Epoch 22/22
 - 30s - loss: 0.0939 - acc: 0.9734 - val_loss: 0.0688 - val_acc: 0.9823
Test accuracy:0.812
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.4943 - acc: 0.7715 - val_loss: 0.3867 - val_acc: 0.8281
Epoch 2/22
 - 30s - loss: 0.3600 - acc: 0.8489 - val_loss: 0.3464 - val_acc: 0.8465
Epoch 3/22
 - 30s - loss: 0.3033 - acc: 0.8794 - val_loss: 0.2524 - val_acc: 0.9035
Epoch 4/22
 - 29s - loss: 0.2684 - acc: 0.8966 - val_loss: 0.2226 - val_acc: 0.9204
Epoch 5/22
 - 30s - loss: 0.2415 - acc: 0.9103 - val_loss: 0.1976 - val_acc: 0.9339
Epoch 6/22
 - 30s - loss: 0.2187 - acc: 0.9215 - val_loss: 0.1742 - val_acc: 0.9393
Epoch 7/22
 - 29s - loss: 0.1991 - acc: 0.9305 - val_loss: 0.1586 - val_acc: 0.9467
Epoch 8/22
 - 30s - loss: 0.1851 - acc: 0.9359 - val_loss: 0.1518 - val_acc: 0.9479
Epoch 9/22
 - 30s - loss: 0.1746 - acc: 0.9411 - val_loss: 0.1362 - val_acc: 0.9587
Epoch 10/22
 - 30s - loss: 0.1613 - acc: 0.9471 - val_loss: 0.1289 - val_acc: 0.9622
Epoch 11/22
 - 30s - loss: 0.1517 - acc: 0.9508 - val_loss: 0.1232 - val_acc: 0.9600
Epoch 12/22
 - 30s - loss: 0.1444 - acc: 0.9542 - val_loss: 0.1107 - val_acc: 0.9669
Epoch 13/22
 - 30s - loss: 0.1348 - acc: 0.9600 - val_loss: 0.1072 - val_acc: 0.9660
Epoch 14/22
 - 30s - loss: 0.1260 - acc: 0.9619 - val_loss: 0.0935 - val_acc: 0.9733
Epoch 15/22
 - 30s - loss: 0.1224 - acc: 0.9620 - val_loss: 0.0842 - val_acc: 0.9783
Epoch 16/22
 - 30s - loss: 0.1157 - acc: 0.9673 - val_loss: 0.0853 - val_acc: 0.9782
Epoch 17/22
 - 30s - loss: 0.1122 - acc: 0.9657 - val_loss: 0.0761 - val_acc: 0.9807
Epoch 18/22
 - 29s - loss: 0.1055 - acc: 0.9695 - val_loss: 0.0715 - val_acc: 0.9837
Epoch 19/22
 - 30s - loss: 0.1027 - acc: 0.9714 - val_loss: 0.0696 - val_acc: 0.9836
Epoch 20/22
 - 31s - loss: 0.0969 - acc: 0.9723 - val_loss: 0.0752 - val_acc: 0.9816
Epoch 21/22
 - 30s - loss: 0.0936 - acc: 0.9743 - val_loss: 0.0598 - val_acc: 0.9874
Epoch 22/22
 - 30s - loss: 0.0892 - acc: 0.9762 - val_loss: 0.0598 - val_acc: 0.9882
Test accuracy:0.823
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 33s - loss: 0.4877 - acc: 0.7712 - val_loss: 0.5097 - val_acc: 0.7400
Epoch 2/22
 - 30s - loss: 0.3642 - acc: 0.8456 - val_loss: 0.3117 - val_acc: 0.8746
Epoch 3/22
 - 30s - loss: 0.3100 - acc: 0.8744 - val_loss: 0.2905 - val_acc: 0.8817
Epoch 4/22
 - 30s - loss: 0.2800 - acc: 0.8897 - val_loss: 0.3626 - val_acc: 0.8321
Epoch 5/22
 - 30s - loss: 0.2518 - acc: 0.9053 - val_loss: 0.2486 - val_acc: 0.9052
Epoch 6/22
 - 30s - loss: 0.2301 - acc: 0.9160 - val_loss: 0.2556 - val_acc: 0.8993
Epoch 7/22
 - 30s - loss: 0.2125 - acc: 0.9228 - val_loss: 0.2034 - val_acc: 0.9307
Epoch 8/22
 - 30s - loss: 0.1973 - acc: 0.9300 - val_loss: 0.1587 - val_acc: 0.9480
Epoch 9/22
 - 30s - loss: 0.1831 - acc: 0.9360 - val_loss: 0.2004 - val_acc: 0.9248
Epoch 10/22
 - 30s - loss: 0.1712 - acc: 0.9425 - val_loss: 0.1716 - val_acc: 0.9393
Epoch 11/22
 - 30s - loss: 0.1599 - acc: 0.9472 - val_loss: 0.1284 - val_acc: 0.9623
Epoch 12/22
 - 30s - loss: 0.1504 - acc: 0.9515 - val_loss: 0.1155 - val_acc: 0.9671
Epoch 13/22
 - 30s - loss: 0.1427 - acc: 0.9551 - val_loss: 0.1359 - val_acc: 0.9575
Epoch 14/22
 - 30s - loss: 0.1363 - acc: 0.9578 - val_loss: 0.1352 - val_acc: 0.9559
Epoch 15/22
 - 30s - loss: 0.1271 - acc: 0.9606 - val_loss: 0.1297 - val_acc: 0.9590

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 16/22
 - 30s - loss: 0.1198 - acc: 0.9639 - val_loss: 0.1203 - val_acc: 0.9631
Epoch 00016: early stopping
Test accuracy:0.685
current auc_score ------------------> 0.892
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.4810 - acc: 0.7719 - val_loss: 0.3702 - val_acc: 0.8434
Epoch 2/22
 - 30s - loss: 0.3523 - acc: 0.8502 - val_loss: 0.3051 - val_acc: 0.8726
Epoch 3/22
 - 30s - loss: 0.2999 - acc: 0.8798 - val_loss: 0.2749 - val_acc: 0.8873
Epoch 4/22
 - 30s - loss: 0.2671 - acc: 0.8958 - val_loss: 0.2330 - val_acc: 0.9096
Epoch 5/22
 - 31s - loss: 0.2426 - acc: 0.9074 - val_loss: 0.2094 - val_acc: 0.9199
Epoch 6/22
 - 29s - loss: 0.2255 - acc: 0.9148 - val_loss: 0.2114 - val_acc: 0.9183
Epoch 7/22
 - 30s - loss: 0.2050 - acc: 0.9255 - val_loss: 0.1795 - val_acc: 0.9357
Epoch 8/22
 - 30s - loss: 0.1903 - acc: 0.9319 - val_loss: 0.1741 - val_acc: 0.9375
Epoch 9/22
 - 30s - loss: 0.1785 - acc: 0.9382 - val_loss: 0.1481 - val_acc: 0.9514
Epoch 10/22
 - 30s - loss: 0.1678 - acc: 0.9430 - val_loss: 0.1607 - val_acc: 0.9429
Epoch 11/22
 - 30s - loss: 0.1563 - acc: 0.9476 - val_loss: 0.1266 - val_acc: 0.9577
Epoch 12/22
 - 30s - loss: 0.1476 - acc: 0.9518 - val_loss: 0.1279 - val_acc: 0.9576
Epoch 13/22
 - 30s - loss: 0.1377 - acc: 0.9567 - val_loss: 0.1060 - val_acc: 0.9691
Epoch 14/22
 - 30s - loss: 0.1333 - acc: 0.9580 - val_loss: 0.1021 - val_acc: 0.9724
Epoch 15/22
 - 30s - loss: 0.1253 - acc: 0.9612 - val_loss: 0.0973 - val_acc: 0.9711
Epoch 16/22
 - 30s - loss: 0.1219 - acc: 0.9625 - val_loss: 0.0900 - val_acc: 0.9739
Epoch 17/22
 - 30s - loss: 0.1155 - acc: 0.9653 - val_loss: 0.0895 - val_acc: 0.9748
Epoch 18/22
 - 30s - loss: 0.1103 - acc: 0.9676 - val_loss: 0.0759 - val_acc: 0.9810
Epoch 19/22
 - 30s - loss: 0.1054 - acc: 0.9693 - val_loss: 0.0796 - val_acc: 0.9794
Epoch 20/22
 - 30s - loss: 0.1003 - acc: 0.9709 - val_loss: 0.0739 - val_acc: 0.9813
Epoch 21/22
 - 30s - loss: 0.0965 - acc: 0.9723 - val_loss: 0.0760 - val_acc: 0.9800
Epoch 22/22
 - 30s - loss: 0.0947 - acc: 0.9739 - val_loss: 0.0636 - val_acc: 0.9846
Test accuracy:0.812
current auc_score ------------------> 0.918
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.4817 - acc: 0.7767 - val_loss: 0.4347 - val_acc: 0.7919
Epoch 2/22
 - 30s - loss: 0.3599 - acc: 0.8469 - val_loss: 0.3044 - val_acc: 0.8796
Epoch 3/22
 - 30s - loss: 0.3071 - acc: 0.8754 - val_loss: 0.3135 - val_acc: 0.8619
Epoch 4/22
 - 30s - loss: 0.2761 - acc: 0.8929 - val_loss: 0.2406 - val_acc: 0.9085
Epoch 5/22
 - 29s - loss: 0.2473 - acc: 0.9056 - val_loss: 0.2016 - val_acc: 0.9291
Epoch 6/22
 - 29s - loss: 0.2262 - acc: 0.9176 - val_loss: 0.2174 - val_acc: 0.9184
Epoch 7/22
 - 29s - loss: 0.2081 - acc: 0.9243 - val_loss: 0.1629 - val_acc: 0.9469
Epoch 8/22
 - 29s - loss: 0.1925 - acc: 0.9317 - val_loss: 0.1590 - val_acc: 0.9478
Epoch 9/22
 - 29s - loss: 0.1803 - acc: 0.9361 - val_loss: 0.1481 - val_acc: 0.9531
Epoch 10/22
 - 29s - loss: 0.1696 - acc: 0.9422 - val_loss: 0.1568 - val_acc: 0.9479
Epoch 11/22
 - 28s - loss: 0.1575 - acc: 0.9479 - val_loss: 0.1244 - val_acc: 0.9618
Epoch 12/22
 - 28s - loss: 0.1476 - acc: 0.9513 - val_loss: 0.1177 - val_acc: 0.9657
Epoch 13/22
 - 29s - loss: 0.1430 - acc: 0.9540 - val_loss: 0.1257 - val_acc: 0.9613
Epoch 14/22
 - 28s - loss: 0.1368 - acc: 0.9555 - val_loss: 0.1144 - val_acc: 0.9662
Epoch 15/22
 - 28s - loss: 0.1277 - acc: 0.9604 - val_loss: 0.0935 - val_acc: 0.9749
Epoch 16/22
 - 29s - loss: 0.1208 - acc: 0.9625 - val_loss: 0.0985 - val_acc: 0.9721
Epoch 17/22
 - 29s - loss: 0.1162 - acc: 0.9652 - val_loss: 0.0855 - val_acc: 0.9767
Epoch 18/22
 - 28s - loss: 0.1141 - acc: 0.9651 - val_loss: 0.0932 - val_acc: 0.9755
Epoch 19/22
 - 29s - loss: 0.1085 - acc: 0.9673 - val_loss: 0.0756 - val_acc: 0.9809
Epoch 20/22
 - 28s - loss: 0.1039 - acc: 0.9698 - val_loss: 0.0710 - val_acc: 0.9829
Epoch 21/22
 - 29s - loss: 0.0985 - acc: 0.9719 - val_loss: 0.0725 - val_acc: 0.9809
Epoch 22/22
 - 28s - loss: 0.0969 - acc: 0.9723 - val_loss: 0.0660 - val_acc: 0.9843
Test accuracy:0.799
current auc_score ------------------> 0.906
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 33s - loss: 0.4721 - acc: 0.7801 - val_loss: 0.5230 - val_acc: 0.7270
Epoch 2/22
 - 31s - loss: 0.3438 - acc: 0.8580 - val_loss: 0.2958 - val_acc: 0.8810
Epoch 3/22
 - 29s - loss: 0.2972 - acc: 0.8806 - val_loss: 0.3280 - val_acc: 0.8512
Epoch 4/22
 - 29s - loss: 0.2631 - acc: 0.8997 - val_loss: 0.2379 - val_acc: 0.9118
Epoch 5/22
 - 29s - loss: 0.2404 - acc: 0.9107 - val_loss: 0.2230 - val_acc: 0.9155
Epoch 6/22
 - 29s - loss: 0.2189 - acc: 0.9200 - val_loss: 0.1918 - val_acc: 0.9346
Epoch 7/22
 - 29s - loss: 0.2024 - acc: 0.9284 - val_loss: 0.1927 - val_acc: 0.9359
Epoch 8/22
 - 28s - loss: 0.1906 - acc: 0.9340 - val_loss: 0.1643 - val_acc: 0.9457
Epoch 9/22
 - 28s - loss: 0.1764 - acc: 0.9402 - val_loss: 0.1420 - val_acc: 0.9547
Epoch 10/22
 - 31s - loss: 0.1656 - acc: 0.9441 - val_loss: 0.1492 - val_acc: 0.9516
Epoch 11/22
 - 30s - loss: 0.1546 - acc: 0.9498 - val_loss: 0.1229 - val_acc: 0.9631
Epoch 12/22
 - 30s - loss: 0.1450 - acc: 0.9545 - val_loss: 0.1219 - val_acc: 0.9656
Epoch 13/22
 - 30s - loss: 0.1381 - acc: 0.9560 - val_loss: 0.1022 - val_acc: 0.9729
Epoch 14/22
 - 30s - loss: 0.1328 - acc: 0.9584 - val_loss: 0.1019 - val_acc: 0.9721
Epoch 15/22
 - 30s - loss: 0.1245 - acc: 0.9618 - val_loss: 0.0948 - val_acc: 0.9744
Epoch 16/22
 - 30s - loss: 0.1177 - acc: 0.9659 - val_loss: 0.0860 - val_acc: 0.9779
Epoch 17/22
 - 30s - loss: 0.1129 - acc: 0.9664 - val_loss: 0.0822 - val_acc: 0.9799
Epoch 18/22
 - 30s - loss: 0.1081 - acc: 0.9683 - val_loss: 0.0767 - val_acc: 0.9819
Epoch 19/22
 - 30s - loss: 0.1026 - acc: 0.9705 - val_loss: 0.0801 - val_acc: 0.9769
Epoch 20/22
 - 30s - loss: 0.1012 - acc: 0.9708 - val_loss: 0.0688 - val_acc: 0.9843
Epoch 21/22
 - 30s - loss: 0.0954 - acc: 0.9736 - val_loss: 0.0659 - val_acc: 0.9849
Epoch 22/22
 - 30s - loss: 0.0908 - acc: 0.9752 - val_loss: 0.0590 - val_acc: 0.9861
Test accuracy:0.815
current auc_score ------------------> 0.940
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 32s - loss: 0.5069 - acc: 0.7552 - val_loss: 0.3863 - val_acc: 0.8263
Epoch 2/22
 - 30s - loss: 0.3716 - acc: 0.8391 - val_loss: 0.3149 - val_acc: 0.8721
Epoch 3/22
 - 30s - loss: 0.3159 - acc: 0.8709 - val_loss: 0.2878 - val_acc: 0.8809
Epoch 4/22
 - 30s - loss: 0.2796 - acc: 0.8903 - val_loss: 0.2668 - val_acc: 0.8937
Epoch 5/22
 - 30s - loss: 0.2521 - acc: 0.9017 - val_loss: 0.2198 - val_acc: 0.9157
Epoch 6/22
 - 29s - loss: 0.2279 - acc: 0.9156 - val_loss: 0.1890 - val_acc: 0.9344
Epoch 7/22
 - 29s - loss: 0.2130 - acc: 0.9216 - val_loss: 0.1835 - val_acc: 0.9355
Epoch 8/22
 - 29s - loss: 0.1952 - acc: 0.9299 - val_loss: 0.1553 - val_acc: 0.9521
Epoch 9/22
 - 29s - loss: 0.1836 - acc: 0.9344 - val_loss: 0.1562 - val_acc: 0.9473
Epoch 10/22
 - 29s - loss: 0.1682 - acc: 0.9429 - val_loss: 0.1459 - val_acc: 0.9511
Epoch 11/22
 - 29s - loss: 0.1563 - acc: 0.9487 - val_loss: 0.1262 - val_acc: 0.9621
Epoch 12/22
 - 29s - loss: 0.1461 - acc: 0.9537 - val_loss: 0.1161 - val_acc: 0.9646
Epoch 13/22
 - 29s - loss: 0.1404 - acc: 0.9554 - val_loss: 0.1083 - val_acc: 0.9690
Epoch 14/22
 - 28s - loss: 0.1326 - acc: 0.9591 - val_loss: 0.1099 - val_acc: 0.9655
Epoch 15/22
 - 29s - loss: 0.1255 - acc: 0.9626 - val_loss: 0.0956 - val_acc: 0.9728
Epoch 16/22
 - 29s - loss: 0.1193 - acc: 0.9639 - val_loss: 0.1013 - val_acc: 0.9706
Epoch 17/22
 - 29s - loss: 0.1130 - acc: 0.9662 - val_loss: 0.0814 - val_acc: 0.9816
Epoch 18/22
 - 28s - loss: 0.1082 - acc: 0.9685 - val_loss: 0.0808 - val_acc: 0.9794
Epoch 19/22
 - 29s - loss: 0.1029 - acc: 0.9708 - val_loss: 0.0747 - val_acc: 0.9807
Epoch 20/22
 - 29s - loss: 0.0986 - acc: 0.9720 - val_loss: 0.0692 - val_acc: 0.9836
Epoch 21/22
 - 28s - loss: 0.0961 - acc: 0.9734 - val_loss: 0.0699 - val_acc: 0.9821
Epoch 22/22
 - 29s - loss: 0.0931 - acc: 0.9745 - val_loss: 0.0616 - val_acc: 0.9869
Test accuracy:0.796
current auc_score ------------------> 0.900
accuracies:  [0.7923387096774194, 0.8174731182795699, 0.8186827956989248, 0.8118279569892473, 0.822983870967742, 0.6848118279569892, 0.8119623655913979, 0.7990591397849462, 0.8145161290322581, 0.7956989247311828]
aucs:  [0.9182, 0.9186, 0.9214, 0.9244, 0.9379, 0.8919, 0.9177, 0.9058, 0.9404, 0.9004]
mean and std AUC:  0.918+/-0.014  max:   0.9404
['2-2-2', '30', '3', '16', '0.2', '0.07', '23', 'adadelta', '0.5', 'FALSE', '128', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 27s - loss: 0.5285 - acc: 0.7431 - val_loss: 0.4440 - val_acc: 0.7935
Epoch 2/23
 - 25s - loss: 0.3950 - acc: 0.8274 - val_loss: 0.3791 - val_acc: 0.8256
Epoch 3/23
 - 25s - loss: 0.3422 - acc: 0.8585 - val_loss: 0.3042 - val_acc: 0.8758
Epoch 4/23
 - 24s - loss: 0.3070 - acc: 0.8761 - val_loss: 0.2846 - val_acc: 0.8811
Epoch 5/23
 - 25s - loss: 0.2820 - acc: 0.8886 - val_loss: 0.2843 - val_acc: 0.8818
Epoch 6/23
 - 25s - loss: 0.2625 - acc: 0.8998 - val_loss: 0.2791 - val_acc: 0.8828
Epoch 7/23
 - 25s - loss: 0.2428 - acc: 0.9087 - val_loss: 0.2158 - val_acc: 0.9192
Epoch 8/23
 - 24s - loss: 0.2287 - acc: 0.9171 - val_loss: 0.2087 - val_acc: 0.9213
Epoch 9/23
 - 25s - loss: 0.2159 - acc: 0.9220 - val_loss: 0.1876 - val_acc: 0.9321
Epoch 10/23
 - 25s - loss: 0.2005 - acc: 0.9295 - val_loss: 0.1781 - val_acc: 0.9372
Epoch 11/23
 - 25s - loss: 0.1910 - acc: 0.9345 - val_loss: 0.1569 - val_acc: 0.9483
Epoch 12/23
 - 24s - loss: 0.1815 - acc: 0.9365 - val_loss: 0.1791 - val_acc: 0.9380
Epoch 13/23
 - 24s - loss: 0.1727 - acc: 0.9427 - val_loss: 0.1509 - val_acc: 0.9497
Epoch 14/23
 - 25s - loss: 0.1629 - acc: 0.9459 - val_loss: 0.1380 - val_acc: 0.9563
Epoch 15/23
 - 25s - loss: 0.1557 - acc: 0.9491 - val_loss: 0.1297 - val_acc: 0.9606
Epoch 16/23
 - 24s - loss: 0.1498 - acc: 0.9518 - val_loss: 0.1176 - val_acc: 0.9672
Epoch 17/23
 - 24s - loss: 0.1437 - acc: 0.9535 - val_loss: 0.1195 - val_acc: 0.9665
Epoch 18/23
 - 25s - loss: 0.1364 - acc: 0.9568 - val_loss: 0.1253 - val_acc: 0.9637
Epoch 19/23
 - 24s - loss: 0.1323 - acc: 0.9590 - val_loss: 0.1031 - val_acc: 0.9713
Epoch 20/23
 - 25s - loss: 0.1265 - acc: 0.9617 - val_loss: 0.0999 - val_acc: 0.9703
Epoch 21/23
 - 25s - loss: 0.1232 - acc: 0.9620 - val_loss: 0.0910 - val_acc: 0.9765
Epoch 22/23
 - 25s - loss: 0.1172 - acc: 0.9646 - val_loss: 0.0908 - val_acc: 0.9748
Epoch 23/23
 - 25s - loss: 0.1143 - acc: 0.9668 - val_loss: 0.0816 - val_acc: 0.9793
Test accuracy:0.804
current auc_score ------------------> 0.912
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 27s - loss: 0.5220 - acc: 0.7450 - val_loss: 0.4152 - val_acc: 0.8077
Epoch 2/23
 - 25s - loss: 0.3936 - acc: 0.8265 - val_loss: 0.3476 - val_acc: 0.8519
Epoch 3/23
 - 25s - loss: 0.3432 - acc: 0.8542 - val_loss: 0.2998 - val_acc: 0.8822
Epoch 4/23
 - 24s - loss: 0.3099 - acc: 0.8735 - val_loss: 0.3058 - val_acc: 0.8689
Epoch 5/23
 - 25s - loss: 0.2842 - acc: 0.8844 - val_loss: 0.2820 - val_acc: 0.8820
Epoch 6/23
 - 25s - loss: 0.2634 - acc: 0.8968 - val_loss: 0.2461 - val_acc: 0.9012
Epoch 7/23
 - 25s - loss: 0.2474 - acc: 0.9071 - val_loss: 0.2189 - val_acc: 0.9211
Epoch 8/23
 - 25s - loss: 0.2320 - acc: 0.9152 - val_loss: 0.1924 - val_acc: 0.9342
Epoch 9/23
 - 25s - loss: 0.2167 - acc: 0.9205 - val_loss: 0.1860 - val_acc: 0.9319
Epoch 10/23
 - 25s - loss: 0.2043 - acc: 0.9257 - val_loss: 0.1715 - val_acc: 0.9426
Epoch 11/23
 - 25s - loss: 0.1952 - acc: 0.9307 - val_loss: 0.1741 - val_acc: 0.9375
Epoch 12/23
 - 24s - loss: 0.1846 - acc: 0.9362 - val_loss: 0.1488 - val_acc: 0.9518
Epoch 13/23
 - 25s - loss: 0.1746 - acc: 0.9400 - val_loss: 0.1408 - val_acc: 0.9552
Epoch 14/23
 - 25s - loss: 0.1672 - acc: 0.9444 - val_loss: 0.1391 - val_acc: 0.9533
Epoch 15/23
 - 25s - loss: 0.1606 - acc: 0.9474 - val_loss: 0.1388 - val_acc: 0.9531
Epoch 16/23
 - 25s - loss: 0.1506 - acc: 0.9514 - val_loss: 0.1347 - val_acc: 0.9523
Epoch 17/23
 - 25s - loss: 0.1460 - acc: 0.9518 - val_loss: 0.1140 - val_acc: 0.9674
Epoch 18/23
 - 25s - loss: 0.1398 - acc: 0.9544 - val_loss: 0.1080 - val_acc: 0.9671
Epoch 19/23
 - 27s - loss: 0.1350 - acc: 0.9572 - val_loss: 0.0988 - val_acc: 0.9728
Epoch 20/23
 - 26s - loss: 0.1292 - acc: 0.9604 - val_loss: 0.0966 - val_acc: 0.9723
Epoch 21/23
 - 26s - loss: 0.1243 - acc: 0.9613 - val_loss: 0.1012 - val_acc: 0.9680
Epoch 22/23
 - 25s - loss: 0.1191 - acc: 0.9638 - val_loss: 0.0907 - val_acc: 0.9755
Epoch 23/23
 - 26s - loss: 0.1148 - acc: 0.9650 - val_loss: 0.0860 - val_acc: 0.9787
Test accuracy:0.850
current auc_score ------------------> 0.951
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5246 - acc: 0.7472 - val_loss: 0.4334 - val_acc: 0.8041
Epoch 2/23
 - 26s - loss: 0.3977 - acc: 0.8259 - val_loss: 0.3834 - val_acc: 0.8299
Epoch 3/23
 - 26s - loss: 0.3416 - acc: 0.8582 - val_loss: 0.3065 - val_acc: 0.8717
Epoch 4/23
 - 26s - loss: 0.3008 - acc: 0.8815 - val_loss: 0.2789 - val_acc: 0.8898
Epoch 5/23
 - 26s - loss: 0.2738 - acc: 0.8946 - val_loss: 0.2863 - val_acc: 0.8811
Epoch 6/23
 - 26s - loss: 0.2528 - acc: 0.9071 - val_loss: 0.2190 - val_acc: 0.9192
Epoch 7/23
 - 26s - loss: 0.2334 - acc: 0.9150 - val_loss: 0.1964 - val_acc: 0.9277
Epoch 8/23
 - 26s - loss: 0.2196 - acc: 0.9205 - val_loss: 0.2366 - val_acc: 0.9037
Epoch 9/23
 - 26s - loss: 0.2060 - acc: 0.9283 - val_loss: 0.1756 - val_acc: 0.9396
Epoch 10/23
 - 25s - loss: 0.1946 - acc: 0.9316 - val_loss: 0.1576 - val_acc: 0.9462
Epoch 11/23
 - 25s - loss: 0.1854 - acc: 0.9371 - val_loss: 0.1491 - val_acc: 0.9517
Epoch 12/23
 - 25s - loss: 0.1732 - acc: 0.9411 - val_loss: 0.1677 - val_acc: 0.9421
Epoch 13/23
 - 25s - loss: 0.1654 - acc: 0.9460 - val_loss: 0.1590 - val_acc: 0.9455
Epoch 14/23
 - 25s - loss: 0.1578 - acc: 0.9477 - val_loss: 0.1240 - val_acc: 0.9617
Epoch 15/23
 - 25s - loss: 0.1507 - acc: 0.9519 - val_loss: 0.1120 - val_acc: 0.9669
Epoch 16/23
 - 25s - loss: 0.1452 - acc: 0.9538 - val_loss: 0.1236 - val_acc: 0.9608
Epoch 17/23
 - 25s - loss: 0.1399 - acc: 0.9553 - val_loss: 0.1340 - val_acc: 0.9566
Epoch 18/23
 - 24s - loss: 0.1319 - acc: 0.9594 - val_loss: 0.1235 - val_acc: 0.9607

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/23
 - 25s - loss: 0.1262 - acc: 0.9618 - val_loss: 0.0964 - val_acc: 0.9738
Epoch 20/23
 - 27s - loss: 0.1229 - acc: 0.9627 - val_loss: 0.0956 - val_acc: 0.9738
Epoch 21/23
 - 25s - loss: 0.1226 - acc: 0.9636 - val_loss: 0.0958 - val_acc: 0.9733
Epoch 22/23
 - 25s - loss: 0.1220 - acc: 0.9638 - val_loss: 0.0940 - val_acc: 0.9730
Epoch 23/23
 - 25s - loss: 0.1194 - acc: 0.9643 - val_loss: 0.0905 - val_acc: 0.9744
Test accuracy:0.835
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5305 - acc: 0.7423 - val_loss: 0.4940 - val_acc: 0.7598
Epoch 2/23
 - 27s - loss: 0.4110 - acc: 0.8214 - val_loss: 0.3867 - val_acc: 0.8303
Epoch 3/23
 - 26s - loss: 0.3514 - acc: 0.8527 - val_loss: 0.4105 - val_acc: 0.8134
Epoch 4/23
 - 26s - loss: 0.3159 - acc: 0.8717 - val_loss: 0.3049 - val_acc: 0.8780
Epoch 5/23
 - 26s - loss: 0.2884 - acc: 0.8860 - val_loss: 0.3100 - val_acc: 0.8760
Epoch 6/23
 - 26s - loss: 0.2622 - acc: 0.8998 - val_loss: 0.2615 - val_acc: 0.8973
Epoch 7/23
 - 26s - loss: 0.2468 - acc: 0.9046 - val_loss: 0.2287 - val_acc: 0.9155
Epoch 8/23
 - 26s - loss: 0.2326 - acc: 0.9130 - val_loss: 0.2660 - val_acc: 0.8955
Epoch 9/23
 - 26s - loss: 0.2166 - acc: 0.9202 - val_loss: 0.2133 - val_acc: 0.9217
Epoch 10/23
 - 26s - loss: 0.2055 - acc: 0.9277 - val_loss: 0.1956 - val_acc: 0.9324
Epoch 11/23
 - 26s - loss: 0.1951 - acc: 0.9312 - val_loss: 0.1960 - val_acc: 0.9307
Epoch 12/23
 - 26s - loss: 0.1844 - acc: 0.9361 - val_loss: 0.1597 - val_acc: 0.9480
Epoch 13/23
 - 26s - loss: 0.1741 - acc: 0.9404 - val_loss: 0.1600 - val_acc: 0.9459
Epoch 14/23
 - 26s - loss: 0.1682 - acc: 0.9423 - val_loss: 0.1545 - val_acc: 0.9501
Epoch 15/23
 - 26s - loss: 0.1603 - acc: 0.9470 - val_loss: 0.1423 - val_acc: 0.9585
Epoch 16/23
 - 26s - loss: 0.1537 - acc: 0.9493 - val_loss: 0.1540 - val_acc: 0.9528
Epoch 17/23
 - 26s - loss: 0.1470 - acc: 0.9515 - val_loss: 0.1355 - val_acc: 0.9608
Epoch 18/23
 - 25s - loss: 0.1401 - acc: 0.9558 - val_loss: 0.1162 - val_acc: 0.9660
Epoch 19/23
 - 26s - loss: 0.1355 - acc: 0.9577 - val_loss: 0.1060 - val_acc: 0.9709
Epoch 20/23
 - 26s - loss: 0.1309 - acc: 0.9595 - val_loss: 0.1079 - val_acc: 0.9681
Epoch 21/23
 - 26s - loss: 0.1239 - acc: 0.9623 - val_loss: 0.0987 - val_acc: 0.9719
Epoch 22/23
 - 26s - loss: 0.1199 - acc: 0.9635 - val_loss: 0.1096 - val_acc: 0.9703
Epoch 23/23
 - 26s - loss: 0.1158 - acc: 0.9655 - val_loss: 0.0935 - val_acc: 0.9748
Test accuracy:0.813
current auc_score ------------------> 0.938
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5176 - acc: 0.7516 - val_loss: 0.4206 - val_acc: 0.8146
Epoch 2/23
 - 26s - loss: 0.3848 - acc: 0.8351 - val_loss: 0.3488 - val_acc: 0.8523
Epoch 3/23
 - 26s - loss: 0.3314 - acc: 0.8637 - val_loss: 0.3088 - val_acc: 0.8707
Epoch 4/23
 - 25s - loss: 0.2977 - acc: 0.8821 - val_loss: 0.2779 - val_acc: 0.8888
Epoch 5/23
 - 26s - loss: 0.2710 - acc: 0.8940 - val_loss: 0.3159 - val_acc: 0.8633
Epoch 6/23
 - 25s - loss: 0.2472 - acc: 0.9076 - val_loss: 0.2191 - val_acc: 0.9185
Epoch 7/23
 - 26s - loss: 0.2281 - acc: 0.9172 - val_loss: 0.1998 - val_acc: 0.9303
Epoch 8/23
 - 26s - loss: 0.2121 - acc: 0.9246 - val_loss: 0.1792 - val_acc: 0.9410
Epoch 9/23
 - 26s - loss: 0.1990 - acc: 0.9304 - val_loss: 0.2070 - val_acc: 0.9188
Epoch 10/23
 - 26s - loss: 0.1875 - acc: 0.9346 - val_loss: 0.1512 - val_acc: 0.9519
Epoch 11/23
 - 26s - loss: 0.1766 - acc: 0.9398 - val_loss: 0.1593 - val_acc: 0.9433
Epoch 12/23
 - 26s - loss: 0.1670 - acc: 0.9457 - val_loss: 0.1425 - val_acc: 0.9531
Epoch 13/23
 - 26s - loss: 0.1564 - acc: 0.9485 - val_loss: 0.1304 - val_acc: 0.9580
Epoch 14/23
 - 25s - loss: 0.1491 - acc: 0.9522 - val_loss: 0.1208 - val_acc: 0.9660
Epoch 15/23
 - 26s - loss: 0.1414 - acc: 0.9540 - val_loss: 0.1098 - val_acc: 0.9669
Epoch 16/23
 - 26s - loss: 0.1354 - acc: 0.9580 - val_loss: 0.1056 - val_acc: 0.9684
Epoch 17/23
 - 26s - loss: 0.1286 - acc: 0.9611 - val_loss: 0.1073 - val_acc: 0.9655
Epoch 18/23
 - 26s - loss: 0.1241 - acc: 0.9626 - val_loss: 0.1035 - val_acc: 0.9716
Epoch 19/23
 - 26s - loss: 0.1199 - acc: 0.9632 - val_loss: 0.0905 - val_acc: 0.9738
Epoch 20/23
 - 26s - loss: 0.1156 - acc: 0.9660 - val_loss: 0.0888 - val_acc: 0.9755
Epoch 21/23
 - 26s - loss: 0.1116 - acc: 0.9660 - val_loss: 0.0836 - val_acc: 0.9768
Epoch 22/23
 - 26s - loss: 0.1067 - acc: 0.9694 - val_loss: 0.0801 - val_acc: 0.9783
Epoch 23/23
 - 26s - loss: 0.1035 - acc: 0.9695 - val_loss: 0.0794 - val_acc: 0.9788
Test accuracy:0.827
current auc_score ------------------> 0.925
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5403 - acc: 0.7308 - val_loss: 0.4171 - val_acc: 0.8154
Epoch 2/23
 - 26s - loss: 0.4013 - acc: 0.8253 - val_loss: 0.3468 - val_acc: 0.8535
Epoch 3/23
 - 26s - loss: 0.3482 - acc: 0.8545 - val_loss: 0.3093 - val_acc: 0.8771
Epoch 4/23
 - 26s - loss: 0.3132 - acc: 0.8725 - val_loss: 0.2892 - val_acc: 0.8780
Epoch 5/23
 - 26s - loss: 0.2868 - acc: 0.8864 - val_loss: 0.2657 - val_acc: 0.8942
Epoch 6/23
 - 26s - loss: 0.2665 - acc: 0.8949 - val_loss: 0.2424 - val_acc: 0.9066
Epoch 7/23
 - 26s - loss: 0.2475 - acc: 0.9065 - val_loss: 0.2212 - val_acc: 0.9189
Epoch 8/23
 - 26s - loss: 0.2330 - acc: 0.9123 - val_loss: 0.2090 - val_acc: 0.9218
Epoch 9/23
 - 26s - loss: 0.2193 - acc: 0.9186 - val_loss: 0.1786 - val_acc: 0.9411
Epoch 10/23
 - 26s - loss: 0.2064 - acc: 0.9249 - val_loss: 0.1692 - val_acc: 0.9429
Epoch 11/23
 - 26s - loss: 0.1932 - acc: 0.9308 - val_loss: 0.1653 - val_acc: 0.9419
Epoch 12/23
 - 26s - loss: 0.1844 - acc: 0.9368 - val_loss: 0.1716 - val_acc: 0.9404
Epoch 13/23
 - 26s - loss: 0.1740 - acc: 0.9400 - val_loss: 0.1395 - val_acc: 0.9551
Epoch 14/23
 - 26s - loss: 0.1647 - acc: 0.9461 - val_loss: 0.1357 - val_acc: 0.9567
Epoch 15/23
 - 26s - loss: 0.1588 - acc: 0.9485 - val_loss: 0.1213 - val_acc: 0.9646
Epoch 16/23
 - 26s - loss: 0.1513 - acc: 0.9505 - val_loss: 0.1132 - val_acc: 0.9664
Epoch 17/23
 - 26s - loss: 0.1446 - acc: 0.9536 - val_loss: 0.1099 - val_acc: 0.9674
Epoch 18/23
 - 26s - loss: 0.1382 - acc: 0.9562 - val_loss: 0.1196 - val_acc: 0.9635
Epoch 19/23
 - 26s - loss: 0.1326 - acc: 0.9581 - val_loss: 0.1057 - val_acc: 0.9703
Epoch 20/23
 - 26s - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1138 - val_acc: 0.9636
Epoch 21/23
 - 26s - loss: 0.1225 - acc: 0.9636 - val_loss: 0.0881 - val_acc: 0.9772
Epoch 22/23
 - 26s - loss: 0.1186 - acc: 0.9638 - val_loss: 0.1005 - val_acc: 0.9691
Epoch 23/23
 - 26s - loss: 0.1162 - acc: 0.9648 - val_loss: 0.0873 - val_acc: 0.9770
Test accuracy:0.782
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5210 - acc: 0.7523 - val_loss: 0.4153 - val_acc: 0.8106
Epoch 2/23
 - 26s - loss: 0.4034 - acc: 0.8243 - val_loss: 0.3451 - val_acc: 0.8573
Epoch 3/23
 - 26s - loss: 0.3493 - acc: 0.8546 - val_loss: 0.3144 - val_acc: 0.8695
Epoch 4/23
 - 26s - loss: 0.3136 - acc: 0.8725 - val_loss: 0.3161 - val_acc: 0.8632
Epoch 5/23
 - 26s - loss: 0.2893 - acc: 0.8843 - val_loss: 0.3206 - val_acc: 0.8603
Epoch 6/23
 - 26s - loss: 0.2638 - acc: 0.8997 - val_loss: 0.2779 - val_acc: 0.8852
Epoch 7/23
 - 26s - loss: 0.2479 - acc: 0.9067 - val_loss: 0.2174 - val_acc: 0.9231
Epoch 8/23
 - 26s - loss: 0.2316 - acc: 0.9146 - val_loss: 0.2067 - val_acc: 0.9249
Epoch 9/23
 - 26s - loss: 0.2205 - acc: 0.9192 - val_loss: 0.2081 - val_acc: 0.9221
Epoch 10/23
 - 26s - loss: 0.2074 - acc: 0.9258 - val_loss: 0.1803 - val_acc: 0.9389
Epoch 11/23
 - 26s - loss: 0.1970 - acc: 0.9303 - val_loss: 0.1699 - val_acc: 0.9435
Epoch 12/23
 - 26s - loss: 0.1877 - acc: 0.9336 - val_loss: 0.1558 - val_acc: 0.9498
Epoch 13/23
 - 26s - loss: 0.1764 - acc: 0.9397 - val_loss: 0.1518 - val_acc: 0.9527
Epoch 14/23
 - 26s - loss: 0.1688 - acc: 0.9435 - val_loss: 0.1374 - val_acc: 0.9548
Epoch 15/23
 - 26s - loss: 0.1617 - acc: 0.9458 - val_loss: 0.1314 - val_acc: 0.9591
Epoch 16/23
 - 26s - loss: 0.1556 - acc: 0.9488 - val_loss: 0.1236 - val_acc: 0.9602
Epoch 17/23
 - 26s - loss: 0.1466 - acc: 0.9530 - val_loss: 0.1197 - val_acc: 0.9652
Epoch 18/23
 - 26s - loss: 0.1431 - acc: 0.9537 - val_loss: 0.1313 - val_acc: 0.9575
Epoch 19/23
 - 26s - loss: 0.1374 - acc: 0.9571 - val_loss: 0.1062 - val_acc: 0.9699
Epoch 20/23
 - 26s - loss: 0.1306 - acc: 0.9596 - val_loss: 0.1222 - val_acc: 0.9623
Epoch 21/23
 - 26s - loss: 0.1277 - acc: 0.9607 - val_loss: 0.1017 - val_acc: 0.9706
Epoch 22/23
 - 26s - loss: 0.1224 - acc: 0.9633 - val_loss: 0.0926 - val_acc: 0.9765
Epoch 23/23
 - 26s - loss: 0.1166 - acc: 0.9656 - val_loss: 0.0959 - val_acc: 0.9730
Test accuracy:0.815
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5282 - acc: 0.7456 - val_loss: 0.4212 - val_acc: 0.8094
Epoch 2/23
 - 26s - loss: 0.3975 - acc: 0.8261 - val_loss: 0.3552 - val_acc: 0.8426
Epoch 3/23
 - 25s - loss: 0.3471 - acc: 0.8548 - val_loss: 0.3211 - val_acc: 0.8617
Epoch 4/23
 - 25s - loss: 0.3146 - acc: 0.8717 - val_loss: 0.2966 - val_acc: 0.8808
Epoch 5/23
 - 26s - loss: 0.2848 - acc: 0.8869 - val_loss: 0.2561 - val_acc: 0.9001
Epoch 6/23
 - 26s - loss: 0.2614 - acc: 0.8981 - val_loss: 0.2356 - val_acc: 0.9109
Epoch 7/23
 - 26s - loss: 0.2432 - acc: 0.9086 - val_loss: 0.2261 - val_acc: 0.9138
Epoch 8/23
 - 26s - loss: 0.2271 - acc: 0.9163 - val_loss: 0.2158 - val_acc: 0.9174
Epoch 9/23
 - 26s - loss: 0.2110 - acc: 0.9236 - val_loss: 0.1830 - val_acc: 0.9360
Epoch 10/23
 - 26s - loss: 0.2011 - acc: 0.9283 - val_loss: 0.1749 - val_acc: 0.9370
Epoch 11/23
 - 26s - loss: 0.1887 - acc: 0.9336 - val_loss: 0.1584 - val_acc: 0.9457
Epoch 12/23
 - 26s - loss: 0.1795 - acc: 0.9390 - val_loss: 0.1505 - val_acc: 0.9487
Epoch 13/23
 - 26s - loss: 0.1704 - acc: 0.9416 - val_loss: 0.1442 - val_acc: 0.9494
Epoch 14/23
 - 26s - loss: 0.1606 - acc: 0.9462 - val_loss: 0.1280 - val_acc: 0.9586
Epoch 15/23
 - 26s - loss: 0.1526 - acc: 0.9512 - val_loss: 0.1212 - val_acc: 0.9631
Epoch 16/23
 - 26s - loss: 0.1451 - acc: 0.9534 - val_loss: 0.1153 - val_acc: 0.9654
Epoch 17/23
 - 26s - loss: 0.1418 - acc: 0.9551 - val_loss: 0.1066 - val_acc: 0.9703
Epoch 18/23
 - 26s - loss: 0.1342 - acc: 0.9581 - val_loss: 0.1115 - val_acc: 0.9652
Epoch 19/23
 - 26s - loss: 0.1280 - acc: 0.9601 - val_loss: 0.1288 - val_acc: 0.9544
Epoch 20/23
 - 26s - loss: 0.1229 - acc: 0.9621 - val_loss: 0.1014 - val_acc: 0.9699
Epoch 21/23
 - 26s - loss: 0.1186 - acc: 0.9636 - val_loss: 0.0902 - val_acc: 0.9743
Epoch 22/23
 - 26s - loss: 0.1138 - acc: 0.9651 - val_loss: 0.0948 - val_acc: 0.9716
Epoch 23/23
 - 26s - loss: 0.1114 - acc: 0.9676 - val_loss: 0.0789 - val_acc: 0.9804
Test accuracy:0.839
current auc_score ------------------> 0.928
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.5223 - acc: 0.7445 - val_loss: 0.4170 - val_acc: 0.8111
Epoch 2/23
 - 25s - loss: 0.4027 - acc: 0.8210 - val_loss: 0.3752 - val_acc: 0.8276
Epoch 3/23
 - 25s - loss: 0.3518 - acc: 0.8524 - val_loss: 0.3473 - val_acc: 0.8451
Epoch 4/23
 - 25s - loss: 0.3166 - acc: 0.8709 - val_loss: 0.3216 - val_acc: 0.8576
Epoch 5/23
 - 25s - loss: 0.2893 - acc: 0.8850 - val_loss: 0.2633 - val_acc: 0.8973
Epoch 6/23
 - 26s - loss: 0.2689 - acc: 0.8967 - val_loss: 0.2734 - val_acc: 0.8848
Epoch 7/23
 - 26s - loss: 0.2486 - acc: 0.9056 - val_loss: 0.2229 - val_acc: 0.9174
Epoch 8/23
 - 26s - loss: 0.2332 - acc: 0.9151 - val_loss: 0.2914 - val_acc: 0.8719
Epoch 9/23
 - 26s - loss: 0.2194 - acc: 0.9208 - val_loss: 0.2528 - val_acc: 0.8973
Epoch 10/23
 - 26s - loss: 0.2057 - acc: 0.9253 - val_loss: 0.1802 - val_acc: 0.9379
Epoch 11/23
 - 26s - loss: 0.1958 - acc: 0.9304 - val_loss: 0.2183 - val_acc: 0.9116
Epoch 12/23
 - 26s - loss: 0.1856 - acc: 0.9357 - val_loss: 0.1661 - val_acc: 0.9457
Epoch 13/23
 - 26s - loss: 0.1768 - acc: 0.9398 - val_loss: 0.1525 - val_acc: 0.9501
Epoch 14/23
 - 26s - loss: 0.1681 - acc: 0.9430 - val_loss: 0.1530 - val_acc: 0.9485
Epoch 15/23
 - 26s - loss: 0.1607 - acc: 0.9463 - val_loss: 0.1309 - val_acc: 0.9583
Epoch 16/23
 - 26s - loss: 0.1542 - acc: 0.9496 - val_loss: 0.1609 - val_acc: 0.9421
Epoch 17/23
 - 26s - loss: 0.1465 - acc: 0.9532 - val_loss: 0.1217 - val_acc: 0.9647
Epoch 18/23
 - 26s - loss: 0.1398 - acc: 0.9552 - val_loss: 0.1208 - val_acc: 0.9626
Epoch 19/23
 - 26s - loss: 0.1328 - acc: 0.9585 - val_loss: 0.1235 - val_acc: 0.9603
Epoch 20/23
 - 26s - loss: 0.1287 - acc: 0.9596 - val_loss: 0.1208 - val_acc: 0.9632
Epoch 21/23
 - 26s - loss: 0.1269 - acc: 0.9600 - val_loss: 0.1055 - val_acc: 0.9679
Epoch 22/23
 - 26s - loss: 0.1187 - acc: 0.9646 - val_loss: 0.1018 - val_acc: 0.9720
Epoch 23/23
 - 26s - loss: 0.1158 - acc: 0.9655 - val_loss: 0.0931 - val_acc: 0.9741
Test accuracy:0.824
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 27s - loss: 0.5253 - acc: 0.7491 - val_loss: 0.4082 - val_acc: 0.8190
Epoch 2/23
 - 26s - loss: 0.4026 - acc: 0.8237 - val_loss: 0.3429 - val_acc: 0.8520
Epoch 3/23
 - 26s - loss: 0.3458 - acc: 0.8556 - val_loss: 0.3032 - val_acc: 0.8800
Epoch 4/23
 - 26s - loss: 0.3102 - acc: 0.8739 - val_loss: 0.2657 - val_acc: 0.9007
Epoch 5/23
 - 25s - loss: 0.2843 - acc: 0.8866 - val_loss: 0.2643 - val_acc: 0.8968
Epoch 6/23
 - 26s - loss: 0.2629 - acc: 0.8983 - val_loss: 0.2295 - val_acc: 0.9163
Epoch 7/23
 - 26s - loss: 0.2453 - acc: 0.9079 - val_loss: 0.2643 - val_acc: 0.8923
Epoch 8/23
 - 26s - loss: 0.2311 - acc: 0.9133 - val_loss: 0.1975 - val_acc: 0.9301
Epoch 9/23
 - 26s - loss: 0.2169 - acc: 0.9199 - val_loss: 0.2115 - val_acc: 0.9238
Epoch 10/23
 - 26s - loss: 0.2048 - acc: 0.9264 - val_loss: 0.1754 - val_acc: 0.9389
Epoch 11/23
 - 26s - loss: 0.1954 - acc: 0.9301 - val_loss: 0.1669 - val_acc: 0.9403
Epoch 12/23
 - 26s - loss: 0.1830 - acc: 0.9382 - val_loss: 0.1489 - val_acc: 0.9516
Epoch 13/23
 - 26s - loss: 0.1750 - acc: 0.9423 - val_loss: 0.1424 - val_acc: 0.9518
Epoch 14/23
 - 26s - loss: 0.1678 - acc: 0.9450 - val_loss: 0.1520 - val_acc: 0.9498
Epoch 15/23
 - 26s - loss: 0.1562 - acc: 0.9486 - val_loss: 0.1258 - val_acc: 0.9587
Epoch 16/23
 - 26s - loss: 0.1527 - acc: 0.9503 - val_loss: 0.1202 - val_acc: 0.9629
Epoch 17/23
 - 26s - loss: 0.1433 - acc: 0.9540 - val_loss: 0.1204 - val_acc: 0.9597
Epoch 18/23
 - 26s - loss: 0.1398 - acc: 0.9542 - val_loss: 0.1080 - val_acc: 0.9666
Epoch 19/23
 - 26s - loss: 0.1347 - acc: 0.9578 - val_loss: 0.1198 - val_acc: 0.9588
Epoch 20/23
 - 26s - loss: 0.1285 - acc: 0.9606 - val_loss: 0.0989 - val_acc: 0.9714
Epoch 21/23
 - 25s - loss: 0.1237 - acc: 0.9622 - val_loss: 0.0900 - val_acc: 0.9744
Epoch 22/23
 - 25s - loss: 0.1192 - acc: 0.9634 - val_loss: 0.0910 - val_acc: 0.9735
Epoch 23/23
 - 25s - loss: 0.1145 - acc: 0.9656 - val_loss: 0.0836 - val_acc: 0.9785
Test accuracy:0.832
current auc_score ------------------> 0.913
accuracies:  [0.8041666666666667, 0.85, 0.8346774193548387, 0.8129032258064516, 0.8268817204301075, 0.7818548387096774, 0.8146505376344086, 0.8389784946236559, 0.8239247311827957, 0.8317204301075268]
aucs:  [0.9123, 0.9511, 0.9389, 0.9384, 0.9252, 0.9098, 0.9459, 0.9276, 0.9326, 0.9135]
mean and std AUC:  0.93+/-0.014  max:   0.9511
['2-2-2', '30', '3', '16', '0.2', '0.07', '25', 'adadelta', '0.5', 'FALSE', '256', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5625 - acc: 0.7175 - val_loss: 0.4685 - val_acc: 0.7782
Epoch 2/25
 - 19s - loss: 0.4471 - acc: 0.7992 - val_loss: 0.4007 - val_acc: 0.8219
Epoch 3/25
 - 20s - loss: 0.3887 - acc: 0.8333 - val_loss: 0.3527 - val_acc: 0.8550
Epoch 4/25
 - 20s - loss: 0.3518 - acc: 0.8524 - val_loss: 0.3739 - val_acc: 0.8287
Epoch 5/25
 - 19s - loss: 0.3229 - acc: 0.8688 - val_loss: 0.3412 - val_acc: 0.8475
Epoch 6/25
 - 19s - loss: 0.3004 - acc: 0.8806 - val_loss: 0.3629 - val_acc: 0.8304
Epoch 7/25
 - 19s - loss: 0.2832 - acc: 0.8897 - val_loss: 0.2879 - val_acc: 0.8800
Epoch 8/25
 - 19s - loss: 0.2687 - acc: 0.8972 - val_loss: 0.2456 - val_acc: 0.9068
Epoch 9/25
 - 19s - loss: 0.2523 - acc: 0.9042 - val_loss: 0.3469 - val_acc: 0.8422
Epoch 10/25
 - 19s - loss: 0.2423 - acc: 0.9111 - val_loss: 0.2541 - val_acc: 0.8997
Epoch 11/25
 - 19s - loss: 0.2311 - acc: 0.9151 - val_loss: 0.2331 - val_acc: 0.9118
Epoch 12/25
 - 19s - loss: 0.2201 - acc: 0.9217 - val_loss: 0.2298 - val_acc: 0.9119
Epoch 13/25
 - 19s - loss: 0.2136 - acc: 0.9247 - val_loss: 0.1817 - val_acc: 0.9395
Epoch 14/25
 - 19s - loss: 0.2027 - acc: 0.9294 - val_loss: 0.2082 - val_acc: 0.9224
Epoch 15/25
 - 19s - loss: 0.1951 - acc: 0.9324 - val_loss: 0.1781 - val_acc: 0.9415
Epoch 16/25
 - 19s - loss: 0.1891 - acc: 0.9362 - val_loss: 0.1557 - val_acc: 0.9516
Epoch 17/25
 - 19s - loss: 0.1825 - acc: 0.9370 - val_loss: 0.1550 - val_acc: 0.9494
Epoch 18/25
 - 19s - loss: 0.1752 - acc: 0.9428 - val_loss: 0.1794 - val_acc: 0.9390
Epoch 19/25
 - 19s - loss: 0.1689 - acc: 0.9448 - val_loss: 0.1759 - val_acc: 0.9400
Epoch 20/25
 - 19s - loss: 0.1631 - acc: 0.9465 - val_loss: 0.1376 - val_acc: 0.9577
Epoch 21/25
 - 19s - loss: 0.1575 - acc: 0.9507 - val_loss: 0.1446 - val_acc: 0.9542
Epoch 22/25
 - 19s - loss: 0.1527 - acc: 0.9507 - val_loss: 0.1369 - val_acc: 0.9578
Epoch 23/25
 - 19s - loss: 0.1465 - acc: 0.9539 - val_loss: 0.1217 - val_acc: 0.9645
Epoch 24/25
 - 19s - loss: 0.1431 - acc: 0.9538 - val_loss: 0.1172 - val_acc: 0.9652
Epoch 25/25
 - 19s - loss: 0.1381 - acc: 0.9577 - val_loss: 0.1204 - val_acc: 0.9640
Test accuracy:0.832
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5799 - acc: 0.7021 - val_loss: 0.4686 - val_acc: 0.7843
Epoch 2/25
 - 19s - loss: 0.4406 - acc: 0.8011 - val_loss: 0.4366 - val_acc: 0.7918
Epoch 3/25
 - 19s - loss: 0.3837 - acc: 0.8339 - val_loss: 0.4160 - val_acc: 0.8016
Epoch 4/25
 - 19s - loss: 0.3435 - acc: 0.8566 - val_loss: 0.3544 - val_acc: 0.8412
Epoch 5/25
 - 19s - loss: 0.3160 - acc: 0.8706 - val_loss: 0.3415 - val_acc: 0.8494
Epoch 6/25
 - 19s - loss: 0.2947 - acc: 0.8827 - val_loss: 0.3417 - val_acc: 0.8500
Epoch 7/25
 - 19s - loss: 0.2769 - acc: 0.8916 - val_loss: 0.3172 - val_acc: 0.8589
Epoch 8/25
 - 19s - loss: 0.2621 - acc: 0.9001 - val_loss: 0.2618 - val_acc: 0.8931
Epoch 9/25
 - 19s - loss: 0.2480 - acc: 0.9057 - val_loss: 0.2445 - val_acc: 0.9036
Epoch 10/25
 - 19s - loss: 0.2351 - acc: 0.9138 - val_loss: 0.2053 - val_acc: 0.9252
Epoch 11/25
 - 19s - loss: 0.2241 - acc: 0.9192 - val_loss: 0.1964 - val_acc: 0.9295
Epoch 12/25
 - 19s - loss: 0.2143 - acc: 0.9221 - val_loss: 0.2012 - val_acc: 0.9251
Epoch 13/25
 - 19s - loss: 0.2044 - acc: 0.9271 - val_loss: 0.1812 - val_acc: 0.9381
Epoch 14/25
 - 19s - loss: 0.2004 - acc: 0.9293 - val_loss: 0.1758 - val_acc: 0.9374
Epoch 15/25
 - 19s - loss: 0.1886 - acc: 0.9342 - val_loss: 0.1671 - val_acc: 0.9433
Epoch 16/25
 - 19s - loss: 0.1816 - acc: 0.9372 - val_loss: 0.1497 - val_acc: 0.9538
Epoch 17/25
 - 19s - loss: 0.1758 - acc: 0.9396 - val_loss: 0.1395 - val_acc: 0.9557
Epoch 18/25
 - 19s - loss: 0.1681 - acc: 0.9439 - val_loss: 0.1685 - val_acc: 0.9410
Epoch 19/25
 - 19s - loss: 0.1640 - acc: 0.9456 - val_loss: 0.1278 - val_acc: 0.9622
Epoch 20/25
 - 19s - loss: 0.1576 - acc: 0.9488 - val_loss: 0.1325 - val_acc: 0.9571
Epoch 21/25
 - 19s - loss: 0.1520 - acc: 0.9503 - val_loss: 0.1179 - val_acc: 0.9639
Epoch 22/25
 - 19s - loss: 0.1488 - acc: 0.9529 - val_loss: 0.1192 - val_acc: 0.9647
Epoch 23/25
 - 19s - loss: 0.1432 - acc: 0.9553 - val_loss: 0.1087 - val_acc: 0.9669
Epoch 24/25
 - 19s - loss: 0.1384 - acc: 0.9572 - val_loss: 0.1080 - val_acc: 0.9670
Epoch 25/25
 - 19s - loss: 0.1339 - acc: 0.9581 - val_loss: 0.1107 - val_acc: 0.9651
Test accuracy:0.841
current auc_score ------------------> 0.948
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5472 - acc: 0.7311 - val_loss: 0.4653 - val_acc: 0.7819
Epoch 2/25
 - 19s - loss: 0.4362 - acc: 0.8022 - val_loss: 0.5141 - val_acc: 0.7730
Epoch 3/25
 - 19s - loss: 0.3850 - acc: 0.8326 - val_loss: 0.3841 - val_acc: 0.8345
Epoch 4/25
 - 19s - loss: 0.3496 - acc: 0.8536 - val_loss: 0.4477 - val_acc: 0.8070
Epoch 5/25
 - 19s - loss: 0.3206 - acc: 0.8696 - val_loss: 0.3253 - val_acc: 0.8666
Epoch 6/25
 - 19s - loss: 0.2983 - acc: 0.8816 - val_loss: 0.2736 - val_acc: 0.8962
Epoch 7/25
 - 19s - loss: 0.2798 - acc: 0.8895 - val_loss: 0.2519 - val_acc: 0.9075
Epoch 8/25
 - 19s - loss: 0.2670 - acc: 0.8954 - val_loss: 0.2581 - val_acc: 0.9026
Epoch 9/25
 - 19s - loss: 0.2518 - acc: 0.9062 - val_loss: 0.2376 - val_acc: 0.9119
Epoch 10/25
 - 19s - loss: 0.2387 - acc: 0.9113 - val_loss: 0.2097 - val_acc: 0.9273
Epoch 11/25
 - 19s - loss: 0.2269 - acc: 0.9178 - val_loss: 0.1973 - val_acc: 0.9335
Epoch 12/25
 - 19s - loss: 0.2178 - acc: 0.9202 - val_loss: 0.1907 - val_acc: 0.9354
Epoch 13/25
 - 19s - loss: 0.2101 - acc: 0.9259 - val_loss: 0.1752 - val_acc: 0.9433
Epoch 14/25
 - 19s - loss: 0.2003 - acc: 0.9297 - val_loss: 0.1705 - val_acc: 0.9447
Epoch 15/25
 - 19s - loss: 0.1914 - acc: 0.9335 - val_loss: 0.1622 - val_acc: 0.9489
Epoch 16/25
 - 19s - loss: 0.1848 - acc: 0.9362 - val_loss: 0.1575 - val_acc: 0.9506
Epoch 17/25
 - 19s - loss: 0.1778 - acc: 0.9390 - val_loss: 0.1460 - val_acc: 0.9559
Epoch 18/25
 - 19s - loss: 0.1704 - acc: 0.9439 - val_loss: 0.1504 - val_acc: 0.9514
Epoch 19/25
 - 19s - loss: 0.1671 - acc: 0.9449 - val_loss: 0.1386 - val_acc: 0.9561
Epoch 20/25
 - 19s - loss: 0.1599 - acc: 0.9473 - val_loss: 0.1431 - val_acc: 0.9539
Epoch 21/25
 - 19s - loss: 0.1562 - acc: 0.9490 - val_loss: 0.1246 - val_acc: 0.9630
Epoch 22/25
 - 19s - loss: 0.1493 - acc: 0.9516 - val_loss: 0.1176 - val_acc: 0.9677
Epoch 23/25
 - 19s - loss: 0.1436 - acc: 0.9547 - val_loss: 0.1356 - val_acc: 0.9557
Epoch 24/25
 - 19s - loss: 0.1404 - acc: 0.9565 - val_loss: 0.1238 - val_acc: 0.9597
Epoch 25/25
 - 19s - loss: 0.1358 - acc: 0.9584 - val_loss: 0.1096 - val_acc: 0.9686
Test accuracy:0.831
current auc_score ------------------> 0.921
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5549 - acc: 0.7230 - val_loss: 0.4586 - val_acc: 0.8053
Epoch 2/25
 - 20s - loss: 0.4262 - acc: 0.8114 - val_loss: 0.4158 - val_acc: 0.8170
Epoch 3/25
 - 19s - loss: 0.3748 - acc: 0.8390 - val_loss: 0.3823 - val_acc: 0.8237
Epoch 4/25
 - 19s - loss: 0.3391 - acc: 0.8577 - val_loss: 0.4216 - val_acc: 0.7988
Epoch 5/25
 - 19s - loss: 0.3153 - acc: 0.8694 - val_loss: 0.3230 - val_acc: 0.8612
Epoch 6/25
 - 19s - loss: 0.2941 - acc: 0.8816 - val_loss: 0.3161 - val_acc: 0.8613
Epoch 7/25
 - 19s - loss: 0.2773 - acc: 0.8908 - val_loss: 0.2661 - val_acc: 0.8957
Epoch 8/25
 - 19s - loss: 0.2614 - acc: 0.8987 - val_loss: 0.2857 - val_acc: 0.8813
Epoch 9/25
 - 19s - loss: 0.2452 - acc: 0.9057 - val_loss: 0.2453 - val_acc: 0.9040
Epoch 10/25
 - 19s - loss: 0.2341 - acc: 0.9123 - val_loss: 0.2325 - val_acc: 0.9110
Epoch 11/25
 - 19s - loss: 0.2235 - acc: 0.9188 - val_loss: 0.2106 - val_acc: 0.9242
Epoch 12/25
 - 19s - loss: 0.2120 - acc: 0.9254 - val_loss: 0.2205 - val_acc: 0.9163
Epoch 13/25
 - 19s - loss: 0.2040 - acc: 0.9287 - val_loss: 0.2256 - val_acc: 0.9096
Epoch 14/25
 - 19s - loss: 0.1936 - acc: 0.9323 - val_loss: 0.1887 - val_acc: 0.9324
Epoch 15/25
 - 19s - loss: 0.1872 - acc: 0.9356 - val_loss: 0.1582 - val_acc: 0.9504
Epoch 16/25
 - 19s - loss: 0.1798 - acc: 0.9381 - val_loss: 0.1457 - val_acc: 0.9562
Epoch 17/25
 - 19s - loss: 0.1701 - acc: 0.9430 - val_loss: 0.1376 - val_acc: 0.9582
Epoch 18/25
 - 19s - loss: 0.1668 - acc: 0.9451 - val_loss: 0.1343 - val_acc: 0.9612
Epoch 19/25
 - 19s - loss: 0.1603 - acc: 0.9472 - val_loss: 0.1261 - val_acc: 0.9636
Epoch 20/25
 - 19s - loss: 0.1541 - acc: 0.9504 - val_loss: 0.1228 - val_acc: 0.9632
Epoch 21/25
 - 19s - loss: 0.1479 - acc: 0.9524 - val_loss: 0.1182 - val_acc: 0.9651
Epoch 22/25
 - 19s - loss: 0.1440 - acc: 0.9534 - val_loss: 0.1130 - val_acc: 0.9689
Epoch 23/25
 - 19s - loss: 0.1405 - acc: 0.9565 - val_loss: 0.1129 - val_acc: 0.9693
Epoch 24/25
 - 19s - loss: 0.1347 - acc: 0.9591 - val_loss: 0.1041 - val_acc: 0.9710
Epoch 25/25
 - 19s - loss: 0.1301 - acc: 0.9599 - val_loss: 0.1016 - val_acc: 0.9726
Test accuracy:0.838
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5597 - acc: 0.7285 - val_loss: 0.4731 - val_acc: 0.7796
Epoch 2/25
 - 19s - loss: 0.4323 - acc: 0.8081 - val_loss: 0.3963 - val_acc: 0.8219
Epoch 3/25
 - 19s - loss: 0.3772 - acc: 0.8399 - val_loss: 0.3533 - val_acc: 0.8478
Epoch 4/25
 - 19s - loss: 0.3392 - acc: 0.8594 - val_loss: 0.3434 - val_acc: 0.8488
Epoch 5/25
 - 19s - loss: 0.3134 - acc: 0.8736 - val_loss: 0.2788 - val_acc: 0.8938
Epoch 6/25
 - 19s - loss: 0.2916 - acc: 0.8848 - val_loss: 0.2558 - val_acc: 0.9045
Epoch 7/25
 - 19s - loss: 0.2741 - acc: 0.8940 - val_loss: 0.2368 - val_acc: 0.9119
Epoch 8/25
 - 19s - loss: 0.2567 - acc: 0.9029 - val_loss: 0.2279 - val_acc: 0.9173
Epoch 9/25
 - 19s - loss: 0.2441 - acc: 0.9081 - val_loss: 0.2071 - val_acc: 0.9276
Epoch 10/25
 - 19s - loss: 0.2316 - acc: 0.9162 - val_loss: 0.1954 - val_acc: 0.9339
Epoch 11/25
 - 19s - loss: 0.2185 - acc: 0.9212 - val_loss: 0.2011 - val_acc: 0.9288
Epoch 12/25
 - 19s - loss: 0.2104 - acc: 0.9242 - val_loss: 0.1730 - val_acc: 0.9429
Epoch 13/25
 - 19s - loss: 0.1987 - acc: 0.9301 - val_loss: 0.1642 - val_acc: 0.9459
Epoch 14/25
 - 19s - loss: 0.1911 - acc: 0.9337 - val_loss: 0.1568 - val_acc: 0.9516
Epoch 15/25
 - 19s - loss: 0.1837 - acc: 0.9374 - val_loss: 0.1766 - val_acc: 0.9350
Epoch 16/25
 - 19s - loss: 0.1757 - acc: 0.9404 - val_loss: 0.1397 - val_acc: 0.9565
Epoch 17/25
 - 19s - loss: 0.1689 - acc: 0.9440 - val_loss: 0.1382 - val_acc: 0.9561
Epoch 18/25
 - 19s - loss: 0.1641 - acc: 0.9452 - val_loss: 0.1356 - val_acc: 0.9598
Epoch 19/25
 - 19s - loss: 0.1573 - acc: 0.9486 - val_loss: 0.1288 - val_acc: 0.9605
Epoch 20/25
 - 19s - loss: 0.1501 - acc: 0.9514 - val_loss: 0.1187 - val_acc: 0.9661
Epoch 21/25
 - 19s - loss: 0.1465 - acc: 0.9531 - val_loss: 0.1221 - val_acc: 0.9610
Epoch 22/25
 - 19s - loss: 0.1403 - acc: 0.9560 - val_loss: 0.1093 - val_acc: 0.9677
Epoch 23/25
 - 19s - loss: 0.1341 - acc: 0.9586 - val_loss: 0.1049 - val_acc: 0.9696
Epoch 24/25
 - 19s - loss: 0.1312 - acc: 0.9602 - val_loss: 0.1005 - val_acc: 0.9719
Epoch 25/25
 - 19s - loss: 0.1273 - acc: 0.9619 - val_loss: 0.0980 - val_acc: 0.9714
Test accuracy:0.839
current auc_score ------------------> 0.932
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 21s - loss: 0.5621 - acc: 0.7189 - val_loss: 0.4930 - val_acc: 0.7720
Epoch 2/25
 - 19s - loss: 0.4374 - acc: 0.8041 - val_loss: 0.4226 - val_acc: 0.8062
Epoch 3/25
 - 19s - loss: 0.3829 - acc: 0.8345 - val_loss: 0.4341 - val_acc: 0.7874
Epoch 4/25
 - 19s - loss: 0.3484 - acc: 0.8556 - val_loss: 0.4718 - val_acc: 0.7728
Epoch 5/25
 - 19s - loss: 0.3192 - acc: 0.8704 - val_loss: 0.3107 - val_acc: 0.8695
Epoch 6/25
 - 19s - loss: 0.2987 - acc: 0.8814 - val_loss: 0.2652 - val_acc: 0.8981
Epoch 7/25
 - 19s - loss: 0.2821 - acc: 0.8894 - val_loss: 0.2848 - val_acc: 0.8848
Epoch 8/25
 - 19s - loss: 0.2650 - acc: 0.8991 - val_loss: 0.2380 - val_acc: 0.9103
Epoch 9/25
 - 19s - loss: 0.2530 - acc: 0.9043 - val_loss: 0.2212 - val_acc: 0.9169
Epoch 10/25
 - 19s - loss: 0.2394 - acc: 0.9122 - val_loss: 0.2148 - val_acc: 0.9183
Epoch 11/25
 - 19s - loss: 0.2278 - acc: 0.9155 - val_loss: 0.1996 - val_acc: 0.9280
Epoch 12/25
 - 19s - loss: 0.2202 - acc: 0.9199 - val_loss: 0.1928 - val_acc: 0.9311
Epoch 13/25
 - 19s - loss: 0.2089 - acc: 0.9262 - val_loss: 0.1921 - val_acc: 0.9316
Epoch 14/25
 - 19s - loss: 0.2005 - acc: 0.9287 - val_loss: 0.1717 - val_acc: 0.9418
Epoch 15/25
 - 19s - loss: 0.1909 - acc: 0.9345 - val_loss: 0.1649 - val_acc: 0.9438
Epoch 16/25
 - 19s - loss: 0.1837 - acc: 0.9368 - val_loss: 0.1553 - val_acc: 0.9483
Epoch 17/25
 - 19s - loss: 0.1776 - acc: 0.9396 - val_loss: 0.1500 - val_acc: 0.9490
Epoch 18/25
 - 19s - loss: 0.1708 - acc: 0.9442 - val_loss: 0.1513 - val_acc: 0.9494
Epoch 19/25
 - 19s - loss: 0.1660 - acc: 0.9454 - val_loss: 0.1436 - val_acc: 0.9536
Epoch 20/25
 - 19s - loss: 0.1580 - acc: 0.9486 - val_loss: 0.1369 - val_acc: 0.9561
Epoch 21/25
 - 19s - loss: 0.1546 - acc: 0.9506 - val_loss: 0.1311 - val_acc: 0.9575
Epoch 22/25
 - 19s - loss: 0.1483 - acc: 0.9535 - val_loss: 0.1256 - val_acc: 0.9585
Epoch 23/25
 - 19s - loss: 0.1439 - acc: 0.9542 - val_loss: 0.1203 - val_acc: 0.9639
Epoch 24/25
 - 19s - loss: 0.1388 - acc: 0.9565 - val_loss: 0.1116 - val_acc: 0.9662
Epoch 25/25
 - 19s - loss: 0.1341 - acc: 0.9585 - val_loss: 0.1068 - val_acc: 0.9691
Test accuracy:0.852
current auc_score ------------------> 0.932
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5646 - acc: 0.7181 - val_loss: 0.4610 - val_acc: 0.7869
Epoch 2/25
 - 19s - loss: 0.4336 - acc: 0.8034 - val_loss: 0.3955 - val_acc: 0.8207
Epoch 3/25
 - 19s - loss: 0.3811 - acc: 0.8360 - val_loss: 0.3642 - val_acc: 0.8385
Epoch 4/25
 - 19s - loss: 0.3473 - acc: 0.8533 - val_loss: 0.3364 - val_acc: 0.8582
Epoch 5/25
 - 19s - loss: 0.3215 - acc: 0.8668 - val_loss: 0.2968 - val_acc: 0.8835
Epoch 6/25
 - 19s - loss: 0.3017 - acc: 0.8789 - val_loss: 0.2856 - val_acc: 0.8869
Epoch 7/25
 - 19s - loss: 0.2871 - acc: 0.8868 - val_loss: 0.3138 - val_acc: 0.8699
Epoch 8/25
 - 19s - loss: 0.2722 - acc: 0.8943 - val_loss: 0.2775 - val_acc: 0.8902
Epoch 9/25
 - 19s - loss: 0.2599 - acc: 0.9004 - val_loss: 0.2321 - val_acc: 0.9194
Epoch 10/25
 - 21s - loss: 0.2503 - acc: 0.9056 - val_loss: 0.2256 - val_acc: 0.9211
Epoch 11/25
 - 20s - loss: 0.2394 - acc: 0.9109 - val_loss: 0.2114 - val_acc: 0.9281
Epoch 12/25
 - 20s - loss: 0.2295 - acc: 0.9157 - val_loss: 0.2075 - val_acc: 0.9268
Epoch 13/25
 - 19s - loss: 0.2202 - acc: 0.9187 - val_loss: 0.1973 - val_acc: 0.9331
Epoch 14/25
 - 20s - loss: 0.2118 - acc: 0.9246 - val_loss: 0.1825 - val_acc: 0.9419
Epoch 15/25
 - 20s - loss: 0.2057 - acc: 0.9267 - val_loss: 0.1736 - val_acc: 0.9413
Epoch 16/25
 - 20s - loss: 0.1999 - acc: 0.9282 - val_loss: 0.1647 - val_acc: 0.9488
Epoch 17/25
 - 20s - loss: 0.1915 - acc: 0.9328 - val_loss: 0.1663 - val_acc: 0.9487
Epoch 18/25
 - 20s - loss: 0.1832 - acc: 0.9386 - val_loss: 0.1514 - val_acc: 0.9548
Epoch 19/25
 - 20s - loss: 0.1776 - acc: 0.9392 - val_loss: 0.1500 - val_acc: 0.9541
Epoch 20/25
 - 20s - loss: 0.1722 - acc: 0.9423 - val_loss: 0.1386 - val_acc: 0.9596
Epoch 21/25
 - 20s - loss: 0.1685 - acc: 0.9441 - val_loss: 0.1398 - val_acc: 0.9585
Epoch 22/25
 - 20s - loss: 0.1642 - acc: 0.9457 - val_loss: 0.1319 - val_acc: 0.9626
Epoch 23/25
 - 20s - loss: 0.1571 - acc: 0.9487 - val_loss: 0.1245 - val_acc: 0.9655
Epoch 24/25
 - 20s - loss: 0.1526 - acc: 0.9505 - val_loss: 0.1221 - val_acc: 0.9646
Epoch 25/25
 - 20s - loss: 0.1486 - acc: 0.9528 - val_loss: 0.1152 - val_acc: 0.9676
Test accuracy:0.811
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5557 - acc: 0.7281 - val_loss: 0.4553 - val_acc: 0.7977
Epoch 2/25
 - 20s - loss: 0.4362 - acc: 0.8094 - val_loss: 0.3885 - val_acc: 0.8372
Epoch 3/25
 - 20s - loss: 0.3804 - acc: 0.8395 - val_loss: 0.3441 - val_acc: 0.8591
Epoch 4/25
 - 20s - loss: 0.3408 - acc: 0.8594 - val_loss: 0.3088 - val_acc: 0.8818
Epoch 5/25
 - 20s - loss: 0.3125 - acc: 0.8736 - val_loss: 0.2784 - val_acc: 0.8943
Epoch 6/25
 - 20s - loss: 0.2900 - acc: 0.8861 - val_loss: 0.2589 - val_acc: 0.9054
Epoch 7/25
 - 20s - loss: 0.2693 - acc: 0.8956 - val_loss: 0.2443 - val_acc: 0.9115
Epoch 8/25
 - 20s - loss: 0.2549 - acc: 0.9040 - val_loss: 0.2273 - val_acc: 0.9202
Epoch 9/25
 - 20s - loss: 0.2403 - acc: 0.9107 - val_loss: 0.2168 - val_acc: 0.9229
Epoch 10/25
 - 20s - loss: 0.2276 - acc: 0.9160 - val_loss: 0.2069 - val_acc: 0.9239
Epoch 11/25
 - 20s - loss: 0.2162 - acc: 0.9223 - val_loss: 0.1946 - val_acc: 0.9340
Epoch 12/25
 - 20s - loss: 0.2053 - acc: 0.9263 - val_loss: 0.1801 - val_acc: 0.9389
Epoch 13/25
 - 20s - loss: 0.1961 - acc: 0.9315 - val_loss: 0.1711 - val_acc: 0.9436
Epoch 14/25
 - 20s - loss: 0.1876 - acc: 0.9368 - val_loss: 0.1795 - val_acc: 0.9391
Epoch 15/25
 - 20s - loss: 0.1800 - acc: 0.9390 - val_loss: 0.1573 - val_acc: 0.9483
Epoch 16/25
 - 20s - loss: 0.1751 - acc: 0.9417 - val_loss: 0.1532 - val_acc: 0.9493
Epoch 17/25
 - 20s - loss: 0.1665 - acc: 0.9453 - val_loss: 0.1500 - val_acc: 0.9503
Epoch 18/25
 - 20s - loss: 0.1604 - acc: 0.9473 - val_loss: 0.1433 - val_acc: 0.9536
Epoch 19/25
 - 20s - loss: 0.1563 - acc: 0.9494 - val_loss: 0.1315 - val_acc: 0.9591
Epoch 20/25
 - 20s - loss: 0.1514 - acc: 0.9512 - val_loss: 0.1319 - val_acc: 0.9588
Epoch 21/25
 - 20s - loss: 0.1451 - acc: 0.9542 - val_loss: 0.1283 - val_acc: 0.9580
Epoch 22/25
 - 20s - loss: 0.1411 - acc: 0.9558 - val_loss: 0.1286 - val_acc: 0.9587
Epoch 23/25
 - 20s - loss: 0.1369 - acc: 0.9575 - val_loss: 0.1105 - val_acc: 0.9682
Epoch 24/25
 - 20s - loss: 0.1327 - acc: 0.9593 - val_loss: 0.1096 - val_acc: 0.9689
Epoch 25/25
 - 20s - loss: 0.1276 - acc: 0.9611 - val_loss: 0.1103 - val_acc: 0.9676
Test accuracy:0.838
current auc_score ------------------> 0.936
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5682 - acc: 0.7185 - val_loss: 0.4816 - val_acc: 0.7747
Epoch 2/25
 - 20s - loss: 0.4345 - acc: 0.8067 - val_loss: 0.3945 - val_acc: 0.8247
Epoch 3/25
 - 20s - loss: 0.3791 - acc: 0.8374 - val_loss: 0.3868 - val_acc: 0.8163
Epoch 4/25
 - 20s - loss: 0.3418 - acc: 0.8566 - val_loss: 0.3276 - val_acc: 0.8581
Epoch 5/25
 - 20s - loss: 0.3148 - acc: 0.8711 - val_loss: 0.2842 - val_acc: 0.8848
Epoch 6/25
 - 20s - loss: 0.2928 - acc: 0.8833 - val_loss: 0.2773 - val_acc: 0.8869
Epoch 7/25
 - 20s - loss: 0.2758 - acc: 0.8919 - val_loss: 0.2730 - val_acc: 0.8921
Epoch 8/25
 - 20s - loss: 0.2630 - acc: 0.8987 - val_loss: 0.2579 - val_acc: 0.8947
Epoch 9/25
 - 20s - loss: 0.2495 - acc: 0.9040 - val_loss: 0.2919 - val_acc: 0.8710
Epoch 10/25
 - 20s - loss: 0.2386 - acc: 0.9103 - val_loss: 0.2050 - val_acc: 0.9270
Epoch 11/25
 - 20s - loss: 0.2287 - acc: 0.9145 - val_loss: 0.2185 - val_acc: 0.9182
Epoch 12/25
 - 20s - loss: 0.2195 - acc: 0.9202 - val_loss: 0.2031 - val_acc: 0.9273
Epoch 13/25
 - 20s - loss: 0.2094 - acc: 0.9237 - val_loss: 0.2018 - val_acc: 0.9265
Epoch 14/25
 - 20s - loss: 0.2030 - acc: 0.9271 - val_loss: 0.1806 - val_acc: 0.9367
Epoch 15/25
 - 20s - loss: 0.1949 - acc: 0.9311 - val_loss: 0.1763 - val_acc: 0.9394
Epoch 16/25
 - 20s - loss: 0.1855 - acc: 0.9358 - val_loss: 0.2052 - val_acc: 0.9216
Epoch 17/25
 - 20s - loss: 0.1830 - acc: 0.9360 - val_loss: 0.1553 - val_acc: 0.9519
Epoch 18/25
 - 20s - loss: 0.1747 - acc: 0.9403 - val_loss: 0.1610 - val_acc: 0.9474
Epoch 19/25
 - 20s - loss: 0.1681 - acc: 0.9428 - val_loss: 0.1394 - val_acc: 0.9563
Epoch 20/25
 - 20s - loss: 0.1616 - acc: 0.9452 - val_loss: 0.1394 - val_acc: 0.9571
Epoch 21/25
 - 20s - loss: 0.1557 - acc: 0.9486 - val_loss: 0.1378 - val_acc: 0.9559
Epoch 22/25
 - 20s - loss: 0.1519 - acc: 0.9514 - val_loss: 0.1336 - val_acc: 0.9577
Epoch 23/25
 - 20s - loss: 0.1478 - acc: 0.9511 - val_loss: 0.1215 - val_acc: 0.9650
Epoch 24/25
 - 20s - loss: 0.1426 - acc: 0.9542 - val_loss: 0.1191 - val_acc: 0.9637
Epoch 25/25
 - 20s - loss: 0.1376 - acc: 0.9568 - val_loss: 0.1129 - val_acc: 0.9635
Test accuracy:0.843
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  flatten
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3924)         0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            3925        flatten_1[0][0]                  
==================================================================================================
Total params: 95,483
Trainable params: 94,293
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5640 - acc: 0.7214 - val_loss: 0.4581 - val_acc: 0.7915
Epoch 2/25
 - 20s - loss: 0.4392 - acc: 0.8025 - val_loss: 0.4093 - val_acc: 0.8139
Epoch 3/25
 - 20s - loss: 0.3826 - acc: 0.8352 - val_loss: 0.3843 - val_acc: 0.8213
Epoch 4/25
 - 20s - loss: 0.3479 - acc: 0.8530 - val_loss: 0.3289 - val_acc: 0.8587
Epoch 5/25
 - 20s - loss: 0.3209 - acc: 0.8677 - val_loss: 0.3022 - val_acc: 0.8696
Epoch 6/25
 - 20s - loss: 0.2995 - acc: 0.8803 - val_loss: 0.2949 - val_acc: 0.8747
Epoch 7/25
 - 20s - loss: 0.2801 - acc: 0.8901 - val_loss: 0.2592 - val_acc: 0.8958
Epoch 8/25
 - 20s - loss: 0.2672 - acc: 0.8971 - val_loss: 0.2510 - val_acc: 0.9010
Epoch 9/25
 - 20s - loss: 0.2524 - acc: 0.9048 - val_loss: 0.2308 - val_acc: 0.9086
Epoch 10/25
 - 20s - loss: 0.2392 - acc: 0.9094 - val_loss: 0.2315 - val_acc: 0.9114
Epoch 11/25
 - 20s - loss: 0.2290 - acc: 0.9156 - val_loss: 0.1985 - val_acc: 0.9275
Epoch 12/25
 - 20s - loss: 0.2188 - acc: 0.9205 - val_loss: 0.1843 - val_acc: 0.9393
Epoch 13/25
 - 20s - loss: 0.2093 - acc: 0.9256 - val_loss: 0.2025 - val_acc: 0.9239
Epoch 14/25
 - 20s - loss: 0.1985 - acc: 0.9295 - val_loss: 0.1764 - val_acc: 0.9395
Epoch 15/25
 - 20s - loss: 0.1936 - acc: 0.9320 - val_loss: 0.1642 - val_acc: 0.9454
Epoch 16/25
 - 20s - loss: 0.1850 - acc: 0.9371 - val_loss: 0.1527 - val_acc: 0.9526
Epoch 17/25
 - 20s - loss: 0.1778 - acc: 0.9409 - val_loss: 0.1485 - val_acc: 0.9521
Epoch 18/25
 - 20s - loss: 0.1706 - acc: 0.9438 - val_loss: 0.1650 - val_acc: 0.9439
Epoch 19/25
 - 19s - loss: 0.1647 - acc: 0.9459 - val_loss: 0.1372 - val_acc: 0.9553
Epoch 20/25
 - 20s - loss: 0.1585 - acc: 0.9476 - val_loss: 0.1434 - val_acc: 0.9536
Epoch 21/25
 - 20s - loss: 0.1557 - acc: 0.9498 - val_loss: 0.1246 - val_acc: 0.9618
Epoch 22/25
 - 19s - loss: 0.1493 - acc: 0.9514 - val_loss: 0.1519 - val_acc: 0.9504
Epoch 23/25
 - 20s - loss: 0.1446 - acc: 0.9535 - val_loss: 0.1152 - val_acc: 0.9667
Epoch 24/25
 - 20s - loss: 0.1385 - acc: 0.9574 - val_loss: 0.1134 - val_acc: 0.9639
Epoch 25/25
 - 19s - loss: 0.1353 - acc: 0.9585 - val_loss: 0.1061 - val_acc: 0.9703
Test accuracy:0.853
current auc_score ------------------> 0.946
accuracies:  [0.8315860215053763, 0.8405913978494624, 0.8310483870967742, 0.8384408602150538, 0.8385752688172043, 0.8521505376344086, 0.8112903225806452, 0.8379032258064516, 0.8426075268817205, 0.8530913978494624]
aucs:  [0.9348, 0.9476, 0.9209, 0.936, 0.9316, 0.932, 0.9132, 0.9362, 0.9295, 0.9461]
mean and std AUC:  0.933+/-0.01  max:   0.9476
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '32', 'flatten'], '0.921+/-0.012', 0.941)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '22', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.918+/-0.014', 0.94)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '23', 'adadelta', '0.5', 'FALSE', '128', 'flatten'], '0.93+/-0.014', 0.951)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '25', 'adadelta', '0.5', 'FALSE', '256', 'flatten'], '0.933+/-0.01', 0.948)
