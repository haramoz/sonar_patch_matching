python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
Gpus in the use 1
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs
['3-3-2-2', '6', '4', '16', '0.2', '0.0002', '5']
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs
['3-3-2-2', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 234)          22695       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 468)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          240128      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 265,384
Trainable params: 263,182
Non-trainable params: 2,202
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.7980 - acc: 0.6437 - val_loss: 0.7383 - val_acc: 0.6189
Epoch 2/5
 - 35s - loss: 0.6453 - acc: 0.7103 - val_loss: 0.6417 - val_acc: 0.6921
Epoch 3/5
 - 35s - loss: 0.5555 - acc: 0.7573 - val_loss: 0.6041 - val_acc: 0.7282
Epoch 4/5
 - 34s - loss: 0.4814 - acc: 0.8001 - val_loss: 0.4981 - val_acc: 0.7917
Epoch 5/5
 - 34s - loss: 0.4159 - acc: 0.8356 - val_loss: 0.4261 - val_acc: 0.8365
Test accuracy:0.624
current auc_score ------------------> 0.779
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 234)          22695       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 468)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          240128      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 265,384
Trainable params: 263,182
Non-trainable params: 2,202
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.8345 - acc: 0.6292 - val_loss: 0.6728 - val_acc: 0.6399
Epoch 2/5
 - 38s - loss: 0.6733 - acc: 0.6992 - val_loss: 0.6593 - val_acc: 0.6727
Epoch 3/5
 - 37s - loss: 0.5781 - acc: 0.7491 - val_loss: 0.5498 - val_acc: 0.7648
Epoch 4/5
 - 38s - loss: 0.4988 - acc: 0.7965 - val_loss: 0.4672 - val_acc: 0.8195
Epoch 5/5
 - 38s - loss: 0.4370 - acc: 0.8311 - val_loss: 0.4210 - val_acc: 0.8445
Test accuracy:0.655
current auc_score ------------------> 0.764
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 234)          22695       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 468)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          240128      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 265,384
Trainable params: 263,182
Non-trainable params: 2,202
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8309 - acc: 0.6342 - val_loss: 0.6371 - val_acc: 0.6899
Epoch 2/5
 - 34s - loss: 0.6621 - acc: 0.7084 - val_loss: 0.5558 - val_acc: 0.7595
Epoch 3/5
 - 35s - loss: 0.5694 - acc: 0.7584 - val_loss: 0.5005 - val_acc: 0.7890
Epoch 4/5
 - 35s - loss: 0.4935 - acc: 0.7976 - val_loss: 0.4440 - val_acc: 0.8254
Epoch 5/5
 - 35s - loss: 0.4362 - acc: 0.8295 - val_loss: 0.4172 - val_acc: 0.8441
Test accuracy:0.662
current auc_score ------------------> 0.788
accuracies:  [0.6241935483870967, 0.6545698924731183, 0.6618279569892473]
['3-3-2-2', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 459)          77823       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 918)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          470528      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 550,912
Trainable params: 547,780
Non-trainable params: 3,132
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8386 - acc: 0.6522 - val_loss: 0.7031 - val_acc: 0.6886
Epoch 2/5
 - 33s - loss: 0.6594 - acc: 0.7369 - val_loss: 0.6206 - val_acc: 0.7614
Epoch 3/5
 - 33s - loss: 0.5506 - acc: 0.7964 - val_loss: 0.5246 - val_acc: 0.8228
Epoch 4/5
 - 34s - loss: 0.4596 - acc: 0.8448 - val_loss: 0.4117 - val_acc: 0.8796
Epoch 5/5
 - 34s - loss: 0.3838 - acc: 0.8852 - val_loss: 0.3844 - val_acc: 0.8923
Test accuracy:0.683
current auc_score ------------------> 0.853
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 459)          77823       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 918)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          470528      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 550,912
Trainable params: 547,780
Non-trainable params: 3,132
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.8505 - acc: 0.6523 - val_loss: 1.8617 - val_acc: 0.5085
Epoch 2/5
 - 34s - loss: 0.6523 - acc: 0.7404 - val_loss: 1.2605 - val_acc: 0.5146
Epoch 3/5
 - 34s - loss: 0.5362 - acc: 0.8015 - val_loss: 1.9266 - val_acc: 0.5038
Epoch 4/5
 - 34s - loss: 0.4397 - acc: 0.8554 - val_loss: 1.4739 - val_acc: 0.5046

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 33s - loss: 0.3793 - acc: 0.8883 - val_loss: 1.6544 - val_acc: 0.5040
Test accuracy:0.500
current auc_score ------------------> 0.609
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 459)          77823       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 918)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          470528      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 550,912
Trainable params: 547,780
Non-trainable params: 3,132
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8554 - acc: 0.6511 - val_loss: 1.0239 - val_acc: 0.5502
Epoch 2/5
 - 34s - loss: 0.6659 - acc: 0.7364 - val_loss: 0.7715 - val_acc: 0.6578
Epoch 3/5
 - 34s - loss: 0.5456 - acc: 0.8016 - val_loss: 0.5965 - val_acc: 0.7830
Epoch 4/5
 - 34s - loss: 0.4529 - acc: 0.8519 - val_loss: 0.5053 - val_acc: 0.8279
Epoch 5/5
 - 34s - loss: 0.3948 - acc: 0.8815 - val_loss: 0.3721 - val_acc: 0.8888
Test accuracy:0.645
current auc_score ------------------> 0.832
accuracies:  [0.6831989247311828, 0.5001344086021505, 0.6454301075268817]
['3-3-2-2', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 684)          166534      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1368)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          700928      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 870,023
Trainable params: 865,967
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.8725 - acc: 0.6664 - val_loss: 1.0572 - val_acc: 0.5901
Epoch 2/5
 - 35s - loss: 0.6652 - acc: 0.7664 - val_loss: 0.6907 - val_acc: 0.7550
Epoch 3/5
 - 35s - loss: 0.5397 - acc: 0.8350 - val_loss: 0.5035 - val_acc: 0.8543
Epoch 4/5
 - 34s - loss: 0.4516 - acc: 0.8798 - val_loss: 0.4563 - val_acc: 0.8813
Epoch 5/5
 - 35s - loss: 0.3792 - acc: 0.9147 - val_loss: 0.3467 - val_acc: 0.9267
Test accuracy:0.653
current auc_score ------------------> 0.825
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 684)          166534      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1368)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          700928      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 870,023
Trainable params: 865,967
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.8767 - acc: 0.6669 - val_loss: 2.6253 - val_acc: 0.5034
Epoch 2/5
 - 35s - loss: 0.6648 - acc: 0.7658 - val_loss: 1.7813 - val_acc: 0.5134
Epoch 3/5
 - 35s - loss: 0.5432 - acc: 0.8287 - val_loss: 0.5250 - val_acc: 0.8337
Epoch 4/5
 - 34s - loss: 0.4581 - acc: 0.8759 - val_loss: 0.5050 - val_acc: 0.8562
Epoch 5/5
 - 35s - loss: 0.3864 - acc: 0.9108 - val_loss: 0.4361 - val_acc: 0.8865
Test accuracy:0.654
current auc_score ------------------> 0.848
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 684)          166534      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1368)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          700928      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 870,023
Trainable params: 865,967
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8584 - acc: 0.6837 - val_loss: 1.0496 - val_acc: 0.5602
Epoch 2/5
 - 34s - loss: 0.6320 - acc: 0.7846 - val_loss: 0.7560 - val_acc: 0.7008
Epoch 3/5
 - 35s - loss: 0.5177 - acc: 0.8465 - val_loss: 0.4662 - val_acc: 0.8759
Epoch 4/5
 - 34s - loss: 0.4368 - acc: 0.8858 - val_loss: 0.4071 - val_acc: 0.9039
Epoch 5/5
 - 34s - loss: 0.3710 - acc: 0.9179 - val_loss: 0.3356 - val_acc: 0.9367
Test accuracy:0.643
current auc_score ------------------> 0.826
accuracies:  [0.6532258064516129, 0.6543010752688172, 0.6430107526881721]
['2-3-4', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1440)         20224       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2880)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1475072     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,497,857
Trainable params: 1,495,773
Non-trainable params: 2,084
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6023 - acc: 0.7482 - val_loss: 0.3903 - val_acc: 0.8491
Epoch 2/5
 - 32s - loss: 0.3726 - acc: 0.8609 - val_loss: 0.2977 - val_acc: 0.9032
Epoch 3/5
 - 32s - loss: 0.2725 - acc: 0.9100 - val_loss: 0.2101 - val_acc: 0.9447
Epoch 4/5
 - 32s - loss: 0.2114 - acc: 0.9389 - val_loss: 0.1556 - val_acc: 0.9657
Epoch 5/5
 - 32s - loss: 0.1699 - acc: 0.9585 - val_loss: 0.1288 - val_acc: 0.9744
Test accuracy:0.715
current auc_score ------------------> 0.921
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1440)         20224       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2880)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1475072     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,497,857
Trainable params: 1,495,773
Non-trainable params: 2,084
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6114 - acc: 0.7451 - val_loss: 0.4649 - val_acc: 0.8138
Epoch 2/5
 - 32s - loss: 0.3857 - acc: 0.8531 - val_loss: 0.2836 - val_acc: 0.9094
Epoch 3/5
 - 33s - loss: 0.2778 - acc: 0.9087 - val_loss: 0.2174 - val_acc: 0.9355
Epoch 4/5
 - 32s - loss: 0.2109 - acc: 0.9405 - val_loss: 0.1528 - val_acc: 0.9650
Epoch 5/5
 - 32s - loss: 0.1672 - acc: 0.9587 - val_loss: 0.1486 - val_acc: 0.9654
Test accuracy:0.640
current auc_score ------------------> 0.866
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1440)         20224       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2880)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1475072     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,497,857
Trainable params: 1,495,773
Non-trainable params: 2,084
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6408 - acc: 0.7299 - val_loss: 0.8736 - val_acc: 0.5979
Epoch 2/5
 - 32s - loss: 0.3954 - acc: 0.8478 - val_loss: 0.8527 - val_acc: 0.6689
Epoch 3/5
 - 32s - loss: 0.2883 - acc: 0.9026 - val_loss: 0.2179 - val_acc: 0.9395
Epoch 4/5
 - 32s - loss: 0.2246 - acc: 0.9353 - val_loss: 0.1589 - val_acc: 0.9611
Epoch 5/5
 - 32s - loss: 0.1737 - acc: 0.9565 - val_loss: 0.1353 - val_acc: 0.9715
Test accuracy:0.677
current auc_score ------------------> 0.864
accuracies:  [0.7147849462365592, 0.6399193548387097, 0.6768817204301075]
['2-3-4', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2736)         69136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 5472)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2802176     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,873,873
Trainable params: 2,870,961
Non-trainable params: 2,912
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.7202 - acc: 0.7221 - val_loss: 0.5195 - val_acc: 0.7992
Epoch 2/5
 - 32s - loss: 0.4464 - acc: 0.8496 - val_loss: 0.3599 - val_acc: 0.8916
Epoch 3/5
 - 32s - loss: 0.3266 - acc: 0.9095 - val_loss: 0.2891 - val_acc: 0.9262
Epoch 4/5
 - 32s - loss: 0.2491 - acc: 0.9454 - val_loss: 0.2061 - val_acc: 0.9637
Epoch 5/5
 - 32s - loss: 0.2026 - acc: 0.9655 - val_loss: 0.1704 - val_acc: 0.9774
Test accuracy:0.738
current auc_score ------------------> 0.872
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2736)         69136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 5472)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2802176     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,873,873
Trainable params: 2,870,961
Non-trainable params: 2,912
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6714 - acc: 0.7382 - val_loss: 3.1825 - val_acc: 0.4986
Epoch 2/5
 - 32s - loss: 0.4126 - acc: 0.8616 - val_loss: 0.8925 - val_acc: 0.5891
Epoch 3/5
 - 32s - loss: 0.3028 - acc: 0.9188 - val_loss: 0.9897 - val_acc: 0.5751
Epoch 4/5
 - 32s - loss: 0.2312 - acc: 0.9523 - val_loss: 0.8373 - val_acc: 0.7146
Epoch 5/5
 - 32s - loss: 0.1863 - acc: 0.9706 - val_loss: 0.6364 - val_acc: 0.7578
Test accuracy:0.741
current auc_score ------------------> 0.777
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2736)         69136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 5472)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2802176     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,873,873
Trainable params: 2,870,961
Non-trainable params: 2,912
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6179 - acc: 0.7667 - val_loss: 1.8803 - val_acc: 0.5134
Epoch 2/5
 - 33s - loss: 0.3766 - acc: 0.8836 - val_loss: 2.0576 - val_acc: 0.5184
Epoch 3/5
 - 33s - loss: 0.2750 - acc: 0.9326 - val_loss: 3.0531 - val_acc: 0.5044

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 32s - loss: 0.2154 - acc: 0.9601 - val_loss: 2.8756 - val_acc: 0.5044
Epoch 5/5
 - 32s - loss: 0.1949 - acc: 0.9668 - val_loss: 0.1624 - val_acc: 0.9779
Test accuracy:0.728
current auc_score ------------------> 0.866
accuracies:  [0.7380376344086022, 0.7413978494623656, 0.7278225806451613]
['2-3-4', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4032)         148144      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 8064)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4129280     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 4,279,985
Trainable params: 4,276,245
Non-trainable params: 3,740
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6878 - acc: 0.7551 - val_loss: 0.6584 - val_acc: 0.7437
Epoch 2/5
 - 32s - loss: 0.4429 - acc: 0.8719 - val_loss: 0.3871 - val_acc: 0.8997
Epoch 3/5
 - 33s - loss: 0.3253 - acc: 0.9326 - val_loss: 0.2576 - val_acc: 0.9629
Epoch 4/5
 - 33s - loss: 0.2525 - acc: 0.9646 - val_loss: 0.2155 - val_acc: 0.9777
Epoch 5/5
 - 32s - loss: 0.2160 - acc: 0.9778 - val_loss: 0.1781 - val_acc: 0.9921
Test accuracy:0.640
current auc_score ------------------> 0.825
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4032)         148144      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 8064)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4129280     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 4,279,985
Trainable params: 4,276,245
Non-trainable params: 3,740
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.6952 - acc: 0.7486 - val_loss: 0.5422 - val_acc: 0.8333
Epoch 2/5
 - 37s - loss: 0.4219 - acc: 0.8843 - val_loss: 0.4185 - val_acc: 0.9021
Epoch 3/5
 - 37s - loss: 0.3009 - acc: 0.9423 - val_loss: 0.2639 - val_acc: 0.9576
Epoch 4/5
 - 37s - loss: 0.2369 - acc: 0.9693 - val_loss: 0.1951 - val_acc: 0.9871
Epoch 5/5
 - 37s - loss: 0.2026 - acc: 0.9810 - val_loss: 0.1824 - val_acc: 0.9886
Test accuracy:0.714
current auc_score ------------------> 0.901
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4032)         148144      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 8064)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4129280     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 4,279,985
Trainable params: 4,276,245
Non-trainable params: 3,740
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.7153 - acc: 0.7392 - val_loss: 0.6470 - val_acc: 0.7610
Epoch 2/5
 - 33s - loss: 0.4600 - acc: 0.8646 - val_loss: 0.4221 - val_acc: 0.8942
Epoch 3/5
 - 32s - loss: 0.3300 - acc: 0.9301 - val_loss: 0.2908 - val_acc: 0.9488
Epoch 4/5
 - 32s - loss: 0.2560 - acc: 0.9624 - val_loss: 0.2224 - val_acc: 0.9764
Epoch 5/5
 - 32s - loss: 0.2161 - acc: 0.9765 - val_loss: 0.1748 - val_acc: 0.9918
Test accuracy:0.676
current auc_score ------------------> 0.918
accuracies:  [0.6395161290322581, 0.7135752688172043, 0.6758064516129032]
['3-6', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7632)         21526       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 15264)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7815680     merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 7,839,767
Trainable params: 7,837,589
Non-trainable params: 2,178
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.4939 - acc: 0.8047 - val_loss: 3.2871 - val_acc: 0.5039
Epoch 2/5
 - 31s - loss: 0.2475 - acc: 0.9255 - val_loss: 0.1814 - val_acc: 0.9617
Epoch 3/5
 - 31s - loss: 0.1634 - acc: 0.9634 - val_loss: 0.1156 - val_acc: 0.9808
Epoch 4/5
 - 31s - loss: 0.1200 - acc: 0.9785 - val_loss: 0.0875 - val_acc: 0.9902
Epoch 5/5
 - 31s - loss: 0.0969 - acc: 0.9862 - val_loss: 0.0786 - val_acc: 0.9941
Test accuracy:0.706
current auc_score ------------------> 0.894
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7632)         21526       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 15264)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7815680     merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 7,839,767
Trainable params: 7,837,589
Non-trainable params: 2,178
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.5240 - acc: 0.7891 - val_loss: 0.3036 - val_acc: 0.9040
Epoch 2/5
 - 34s - loss: 0.2733 - acc: 0.9129 - val_loss: 0.1976 - val_acc: 0.9539
Epoch 3/5
 - 34s - loss: 0.1848 - acc: 0.9542 - val_loss: 0.1355 - val_acc: 0.9748
Epoch 4/5
 - 34s - loss: 0.1396 - acc: 0.9711 - val_loss: 0.1102 - val_acc: 0.9838
Epoch 5/5
 - 34s - loss: 0.1123 - acc: 0.9808 - val_loss: 0.0913 - val_acc: 0.9898
Test accuracy:0.640
current auc_score ------------------> 0.897
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7632)         21526       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 15264)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7815680     merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 7,839,767
Trainable params: 7,837,589
Non-trainable params: 2,178
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.5370 - acc: 0.7775 - val_loss: 0.3139 - val_acc: 0.8961
Epoch 2/5
 - 32s - loss: 0.2851 - acc: 0.9063 - val_loss: 0.2200 - val_acc: 0.9400
Epoch 3/5
 - 31s - loss: 0.1910 - acc: 0.9497 - val_loss: 0.1312 - val_acc: 0.9762
Epoch 4/5
 - 32s - loss: 0.1399 - acc: 0.9719 - val_loss: 0.1013 - val_acc: 0.9841
Epoch 5/5
 - 32s - loss: 0.1123 - acc: 0.9805 - val_loss: 0.0899 - val_acc: 0.9893
Test accuracy:0.569
current auc_score ------------------> 0.904
accuracies:  [0.7057795698924731, 0.6404569892473119, 0.5692204301075269]
['3-6', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        73024       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 14,526,785
Trainable params: 14,523,725
Non-trainable params: 3,060
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.5592 - acc: 0.7933 - val_loss: 0.3664 - val_acc: 0.8911
Epoch 2/5
 - 35s - loss: 0.3180 - acc: 0.9111 - val_loss: 0.2393 - val_acc: 0.9542
Epoch 3/5
 - 35s - loss: 0.2136 - acc: 0.9599 - val_loss: 0.1673 - val_acc: 0.9810
Epoch 4/5
 - 35s - loss: 0.1722 - acc: 0.9747 - val_loss: 0.1310 - val_acc: 0.9906
Epoch 5/5
 - 35s - loss: 0.1427 - acc: 0.9855 - val_loss: 0.1225 - val_acc: 0.9925
Test accuracy:0.647
current auc_score ------------------> 0.816
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        73024       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 14,526,785
Trainable params: 14,523,725
Non-trainable params: 3,060
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6007 - acc: 0.7661 - val_loss: 0.4096 - val_acc: 0.8597
Epoch 2/5
 - 32s - loss: 0.3528 - acc: 0.8943 - val_loss: 0.2699 - val_acc: 0.9378
Epoch 3/5
 - 33s - loss: 0.2479 - acc: 0.9458 - val_loss: 0.2029 - val_acc: 0.9649
Epoch 4/5
 - 33s - loss: 0.1896 - acc: 0.9699 - val_loss: 0.1531 - val_acc: 0.9859
Epoch 5/5
 - 33s - loss: 0.1614 - acc: 0.9785 - val_loss: 0.1241 - val_acc: 0.9916
Test accuracy:0.585
current auc_score ------------------> 0.863
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        73024       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 14,526,785
Trainable params: 14,523,725
Non-trainable params: 3,060
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5862 - acc: 0.7784 - val_loss: 1.1217 - val_acc: 0.5852
Epoch 2/5
 - 32s - loss: 0.3322 - acc: 0.9077 - val_loss: 0.2521 - val_acc: 0.9575
Epoch 3/5
 - 32s - loss: 0.2329 - acc: 0.9543 - val_loss: 0.1984 - val_acc: 0.9680
Epoch 4/5
 - 33s - loss: 0.1838 - acc: 0.9730 - val_loss: 0.1489 - val_acc: 0.9869
Epoch 5/5
 - 32s - loss: 0.1542 - acc: 0.9825 - val_loss: 0.1301 - val_acc: 0.9931
Test accuracy:0.637
current auc_score ------------------> 0.899
accuracies:  [0.6471774193548387, 0.5848118279569893, 0.6366935483870968]
['3-6', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 20592)        155950      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 41184)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          21086720    merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 21,245,231
Trainable params: 21,241,289
Non-trainable params: 3,942
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6323 - acc: 0.7774 - val_loss: 0.5059 - val_acc: 0.8384
Epoch 2/5
 - 33s - loss: 0.3757 - acc: 0.9070 - val_loss: 0.3334 - val_acc: 0.9325
Epoch 3/5
 - 33s - loss: 0.2725 - acc: 0.9557 - val_loss: 0.2356 - val_acc: 0.9703
Epoch 4/5
 - 33s - loss: 0.2217 - acc: 0.9728 - val_loss: 0.1744 - val_acc: 0.9917
Epoch 5/5
 - 33s - loss: 0.1901 - acc: 0.9830 - val_loss: 0.1612 - val_acc: 0.9922
Test accuracy:0.631
current auc_score ------------------> 0.890
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 20592)        155950      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 41184)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          21086720    merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 21,245,231
Trainable params: 21,241,289
Non-trainable params: 3,942
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6359 - acc: 0.7757 - val_loss: 0.5750 - val_acc: 0.7668
Epoch 2/5
 - 32s - loss: 0.3771 - acc: 0.9051 - val_loss: 0.3119 - val_acc: 0.9506
Epoch 3/5
 - 32s - loss: 0.2682 - acc: 0.9552 - val_loss: 0.2780 - val_acc: 0.9492
Epoch 4/5
 - 32s - loss: 0.2108 - acc: 0.9769 - val_loss: 0.1889 - val_acc: 0.9872
Epoch 5/5
 - 33s - loss: 0.1835 - acc: 0.9844 - val_loss: 0.1789 - val_acc: 0.9873
Test accuracy:0.587
current auc_score ------------------> 0.888
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 20592)        155950      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 41184)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          21086720    merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 21,245,231
Trainable params: 21,241,289
Non-trainable params: 3,942
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.5907 - acc: 0.7980 - val_loss: 0.3881 - val_acc: 0.9118
Epoch 2/5
 - 36s - loss: 0.3393 - acc: 0.9237 - val_loss: 0.2509 - val_acc: 0.9686
Epoch 3/5
 - 36s - loss: 0.2488 - acc: 0.9656 - val_loss: 0.1935 - val_acc: 0.9832
Epoch 4/5
 - 36s - loss: 0.2035 - acc: 0.9795 - val_loss: 0.1624 - val_acc: 0.9927
Epoch 5/5
 - 36s - loss: 0.1751 - acc: 0.9874 - val_loss: 0.1437 - val_acc: 0.9960
Test accuracy:0.633
current auc_score ------------------> 0.890
accuracies:  [0.630510752688172, 0.5865591397849462, 0.6325268817204301]
['2-3', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4608)         11184       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9216)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4719104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 4,732,849
Trainable params: 4,731,237
Non-trainable params: 1,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4980 - acc: 0.7891 - val_loss: 0.2628 - val_acc: 0.9142
Epoch 2/5
 - 25s - loss: 0.2408 - acc: 0.9194 - val_loss: 0.1548 - val_acc: 0.9659
Epoch 3/5
 - 25s - loss: 0.1468 - acc: 0.9624 - val_loss: 0.0943 - val_acc: 0.9836
Epoch 4/5
 - 25s - loss: 0.0999 - acc: 0.9809 - val_loss: 0.0678 - val_acc: 0.9907
Epoch 5/5
 - 25s - loss: 0.0781 - acc: 0.9874 - val_loss: 0.0542 - val_acc: 0.9935
Test accuracy:0.693
current auc_score ------------------> 0.854
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4608)         11184       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9216)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4719104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 4,732,849
Trainable params: 4,731,237
Non-trainable params: 1,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4939 - acc: 0.7951 - val_loss: 0.2623 - val_acc: 0.9065
Epoch 2/5
 - 27s - loss: 0.2278 - acc: 0.9233 - val_loss: 0.1510 - val_acc: 0.9650
Epoch 3/5
 - 26s - loss: 0.1446 - acc: 0.9612 - val_loss: 0.1162 - val_acc: 0.9775
Epoch 4/5
 - 27s - loss: 0.1065 - acc: 0.9766 - val_loss: 0.0791 - val_acc: 0.9867
Epoch 5/5
 - 27s - loss: 0.0839 - acc: 0.9849 - val_loss: 0.0676 - val_acc: 0.9903
Test accuracy:0.748
current auc_score ------------------> 0.898
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4608)         11184       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9216)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4719104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 4,732,849
Trainable params: 4,731,237
Non-trainable params: 1,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 29s - loss: 0.4726 - acc: 0.8060 - val_loss: 0.2320 - val_acc: 0.9183
Epoch 2/5
 - 25s - loss: 0.2183 - acc: 0.9287 - val_loss: 0.1311 - val_acc: 0.9665
Epoch 3/5
 - 25s - loss: 0.1389 - acc: 0.9639 - val_loss: 0.0882 - val_acc: 0.9838
Epoch 4/5
 - 25s - loss: 0.1045 - acc: 0.9786 - val_loss: 0.0722 - val_acc: 0.9874
Epoch 5/5
 - 25s - loss: 0.0794 - acc: 0.9857 - val_loss: 0.0562 - val_acc: 0.9941
Test accuracy:0.701
current auc_score ------------------> 0.885
accuracies:  [0.6931451612903226, 0.7478494623655914, 0.7010752688172043]
['2-3', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8064)         36192       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16128)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8258048     merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 8,296,801
Trainable params: 8,294,793
Non-trainable params: 2,008
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.5645 - acc: 0.7714 - val_loss: 0.3099 - val_acc: 0.9030
Epoch 2/5
 - 26s - loss: 0.2838 - acc: 0.9107 - val_loss: 0.2237 - val_acc: 0.9425
Epoch 3/5
 - 25s - loss: 0.1865 - acc: 0.9557 - val_loss: 0.1493 - val_acc: 0.9745
Epoch 4/5
 - 25s - loss: 0.1468 - acc: 0.9711 - val_loss: 0.1172 - val_acc: 0.9846
Epoch 5/5
 - 27s - loss: 0.1171 - acc: 0.9819 - val_loss: 0.0930 - val_acc: 0.9898
Test accuracy:0.690
current auc_score ------------------> 0.886
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8064)         36192       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16128)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8258048     merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 8,296,801
Trainable params: 8,294,793
Non-trainable params: 2,008
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4802 - acc: 0.8136 - val_loss: 0.3598 - val_acc: 0.8543
Epoch 2/5
 - 26s - loss: 0.2379 - acc: 0.9320 - val_loss: 0.1540 - val_acc: 0.9691
Epoch 3/5
 - 25s - loss: 0.1601 - acc: 0.9659 - val_loss: 0.1076 - val_acc: 0.9886
Epoch 4/5
 - 25s - loss: 0.1197 - acc: 0.9811 - val_loss: 0.0880 - val_acc: 0.9927
Epoch 5/5
 - 26s - loss: 0.0980 - acc: 0.9877 - val_loss: 0.0832 - val_acc: 0.9928
Test accuracy:0.651
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8064)         36192       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16128)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8258048     merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 8,296,801
Trainable params: 8,294,793
Non-trainable params: 2,008
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4740 - acc: 0.8186 - val_loss: 0.2577 - val_acc: 0.9221
Epoch 2/5
 - 25s - loss: 0.2313 - acc: 0.9338 - val_loss: 0.1624 - val_acc: 0.9682
Epoch 3/5
 - 25s - loss: 0.1606 - acc: 0.9648 - val_loss: 0.1046 - val_acc: 0.9881
Epoch 4/5
 - 25s - loss: 0.1196 - acc: 0.9806 - val_loss: 0.0860 - val_acc: 0.9927
Epoch 5/5
 - 26s - loss: 0.0974 - acc: 0.9871 - val_loss: 0.0735 - val_acc: 0.9946
Test accuracy:0.710
current auc_score ------------------> 0.916
accuracies:  [0.6895161290322581, 0.6509408602150538, 0.7104838709677419]
['2-3', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        76320       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 11,875,873
Trainable params: 11,873,469
Non-trainable params: 2,404
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5492 - acc: 0.7839 - val_loss: 0.3492 - val_acc: 0.8849
Epoch 2/5
 - 27s - loss: 0.2941 - acc: 0.9185 - val_loss: 0.2301 - val_acc: 0.9455
Epoch 3/5
 - 27s - loss: 0.1975 - acc: 0.9606 - val_loss: 0.1402 - val_acc: 0.9858
Epoch 4/5
 - 27s - loss: 0.1507 - acc: 0.9783 - val_loss: 0.1138 - val_acc: 0.9908
Epoch 5/5
 - 27s - loss: 0.1290 - acc: 0.9844 - val_loss: 0.1030 - val_acc: 0.9936
Test accuracy:0.746
current auc_score ------------------> 0.922
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        76320       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 11,875,873
Trainable params: 11,873,469
Non-trainable params: 2,404
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5245 - acc: 0.8052 - val_loss: 0.3146 - val_acc: 0.9144
Epoch 2/5
 - 26s - loss: 0.2629 - acc: 0.9313 - val_loss: 0.1689 - val_acc: 0.9769
Epoch 3/5
 - 26s - loss: 0.1775 - acc: 0.9699 - val_loss: 0.1334 - val_acc: 0.9817
Epoch 4/5
 - 26s - loss: 0.1449 - acc: 0.9808 - val_loss: 0.1127 - val_acc: 0.9920
Epoch 5/5
 - 27s - loss: 0.1201 - acc: 0.9879 - val_loss: 0.1003 - val_acc: 0.9952
Test accuracy:0.621
current auc_score ------------------> 0.842
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        76320       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_14[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_6[0][0]                  
==================================================================================================
Total params: 11,875,873
Trainable params: 11,873,469
Non-trainable params: 2,404
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.5222 - acc: 0.8021 - val_loss: 0.3337 - val_acc: 0.9042
Epoch 2/5
 - 26s - loss: 0.2640 - acc: 0.9336 - val_loss: 0.1893 - val_acc: 0.9736
Epoch 3/5
 - 26s - loss: 0.1822 - acc: 0.9668 - val_loss: 0.1323 - val_acc: 0.9859
Epoch 4/5
 - 26s - loss: 0.1421 - acc: 0.9822 - val_loss: 0.1101 - val_acc: 0.9930
Epoch 5/5
 - 25s - loss: 0.1203 - acc: 0.9880 - val_loss: 0.0914 - val_acc: 0.9960
Test accuracy:0.705
current auc_score ------------------> 0.883
accuracies:  [0.7456989247311828, 0.6209677419354839, 0.7047043010752688]
['6', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4463 - acc: 0.8192 - val_loss: 0.2491 - val_acc: 0.9124
Epoch 2/5
 - 26s - loss: 0.2136 - acc: 0.9326 - val_loss: 0.1477 - val_acc: 0.9621
Epoch 3/5
 - 27s - loss: 0.1384 - acc: 0.9660 - val_loss: 0.1128 - val_acc: 0.9800
Epoch 4/5
 - 27s - loss: 0.1037 - acc: 0.9784 - val_loss: 0.0799 - val_acc: 0.9885
Epoch 5/5
 - 27s - loss: 0.0811 - acc: 0.9865 - val_loss: 0.0564 - val_acc: 0.9945
Test accuracy:0.635
current auc_score ------------------> 0.908
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4634 - acc: 0.8054 - val_loss: 0.2932 - val_acc: 0.8893
Epoch 2/5
 - 27s - loss: 0.2352 - acc: 0.9268 - val_loss: 0.1684 - val_acc: 0.9637
Epoch 3/5
 - 27s - loss: 0.1531 - acc: 0.9614 - val_loss: 0.0997 - val_acc: 0.9853
Epoch 4/5
 - 27s - loss: 0.1081 - acc: 0.9780 - val_loss: 0.0770 - val_acc: 0.9897
Epoch 5/5
 - 27s - loss: 0.0828 - acc: 0.9861 - val_loss: 0.0548 - val_acc: 0.9942
Test accuracy:0.706
current auc_score ------------------> 0.885
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.4616 - acc: 0.8073 - val_loss: 0.2803 - val_acc: 0.9047
Epoch 2/5
 - 28s - loss: 0.2352 - acc: 0.9233 - val_loss: 0.1529 - val_acc: 0.9639
Epoch 3/5
 - 27s - loss: 0.1509 - acc: 0.9636 - val_loss: 0.1081 - val_acc: 0.9816
Epoch 4/5
 - 28s - loss: 0.1157 - acc: 0.9738 - val_loss: 0.0904 - val_acc: 0.9864
Epoch 5/5
 - 28s - loss: 0.0914 - acc: 0.9833 - val_loss: 0.0623 - val_acc: 0.9936
Test accuracy:0.669
current auc_score ------------------> 0.896
accuracies:  [0.6349462365591397, 0.7055107526881721, 0.6692204301075269]
['6', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4854 - acc: 0.7968 - val_loss: 0.2910 - val_acc: 0.8934
Epoch 2/5
 - 26s - loss: 0.2516 - acc: 0.9146 - val_loss: 0.1538 - val_acc: 0.9642
Epoch 3/5
 - 27s - loss: 0.1570 - acc: 0.9603 - val_loss: 0.1110 - val_acc: 0.9772
Epoch 4/5
 - 26s - loss: 0.1103 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9902
Epoch 5/5
 - 27s - loss: 0.0892 - acc: 0.9846 - val_loss: 0.0647 - val_acc: 0.9941
Test accuracy:0.649
current auc_score ------------------> 0.869
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4452 - acc: 0.8137 - val_loss: 1.7046 - val_acc: 0.5103
Epoch 2/5
 - 26s - loss: 0.2216 - acc: 0.9297 - val_loss: 1.3851 - val_acc: 0.5448
Epoch 3/5
 - 27s - loss: 0.1458 - acc: 0.9644 - val_loss: 0.0905 - val_acc: 0.9856
Epoch 4/5
 - 26s - loss: 0.1058 - acc: 0.9792 - val_loss: 0.0704 - val_acc: 0.9902
Epoch 5/5
 - 26s - loss: 0.0841 - acc: 0.9852 - val_loss: 0.0615 - val_acc: 0.9897
Test accuracy:0.725
current auc_score ------------------> 0.885
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.4818 - acc: 0.7939 - val_loss: 0.3091 - val_acc: 0.8840
Epoch 2/5
 - 28s - loss: 0.2402 - acc: 0.9218 - val_loss: 0.1690 - val_acc: 0.9539
Epoch 3/5
 - 28s - loss: 0.1589 - acc: 0.9578 - val_loss: 0.1023 - val_acc: 0.9844
Epoch 4/5
 - 28s - loss: 0.1113 - acc: 0.9760 - val_loss: 0.0772 - val_acc: 0.9872
Epoch 5/5
 - 28s - loss: 0.0873 - acc: 0.9839 - val_loss: 0.0626 - val_acc: 0.9907
Test accuracy:0.734
current auc_score ------------------> 0.869
accuracies:  [0.6490591397849462, 0.7247311827956989, 0.7338709677419355]
['6', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 35s - loss: 0.4910 - acc: 0.8088 - val_loss: 1.5449 - val_acc: 0.5378
Epoch 2/5
 - 29s - loss: 0.2634 - acc: 0.9249 - val_loss: 1.0269 - val_acc: 0.6242
Epoch 3/5
 - 29s - loss: 0.1719 - acc: 0.9645 - val_loss: 1.3725 - val_acc: 0.6077
Epoch 4/5
 - 29s - loss: 0.1274 - acc: 0.9806 - val_loss: 0.0937 - val_acc: 0.9917
Epoch 5/5
 - 29s - loss: 0.1078 - acc: 0.9861 - val_loss: 0.0880 - val_acc: 0.9882
Test accuracy:0.711
current auc_score ------------------> 0.877
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.5091 - acc: 0.7957 - val_loss: 0.3179 - val_acc: 0.8990
Epoch 2/5
 - 30s - loss: 0.2762 - acc: 0.9180 - val_loss: 0.2144 - val_acc: 0.9502
Epoch 3/5
 - 31s - loss: 0.1872 - acc: 0.9594 - val_loss: 0.1468 - val_acc: 0.9823
Epoch 4/5
 - 30s - loss: 0.1417 - acc: 0.9756 - val_loss: 0.0948 - val_acc: 0.9922
Epoch 5/5
 - 30s - loss: 0.1098 - acc: 0.9851 - val_loss: 0.0793 - val_acc: 0.9951
Test accuracy:0.634
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.4931 - acc: 0.8066 - val_loss: 0.2798 - val_acc: 0.9174
Epoch 2/5
 - 31s - loss: 0.2424 - acc: 0.9332 - val_loss: 0.1768 - val_acc: 0.9641
Epoch 3/5
 - 31s - loss: 0.1624 - acc: 0.9689 - val_loss: 0.1183 - val_acc: 0.9862
Epoch 4/5
 - 31s - loss: 0.1195 - acc: 0.9829 - val_loss: 0.0937 - val_acc: 0.9912
Epoch 5/5
 - 31s - loss: 0.1010 - acc: 0.9878 - val_loss: 0.0818 - val_acc: 0.9945
Test accuracy:0.664
current auc_score ------------------> 0.893
accuracies:  [0.7114247311827957, 0.6336021505376344, 0.6637096774193548]
['6', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5375 - acc: 0.7977 - val_loss: 2.5175 - val_acc: 0.5276
Epoch 2/5
 - 33s - loss: 0.2808 - acc: 0.9292 - val_loss: 3.2933 - val_acc: 0.5112
Epoch 3/5
 - 33s - loss: 0.1922 - acc: 0.9672 - val_loss: 4.5208 - val_acc: 0.5040

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 33s - loss: 0.1407 - acc: 0.9847 - val_loss: 2.5931 - val_acc: 0.5168
Epoch 5/5
 - 33s - loss: 0.1230 - acc: 0.9903 - val_loss: 2.6865 - val_acc: 0.5299

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Test accuracy:0.534
current auc_score ------------------> 0.747
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.5453 - acc: 0.7901 - val_loss: 0.4197 - val_acc: 0.8602
Epoch 2/5
 - 35s - loss: 0.3061 - acc: 0.9190 - val_loss: 0.2195 - val_acc: 0.9558
Epoch 3/5
 - 35s - loss: 0.2152 - acc: 0.9599 - val_loss: 0.1523 - val_acc: 0.9853
Epoch 4/5
 - 35s - loss: 0.1654 - acc: 0.9767 - val_loss: 0.1304 - val_acc: 0.9905
Epoch 5/5
 - 35s - loss: 0.1309 - acc: 0.9853 - val_loss: 0.1025 - val_acc: 0.9923
Test accuracy:0.600
current auc_score ------------------> 0.904
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5226 - acc: 0.8075 - val_loss: 0.3340 - val_acc: 0.9081
Epoch 2/5
 - 33s - loss: 0.2912 - acc: 0.9226 - val_loss: 0.1956 - val_acc: 0.9734
Epoch 3/5
 - 33s - loss: 0.1969 - acc: 0.9649 - val_loss: 0.1369 - val_acc: 0.9868
Epoch 4/5
 - 33s - loss: 0.1544 - acc: 0.9784 - val_loss: 0.1128 - val_acc: 0.9939
Epoch 5/5
 - 33s - loss: 0.1256 - acc: 0.9860 - val_loss: 0.0929 - val_acc: 0.9952
Test accuracy:0.659
current auc_score ------------------> 0.913
accuracies:  [0.5340053763440861, 0.6004032258064517, 0.6586021505376344]
['6-12', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        52888       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 14,506,649
Trainable params: 14,502,641
Non-trainable params: 4,008
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6019 - acc: 0.7715 - val_loss: 1.0587 - val_acc: 0.6088
Epoch 2/5
 - 46s - loss: 0.3562 - acc: 0.8944 - val_loss: 2.0552 - val_acc: 0.5074
Epoch 3/5
 - 46s - loss: 0.2485 - acc: 0.9458 - val_loss: 3.2590 - val_acc: 0.5059

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 46s - loss: 0.1961 - acc: 0.9693 - val_loss: 2.4727 - val_acc: 0.5136
Epoch 5/5
 - 46s - loss: 0.1743 - acc: 0.9768 - val_loss: 3.0045 - val_acc: 0.5108

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 00005: early stopping
Test accuracy:0.500
current auc_score ------------------> 0.626
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        52888       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 14,506,649
Trainable params: 14,502,641
Non-trainable params: 4,008
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6050 - acc: 0.7720 - val_loss: 1.6641 - val_acc: 0.5517
Epoch 2/5
 - 46s - loss: 0.3427 - acc: 0.9029 - val_loss: 1.0439 - val_acc: 0.5707
Epoch 3/5
 - 46s - loss: 0.2479 - acc: 0.9462 - val_loss: 0.9828 - val_acc: 0.6180
Epoch 4/5
 - 46s - loss: 0.1975 - acc: 0.9674 - val_loss: 1.1317 - val_acc: 0.6140
Epoch 5/5
 - 46s - loss: 0.1685 - acc: 0.9780 - val_loss: 0.9573 - val_acc: 0.6763
Test accuracy:0.680
current auc_score ------------------> 0.697
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        52888       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 14,506,649
Trainable params: 14,502,641
Non-trainable params: 4,008
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.5787 - acc: 0.7807 - val_loss: 0.3683 - val_acc: 0.8892
Epoch 2/5
 - 47s - loss: 0.3262 - acc: 0.9088 - val_loss: 0.2445 - val_acc: 0.9497
Epoch 3/5
 - 47s - loss: 0.2288 - acc: 0.9542 - val_loss: 0.1658 - val_acc: 0.9803
Epoch 4/5
 - 47s - loss: 0.1783 - acc: 0.9740 - val_loss: 0.1586 - val_acc: 0.9827
Epoch 5/5
 - 47s - loss: 0.1510 - acc: 0.9834 - val_loss: 0.1292 - val_acc: 0.9900
Test accuracy:0.701
current auc_score ------------------> 0.902
accuracies:  [0.5, 0.6798387096774193, 0.7005376344086022]
['6-12', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 27072)        185584      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 54144)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          27722240    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 27,910,385
Trainable params: 27,903,857
Non-trainable params: 6,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 66s - loss: 0.6423 - acc: 0.7938 - val_loss: 2.4793 - val_acc: 0.5038
Epoch 2/5
 - 49s - loss: 0.4261 - acc: 0.9048 - val_loss: 0.8388 - val_acc: 0.6434
Epoch 3/5
 - 49s - loss: 0.3289 - acc: 0.9478 - val_loss: 1.5110 - val_acc: 0.5383
Epoch 4/5
 - 48s - loss: 0.2733 - acc: 0.9682 - val_loss: 0.9482 - val_acc: 0.6352

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 49s - loss: 0.2300 - acc: 0.9840 - val_loss: 0.9261 - val_acc: 0.6520
Test accuracy:0.604
current auc_score ------------------> 0.657
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 27072)        185584      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 54144)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          27722240    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 27,910,385
Trainable params: 27,903,857
Non-trainable params: 6,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.7086 - acc: 0.7525 - val_loss: 0.9238 - val_acc: 0.5722
Epoch 2/5
 - 49s - loss: 0.4697 - acc: 0.8815 - val_loss: 0.8584 - val_acc: 0.6613
Epoch 3/5
 - 49s - loss: 0.3490 - acc: 0.9418 - val_loss: 1.0167 - val_acc: 0.6300
Epoch 4/5
 - 49s - loss: 0.2881 - acc: 0.9638 - val_loss: 1.1779 - val_acc: 0.6064

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 49s - loss: 0.2405 - acc: 0.9803 - val_loss: 1.3861 - val_acc: 0.5798
Test accuracy:0.551
current auc_score ------------------> 0.666
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 27072)        185584      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 54144)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          27722240    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 27,910,385
Trainable params: 27,903,857
Non-trainable params: 6,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.6475 - acc: 0.7887 - val_loss: 0.9059 - val_acc: 0.5890
Epoch 2/5
 - 49s - loss: 0.4172 - acc: 0.9059 - val_loss: 0.9324 - val_acc: 0.5961
Epoch 3/5
 - 49s - loss: 0.3255 - acc: 0.9497 - val_loss: 0.8152 - val_acc: 0.6869
Epoch 4/5
 - 49s - loss: 0.2657 - acc: 0.9704 - val_loss: 0.9920 - val_acc: 0.6239
Epoch 5/5
 - 49s - loss: 0.2283 - acc: 0.9817 - val_loss: 1.1268 - val_acc: 0.6264

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.655
current auc_score ------------------> 0.690
accuracies:  [0.6044354838709678, 0.5513440860215054, 0.6551075268817205]
['6-12', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40032)        399928      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80064)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          40993280    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 41,395,769
Trainable params: 41,386,721
Non-trainable params: 9,048
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 67s - loss: 0.7462 - acc: 0.7826 - val_loss: 1.5485 - val_acc: 0.5231
Epoch 2/5
 - 52s - loss: 0.5110 - acc: 0.9033 - val_loss: 1.9189 - val_acc: 0.5112
Epoch 3/5
 - 52s - loss: 0.3896 - acc: 0.9573 - val_loss: 2.0698 - val_acc: 0.5217

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 52s - loss: 0.3265 - acc: 0.9790 - val_loss: 1.6613 - val_acc: 0.5310
Epoch 5/5
 - 52s - loss: 0.3033 - acc: 0.9853 - val_loss: 1.6971 - val_acc: 0.5385

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Test accuracy:0.531
current auc_score ------------------> 0.541
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40032)        399928      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80064)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          40993280    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 41,395,769
Trainable params: 41,386,721
Non-trainable params: 9,048
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 66s - loss: 0.8326 - acc: 0.7369 - val_loss: 0.6667 - val_acc: 0.8233
Epoch 2/5
 - 52s - loss: 0.5727 - acc: 0.8710 - val_loss: 0.6020 - val_acc: 0.8573
Epoch 3/5
 - 53s - loss: 0.4505 - acc: 0.9324 - val_loss: 0.4028 - val_acc: 0.9539
Epoch 4/5
 - 52s - loss: 0.3739 - acc: 0.9602 - val_loss: 0.3705 - val_acc: 0.9544
Epoch 5/5
 - 53s - loss: 0.3235 - acc: 0.9746 - val_loss: 0.3098 - val_acc: 0.9783
Test accuracy:0.661
current auc_score ------------------> 0.856
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40032)        399928      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80064)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          40993280    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 41,395,769
Trainable params: 41,386,721
Non-trainable params: 9,048
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 66s - loss: 0.7853 - acc: 0.7644 - val_loss: 0.6486 - val_acc: 0.8257
Epoch 2/5
 - 53s - loss: 0.5362 - acc: 0.8913 - val_loss: 0.4701 - val_acc: 0.9320
Epoch 3/5
 - 52s - loss: 0.4232 - acc: 0.9433 - val_loss: 0.3562 - val_acc: 0.9694
Epoch 4/5
 - 52s - loss: 0.3544 - acc: 0.9667 - val_loss: 0.3377 - val_acc: 0.9706
Epoch 5/5
 - 52s - loss: 0.3077 - acc: 0.9796 - val_loss: 0.2938 - val_acc: 0.9783
Test accuracy:0.625
current auc_score ------------------> 0.835
accuracies:  [0.5314516129032258, 0.6606182795698925, 0.6254032258064516]
['6-12', '32', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  32  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 70272)        1217584     input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 140544)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          71959040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 73,179,185
Trainable params: 73,164,257
Non-trainable params: 14,928
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 76s - loss: 0.9133 - acc: 0.8048 - val_loss: 3.0563 - val_acc: 0.5035
Epoch 2/5
 - 60s - loss: 0.6585 - acc: 0.9282 - val_loss: 5.1859 - val_acc: 0.5035
Epoch 3/5
 - 60s - loss: 0.5319 - acc: 0.9706 - val_loss: 4.5123 - val_acc: 0.5035

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 60s - loss: 0.4639 - acc: 0.9862 - val_loss: 2.8147 - val_acc: 0.5149
Epoch 5/5
 - 60s - loss: 0.4335 - acc: 0.9910 - val_loss: 0.4516 - val_acc: 0.9854
Test accuracy:0.565
current auc_score ------------------> 0.807
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  32  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 70272)        1217584     input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 140544)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          71959040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 73,179,185
Trainable params: 73,164,257
Non-trainable params: 14,928
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 76s - loss: 0.9654 - acc: 0.7750 - val_loss: 1.0148 - val_acc: 0.7338
Epoch 2/5
 - 61s - loss: 0.7099 - acc: 0.9002 - val_loss: 0.7325 - val_acc: 0.8835
Epoch 3/5
 - 61s - loss: 0.5696 - acc: 0.9549 - val_loss: 0.5094 - val_acc: 0.9691
Epoch 4/5
 - 61s - loss: 0.4772 - acc: 0.9779 - val_loss: 0.4377 - val_acc: 0.9857
Epoch 5/5
 - 60s - loss: 0.4162 - acc: 0.9854 - val_loss: 0.3679 - val_acc: 0.9939
Test accuracy:0.671
current auc_score ------------------> 0.831
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12]  Growth_rate:  32  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 70272)        1217584     input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 140544)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          71959040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_40[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 73,179,185
Trainable params: 73,164,257
Non-trainable params: 14,928
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 75s - loss: 0.9351 - acc: 0.7912 - val_loss: 0.9157 - val_acc: 0.7769
Epoch 2/5
 - 60s - loss: 0.6743 - acc: 0.9182 - val_loss: 0.6386 - val_acc: 0.9335
Epoch 3/5
 - 60s - loss: 0.5416 - acc: 0.9634 - val_loss: 0.5037 - val_acc: 0.9700
Epoch 4/5
 - 60s - loss: 0.4632 - acc: 0.9794 - val_loss: 0.5096 - val_acc: 0.9580
Epoch 5/5
 - 60s - loss: 0.4110 - acc: 0.9861 - val_loss: 0.3684 - val_acc: 0.9945
Test accuracy:0.721
current auc_score ------------------> 0.842
accuracies:  [0.5650537634408602, 0.6708333333333333, 0.7208333333333333]
['6-12-12', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4356)         102430      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 8712)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4461056     merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 4,566,047
Trainable params: 4,559,253
Non-trainable params: 6,794
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 91s - loss: 0.7230 - acc: 0.7400 - val_loss: 4.6910 - val_acc: 0.4965
Epoch 2/5
 - 68s - loss: 0.5045 - acc: 0.8473 - val_loss: 1.1180 - val_acc: 0.5151
Epoch 3/5
 - 68s - loss: 0.3970 - acc: 0.9061 - val_loss: 1.2668 - val_acc: 0.5243
Epoch 4/5
 - 68s - loss: 0.3202 - acc: 0.9402 - val_loss: 1.2644 - val_acc: 0.5323

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 68s - loss: 0.2712 - acc: 0.9604 - val_loss: 1.1442 - val_acc: 0.5792
Test accuracy:0.618
current auc_score ------------------> 0.634
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4356)         102430      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 8712)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4461056     merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 4,566,047
Trainable params: 4,559,253
Non-trainable params: 6,794
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 90s - loss: 0.7226 - acc: 0.7440 - val_loss: 1.3366 - val_acc: 0.5393
Epoch 2/5
 - 68s - loss: 0.5077 - acc: 0.8480 - val_loss: 1.0048 - val_acc: 0.5901
Epoch 3/5
 - 68s - loss: 0.3938 - acc: 0.9068 - val_loss: 0.3600 - val_acc: 0.9256
Epoch 4/5
 - 68s - loss: 0.3103 - acc: 0.9470 - val_loss: 0.2726 - val_acc: 0.9612
Epoch 5/5
 - 68s - loss: 0.2642 - acc: 0.9651 - val_loss: 0.2180 - val_acc: 0.9808
Test accuracy:0.665
current auc_score ------------------> 0.858
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4356)         102430      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 8712)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4461056     merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 4,566,047
Trainable params: 4,559,253
Non-trainable params: 6,794
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 91s - loss: 0.7161 - acc: 0.7522 - val_loss: 2.3687 - val_acc: 0.4961
Epoch 2/5
 - 68s - loss: 0.4832 - acc: 0.8613 - val_loss: 2.9616 - val_acc: 0.4965
Epoch 3/5
 - 68s - loss: 0.3778 - acc: 0.9138 - val_loss: 0.3118 - val_acc: 0.9502
Epoch 4/5
 - 68s - loss: 0.3051 - acc: 0.9456 - val_loss: 0.2530 - val_acc: 0.9706
Epoch 5/5
 - 68s - loss: 0.2626 - acc: 0.9641 - val_loss: 0.2389 - val_acc: 0.9744
Test accuracy:0.663
current auc_score ------------------> 0.877
accuracies:  [0.6178763440860215, 0.6647849462365591, 0.6631720430107527]
['6-12-12', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8568)         368560      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8774144     merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 9,145,265
Trainable params: 9,133,269
Non-trainable params: 11,996
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 92s - loss: 0.8411 - acc: 0.7596 - val_loss: 1.3057 - val_acc: 0.5126
Epoch 2/5
 - 69s - loss: 0.6271 - acc: 0.8675 - val_loss: 1.6047 - val_acc: 0.4999
Epoch 3/5
 - 70s - loss: 0.5083 - acc: 0.9224 - val_loss: 1.0676 - val_acc: 0.5518
Epoch 4/5
 - 70s - loss: 0.4247 - acc: 0.9587 - val_loss: 1.1033 - val_acc: 0.5468
Epoch 5/5
 - 70s - loss: 0.3709 - acc: 0.9775 - val_loss: 1.4934 - val_acc: 0.5120

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.502
current auc_score ------------------> 0.754
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8568)         368560      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8774144     merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 9,145,265
Trainable params: 9,133,269
Non-trainable params: 11,996
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 93s - loss: 0.8400 - acc: 0.7613 - val_loss: 1.6958 - val_acc: 0.5090
Epoch 2/5
 - 70s - loss: 0.6115 - acc: 0.8756 - val_loss: 1.0834 - val_acc: 0.5538
Epoch 3/5
 - 71s - loss: 0.4978 - acc: 0.9300 - val_loss: 1.2665 - val_acc: 0.4972
Epoch 4/5
 - 71s - loss: 0.4298 - acc: 0.9582 - val_loss: 1.2676 - val_acc: 0.5335

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 71s - loss: 0.3822 - acc: 0.9769 - val_loss: 1.7454 - val_acc: 0.5115
Test accuracy:0.499
current auc_score ------------------> 0.437
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8568)         368560      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8774144     merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 9,145,265
Trainable params: 9,133,269
Non-trainable params: 11,996
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 93s - loss: 0.8536 - acc: 0.7495 - val_loss: 1.0915 - val_acc: 0.5823
Epoch 2/5
 - 71s - loss: 0.6316 - acc: 0.8632 - val_loss: 1.1058 - val_acc: 0.4805
Epoch 3/5
 - 71s - loss: 0.5161 - acc: 0.9199 - val_loss: 1.0331 - val_acc: 0.5717
Epoch 4/5
 - 71s - loss: 0.4387 - acc: 0.9526 - val_loss: 0.4506 - val_acc: 0.9578
Epoch 5/5
 - 71s - loss: 0.3826 - acc: 0.9735 - val_loss: 0.3676 - val_acc: 0.9784
Test accuracy:0.656
current auc_score ------------------> 0.890
accuracies:  [0.5016129032258064, 0.4985215053763441, 0.655510752688172]
['6-12-12', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12780)        800470      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25560)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13087232    merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 13,890,263
Trainable params: 13,873,065
Non-trainable params: 17,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 96s - loss: 0.9969 - acc: 0.7566 - val_loss: 1.7600 - val_acc: 0.4984
Epoch 2/5
 - 73s - loss: 0.7614 - acc: 0.8747 - val_loss: 1.6970 - val_acc: 0.5046
Epoch 3/5
 - 74s - loss: 0.6321 - acc: 0.9347 - val_loss: 0.6954 - val_acc: 0.9076
Epoch 4/5
 - 73s - loss: 0.5472 - acc: 0.9662 - val_loss: 0.5307 - val_acc: 0.9703
Epoch 5/5
 - 74s - loss: 0.4948 - acc: 0.9794 - val_loss: 0.4989 - val_acc: 0.9741
Test accuracy:0.610
current auc_score ------------------> 0.824
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12780)        800470      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25560)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13087232    merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 13,890,263
Trainable params: 13,873,065
Non-trainable params: 17,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 95s - loss: 0.9793 - acc: 0.7623 - val_loss: 1.3406 - val_acc: 0.5220
Epoch 2/5
 - 73s - loss: 0.7447 - acc: 0.8829 - val_loss: 1.4922 - val_acc: 0.5274
Epoch 3/5
 - 73s - loss: 0.6273 - acc: 0.9364 - val_loss: 1.0885 - val_acc: 0.6209
Epoch 4/5
 - 74s - loss: 0.5404 - acc: 0.9676 - val_loss: 1.3799 - val_acc: 0.5449
Epoch 5/5
 - 73s - loss: 0.4899 - acc: 0.9810 - val_loss: 1.0978 - val_acc: 0.6163

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.631
current auc_score ------------------> 0.684
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 12, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12780)        800470      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25560)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13087232    merge_features[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_65[0][0]              
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_31[0][0]                 
==================================================================================================
Total params: 13,890,263
Trainable params: 13,873,065
Non-trainable params: 17,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 96s - loss: 1.0191 - acc: 0.7482 - val_loss: 1.3136 - val_acc: 0.5045
Epoch 2/5
 - 73s - loss: 0.7775 - acc: 0.8671 - val_loss: 0.9230 - val_acc: 0.7919
Epoch 3/5
 - 74s - loss: 0.6454 - acc: 0.9309 - val_loss: 0.5949 - val_acc: 0.9561
Epoch 4/5
 - 74s - loss: 0.5607 - acc: 0.9630 - val_loss: 0.5772 - val_acc: 0.9501
Epoch 5/5
 - 74s - loss: 0.5039 - acc: 0.9775 - val_loss: 0.4817 - val_acc: 0.9808
Test accuracy:0.567
current auc_score ------------------> 0.851
accuracies:  [0.6100806451612903, 0.6313172043010753, 0.5673387096774194]
['4-8-12', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3816)         72720       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7632)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3908096     merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 3,983,377
Trainable params: 3,978,277
Non-trainable params: 5,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 74s - loss: 0.7271 - acc: 0.7217 - val_loss: 1.4946 - val_acc: 0.5221
Epoch 2/5
 - 57s - loss: 0.4932 - acc: 0.8351 - val_loss: 1.1548 - val_acc: 0.5444
Epoch 3/5
 - 57s - loss: 0.3796 - acc: 0.8955 - val_loss: 0.4310 - val_acc: 0.8770
Epoch 4/5
 - 57s - loss: 0.2975 - acc: 0.9360 - val_loss: 0.4017 - val_acc: 0.9005
Epoch 5/5
 - 57s - loss: 0.2423 - acc: 0.9591 - val_loss: 0.3736 - val_acc: 0.9050
Test accuracy:0.588
current auc_score ------------------> 0.827
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3816)         72720       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7632)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3908096     merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 3,983,377
Trainable params: 3,978,277
Non-trainable params: 5,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 74s - loss: 0.6872 - acc: 0.7449 - val_loss: 3.1761 - val_acc: 0.5147
Epoch 2/5
 - 57s - loss: 0.4735 - acc: 0.8444 - val_loss: 3.1646 - val_acc: 0.4965
Epoch 3/5
 - 57s - loss: 0.3679 - acc: 0.9018 - val_loss: 1.8434 - val_acc: 0.4990
Epoch 4/5
 - 57s - loss: 0.2925 - acc: 0.9368 - val_loss: 0.2545 - val_acc: 0.9591
Epoch 5/5
 - 57s - loss: 0.2422 - acc: 0.9613 - val_loss: 0.1903 - val_acc: 0.9788
Test accuracy:0.647
current auc_score ------------------> 0.887
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3816)         72720       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7632)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3908096     merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 3,983,377
Trainable params: 3,978,277
Non-trainable params: 5,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 75s - loss: 0.6799 - acc: 0.7506 - val_loss: 1.4349 - val_acc: 0.5216
Epoch 2/5
 - 58s - loss: 0.4533 - acc: 0.8585 - val_loss: 1.2951 - val_acc: 0.5222
Epoch 3/5
 - 57s - loss: 0.3542 - acc: 0.9093 - val_loss: 0.7577 - val_acc: 0.6514
Epoch 4/5
 - 57s - loss: 0.2797 - acc: 0.9447 - val_loss: 0.8869 - val_acc: 0.6119
Epoch 5/5
 - 57s - loss: 0.2290 - acc: 0.9651 - val_loss: 1.6646 - val_acc: 0.5287

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.509
current auc_score ------------------> 0.710
accuracies:  [0.5877688172043011, 0.646505376344086, 0.5094086021505376]
['4-8-12', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         260688      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 7,931,473
Trainable params: 7,922,737
Non-trainable params: 8,736
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 76s - loss: 0.8441 - acc: 0.7252 - val_loss: 0.9052 - val_acc: 0.6977
Epoch 2/5
 - 58s - loss: 0.5995 - acc: 0.8452 - val_loss: 0.6092 - val_acc: 0.8426
Epoch 3/5
 - 58s - loss: 0.4733 - acc: 0.9107 - val_loss: 0.4267 - val_acc: 0.9398
Epoch 4/5
 - 59s - loss: 0.3897 - acc: 0.9494 - val_loss: 0.3574 - val_acc: 0.9637
Epoch 5/5
 - 58s - loss: 0.3387 - acc: 0.9677 - val_loss: 0.2914 - val_acc: 0.9812
Test accuracy:0.719
current auc_score ------------------> 0.848
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         260688      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 7,931,473
Trainable params: 7,922,737
Non-trainable params: 8,736
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 76s - loss: 0.8292 - acc: 0.7323 - val_loss: 1.3631 - val_acc: 0.5203
Epoch 2/5
 - 58s - loss: 0.6124 - acc: 0.8372 - val_loss: 1.1124 - val_acc: 0.5394
Epoch 3/5
 - 58s - loss: 0.4954 - acc: 0.9016 - val_loss: 0.9057 - val_acc: 0.6274
Epoch 4/5
 - 58s - loss: 0.4077 - acc: 0.9414 - val_loss: 1.3790 - val_acc: 0.5163
Epoch 5/5
 - 58s - loss: 0.3491 - acc: 0.9630 - val_loss: 1.7452 - val_acc: 0.5067

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.501
current auc_score ------------------> 0.537
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 7488)         260688      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 14976)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7668224     merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 7,931,473
Trainable params: 7,922,737
Non-trainable params: 8,736
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 80s - loss: 0.7998 - acc: 0.7491 - val_loss: 1.4953 - val_acc: 0.5046
Epoch 2/5
 - 60s - loss: 0.5643 - acc: 0.8643 - val_loss: 1.6803 - val_acc: 0.5084
Epoch 3/5
 - 58s - loss: 0.4553 - acc: 0.9196 - val_loss: 1.1488 - val_acc: 0.5451
Epoch 4/5
 - 58s - loss: 0.3771 - acc: 0.9527 - val_loss: 1.6235 - val_acc: 0.5151
Epoch 5/5
 - 58s - loss: 0.3268 - acc: 0.9704 - val_loss: 1.4410 - val_acc: 0.5528

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.514
current auc_score ------------------> 0.645
accuracies:  [0.7188172043010753, 0.5014784946236559, 0.514247311827957]
['4-8-12', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11160)        565728      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 22320)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11428352    merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 11,996,641
Trainable params: 11,984,269
Non-trainable params: 12,372
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 78s - loss: 0.8928 - acc: 0.7641 - val_loss: 0.8308 - val_acc: 0.7953
Epoch 2/5
 - 60s - loss: 0.6669 - acc: 0.8731 - val_loss: 0.6533 - val_acc: 0.8913
Epoch 3/5
 - 60s - loss: 0.5523 - acc: 0.9285 - val_loss: 0.5005 - val_acc: 0.9485
Epoch 4/5
 - 60s - loss: 0.4750 - acc: 0.9591 - val_loss: 0.4394 - val_acc: 0.9749
Epoch 5/5
 - 60s - loss: 0.4218 - acc: 0.9755 - val_loss: 0.3720 - val_acc: 0.9900
Test accuracy:0.662
current auc_score ------------------> 0.859
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11160)        565728      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 22320)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11428352    merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 11,996,641
Trainable params: 11,984,269
Non-trainable params: 12,372
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 79s - loss: 0.9325 - acc: 0.7343 - val_loss: 0.8767 - val_acc: 0.7551
Epoch 2/5
 - 59s - loss: 0.6880 - acc: 0.8641 - val_loss: 0.7149 - val_acc: 0.8650
Epoch 3/5
 - 59s - loss: 0.5682 - acc: 0.9222 - val_loss: 0.7299 - val_acc: 0.8496
Epoch 4/5
 - 59s - loss: 0.4862 - acc: 0.9555 - val_loss: 0.7230 - val_acc: 0.8292

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 59s - loss: 0.4327 - acc: 0.9741 - val_loss: 0.6571 - val_acc: 0.8635
Test accuracy:0.829
current auc_score ------------------> 0.885
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 8, 12]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11160)        565728      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 22320)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11428352    merge_features[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_53[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 11,996,641
Trainable params: 11,984,269
Non-trainable params: 12,372
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 77s - loss: 0.9152 - acc: 0.7484 - val_loss: 3.0873 - val_acc: 0.4965
Epoch 2/5
 - 59s - loss: 0.6898 - acc: 0.8600 - val_loss: 0.6547 - val_acc: 0.8884
Epoch 3/5
 - 59s - loss: 0.5594 - acc: 0.9247 - val_loss: 0.5770 - val_acc: 0.9162
Epoch 4/5
 - 59s - loss: 0.4814 - acc: 0.9577 - val_loss: 0.4296 - val_acc: 0.9779
Epoch 5/5
 - 59s - loss: 0.4192 - acc: 0.9767 - val_loss: 0.4250 - val_acc: 0.9749
Test accuracy:0.586
current auc_score ------------------> 0.867
accuracies:  [0.6623655913978495, 0.8290322580645161, 0.5861559139784946]
['2-2-4', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1332)         17558       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2664)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1364480     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 1,384,599
Trainable params: 1,382,657
Non-trainable params: 1,942
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6897 - acc: 0.6990 - val_loss: 0.5520 - val_acc: 0.7634
Epoch 2/5
 - 35s - loss: 0.4268 - acc: 0.8281 - val_loss: 0.3796 - val_acc: 0.8591
Epoch 3/5
 - 34s - loss: 0.3062 - acc: 0.8924 - val_loss: 0.2335 - val_acc: 0.9255
Epoch 4/5
 - 34s - loss: 0.2264 - acc: 0.9329 - val_loss: 0.1974 - val_acc: 0.9454
Epoch 5/5
 - 34s - loss: 0.1703 - acc: 0.9576 - val_loss: 0.1161 - val_acc: 0.9788
Test accuracy:0.762
current auc_score ------------------> 0.921
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1332)         17558       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2664)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1364480     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 1,384,599
Trainable params: 1,382,657
Non-trainable params: 1,942
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6592 - acc: 0.7143 - val_loss: 0.4292 - val_acc: 0.8160
Epoch 2/5
 - 32s - loss: 0.4191 - acc: 0.8324 - val_loss: 0.3352 - val_acc: 0.8745
Epoch 3/5
 - 32s - loss: 0.3115 - acc: 0.8889 - val_loss: 0.2328 - val_acc: 0.9227
Epoch 4/5
 - 32s - loss: 0.2369 - acc: 0.9251 - val_loss: 0.1715 - val_acc: 0.9544
Epoch 5/5
 - 32s - loss: 0.1862 - acc: 0.9473 - val_loss: 0.1242 - val_acc: 0.9734
Test accuracy:0.729
current auc_score ------------------> 0.882
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1332)         17558       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2664)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1364480     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 1,384,599
Trainable params: 1,382,657
Non-trainable params: 1,942
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6557 - acc: 0.7172 - val_loss: 0.4371 - val_acc: 0.8205
Epoch 2/5
 - 33s - loss: 0.4044 - acc: 0.8404 - val_loss: 0.2767 - val_acc: 0.9115
Epoch 3/5
 - 32s - loss: 0.2889 - acc: 0.9003 - val_loss: 0.2332 - val_acc: 0.9270
Epoch 4/5
 - 32s - loss: 0.2192 - acc: 0.9345 - val_loss: 0.1863 - val_acc: 0.9482
Epoch 5/5
 - 32s - loss: 0.1687 - acc: 0.9551 - val_loss: 0.1226 - val_acc: 0.9736
Test accuracy:0.669
current auc_score ------------------> 0.876
accuracies:  [0.7619623655913978, 0.7286290322580645, 0.6686827956989247]
['2-2-4', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2520)         59552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 5040)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2580992     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 2,643,105
Trainable params: 2,640,461
Non-trainable params: 2,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6747 - acc: 0.7300 - val_loss: 0.4948 - val_acc: 0.8188
Epoch 2/5
 - 32s - loss: 0.3994 - acc: 0.8650 - val_loss: 0.3525 - val_acc: 0.8962
Epoch 3/5
 - 32s - loss: 0.2945 - acc: 0.9178 - val_loss: 0.2716 - val_acc: 0.9369
Epoch 4/5
 - 33s - loss: 0.2234 - acc: 0.9516 - val_loss: 0.2290 - val_acc: 0.9526
Epoch 5/5
 - 32s - loss: 0.1795 - acc: 0.9690 - val_loss: 0.2026 - val_acc: 0.9665
Test accuracy:0.643
current auc_score ------------------> 0.856
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2520)         59552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 5040)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2580992     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 2,643,105
Trainable params: 2,640,461
Non-trainable params: 2,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6991 - acc: 0.7236 - val_loss: 0.5059 - val_acc: 0.8018
Epoch 2/5
 - 35s - loss: 0.4513 - acc: 0.8382 - val_loss: 0.3638 - val_acc: 0.8843
Epoch 3/5
 - 35s - loss: 0.3335 - acc: 0.9001 - val_loss: 0.2663 - val_acc: 0.9359
Epoch 4/5
 - 35s - loss: 0.2505 - acc: 0.9395 - val_loss: 0.1804 - val_acc: 0.9714
Epoch 5/5
 - 35s - loss: 0.1969 - acc: 0.9617 - val_loss: 0.1468 - val_acc: 0.9861
Test accuracy:0.660
current auc_score ------------------> 0.895
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2520)         59552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 5040)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2580992     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 2,643,105
Trainable params: 2,640,461
Non-trainable params: 2,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.7036 - acc: 0.7178 - val_loss: 1.4218 - val_acc: 0.4639
Epoch 2/5
 - 32s - loss: 0.4351 - acc: 0.8430 - val_loss: 0.9420 - val_acc: 0.5791
Epoch 3/5
 - 31s - loss: 0.3111 - acc: 0.9090 - val_loss: 0.2380 - val_acc: 0.9463
Epoch 4/5
 - 31s - loss: 0.2327 - acc: 0.9470 - val_loss: 0.1886 - val_acc: 0.9656
Epoch 5/5
 - 31s - loss: 0.1871 - acc: 0.9656 - val_loss: 0.1460 - val_acc: 0.9810
Test accuracy:0.705
current auc_score ------------------> 0.901
accuracies:  [0.6431451612903226, 0.6603494623655914, 0.7045698924731183]
['2-2-4', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3708)         127358      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7416)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3797504     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 3,927,423
Trainable params: 3,924,077
Non-trainable params: 3,346
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6621 - acc: 0.7632 - val_loss: 0.6128 - val_acc: 0.7717
Epoch 2/5
 - 34s - loss: 0.4116 - acc: 0.8780 - val_loss: 0.3329 - val_acc: 0.9219
Epoch 3/5
 - 33s - loss: 0.3024 - acc: 0.9341 - val_loss: 0.2493 - val_acc: 0.9655
Epoch 4/5
 - 34s - loss: 0.2340 - acc: 0.9647 - val_loss: 0.1966 - val_acc: 0.9809
Epoch 5/5
 - 34s - loss: 0.1939 - acc: 0.9789 - val_loss: 0.1575 - val_acc: 0.9922
Test accuracy:0.636
current auc_score ------------------> 0.869
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3708)         127358      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7416)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3797504     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 3,927,423
Trainable params: 3,924,077
Non-trainable params: 3,346
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.6575 - acc: 0.7579 - val_loss: 2.8058 - val_acc: 0.4965
Epoch 2/5
 - 31s - loss: 0.4057 - acc: 0.8821 - val_loss: 0.3475 - val_acc: 0.9170
Epoch 3/5
 - 31s - loss: 0.2879 - acc: 0.9431 - val_loss: 0.2224 - val_acc: 0.9699
Epoch 4/5
 - 31s - loss: 0.2259 - acc: 0.9677 - val_loss: 0.1850 - val_acc: 0.9816
Epoch 5/5
 - 31s - loss: 0.1918 - acc: 0.9798 - val_loss: 0.1575 - val_acc: 0.9903
Test accuracy:0.680
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3708)         127358      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7416)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3797504     merge_features[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_21[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 3,927,423
Trainable params: 3,924,077
Non-trainable params: 3,346
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6461 - acc: 0.7664 - val_loss: 0.9355 - val_acc: 0.5345
Epoch 2/5
 - 32s - loss: 0.3900 - acc: 0.8927 - val_loss: 0.3215 - val_acc: 0.9339
Epoch 3/5
 - 32s - loss: 0.2948 - acc: 0.9373 - val_loss: 0.2299 - val_acc: 0.9690
Epoch 4/5
 - 32s - loss: 0.2285 - acc: 0.9651 - val_loss: 0.2027 - val_acc: 0.9746
Epoch 5/5
 - 32s - loss: 0.1919 - acc: 0.9778 - val_loss: 0.1666 - val_acc: 0.9898
Test accuracy:0.704
current auc_score ------------------> 0.884
accuracies:  [0.6364247311827957, 0.6799731182795699, 0.7043010752688172]
['2-2-2-2-2', '6', '5', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24)           21186       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48)           0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25088       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 48,835
Trainable params: 46,717
Non-trainable params: 2,118
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.9281 - acc: 0.5410 - val_loss: 3.9581 - val_acc: 0.5044
Epoch 2/5
 - 35s - loss: 0.8282 - acc: 0.5773 - val_loss: 5.9570 - val_acc: 0.5035
Epoch 3/5
 - 35s - loss: 0.7728 - acc: 0.6136 - val_loss: 5.2050 - val_acc: 0.5035

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 35s - loss: 0.7355 - acc: 0.6333 - val_loss: 4.8587 - val_acc: 0.5035
Epoch 5/5
 - 35s - loss: 0.7256 - acc: 0.6409 - val_loss: 0.7567 - val_acc: 0.5813
Test accuracy:0.601
current auc_score ------------------> 0.668
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24)           21186       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48)           0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25088       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 48,835
Trainable params: 46,717
Non-trainable params: 2,118
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.9398 - acc: 0.5193 - val_loss: 6.5379 - val_acc: 0.5035
Epoch 2/5
 - 35s - loss: 0.8588 - acc: 0.5404 - val_loss: 0.7533 - val_acc: 0.5242
Epoch 3/5
 - 38s - loss: 0.8055 - acc: 0.5586 - val_loss: 0.7382 - val_acc: 0.5558
Epoch 4/5
 - 37s - loss: 0.7700 - acc: 0.5797 - val_loss: 0.7122 - val_acc: 0.6141
Epoch 5/5
 - 36s - loss: 0.7094 - acc: 0.6338 - val_loss: 0.7083 - val_acc: 0.6355
Test accuracy:0.634
current auc_score ------------------> 0.748
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24)           21186       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48)           0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25088       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 48,835
Trainable params: 46,717
Non-trainable params: 2,118
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.9166 - acc: 0.5510 - val_loss: 2.9470 - val_acc: 0.5035
Epoch 2/5
 - 36s - loss: 0.8210 - acc: 0.5877 - val_loss: 2.2691 - val_acc: 0.5034
Epoch 3/5
 - 36s - loss: 0.7674 - acc: 0.6165 - val_loss: 3.3103 - val_acc: 0.5035
Epoch 4/5
 - 35s - loss: 0.6935 - acc: 0.6603 - val_loss: 1.7970 - val_acc: 0.5035
Epoch 5/5
 - 35s - loss: 0.6532 - acc: 0.6856 - val_loss: 1.8641 - val_acc: 0.5035
Epoch 00005: early stopping
Test accuracy:0.500
current auc_score ------------------> 0.616
accuracies:  [0.6008064516129032, 0.6344086021505376, 0.5]
['2-2-2-2-2', '12', '5', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 47)           73347       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 94)           0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          48640       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 124,548
Trainable params: 121,548
Non-trainable params: 3,000
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.9268 - acc: 0.5881 - val_loss: 3.1393 - val_acc: 0.5033
Epoch 2/5
 - 36s - loss: 0.8003 - acc: 0.6394 - val_loss: 1.9442 - val_acc: 0.5041
Epoch 3/5
 - 36s - loss: 0.7205 - acc: 0.6833 - val_loss: 0.7197 - val_acc: 0.6994
Epoch 4/5
 - 36s - loss: 0.6690 - acc: 0.7137 - val_loss: 0.6889 - val_acc: 0.7170
Epoch 5/5
 - 36s - loss: 0.6260 - acc: 0.7374 - val_loss: 0.7211 - val_acc: 0.7110
Test accuracy:0.694
current auc_score ------------------> 0.775
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 47)           73347       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 94)           0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          48640       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 124,548
Trainable params: 121,548
Non-trainable params: 3,000
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.9425 - acc: 0.5786 - val_loss: 0.8462 - val_acc: 0.5843
Epoch 2/5
 - 36s - loss: 0.8104 - acc: 0.6375 - val_loss: 0.8447 - val_acc: 0.6232
Epoch 3/5
 - 36s - loss: 0.7543 - acc: 0.6623 - val_loss: 0.8376 - val_acc: 0.6192
Epoch 4/5
 - 35s - loss: 0.7068 - acc: 0.6816 - val_loss: 0.8927 - val_acc: 0.6311
Epoch 5/5
 - 35s - loss: 0.6828 - acc: 0.6912 - val_loss: 0.8958 - val_acc: 0.6416

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.684
current auc_score ------------------> 0.777
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 47)           73347       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 94)           0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          48640       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 124,548
Trainable params: 121,548
Non-trainable params: 3,000
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.9591 - acc: 0.5668 - val_loss: 0.9119 - val_acc: 0.4996
Epoch 2/5
 - 36s - loss: 0.8486 - acc: 0.6119 - val_loss: 0.8003 - val_acc: 0.5983
Epoch 3/5
 - 35s - loss: 0.7642 - acc: 0.6574 - val_loss: 0.9116 - val_acc: 0.6028
Epoch 4/5
 - 36s - loss: 0.7124 - acc: 0.6835 - val_loss: 0.8564 - val_acc: 0.6309

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 35s - loss: 0.6856 - acc: 0.6963 - val_loss: 0.7989 - val_acc: 0.6468
Test accuracy:0.686
current auc_score ------------------> 0.712
accuracies:  [0.6935483870967742, 0.6842741935483871, 0.6864247311827957]
['2-2-2-2-2', '18', '5', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 70)           157599      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 140)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          72192       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 232,352
Trainable params: 228,476
Non-trainable params: 3,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.9565 - acc: 0.6131 - val_loss: 2.4507 - val_acc: 0.5005
Epoch 2/5
 - 35s - loss: 0.8484 - acc: 0.6523 - val_loss: 1.7561 - val_acc: 0.5051
Epoch 3/5
 - 35s - loss: 0.7728 - acc: 0.6822 - val_loss: 1.3380 - val_acc: 0.5152
Epoch 4/5
 - 35s - loss: 0.7065 - acc: 0.7185 - val_loss: 1.0009 - val_acc: 0.5497
Epoch 5/5
 - 35s - loss: 0.6629 - acc: 0.7479 - val_loss: 1.0925 - val_acc: 0.5085
Test accuracy:0.502
current auc_score ------------------> 0.693
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 70)           157599      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 140)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          72192       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 232,352
Trainable params: 228,476
Non-trainable params: 3,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 1.0273 - acc: 0.5556 - val_loss: 0.8988 - val_acc: 0.5222
Epoch 2/5
 - 39s - loss: 0.8838 - acc: 0.6329 - val_loss: 1.0619 - val_acc: 0.5802
Epoch 3/5
 - 40s - loss: 0.8040 - acc: 0.6660 - val_loss: 1.4417 - val_acc: 0.5629

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 39s - loss: 0.7652 - acc: 0.6853 - val_loss: 1.3076 - val_acc: 0.5853
Epoch 5/5
 - 40s - loss: 0.7510 - acc: 0.6919 - val_loss: 1.5096 - val_acc: 0.5748

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Test accuracy:0.672
current auc_score ------------------> 0.792
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  5  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 70)           157599      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 140)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          72192       merge_features[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_27[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 232,352
Trainable params: 228,476
Non-trainable params: 3,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 1.0066 - acc: 0.5767 - val_loss: 2.6068 - val_acc: 0.5020
Epoch 2/5
 - 36s - loss: 0.8880 - acc: 0.6235 - val_loss: 1.1237 - val_acc: 0.4625
Epoch 3/5
 - 35s - loss: 0.8191 - acc: 0.6540 - val_loss: 1.0509 - val_acc: 0.4577
Epoch 4/5
 - 36s - loss: 0.7686 - acc: 0.6731 - val_loss: 1.4003 - val_acc: 0.5036
Epoch 5/5
 - 35s - loss: 0.7298 - acc: 0.6990 - val_loss: 1.3227 - val_acc: 0.5035

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.500
current auc_score ------------------> 0.536
accuracies:  [0.5024193548387097, 0.6724462365591398, 0.5]
['2-2-3-3', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 297)          21811       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 594)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          304640      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 329,012
Trainable params: 326,856
Non-trainable params: 2,156
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.7844 - acc: 0.6474 - val_loss: 0.6841 - val_acc: 0.6640
Epoch 2/5
 - 38s - loss: 0.6350 - acc: 0.7205 - val_loss: 0.5930 - val_acc: 0.7302
Epoch 3/5
 - 37s - loss: 0.5478 - acc: 0.7641 - val_loss: 0.5293 - val_acc: 0.7692
Epoch 4/5
 - 38s - loss: 0.4723 - acc: 0.8044 - val_loss: 0.4291 - val_acc: 0.8361
Epoch 5/5
 - 38s - loss: 0.4132 - acc: 0.8380 - val_loss: 0.3438 - val_acc: 0.8755
Test accuracy:0.671
current auc_score ------------------> 0.802
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 297)          21811       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 594)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          304640      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 329,012
Trainable params: 326,856
Non-trainable params: 2,156
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.8701 - acc: 0.5959 - val_loss: 6.3623 - val_acc: 0.5035
Epoch 2/5
 - 35s - loss: 0.7010 - acc: 0.6795 - val_loss: 0.8362 - val_acc: 0.5518
Epoch 3/5
 - 35s - loss: 0.5852 - acc: 0.7449 - val_loss: 0.9877 - val_acc: 0.5295
Epoch 4/5
 - 35s - loss: 0.5057 - acc: 0.7881 - val_loss: 0.4690 - val_acc: 0.8134
Epoch 5/5
 - 36s - loss: 0.4344 - acc: 0.8309 - val_loss: 0.3904 - val_acc: 0.8529
Test accuracy:0.728
current auc_score ------------------> 0.847
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 297)          21811       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 594)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          304640      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 329,012
Trainable params: 326,856
Non-trainable params: 2,156
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.8322 - acc: 0.6389 - val_loss: 0.6945 - val_acc: 0.6445
Epoch 2/5
 - 38s - loss: 0.6692 - acc: 0.7001 - val_loss: 0.6502 - val_acc: 0.6983
Epoch 3/5
 - 38s - loss: 0.5682 - acc: 0.7561 - val_loss: 0.5235 - val_acc: 0.7839
Epoch 4/5
 - 38s - loss: 0.4918 - acc: 0.7990 - val_loss: 0.4552 - val_acc: 0.8264
Epoch 5/5
 - 38s - loss: 0.4322 - acc: 0.8324 - val_loss: 0.3757 - val_acc: 0.8652
Test accuracy:0.724
current auc_score ------------------> 0.812
accuracies:  [0.6711021505376344, 0.7276881720430107, 0.7240591397849462]
['2-2-3-3', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 585)          75578       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1170)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          599552      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 677,691
Trainable params: 674,619
Non-trainable params: 3,072
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.8366 - acc: 0.6596 - val_loss: 0.9198 - val_acc: 0.6022
Epoch 2/5
 - 34s - loss: 0.6465 - acc: 0.7431 - val_loss: 1.5136 - val_acc: 0.5341
Epoch 3/5
 - 35s - loss: 0.5130 - acc: 0.8134 - val_loss: 1.1419 - val_acc: 0.5867

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 35s - loss: 0.4373 - acc: 0.8554 - val_loss: 0.4091 - val_acc: 0.8799
Epoch 5/5
 - 35s - loss: 0.4140 - acc: 0.8686 - val_loss: 0.4202 - val_acc: 0.8742
Test accuracy:0.681
current auc_score ------------------> 0.849
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 585)          75578       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1170)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          599552      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 677,691
Trainable params: 674,619
Non-trainable params: 3,072
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.8686 - acc: 0.6444 - val_loss: 0.8540 - val_acc: 0.5886
Epoch 2/5
 - 38s - loss: 0.6738 - acc: 0.7273 - val_loss: 0.6159 - val_acc: 0.7572
Epoch 3/5
 - 38s - loss: 0.5541 - acc: 0.7903 - val_loss: 0.6008 - val_acc: 0.7884
Epoch 4/5
 - 38s - loss: 0.4649 - acc: 0.8383 - val_loss: 0.4522 - val_acc: 0.8612
Epoch 5/5
 - 38s - loss: 0.3833 - acc: 0.8837 - val_loss: 0.3299 - val_acc: 0.9163
Test accuracy:0.643
current auc_score ------------------> 0.797
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 585)          75578       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1170)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          599552      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 677,691
Trainable params: 674,619
Non-trainable params: 3,072
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.8937 - acc: 0.6322 - val_loss: 0.7867 - val_acc: 0.6171
Epoch 2/5
 - 35s - loss: 0.7053 - acc: 0.7076 - val_loss: 0.6071 - val_acc: 0.7540
Epoch 3/5
 - 35s - loss: 0.5716 - acc: 0.7802 - val_loss: 0.4900 - val_acc: 0.8252
Epoch 4/5
 - 35s - loss: 0.4697 - acc: 0.8383 - val_loss: 0.4216 - val_acc: 0.8696
Epoch 5/5
 - 35s - loss: 0.4006 - acc: 0.8779 - val_loss: 0.4101 - val_acc: 0.8813
Test accuracy:0.699
current auc_score ------------------> 0.857
accuracies:  [0.6811827956989247, 0.6427419354838709, 0.6990591397849463]
['2-2-3-3', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 864)          162364      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1728)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          885248      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 1,050,173
Trainable params: 1,046,193
Non-trainable params: 3,980
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8809 - acc: 0.6717 - val_loss: 1.4123 - val_acc: 0.5828
Epoch 2/5
 - 38s - loss: 0.6756 - acc: 0.7586 - val_loss: 0.8349 - val_acc: 0.7342
Epoch 3/5
 - 39s - loss: 0.5521 - acc: 0.8189 - val_loss: 0.9328 - val_acc: 0.7538
Epoch 4/5
 - 39s - loss: 0.4501 - acc: 0.8751 - val_loss: 0.8875 - val_acc: 0.7815

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 38s - loss: 0.3877 - acc: 0.9060 - val_loss: 0.5913 - val_acc: 0.8429
Test accuracy:0.652
current auc_score ------------------> 0.794
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 864)          162364      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1728)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          885248      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 1,050,173
Trainable params: 1,046,193
Non-trainable params: 3,980
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.8852 - acc: 0.6688 - val_loss: 0.7321 - val_acc: 0.7182
Epoch 2/5
 - 35s - loss: 0.6526 - acc: 0.7726 - val_loss: 0.6668 - val_acc: 0.7659
Epoch 3/5
 - 35s - loss: 0.5403 - acc: 0.8308 - val_loss: 0.6297 - val_acc: 0.7979
Epoch 4/5
 - 34s - loss: 0.4516 - acc: 0.8772 - val_loss: 0.4453 - val_acc: 0.8852
Epoch 5/5
 - 34s - loss: 0.3809 - acc: 0.9123 - val_loss: 0.4014 - val_acc: 0.9026
Test accuracy:0.602
current auc_score ------------------> 0.807
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 864)          162364      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1728)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          885248      merge_features[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_26[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_11[0][0]                 
==================================================================================================
Total params: 1,050,173
Trainable params: 1,046,193
Non-trainable params: 3,980
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.8718 - acc: 0.6719 - val_loss: 0.7855 - val_acc: 0.6704
Epoch 2/5
 - 35s - loss: 0.6436 - acc: 0.7732 - val_loss: 0.5980 - val_acc: 0.8038
Epoch 3/5
 - 35s - loss: 0.5134 - acc: 0.8438 - val_loss: 0.5308 - val_acc: 0.8427
Epoch 4/5
 - 34s - loss: 0.4206 - acc: 0.8904 - val_loss: 0.3789 - val_acc: 0.9133
Epoch 5/5
 - 34s - loss: 0.3476 - acc: 0.9265 - val_loss: 0.2976 - val_acc: 0.9472
Test accuracy:0.651
current auc_score ------------------> 0.849
accuracies:  [0.6518817204301075, 0.6021505376344086, 0.6510752688172043]
['3-3-6-6', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 558)          45235       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1116)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          571904      merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 619,700
Trainable params: 616,266
Non-trainable params: 3,434
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.8621 - acc: 0.6360 - val_loss: 0.9096 - val_acc: 0.5605
Epoch 2/5
 - 46s - loss: 0.7211 - acc: 0.6899 - val_loss: 0.9307 - val_acc: 0.6083
Epoch 3/5
 - 46s - loss: 0.6330 - acc: 0.7301 - val_loss: 0.8297 - val_acc: 0.6619
Epoch 4/5
 - 46s - loss: 0.5562 - acc: 0.7795 - val_loss: 0.6855 - val_acc: 0.7368
Epoch 5/5
 - 46s - loss: 0.4862 - acc: 0.8235 - val_loss: 0.6674 - val_acc: 0.7454
Test accuracy:0.667
current auc_score ------------------> 0.774
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 558)          45235       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1116)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          571904      merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 619,700
Trainable params: 616,266
Non-trainable params: 3,434
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.8705 - acc: 0.6339 - val_loss: 0.7169 - val_acc: 0.6442
Epoch 2/5
 - 46s - loss: 0.6925 - acc: 0.7098 - val_loss: 0.6389 - val_acc: 0.7186
Epoch 3/5
 - 46s - loss: 0.5866 - acc: 0.7676 - val_loss: 0.5795 - val_acc: 0.7656
Epoch 4/5
 - 46s - loss: 0.5014 - acc: 0.8168 - val_loss: 0.5309 - val_acc: 0.8146
Epoch 5/5
 - 45s - loss: 0.4372 - acc: 0.8518 - val_loss: 0.4108 - val_acc: 0.8627
Test accuracy:0.655
current auc_score ------------------> 0.794
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 558)          45235       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1116)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          571904      merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 619,700
Trainable params: 616,266
Non-trainable params: 3,434
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.8694 - acc: 0.6404 - val_loss: 1.2733 - val_acc: 0.5382
Epoch 2/5
 - 44s - loss: 0.7124 - acc: 0.6978 - val_loss: 1.5757 - val_acc: 0.5004
Epoch 3/5
 - 45s - loss: 0.6118 - acc: 0.7499 - val_loss: 1.4323 - val_acc: 0.5148

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 45s - loss: 0.5589 - acc: 0.7812 - val_loss: 0.8173 - val_acc: 0.5885
Epoch 5/5
 - 45s - loss: 0.5360 - acc: 0.7914 - val_loss: 0.8276 - val_acc: 0.5592
Test accuracy:0.549
current auc_score ------------------> 0.586
accuracies:  [0.6670698924731183, 0.6549731182795699, 0.548521505376344]
['3-3-6-6', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1107)         162103      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2214)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1134080     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 1,298,744
Trainable params: 1,293,180
Non-trainable params: 5,564
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.9145 - acc: 0.6640 - val_loss: 4.4568 - val_acc: 0.4965
Epoch 2/5
 - 46s - loss: 0.7245 - acc: 0.7454 - val_loss: 3.2203 - val_acc: 0.4965
Epoch 3/5
 - 47s - loss: 0.6039 - acc: 0.8097 - val_loss: 1.3015 - val_acc: 0.5692
Epoch 4/5
 - 47s - loss: 0.5156 - acc: 0.8608 - val_loss: 0.9495 - val_acc: 0.5840
Epoch 5/5
 - 46s - loss: 0.4391 - acc: 0.8965 - val_loss: 1.1656 - val_acc: 0.5543
Test accuracy:0.494
current auc_score ------------------> 0.671
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1107)         162103      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2214)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1134080     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 1,298,744
Trainable params: 1,293,180
Non-trainable params: 5,564
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.9287 - acc: 0.6577 - val_loss: 1.1348 - val_acc: 0.5848
Epoch 2/5
 - 46s - loss: 0.7484 - acc: 0.7296 - val_loss: 0.8899 - val_acc: 0.7023
Epoch 3/5
 - 47s - loss: 0.6452 - acc: 0.7866 - val_loss: 0.7761 - val_acc: 0.7676
Epoch 4/5
 - 46s - loss: 0.5487 - acc: 0.8413 - val_loss: 0.6365 - val_acc: 0.8345
Epoch 5/5
 - 47s - loss: 0.4639 - acc: 0.8872 - val_loss: 0.4619 - val_acc: 0.8978
Test accuracy:0.632
current auc_score ------------------> 0.834
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1107)         162103      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2214)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1134080     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 1,298,744
Trainable params: 1,293,180
Non-trainable params: 5,564
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 61s - loss: 0.9083 - acc: 0.6630 - val_loss: 1.8833 - val_acc: 0.5035
Epoch 2/5
 - 47s - loss: 0.6927 - acc: 0.7642 - val_loss: 1.2141 - val_acc: 0.5110
Epoch 3/5
 - 47s - loss: 0.5860 - acc: 0.8221 - val_loss: 0.9678 - val_acc: 0.5286
Epoch 4/5
 - 46s - loss: 0.5032 - acc: 0.8658 - val_loss: 1.1533 - val_acc: 0.5119
Epoch 5/5
 - 46s - loss: 0.4388 - acc: 0.8981 - val_loss: 1.5650 - val_acc: 0.5044

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.500
current auc_score ------------------> 0.517
accuracies:  [0.4936827956989247, 0.632258064516129, 0.5004032258064516]
['3-3-6-6', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         351478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,050,295
Trainable params: 2,042,615
Non-trainable params: 7,680
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 62s - loss: 0.9655 - acc: 0.6911 - val_loss: 4.3911 - val_acc: 0.4965
Epoch 2/5
 - 48s - loss: 0.7465 - acc: 0.7865 - val_loss: 1.2976 - val_acc: 0.5251
Epoch 3/5
 - 49s - loss: 0.6170 - acc: 0.8587 - val_loss: 0.6421 - val_acc: 0.8422
Epoch 4/5
 - 49s - loss: 0.5259 - acc: 0.9025 - val_loss: 0.5019 - val_acc: 0.9175
Epoch 5/5
 - 49s - loss: 0.4537 - acc: 0.9342 - val_loss: 0.4394 - val_acc: 0.9440
Test accuracy:0.729
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         351478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,050,295
Trainable params: 2,042,615
Non-trainable params: 7,680
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.9770 - acc: 0.6807 - val_loss: 1.9771 - val_acc: 0.5151
Epoch 2/5
 - 48s - loss: 0.7855 - acc: 0.7617 - val_loss: 1.0395 - val_acc: 0.6189
Epoch 3/5
 - 48s - loss: 0.6763 - acc: 0.8214 - val_loss: 1.3343 - val_acc: 0.5370
Epoch 4/5
 - 48s - loss: 0.5759 - acc: 0.8769 - val_loss: 1.0114 - val_acc: 0.5848
Epoch 5/5
 - 49s - loss: 0.4928 - acc: 0.9184 - val_loss: 1.5896 - val_acc: 0.5041
Test accuracy:0.500
current auc_score ------------------> 0.695
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         351478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,050,295
Trainable params: 2,042,615
Non-trainable params: 7,680
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 62s - loss: 0.9985 - acc: 0.6690 - val_loss: 5.0550 - val_acc: 0.4965
Epoch 2/5
 - 48s - loss: 0.7836 - acc: 0.7673 - val_loss: 2.0477 - val_acc: 0.5041
Epoch 3/5
 - 48s - loss: 0.6572 - acc: 0.8355 - val_loss: 1.6627 - val_acc: 0.5200
Epoch 4/5
 - 49s - loss: 0.5590 - acc: 0.8865 - val_loss: 1.1816 - val_acc: 0.5586
Epoch 5/5
 - 49s - loss: 0.4845 - acc: 0.9217 - val_loss: 1.3707 - val_acc: 0.5458
Test accuracy:0.508
current auc_score ------------------> 0.683
accuracies:  [0.7290322580645161, 0.5001344086021505, 0.5081989247311828]
['3-3-6-6', '24', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2205)         614414      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4410)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2258432     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,875,407
Trainable params: 2,865,597
Non-trainable params: 9,810
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 65s - loss: 1.0426 - acc: 0.6931 - val_loss: 0.9988 - val_acc: 0.7076
Epoch 2/5
 - 51s - loss: 0.8284 - acc: 0.7911 - val_loss: 0.8014 - val_acc: 0.8094
Epoch 3/5
 - 50s - loss: 0.6877 - acc: 0.8658 - val_loss: 0.6757 - val_acc: 0.8837
Epoch 4/5
 - 51s - loss: 0.5849 - acc: 0.9169 - val_loss: 0.5519 - val_acc: 0.9316
Epoch 5/5
 - 51s - loss: 0.5018 - acc: 0.9534 - val_loss: 0.4826 - val_acc: 0.9601
Test accuracy:0.657
current auc_score ------------------> 0.854
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2205)         614414      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4410)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2258432     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,875,407
Trainable params: 2,865,597
Non-trainable params: 9,810
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 64s - loss: 1.0538 - acc: 0.6862 - val_loss: 1.1457 - val_acc: 0.6048
Epoch 2/5
 - 51s - loss: 0.8311 - acc: 0.7912 - val_loss: 0.9997 - val_acc: 0.7357
Epoch 3/5
 - 50s - loss: 0.6935 - acc: 0.8672 - val_loss: 0.8554 - val_acc: 0.7864
Epoch 4/5
 - 50s - loss: 0.5951 - acc: 0.9139 - val_loss: 0.6114 - val_acc: 0.9034
Epoch 5/5
 - 50s - loss: 0.5155 - acc: 0.9479 - val_loss: 0.4727 - val_acc: 0.9601
Test accuracy:0.706
current auc_score ------------------> 0.889
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2205)         614414      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4410)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2258432     merge_features[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_42[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,875,407
Trainable params: 2,865,597
Non-trainable params: 9,810
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 1.0763 - acc: 0.6788 - val_loss: 1.2331 - val_acc: 0.5980
Epoch 2/5
 - 50s - loss: 0.8840 - acc: 0.7653 - val_loss: 0.9406 - val_acc: 0.7666
Epoch 3/5
 - 50s - loss: 0.7474 - acc: 0.8369 - val_loss: 0.8808 - val_acc: 0.7929
Epoch 4/5
 - 50s - loss: 0.6363 - acc: 0.8943 - val_loss: 0.6417 - val_acc: 0.8886
Epoch 5/5
 - 50s - loss: 0.5442 - acc: 0.9366 - val_loss: 0.5273 - val_acc: 0.9384
Test accuracy:0.699
current auc_score ------------------> 0.831
accuracies:  [0.656989247311828, 0.7064516129032258, 0.6993279569892473]
['8-8', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        45904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 11,845,457
Trainable params: 11,841,905
Non-trainable params: 3,552
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 55s - loss: 0.5213 - acc: 0.8073 - val_loss: 0.4180 - val_acc: 0.8503
Epoch 2/5
 - 44s - loss: 0.2903 - acc: 0.9207 - val_loss: 0.2174 - val_acc: 0.9612
Epoch 3/5
 - 44s - loss: 0.2059 - acc: 0.9609 - val_loss: 0.2393 - val_acc: 0.9429
Epoch 4/5
 - 44s - loss: 0.1630 - acc: 0.9758 - val_loss: 0.1624 - val_acc: 0.9774
Epoch 5/5
 - 44s - loss: 0.1351 - acc: 0.9855 - val_loss: 0.1166 - val_acc: 0.9916
Test accuracy:0.597
current auc_score ------------------> 0.856
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        45904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 11,845,457
Trainable params: 11,841,905
Non-trainable params: 3,552
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 57s - loss: 0.5284 - acc: 0.8032 - val_loss: 0.3425 - val_acc: 0.8906
Epoch 2/5
 - 46s - loss: 0.2884 - acc: 0.9224 - val_loss: 0.2105 - val_acc: 0.9637
Epoch 3/5
 - 45s - loss: 0.2116 - acc: 0.9569 - val_loss: 0.1681 - val_acc: 0.9792
Epoch 4/5
 - 45s - loss: 0.1648 - acc: 0.9756 - val_loss: 0.1417 - val_acc: 0.9862
Epoch 5/5
 - 46s - loss: 0.1397 - acc: 0.9842 - val_loss: 0.1132 - val_acc: 0.9911
Test accuracy:0.712
current auc_score ------------------> 0.929
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        45904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 11,845,457
Trainable params: 11,841,905
Non-trainable params: 3,552
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 55s - loss: 0.5664 - acc: 0.7816 - val_loss: 0.7487 - val_acc: 0.6387
Epoch 2/5
 - 43s - loss: 0.3252 - acc: 0.9066 - val_loss: 0.2705 - val_acc: 0.9416
Epoch 3/5
 - 43s - loss: 0.2407 - acc: 0.9459 - val_loss: 0.1922 - val_acc: 0.9649
Epoch 4/5
 - 43s - loss: 0.1858 - acc: 0.9688 - val_loss: 0.1456 - val_acc: 0.9823
Epoch 5/5
 - 43s - loss: 0.1576 - acc: 0.9780 - val_loss: 0.1287 - val_acc: 0.9867
Test accuracy:0.616
current auc_score ------------------> 0.893
accuracies:  [0.5967741935483871, 0.712231182795699, 0.6161290322580645]
['8-8', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 21888)        159088      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 43776)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          22413824    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 22,575,473
Trainable params: 22,569,857
Non-trainable params: 5,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.5958 - acc: 0.8108 - val_loss: 0.4300 - val_acc: 0.8888
Epoch 2/5
 - 48s - loss: 0.3672 - acc: 0.9239 - val_loss: 0.3155 - val_acc: 0.9522
Epoch 3/5
 - 47s - loss: 0.2807 - acc: 0.9612 - val_loss: 0.2525 - val_acc: 0.9767
Epoch 4/5
 - 47s - loss: 0.2394 - acc: 0.9750 - val_loss: 0.2237 - val_acc: 0.9831
Epoch 5/5
 - 47s - loss: 0.2093 - acc: 0.9839 - val_loss: 0.1799 - val_acc: 0.9940
Test accuracy:0.659
current auc_score ------------------> 0.886
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 21888)        159088      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 43776)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          22413824    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 22,575,473
Trainable params: 22,569,857
Non-trainable params: 5,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6408 - acc: 0.7834 - val_loss: 0.4540 - val_acc: 0.8931
Epoch 2/5
 - 47s - loss: 0.4003 - acc: 0.9078 - val_loss: 0.3219 - val_acc: 0.9568
Epoch 3/5
 - 47s - loss: 0.2996 - acc: 0.9561 - val_loss: 0.2384 - val_acc: 0.9818
Epoch 4/5
 - 47s - loss: 0.2485 - acc: 0.9725 - val_loss: 0.2205 - val_acc: 0.9876
Epoch 5/5
 - 47s - loss: 0.2189 - acc: 0.9827 - val_loss: 0.1930 - val_acc: 0.9920
Test accuracy:0.714
current auc_score ------------------> 0.875
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 21888)        159088      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 43776)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          22413824    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 22,575,473
Trainable params: 22,569,857
Non-trainable params: 5,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6223 - acc: 0.7975 - val_loss: 0.8863 - val_acc: 0.5806
Epoch 2/5
 - 47s - loss: 0.3808 - acc: 0.9197 - val_loss: 0.8736 - val_acc: 0.5901
Epoch 3/5
 - 47s - loss: 0.2854 - acc: 0.9605 - val_loss: 2.1229 - val_acc: 0.5054
Epoch 4/5
 - 47s - loss: 0.2348 - acc: 0.9793 - val_loss: 0.1925 - val_acc: 0.9928
Epoch 5/5
 - 47s - loss: 0.2043 - acc: 0.9864 - val_loss: 0.1732 - val_acc: 0.9947
Test accuracy:0.659
current auc_score ------------------> 0.869
accuracies:  [0.6588709677419354, 0.7139784946236559, 0.6587365591397849]
['8-8', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 32256)        341392      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 64512)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          33030656    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 33,374,609
Trainable params: 33,366,929
Non-trainable params: 7,680
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 64s - loss: 0.6783 - acc: 0.8032 - val_loss: 0.6182 - val_acc: 0.8249
Epoch 2/5
 - 52s - loss: 0.4452 - acc: 0.9249 - val_loss: 0.3881 - val_acc: 0.9611
Epoch 3/5
 - 52s - loss: 0.3538 - acc: 0.9639 - val_loss: 0.3708 - val_acc: 0.9497
Epoch 4/5
 - 52s - loss: 0.3038 - acc: 0.9781 - val_loss: 0.2847 - val_acc: 0.9838
Epoch 5/5
 - 52s - loss: 0.2672 - acc: 0.9859 - val_loss: 0.2465 - val_acc: 0.9907
Test accuracy:0.674
current auc_score ------------------> 0.864
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 32256)        341392      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 64512)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          33030656    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 33,374,609
Trainable params: 33,366,929
Non-trainable params: 7,680
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.7431 - acc: 0.7701 - val_loss: 2.9702 - val_acc: 0.4965
Epoch 2/5
 - 50s - loss: 0.4958 - acc: 0.8987 - val_loss: 1.0666 - val_acc: 0.6005
Epoch 3/5
 - 50s - loss: 0.3921 - acc: 0.9462 - val_loss: 0.9692 - val_acc: 0.5958
Epoch 4/5
 - 51s - loss: 0.3273 - acc: 0.9702 - val_loss: 1.0484 - val_acc: 0.5511
Epoch 5/5
 - 51s - loss: 0.2791 - acc: 0.9836 - val_loss: 1.0820 - val_acc: 0.5654

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.498
current auc_score ------------------> 0.631
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [8, 8]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 32256)        341392      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 64512)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          33030656    merge_features[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_36[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 33,374,609
Trainable params: 33,366,929
Non-trainable params: 7,680
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 62s - loss: 0.7205 - acc: 0.7838 - val_loss: 0.6834 - val_acc: 0.7492
Epoch 2/5
 - 50s - loss: 0.4612 - acc: 0.9175 - val_loss: 0.4930 - val_acc: 0.8896
Epoch 3/5
 - 50s - loss: 0.3587 - acc: 0.9607 - val_loss: 0.5014 - val_acc: 0.8759
Epoch 4/5
 - 50s - loss: 0.3061 - acc: 0.9777 - val_loss: 0.4496 - val_acc: 0.8914
Epoch 5/5
 - 50s - loss: 0.2690 - acc: 0.9858 - val_loss: 0.3292 - val_acc: 0.9664
Test accuracy:0.533
current auc_score ------------------> 0.872
accuracies:  [0.6736559139784947, 0.49798387096774194, 0.5333333333333333]
['0.777+/-0.01', '0.765+/-0.11', '0.833+/-0.01', '0.884+/-0.027', '0.838+/-0.043', '0.881+/-0.04', '0.898+/-0.005', '0.859+/-0.034', '0.889+/-0.001', '0.879+/-0.018', '0.894+/-0.016', '0.882+/-0.033', '0.896+/-0.009', '0.874+/-0.007', '0.891+/-0.01', '0.855+/-0.076', '0.742+/-0.117', '0.671+/-0.014', '0.744+/-0.144', '0.827+/-0.015', '0.79+/-0.11', '0.694+/-0.19', '0.786+/-0.073', '0.808+/-0.074', '0.677+/-0.129', '0.87+/-0.011', '0.893+/-0.02', '0.884+/-0.02', '0.885+/-0.014', '0.677+/-0.054', '0.755+/-0.03', '0.674+/-0.105', '0.82+/-0.019', '0.835+/-0.027', '0.817+/-0.024', '0.718+/-0.094', '0.674+/-0.129', '0.752+/-0.09', '0.858+/-0.024', '0.893+/-0.03', '0.877+/-0.007', '0.789+/-0.112']
