python hello-world.py
python hyperas_simple.py
python hyperas_contrastive_loss.py
python densenet_siamese_best_run.py
python hyperas_densenet.py
python hyperas_densenet_siamese.py
python densenet_simple.py
python keras_densenet_siamese.py
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_1[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 96, 96)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 96, 96)   0           concatenate_2[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 66, 48, 48)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 78, 48, 48)   0           concatenate_4[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_7[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 90, 48, 48)   0           concatenate_5[0][0]              
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 90)           0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            91          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 28s - loss: 0.5214 - acc: 0.7549 - val_loss: 0.4938 - val_acc: 0.8165
Epoch 2/15
 - 25s - loss: 0.4661 - acc: 0.7764 - val_loss: 0.4429 - val_acc: 0.8147
Epoch 3/15
 - 25s - loss: 0.4446 - acc: 0.7888 - val_loss: 0.4947 - val_acc: 0.7965
Epoch 4/15
 - 25s - loss: 0.4235 - acc: 0.8025 - val_loss: 0.4746 - val_acc: 0.7839
Epoch 00004: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 245us/step
Test accuracy: 0.7838709677419354
Test accuracy 0.6: 0.8104838709677419
auc_score ------------------>  0.886172967973176
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_2[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_10[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 42, 96, 96)   0           concatenate_7[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 54, 96, 96)   0           concatenate_8[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_12[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_2[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 78, 48, 48)   0           concatenate_10[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_15[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 90, 48, 48)   0           concatenate_11[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 90)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            91          global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5314 - acc: 0.7512 - val_loss: 0.4517 - val_acc: 0.8321
Epoch 2/15
 - 26s - loss: 0.4685 - acc: 0.7778 - val_loss: 0.4688 - val_acc: 0.8008
Epoch 3/15
 - 26s - loss: 0.4425 - acc: 0.7929 - val_loss: 0.4666 - val_acc: 0.8266
Epoch 4/15
 - 26s - loss: 0.4249 - acc: 0.8024 - val_loss: 0.3764 - val_acc: 0.8527
Epoch 5/15
 - 26s - loss: 0.4058 - acc: 0.8126 - val_loss: 0.4502 - val_acc: 0.8113
Epoch 6/15
 - 26s - loss: 0.3958 - acc: 0.8199 - val_loss: 0.3575 - val_acc: 0.8622
Epoch 7/15
 - 26s - loss: 0.3842 - acc: 0.8235 - val_loss: 0.3819 - val_acc: 0.8375
Epoch 8/15
 - 26s - loss: 0.3748 - acc: 0.8293 - val_loss: 0.4234 - val_acc: 0.8212
Epoch 9/15
 - 26s - loss: 0.3672 - acc: 0.8362 - val_loss: 0.4338 - val_acc: 0.8355
Epoch 00009: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 248us/step
Test accuracy: 0.8354838709677419
Test accuracy 0.6: 0.8458333333333333
auc_score ------------------>  0.9044550670597757
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_3[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_17[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_13[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_18[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 42, 96, 96)   0           concatenate_13[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_14[0][0]             
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_19[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 54, 96, 96)   0           concatenate_14[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_15[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_20[0][0]              
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_21[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_3[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_16[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_22[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 78, 48, 48)   0           concatenate_16[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_17[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_23[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 90, 48, 48)   0           concatenate_17[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_18[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 90)           0           activation_24[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            91          global_average_pooling2d_3[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5367 - acc: 0.7475 - val_loss: 0.4733 - val_acc: 0.8142
Epoch 2/15
 - 26s - loss: 0.4685 - acc: 0.7774 - val_loss: 0.4125 - val_acc: 0.8245
Epoch 3/15
 - 26s - loss: 0.4352 - acc: 0.7944 - val_loss: 0.4131 - val_acc: 0.8306
Epoch 4/15
 - 26s - loss: 0.4128 - acc: 0.8056 - val_loss: 0.6979 - val_acc: 0.7882
Epoch 5/15
 - 26s - loss: 0.3970 - acc: 0.8163 - val_loss: 0.4608 - val_acc: 0.7997
Epoch 6/15
 - 26s - loss: 0.3855 - acc: 0.8233 - val_loss: 0.4789 - val_acc: 0.7942
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 244us/step
Test accuracy: 0.7942204301075269
Test accuracy 0.6: 0.8059139784946237
auc_score ------------------>  0.8987770262458088
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_4[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_19[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_26[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 42, 96, 96)   0           concatenate_19[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_20[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_27[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 54, 96, 96)   0           concatenate_20[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_21[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_28[0][0]              
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_29[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_4[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_30[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 78, 48, 48)   0           concatenate_22[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_23[0][0]             
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_31[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 90, 48, 48)   0           concatenate_23[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_24[0][0]             
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 90)           0           activation_32[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            91          global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5265 - acc: 0.7543 - val_loss: 0.5181 - val_acc: 0.7828
Epoch 2/15
 - 25s - loss: 0.4638 - acc: 0.7829 - val_loss: 0.5990 - val_acc: 0.7577
Epoch 3/15
 - 25s - loss: 0.4361 - acc: 0.7969 - val_loss: 0.4587 - val_acc: 0.8138
Epoch 4/15
 - 25s - loss: 0.4172 - acc: 0.8065 - val_loss: 0.7109 - val_acc: 0.7652
Epoch 5/15
 - 25s - loss: 0.4040 - acc: 0.8157 - val_loss: 0.5425 - val_acc: 0.7828
Epoch 6/15
 - 25s - loss: 0.3902 - acc: 0.8225 - val_loss: 0.4257 - val_acc: 0.8273
Epoch 7/15
 - 25s - loss: 0.3806 - acc: 0.8290 - val_loss: 0.5141 - val_acc: 0.7634
Epoch 8/15
 - 25s - loss: 0.3670 - acc: 0.8372 - val_loss: 0.4854 - val_acc: 0.7825
Epoch 9/15
 - 25s - loss: 0.3594 - acc: 0.8414 - val_loss: 0.5981 - val_acc: 0.7466
Epoch 00009: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 246us/step
Test accuracy: 0.7466397849462365
Test accuracy 0.6: 0.7095430107526882
auc_score ------------------>  0.8699021563186496
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_5[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_33[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_25[0][0]             
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_34[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 42, 96, 96)   0           concatenate_25[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_35[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 54, 96, 96)   0           concatenate_26[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_27[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_36[0][0]              
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_37[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_5[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_28[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_38[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 78, 48, 48)   0           concatenate_28[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_29[0][0]             
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_39[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 90, 48, 48)   0           concatenate_29[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_30[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 90)           0           activation_40[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            91          global_average_pooling2d_5[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5369 - acc: 0.7472 - val_loss: 0.4961 - val_acc: 0.7871
Epoch 2/15
 - 25s - loss: 0.4655 - acc: 0.7817 - val_loss: 0.4715 - val_acc: 0.7952
Epoch 3/15
 - 25s - loss: 0.4387 - acc: 0.7940 - val_loss: 0.4638 - val_acc: 0.7630
Epoch 4/15
 - 25s - loss: 0.4216 - acc: 0.8031 - val_loss: 0.3940 - val_acc: 0.8399
Epoch 5/15
 - 25s - loss: 0.4108 - acc: 0.8100 - val_loss: 0.4236 - val_acc: 0.8183
Epoch 6/15
 - 25s - loss: 0.3951 - acc: 0.8183 - val_loss: 0.4371 - val_acc: 0.7957
Epoch 7/15
 - 25s - loss: 0.3835 - acc: 0.8257 - val_loss: 0.6972 - val_acc: 0.7520
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 2s
 256/7440 [>.............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 1s
 672/7440 [=>............................] - ETA: 1s
 896/7440 [==>...........................] - ETA: 1s
1120/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1792/7440 [======>.......................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2240/7440 [========>.....................] - ETA: 1s
2464/7440 [========>.....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3136/7440 [===========>..................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3584/7440 [=============>................] - ETA: 0s
3808/7440 [==============>...............] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4480/7440 [=================>............] - ETA: 0s
4704/7440 [=================>............] - ETA: 0s
4896/7440 [==================>...........] - ETA: 0s
5120/7440 [===================>..........] - ETA: 0s
5344/7440 [====================>.........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6240/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 256us/step
Test accuracy: 0.7520161290322581
Test accuracy 0.6: 0.725268817204301
auc_score ------------------>  0.8203501849924846
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_6[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_41[0][0]              
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_31[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_42[0][0]              
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 42, 96, 96)   0           concatenate_31[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_32[0][0]             
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_43[0][0]              
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 54, 96, 96)   0           concatenate_32[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_33[0][0]             
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_44[0][0]              
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_45[0][0]              
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_6[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_34[0][0]             
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_46[0][0]              
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 78, 48, 48)   0           concatenate_34[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_35[0][0]             
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_47[0][0]              
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 90, 48, 48)   0           concatenate_35[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_36[0][0]             
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 90)           0           activation_48[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            91          global_average_pooling2d_6[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5499 - acc: 0.7373 - val_loss: 0.5144 - val_acc: 0.8305
Epoch 2/15
 - 25s - loss: 0.4755 - acc: 0.7747 - val_loss: 0.4723 - val_acc: 0.8172
Epoch 3/15
 - 25s - loss: 0.4455 - acc: 0.7910 - val_loss: 0.4852 - val_acc: 0.7734
Epoch 4/15
 - 25s - loss: 0.4282 - acc: 0.8015 - val_loss: 0.4250 - val_acc: 0.8472
Epoch 5/15
 - 25s - loss: 0.4096 - acc: 0.8103 - val_loss: 0.5197 - val_acc: 0.7815
Epoch 6/15
 - 25s - loss: 0.3946 - acc: 0.8197 - val_loss: 0.3992 - val_acc: 0.8286
Epoch 7/15
 - 25s - loss: 0.3828 - acc: 0.8271 - val_loss: 0.4319 - val_acc: 0.7966
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 244us/step
Test accuracy: 0.7966397849462366
Test accuracy 0.6: 0.8036290322580645
auc_score ------------------>  0.8855834128222916
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_7[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_49[0][0]              
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_37[0][0]             
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_50[0][0]              
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 42, 96, 96)   0           concatenate_37[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_38[0][0]             
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_51[0][0]              
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 54, 96, 96)   0           concatenate_38[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_39[0][0]             
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_52[0][0]              
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_53[0][0]              
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_7[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_40[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_54[0][0]              
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 78, 48, 48)   0           concatenate_40[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_41[0][0]             
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_55[0][0]              
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 90, 48, 48)   0           concatenate_41[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_42[0][0]             
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 90)           0           activation_56[0][0]              
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 1)            91          global_average_pooling2d_7[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5325 - acc: 0.7514 - val_loss: 0.5223 - val_acc: 0.8151
Epoch 2/15
 - 25s - loss: 0.4643 - acc: 0.7815 - val_loss: 0.4588 - val_acc: 0.7931
Epoch 3/15
 - 25s - loss: 0.4382 - acc: 0.7962 - val_loss: 0.3986 - val_acc: 0.8228
Epoch 4/15
 - 25s - loss: 0.4167 - acc: 0.8086 - val_loss: 0.3982 - val_acc: 0.8223
Epoch 5/15
 - 25s - loss: 0.4039 - acc: 0.8131 - val_loss: 0.4611 - val_acc: 0.7949
Epoch 6/15
 - 25s - loss: 0.3874 - acc: 0.8240 - val_loss: 0.4280 - val_acc: 0.8262
Epoch 7/15
 - 25s - loss: 0.3771 - acc: 0.8305 - val_loss: 0.3530 - val_acc: 0.8633
Epoch 8/15
 - 25s - loss: 0.3711 - acc: 0.8347 - val_loss: 0.4336 - val_acc: 0.8216
Epoch 9/15
 - 25s - loss: 0.3601 - acc: 0.8396 - val_loss: 0.4626 - val_acc: 0.8050
Epoch 10/15
 - 25s - loss: 0.3553 - acc: 0.8426 - val_loss: 0.3616 - val_acc: 0.8410
Epoch 00010: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 1s
 672/7440 [=>............................] - ETA: 1s
 864/7440 [==>...........................] - ETA: 1s
1088/7440 [===>..........................] - ETA: 1s
1312/7440 [====>.........................] - ETA: 1s
1536/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2368/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2816/7440 [==========>...................] - ETA: 1s
3008/7440 [===========>..................] - ETA: 1s
3200/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3584/7440 [=============>................] - ETA: 1s
3776/7440 [==============>...............] - ETA: 0s
3968/7440 [===============>..............] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4384/7440 [================>.............] - ETA: 0s
4576/7440 [=================>............] - ETA: 0s
4768/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5344/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5728/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6112/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 262us/step
Test accuracy: 0.8409946236559139
Test accuracy 0.6: 0.8440860215053764
auc_score ------------------>  0.9245373020002312
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_8 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_8[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_57[0][0]              
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_43[0][0]             
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_58[0][0]              
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 42, 96, 96)   0           concatenate_43[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_44[0][0]             
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_59[0][0]              
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 54, 96, 96)   0           concatenate_44[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_45[0][0]             
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_60[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_61[0][0]              
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_8[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_46[0][0]             
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_62[0][0]              
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 78, 48, 48)   0           concatenate_46[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_47[0][0]             
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_63[0][0]              
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 90, 48, 48)   0           concatenate_47[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_48[0][0]             
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 90)           0           activation_64[0][0]              
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            91          global_average_pooling2d_8[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 28s - loss: 0.5360 - acc: 0.7464 - val_loss: 0.6491 - val_acc: 0.7968
Epoch 2/15
 - 26s - loss: 0.4699 - acc: 0.7795 - val_loss: 0.4562 - val_acc: 0.8090
Epoch 3/15
 - 26s - loss: 0.4425 - acc: 0.7934 - val_loss: 0.4741 - val_acc: 0.7730
Epoch 4/15
 - 26s - loss: 0.4244 - acc: 0.8023 - val_loss: 0.6284 - val_acc: 0.7685
Epoch 5/15
 - 26s - loss: 0.4081 - acc: 0.8120 - val_loss: 0.4369 - val_acc: 0.8133
Epoch 6/15
 - 26s - loss: 0.3944 - acc: 0.8222 - val_loss: 0.4454 - val_acc: 0.8266
Epoch 7/15
 - 26s - loss: 0.3795 - acc: 0.8285 - val_loss: 0.6258 - val_acc: 0.7757
Epoch 8/15
 - 26s - loss: 0.3721 - acc: 0.8324 - val_loss: 0.4779 - val_acc: 0.8098
Epoch 9/15
 - 26s - loss: 0.3632 - acc: 0.8393 - val_loss: 0.4807 - val_acc: 0.7845
Epoch 00009: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 252us/step
Test accuracy: 0.7845430107526882
Test accuracy 0.6: 0.7977150537634409
auc_score ------------------>  0.8860342958723552
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_9[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_65[0][0]              
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_49[0][0]             
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_66[0][0]              
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 42, 96, 96)   0           concatenate_49[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_50[0][0]             
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_67[0][0]              
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 54, 96, 96)   0           concatenate_50[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_51[0][0]             
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_68[0][0]              
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_69[0][0]              
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_9[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_52[0][0]             
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_70[0][0]              
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 78, 48, 48)   0           concatenate_52[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_53[0][0]             
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_71[0][0]              
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 90, 48, 48)   0           concatenate_53[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_54[0][0]             
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 90)           0           activation_72[0][0]              
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1)            91          global_average_pooling2d_9[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 29s - loss: 0.5382 - acc: 0.7439 - val_loss: 0.4680 - val_acc: 0.8015
Epoch 2/15
 - 26s - loss: 0.4664 - acc: 0.7808 - val_loss: 0.4458 - val_acc: 0.8167
Epoch 3/15
 - 25s - loss: 0.4389 - acc: 0.7938 - val_loss: 0.5559 - val_acc: 0.7263
Epoch 4/15
 - 25s - loss: 0.4225 - acc: 0.8009 - val_loss: 0.4106 - val_acc: 0.8239
Epoch 5/15
 - 25s - loss: 0.4081 - acc: 0.8115 - val_loss: 0.4489 - val_acc: 0.7809
Epoch 6/15
 - 26s - loss: 0.3963 - acc: 0.8189 - val_loss: 0.3859 - val_acc: 0.8270
Epoch 7/15
 - 25s - loss: 0.3871 - acc: 0.8253 - val_loss: 0.4328 - val_acc: 0.7977
Epoch 8/15
 - 25s - loss: 0.3802 - acc: 0.8283 - val_loss: 0.4049 - val_acc: 0.8292
Epoch 9/15
 - 25s - loss: 0.3710 - acc: 0.8348 - val_loss: 0.3996 - val_acc: 0.8160
Epoch 10/15
 - 25s - loss: 0.3639 - acc: 0.8385 - val_loss: 0.4333 - val_acc: 0.8222
Epoch 11/15
 - 25s - loss: 0.3552 - acc: 0.8430 - val_loss: 0.4620 - val_acc: 0.7993

Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.
Epoch 00011: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 1s
 672/7440 [=>............................] - ETA: 1s
 896/7440 [==>...........................] - ETA: 1s
1120/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1792/7440 [======>.......................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2240/7440 [========>.....................] - ETA: 1s
2464/7440 [========>.....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3136/7440 [===========>..................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3552/7440 [=============>................] - ETA: 1s
3776/7440 [==============>...............] - ETA: 0s
3968/7440 [===============>..............] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4416/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4864/7440 [==================>...........] - ETA: 0s
5088/7440 [===================>..........] - ETA: 0s
5312/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 257us/step
Test accuracy: 0.7993279569892473
Test accuracy 0.6: 0.8224462365591397
auc_score ------------------>  0.9067281983466295
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_10[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_73[0][0]              
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_55[0][0]             
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_74[0][0]              
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 42, 96, 96)   0           concatenate_55[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_56[0][0]             
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_75[0][0]              
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 54, 96, 96)   0           concatenate_56[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_57[0][0]             
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_76[0][0]              
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_77[0][0]              
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_10[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_58[0][0]             
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_78[0][0]              
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 78, 48, 48)   0           concatenate_58[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_59[0][0]             
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_79[0][0]              
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 90, 48, 48)   0           concatenate_59[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_60[0][0]             
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_10 (Gl (None, 90)           0           activation_80[0][0]              
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1)            91          global_average_pooling2d_10[0][0]
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 28s - loss: 0.5344 - acc: 0.7513 - val_loss: 0.4837 - val_acc: 0.8046
Epoch 2/15
 - 26s - loss: 0.4650 - acc: 0.7841 - val_loss: 0.4770 - val_acc: 0.7903
Epoch 3/15
 - 26s - loss: 0.4389 - acc: 0.7952 - val_loss: 0.4734 - val_acc: 0.7875
Epoch 4/15
 - 26s - loss: 0.4200 - acc: 0.8046 - val_loss: 0.5184 - val_acc: 0.7601
Epoch 00004: early stopping

  32/7440 [..............................] - ETA: 1s
 224/7440 [..............................] - ETA: 1s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 267us/step
Test accuracy: 0.7600806451612904
Test accuracy 0.6: 0.7212365591397849
auc_score ------------------>  0.8854462943692913
[0.886, 0.904, 0.899, 0.87, 0.82, 0.886, 0.925, 0.886, 0.907, 0.885]
0.887  0.027
