python hello-world.py
python hyperas_simple.py
python hyperas_contrastive_loss.py
python densenet_siamese_best_run.py
python hyperas_densenet.py
python hyperas_densenet_siamese.py
python densenet_simple.py
python keras_densenet_siamese.py
python keras_densenet_simple.py
>>> Imports:
#coding=utf-8

try:
    import numpy as np
except:
    pass

try:
    import random
except:
    pass

try:
    import h5py
except:
    pass

try:
    import tensorflow as tf
except:
    pass

try:
    import matplotlib.pyplot as plt
except:
    pass

try:
    import keras.backend as K
except:
    pass

try:
    from keras.initializers import RandomNormal
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D
except:
    pass

try:
    from keras.layers import Input, concatenate, Concatenate
except:
    pass

try:
    from keras.layers import normalization, BatchNormalization, Lambda
except:
    pass

try:
    from keras.layers import Flatten, Conv2D, MaxPooling2D
except:
    pass

try:
    from keras.regularizers import l2
except:
    pass

try:
    from keras.optimizers import RMSprop, Adam
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.models import Model, Sequential
except:
    pass

try:
    from keras.models import model_from_json
except:
    pass

try:
    from keras.models import load_model
except:
    pass

try:
    import keras.initializers
except:
    pass

try:
    from keras.losses import binary_crossentropy
except:
    pass

try:
    from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
except:
    pass

try:
    from sklearn.metrics import accuracy_score
except:
    pass

try:
    from sklearn.metrics import roc_auc_score
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from keras_contrib.applications import DenseNet
except:
    pass

try:
    import pickle
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'depth': hp.choice('depth', [7,10,13,16,19,22,25,28,31,34,37,40]),
        'growth_rate': hp.choice('growth_rate', [6,8,10,12,14,16]),
        'batch_size': hp.choice('batch_size', [64,128]),
    }

>>> Functions
  1: def process_data():
  2:     f = h5py.File('matchedImagesSplitClasses-2017-02-24-17-39-44-96-96-split-val0.15-tr0.7-tst0.15.hdf5','r')
  3:     ln_training = 39840
  4:     X_train = f['X_train'].value
  5:     X_train_resize = X_train[0:ln_training,:,:,:]
  6:     #print(X_train_resize.shape)
  7:     y_train = f['y_train'].value
  8:     y_train_resize = y_train[0:ln_training,]
  9:     y_train_categorical = np_utils.to_categorical(y_train_resize, 2)
 10:     #X_reshaped = X_train_resize.reshape(*X_train_resize.shape[:1], -2)
 11:     #print(X_reshaped.shape)
 12:     ln_validation = 7440
 13:     X_val = f['X_val'].value
 14:     X_val_resize = X_val[0:ln_validation,:,:,:]
 15: 
 16:     #X_val_reshaped = X_val
 17:     #X_val_reshaped = X_val_resize.reshape(*X_val_resize.shape[:1], -2)
 18: 
 19:     y_val = f['y_val'].value
 20:     y_val_reshaped = y_val[0:ln_validation]
 21:     y_val_categorical = np_utils.to_categorical(y_val_reshaped, 2)
 22:     return X_train,y_train,X_val,y_val
 23: 
 24: 
>>> Data
 1: 
 2: X_train,y_train,X_val,y_val = process_data()
 3: 
 4: 
 5: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     epochs = 30
   4:     #input_shape = (1,96,96)
   5:     es_patience = 5
   6:     lr_patience = 5
   7:     dropout = None
   8:     depth = space['depth']
   9:     nb_dense_block = 3
  10:     nb_filter = 16
  11:     growth_rate = space['growth_rate']
  12:     weight_decay = 1E-4
  13:     lr = 3E-4
  14:     weight_file = 'keras_densenet_simple_wt_28Sept_519am.h5'
  15:     
  16:     nb_classes = 1
  17:     img_dim = (2,96,96) 
  18:     n_channels = 2 
  19: 
  20:     
  21:     model  = DenseNet(depth=depth, nb_dense_block=nb_dense_block,
  22:                  growth_rate=growth_rate, nb_filter=nb_filter,
  23:                  dropout_rate=dropout,activation='sigmoid',
  24:                  input_shape=img_dim,include_top=True,
  25:                  bottleneck=True,reduction=0.5,
  26:                  classes=nb_classes,pooling='avg',
  27:                  weights=None)
  28:     
  29: 
  30:     model.summary()
  31:     opt = Adam(lr=lr)
  32:     model.compile(loss=binary_crossentropy, optimizer=opt, metrics=['accuracy'])
  33: 
  34:     es = EarlyStopping(monitor='val_loss', patience=es_patience,verbose=1)
  35:     #es = EarlyStopping(monitor='val_acc', patience=es_patience,verbose=1,restore_best_weights=True)
  36:     checkpointer = ModelCheckpoint(filepath=weight_file,verbose=1, save_best_only=True)
  37: 
  38:     lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), cooldown=0, patience=lr_patience, min_lr=0.5e-6,verbose=1)
  39: 
  40:     model.fit(X_train,y_train,
  41:           batch_size=space['batch_size'],
  42:           epochs=epochs,
  43:           callbacks=[es,lr_reducer,checkpointer],
  44:           validation_data=(X_val,y_val),
  45:           verbose=2)
  46:     
  47:     score, acc = model.evaluate(X_val, y_val)
  48:     print('current Test accuracy:', acc)
  49:     pred = model.predict(X_val)
  50:     auc_score = roc_auc_score(y_val,pred)
  51:     print("current auc_score ------------------> ",auc_score)
  52: 
  53:     model = load_model(weight_file) #This is the best model
  54:     score, acc = model.evaluate(X_val, y_val)
  55:     print('Best saved model Test accuracy:', acc)
  56:     pred = model.predict(X_val)
  57:     auc_score = roc_auc_score(y_val,pred)
  58:     print("best saved model auc_score ------------------> ",auc_score)
  59: 
  60:     
  61:     return {'loss': -auc_score, 'status': STATUS_OK, 'model': model}  
  62: 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_1 (Activation)    (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_1 (Average (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_2 (Activation)    (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_2 (Average (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_3 (Activation)    (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_1 ( (None, 4)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 8s - loss: 0.6763 - acc: 0.6085 - val_loss: 0.6219 - val_acc: 0.7895

Epoch 00001: val_loss improved from inf to 0.62190, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 6s - loss: 0.6476 - acc: 0.6755 - val_loss: 0.5864 - val_acc: 0.7965

Epoch 00002: val_loss improved from 0.62190 to 0.58636, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 6s - loss: 0.6275 - acc: 0.6856 - val_loss: 0.5571 - val_acc: 0.7840

Epoch 00003: val_loss improved from 0.58636 to 0.55711, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 6s - loss: 0.6106 - acc: 0.6967 - val_loss: 0.5333 - val_acc: 0.7966

Epoch 00004: val_loss improved from 0.55711 to 0.53330, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 6s - loss: 0.5949 - acc: 0.7116 - val_loss: 0.5253 - val_acc: 0.8188

Epoch 00005: val_loss improved from 0.53330 to 0.52528, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 6s - loss: 0.5800 - acc: 0.7216 - val_loss: 0.5251 - val_acc: 0.7996

Epoch 00006: val_loss improved from 0.52528 to 0.52510, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 6s - loss: 0.5686 - acc: 0.7310 - val_loss: 0.5223 - val_acc: 0.8079

Epoch 00007: val_loss improved from 0.52510 to 0.52231, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 8/30
 - 6s - loss: 0.5575 - acc: 0.7366 - val_loss: 0.5264 - val_acc: 0.8339

Epoch 00008: val_loss did not improve from 0.52231
Epoch 9/30
 - 6s - loss: 0.5479 - acc: 0.7431 - val_loss: 0.5261 - val_acc: 0.7788

Epoch 00009: val_loss did not improve from 0.52231
Epoch 10/30
 - 6s - loss: 0.5401 - acc: 0.7474 - val_loss: 0.5038 - val_acc: 0.8538

Epoch 00010: val_loss improved from 0.52231 to 0.50380, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 11/30
 - 6s - loss: 0.5331 - acc: 0.7509 - val_loss: 0.5204 - val_acc: 0.8051

Epoch 00011: val_loss did not improve from 0.50380
Epoch 12/30
 - 6s - loss: 0.5265 - acc: 0.7535 - val_loss: 0.5467 - val_acc: 0.7871

Epoch 00012: val_loss did not improve from 0.50380
Epoch 13/30
 - 6s - loss: 0.5205 - acc: 0.7562 - val_loss: 0.7138 - val_acc: 0.7339

Epoch 00013: val_loss did not improve from 0.50380
Epoch 14/30
 - 6s - loss: 0.5164 - acc: 0.7576 - val_loss: 0.5337 - val_acc: 0.8058

Epoch 00014: val_loss did not improve from 0.50380
Epoch 15/30
 - 6s - loss: 0.5125 - acc: 0.7576 - val_loss: 0.5440 - val_acc: 0.8145

Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00015: val_loss did not improve from 0.50380
Epoch 00015: early stopping

  32/7440 [..............................] - ETA: 0s
 672/7440 [=>............................] - ETA: 0s
1344/7440 [====>.........................] - ETA: 0s
2016/7440 [=======>......................] - ETA: 0s
2688/7440 [=========>....................] - ETA: 0s
3360/7440 [============>.................] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4704/7440 [=================>............] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
6112/7440 [=======================>......] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
7440/7440 [==============================] - 1s 76us/step
current Test accuracy: 0.8145161290322581
current auc_score ------------------>  0.8574408891201295

  32/7440 [..............................] - ETA: 21s
 704/7440 [=>............................] - ETA: 1s 
1376/7440 [====>.........................] - ETA: 0s
2048/7440 [=======>......................] - ETA: 0s
2752/7440 [==========>...................] - ETA: 0s
3424/7440 [============>.................] - ETA: 0s
4096/7440 [===============>..............] - ETA: 0s
4768/7440 [==================>...........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
7440/7440 [==============================] - 1s 88us/step
Best saved model Test accuracy: 0.853763440860215
best saved model auc_score ------------------>  0.8752982281188576
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_2[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_6[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_7[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 96, 96)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_8[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 58, 96, 96)   0           concatenate_2[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 58, 96, 96)   232         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 58, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 29, 96, 96)   1682        activation_10[0][0]              
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 29, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 29, 48, 48)   116         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 29, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   1624        activation_11[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 43, 48, 48)   0           average_pooling2d_3[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   2408        activation_13[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 57, 48, 48)   0           concatenate_4[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 57, 48, 48)   228         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 57, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3192        activation_15[0][0]              
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_16[0][0]              
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 48, 48)   0           concatenate_5[0][0]              
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 71, 48, 48)   284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 71, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 48, 48)   2485        activation_17[0][0]              
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 35, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 24, 24)   140         average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 35, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 56, 24, 24)   1960        activation_18[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 56, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_19[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 49, 24, 24)   0           average_pooling2d_4[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 24, 24)   196         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 49, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 56, 24, 24)   2744        activation_20[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 56, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_21[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 63, 24, 24)   0           concatenate_7[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 63, 24, 24)   252         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 63, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 56, 24, 24)   3528        activation_22[0][0]              
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 56, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_23[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 77, 24, 24)   0           concatenate_8[0][0]              
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 77, 24, 24)   308         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 77, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 77)           0           activation_24[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            78          global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 92,837
Trainable params: 90,685
Non-trainable params: 2,152
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 46s - loss: 0.5933 - acc: 0.7696 - val_loss: 0.5426 - val_acc: 0.8089

Epoch 00001: val_loss improved from inf to 0.54262, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 41s - loss: 0.4954 - acc: 0.8191 - val_loss: 0.5183 - val_acc: 0.8198

Epoch 00002: val_loss improved from 0.54262 to 0.51831, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 41s - loss: 0.4426 - acc: 0.8465 - val_loss: 0.7277 - val_acc: 0.7562

Epoch 00003: val_loss did not improve from 0.51831
Epoch 4/30
 - 41s - loss: 0.4062 - acc: 0.8661 - val_loss: 1.0257 - val_acc: 0.7223

Epoch 00004: val_loss did not improve from 0.51831
Epoch 5/30
 - 41s - loss: 0.3748 - acc: 0.8796 - val_loss: 0.5017 - val_acc: 0.8332

Epoch 00005: val_loss improved from 0.51831 to 0.50167, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 41s - loss: 0.3514 - acc: 0.8909 - val_loss: 0.6221 - val_acc: 0.8411

Epoch 00006: val_loss did not improve from 0.50167
Epoch 7/30
 - 41s - loss: 0.3340 - acc: 0.8992 - val_loss: 0.5392 - val_acc: 0.8296

Epoch 00007: val_loss did not improve from 0.50167
Epoch 8/30
 - 41s - loss: 0.3124 - acc: 0.9096 - val_loss: 0.6019 - val_acc: 0.8427

Epoch 00008: val_loss did not improve from 0.50167
Epoch 9/30
 - 41s - loss: 0.2935 - acc: 0.9169 - val_loss: 0.6629 - val_acc: 0.8019

Epoch 00009: val_loss did not improve from 0.50167
Epoch 10/30
 - 41s - loss: 0.2814 - acc: 0.9231 - val_loss: 0.9244 - val_acc: 0.7163

Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00010: val_loss did not improve from 0.50167
Epoch 00010: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 2s
 320/7440 [>.............................] - ETA: 2s
 480/7440 [>.............................] - ETA: 2s
 640/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 960/7440 [==>...........................] - ETA: 2s
1120/7440 [===>..........................] - ETA: 2s
1248/7440 [====>.........................] - ETA: 2s
1408/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1728/7440 [=====>........................] - ETA: 2s
1888/7440 [======>.......................] - ETA: 2s
2048/7440 [=======>......................] - ETA: 2s
2176/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 1s
2464/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2880/7440 [==========>...................] - ETA: 1s
3008/7440 [===========>..................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3456/7440 [============>.................] - ETA: 1s
3584/7440 [=============>................] - ETA: 1s
3712/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4992/7440 [===================>..........] - ETA: 0s
5120/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5440/7440 [====================>.........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5728/7440 [======================>.......] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 388us/step
current Test accuracy: 0.7162634408602151
current auc_score ------------------>  0.8815047982425713

  32/7440 [..............................] - ETA: 2:08
 160/7440 [..............................] - ETA: 27s 
 288/7440 [>.............................] - ETA: 16s
 416/7440 [>.............................] - ETA: 11s
 544/7440 [=>............................] - ETA: 9s 
 672/7440 [=>............................] - ETA: 8s
 800/7440 [==>...........................] - ETA: 7s
 928/7440 [==>...........................] - ETA: 6s
1056/7440 [===>..........................] - ETA: 5s
1184/7440 [===>..........................] - ETA: 5s
1312/7440 [====>.........................] - ETA: 4s
1440/7440 [====>.........................] - ETA: 4s
1568/7440 [=====>........................] - ETA: 4s
1696/7440 [=====>........................] - ETA: 4s
1824/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2080/7440 [=======>......................] - ETA: 3s
2208/7440 [=======>......................] - ETA: 3s
2368/7440 [========>.....................] - ETA: 3s
2496/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 2s
2784/7440 [==========>...................] - ETA: 2s
2912/7440 [==========>...................] - ETA: 2s
3040/7440 [===========>..................] - ETA: 2s
3168/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3424/7440 [============>.................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3712/7440 [=============>................] - ETA: 2s
3840/7440 [==============>...............] - ETA: 1s
3968/7440 [===============>..............] - ETA: 1s
4096/7440 [===============>..............] - ETA: 1s
4224/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4800/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5056/7440 [===================>..........] - ETA: 1s
5184/7440 [===================>..........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5440/7440 [====================>.........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5696/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 468us/step
Best saved model Test accuracy: 0.8331989247311828
best saved model auc_score ------------------>  0.9094721210544572
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_3[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 64, 96, 96)   1024        activation_25[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 64, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_26[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 32, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 32, 96, 96)   128         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 16, 96, 96)   512         activation_27[0][0]              
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 16, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 16, 48, 48)   64          average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 64, 48, 48)   1024        activation_28[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 64, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_29[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 32, 48, 48)   0           average_pooling2d_5[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 32, 48, 48)   128         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 32, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 16, 48, 48)   512         activation_30[0][0]              
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 16, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 64, 24, 24)   1024        activation_31[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 64, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_32[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 32, 24, 24)   0           average_pooling2d_6[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 32, 24, 24)   128         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 32, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 32)           0           activation_33[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            33          global_average_pooling2d_3[0][0] 
==================================================================================================
Total params: 33,409
Trainable params: 32,737
Non-trainable params: 672
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 22s - loss: 0.5444 - acc: 0.7621 - val_loss: 0.4931 - val_acc: 0.7839

Epoch 00001: val_loss improved from inf to 0.49307, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 18s - loss: 0.4677 - acc: 0.7997 - val_loss: 0.5303 - val_acc: 0.7684

Epoch 00002: val_loss did not improve from 0.49307
Epoch 3/30
 - 18s - loss: 0.4377 - acc: 0.8126 - val_loss: 0.4530 - val_acc: 0.8266

Epoch 00003: val_loss improved from 0.49307 to 0.45305, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 18s - loss: 0.4177 - acc: 0.8255 - val_loss: 0.4183 - val_acc: 0.8409

Epoch 00004: val_loss improved from 0.45305 to 0.41835, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 18s - loss: 0.4017 - acc: 0.8336 - val_loss: 0.4799 - val_acc: 0.7992

Epoch 00005: val_loss did not improve from 0.41835
Epoch 6/30
 - 18s - loss: 0.3868 - acc: 0.8417 - val_loss: 0.3865 - val_acc: 0.8485

Epoch 00006: val_loss improved from 0.41835 to 0.38645, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 19s - loss: 0.3781 - acc: 0.8468 - val_loss: 0.4190 - val_acc: 0.8313

Epoch 00007: val_loss did not improve from 0.38645
Epoch 8/30
 - 19s - loss: 0.3671 - acc: 0.8525 - val_loss: 0.4121 - val_acc: 0.8349

Epoch 00008: val_loss did not improve from 0.38645
Epoch 9/30
 - 19s - loss: 0.3567 - acc: 0.8593 - val_loss: 0.3973 - val_acc: 0.8413

Epoch 00009: val_loss did not improve from 0.38645
Epoch 10/30
 - 19s - loss: 0.3490 - acc: 0.8630 - val_loss: 0.4011 - val_acc: 0.8481

Epoch 00010: val_loss did not improve from 0.38645
Epoch 11/30
 - 19s - loss: 0.3372 - acc: 0.8678 - val_loss: 0.4634 - val_acc: 0.8103

Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00011: val_loss did not improve from 0.38645
Epoch 00011: early stopping

  32/7440 [..............................] - ETA: 1s
 288/7440 [>.............................] - ETA: 1s
 576/7440 [=>............................] - ETA: 1s
 864/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1440/7440 [====>.........................] - ETA: 1s
1728/7440 [=====>........................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2304/7440 [========>.....................] - ETA: 0s
2592/7440 [=========>....................] - ETA: 0s
2880/7440 [==========>...................] - ETA: 0s
3168/7440 [===========>..................] - ETA: 0s
3456/7440 [============>.................] - ETA: 0s
3744/7440 [==============>...............] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4320/7440 [================>.............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
4896/7440 [==================>...........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 189us/step
current Test accuracy: 0.8103494623655914
current auc_score ------------------>  0.8971570774077927

  32/7440 [..............................] - ETA: 1:50
 576/7440 [=>............................] - ETA: 6s  
1152/7440 [===>..........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 2s
2368/7440 [========>.....................] - ETA: 1s
2976/7440 [===========>..................] - ETA: 1s
3584/7440 [=============>................] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4800/7440 [==================>...........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 150us/step
Best saved model Test accuracy: 0.8538978494623656
best saved model auc_score ------------------>  0.8753010463637415
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_4[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 64, 96, 96)   1024        activation_34[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 64, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_35[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 32, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 32, 96, 96)   128         concatenate_13[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 32, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 64, 96, 96)   2048        activation_36[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 64, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_37[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 48, 96, 96)   0           concatenate_13[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 48, 96, 96)   192         concatenate_14[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 48, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 64, 96, 96)   3072        activation_38[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 64, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_39[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 64, 96, 96)   0           concatenate_14[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 96, 96)   256         concatenate_15[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 64, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 96, 96)   2048        activation_40[0][0]              
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 32, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 48, 48)   128         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 32, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 64, 48, 48)   2048        activation_41[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 64, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_42[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 48, 48, 48)   0           average_pooling2d_7[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 48, 48, 48)   192         concatenate_16[0][0]             
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 48, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 64, 48, 48)   3072        activation_43[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 64, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_44[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 64, 48, 48)   0           concatenate_16[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 64, 48, 48)   256         concatenate_17[0][0]             
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 64, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 64, 48, 48)   4096        activation_45[0][0]              
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 64, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_46[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 80, 48, 48)   0           concatenate_17[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 80, 48, 48)   320         concatenate_18[0][0]             
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 80, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 40, 48, 48)   3200        activation_47[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 40, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 40, 24, 24)   160         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 40, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 64, 24, 24)   2560        activation_48[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 64, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_49[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 56, 24, 24)   0           average_pooling2d_8[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 56, 24, 24)   224         concatenate_19[0][0]             
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 56, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 64, 24, 24)   3584        activation_50[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 64, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_51[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 72, 24, 24)   0           concatenate_19[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 72, 24, 24)   288         concatenate_20[0][0]             
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 72, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 64, 24, 24)   4608        activation_52[0][0]              
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 64, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_53[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 88, 24, 24)   0           concatenate_20[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 88, 24, 24)   352         concatenate_21[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 88, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 88)           0           activation_54[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            89          global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 119,545
Trainable params: 117,113
Non-trainable params: 2,432
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 51s - loss: 0.6041 - acc: 0.7660 - val_loss: 0.6228 - val_acc: 0.7996

Epoch 00001: val_loss improved from inf to 0.62277, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 45s - loss: 0.5079 - acc: 0.8171 - val_loss: 0.7084 - val_acc: 0.7300

Epoch 00002: val_loss did not improve from 0.62277
Epoch 3/30
 - 45s - loss: 0.4554 - acc: 0.8448 - val_loss: 0.7696 - val_acc: 0.7448

Epoch 00003: val_loss did not improve from 0.62277
Epoch 4/30
 - 45s - loss: 0.4183 - acc: 0.8637 - val_loss: 0.6510 - val_acc: 0.8086

Epoch 00004: val_loss did not improve from 0.62277
Epoch 5/30
 - 45s - loss: 0.3860 - acc: 0.8822 - val_loss: 0.5734 - val_acc: 0.8016

Epoch 00005: val_loss improved from 0.62277 to 0.57344, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 45s - loss: 0.3559 - acc: 0.8948 - val_loss: 0.5622 - val_acc: 0.8077

Epoch 00006: val_loss improved from 0.57344 to 0.56218, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 45s - loss: 0.3315 - acc: 0.9061 - val_loss: 0.5789 - val_acc: 0.8203

Epoch 00007: val_loss did not improve from 0.56218
Epoch 8/30
 - 45s - loss: 0.3107 - acc: 0.9156 - val_loss: 0.5463 - val_acc: 0.7956

Epoch 00008: val_loss improved from 0.56218 to 0.54634, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 9/30
 - 45s - loss: 0.2937 - acc: 0.9241 - val_loss: 1.0833 - val_acc: 0.7301

Epoch 00009: val_loss did not improve from 0.54634
Epoch 10/30
 - 46s - loss: 0.2698 - acc: 0.9340 - val_loss: 0.6194 - val_acc: 0.8255

Epoch 00010: val_loss did not improve from 0.54634
Epoch 11/30
 - 46s - loss: 0.2598 - acc: 0.9375 - val_loss: 0.7141 - val_acc: 0.8012

Epoch 00011: val_loss did not improve from 0.54634
Epoch 12/30
 - 45s - loss: 0.2481 - acc: 0.9423 - val_loss: 1.1850 - val_acc: 0.7058

Epoch 00012: val_loss did not improve from 0.54634
Epoch 13/30
 - 45s - loss: 0.2327 - acc: 0.9486 - val_loss: 0.7808 - val_acc: 0.8091

Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00013: val_loss did not improve from 0.54634
Epoch 00013: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 445us/step
current Test accuracy: 0.8091397849462365
current auc_score ------------------>  0.9172694820210429

  32/7440 [..............................] - ETA: 3:56
 160/7440 [..............................] - ETA: 49s 
 288/7440 [>.............................] - ETA: 28s
 416/7440 [>.............................] - ETA: 20s
 544/7440 [=>............................] - ETA: 15s
 672/7440 [=>............................] - ETA: 13s
 800/7440 [==>...........................] - ETA: 11s
 928/7440 [==>...........................] - ETA: 9s 
1056/7440 [===>..........................] - ETA: 8s
1184/7440 [===>..........................] - ETA: 8s
1312/7440 [====>.........................] - ETA: 7s
1440/7440 [====>.........................] - ETA: 6s
1568/7440 [=====>........................] - ETA: 6s
1696/7440 [=====>........................] - ETA: 5s
1824/7440 [======>.......................] - ETA: 5s
1952/7440 [======>.......................] - ETA: 5s
2080/7440 [=======>......................] - ETA: 4s
2208/7440 [=======>......................] - ETA: 4s
2336/7440 [========>.....................] - ETA: 4s
2464/7440 [========>.....................] - ETA: 4s
2592/7440 [=========>....................] - ETA: 4s
2720/7440 [=========>....................] - ETA: 3s
2848/7440 [==========>...................] - ETA: 3s
2976/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3232/7440 [============>.................] - ETA: 3s
3360/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 2s
3616/7440 [=============>................] - ETA: 2s
3744/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
4000/7440 [===============>..............] - ETA: 2s
4128/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4384/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 575us/step
Best saved model Test accuracy: 0.8245967741935484
best saved model auc_score ------------------>  0.9195556205919759
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_5[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 48, 96, 96)   768         activation_55[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 48, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_56[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 28, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 28, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 48, 96, 96)   1344        activation_57[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 48, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_58[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 40, 96, 96)   0           concatenate_22[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_23[0][0]             
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 40, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 48, 96, 96)   1920        activation_59[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 48, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_60[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 52, 96, 96)   0           concatenate_23[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_24[0][0]             
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 52, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 48, 96, 96)   2496        activation_61[0][0]              
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 48, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_62[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 64, 96, 96)   0           concatenate_24[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 96, 96)   256         concatenate_25[0][0]             
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 64, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 48, 96, 96)   3072        activation_63[0][0]              
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 48, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_64[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 76, 96, 96)   0           concatenate_25[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 96, 96)   304         concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 76, 96, 96)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_bottleneck_conv2D (Co (None, 48, 96, 96)   3648        activation_65[0][0]              
__________________________________________________________________________________________________
dense_0_5_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_5_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 48, 96, 96)   0           dense_0_5_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_66[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 88, 96, 96)   0           concatenate_26[0][0]             
                                                                 dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 96, 96)   352         concatenate_27[0][0]             
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 88, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 96, 96)   3872        activation_67[0][0]              
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 44, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 48, 48)   176         average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 44, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 48, 48, 48)   2112        activation_68[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 48, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_69[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 56, 48, 48)   0           average_pooling2d_9[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 48, 48)   224         concatenate_28[0][0]             
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 56, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 48, 48, 48)   2688        activation_70[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 48, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_71[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 68, 48, 48)   0           concatenate_28[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 48, 48)   272         concatenate_29[0][0]             
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 68, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 48, 48, 48)   3264        activation_72[0][0]              
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 48, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_73[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 80, 48, 48)   0           concatenate_29[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 48, 48)   320         concatenate_30[0][0]             
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 80, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 48, 48, 48)   3840        activation_74[0][0]              
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 48, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_75[0][0]              
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 92, 48, 48)   0           concatenate_30[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 48, 48)   368         concatenate_31[0][0]             
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 92, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 48, 48, 48)   4416        activation_76[0][0]              
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 48, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_77[0][0]              
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 104, 48, 48)  0           concatenate_31[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 48, 48)  416         concatenate_32[0][0]             
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 104, 48, 48)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_bottleneck_conv2D (Co (None, 48, 48, 48)   4992        activation_78[0][0]              
__________________________________________________________________________________________________
dense_1_5_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_5_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 48, 48, 48)   0           dense_1_5_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_79[0][0]              
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 116, 48, 48)  0           concatenate_32[0][0]             
                                                                 dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 116, 48, 48)  464         concatenate_33[0][0]             
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 116, 48, 48)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 58, 48, 48)   6728        activation_80[0][0]              
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 58, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 58, 24, 24)   232         average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 58, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 48, 24, 24)   2784        activation_81[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 48, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_82[0][0]              
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 70, 24, 24)   0           average_pooling2d_10[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_34[0][0]             
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 70, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 48, 24, 24)   3360        activation_83[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 48, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_84[0][0]              
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 82, 24, 24)   0           concatenate_34[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_35[0][0]             
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 82, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 48, 24, 24)   3936        activation_85[0][0]              
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 48, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_86[0][0]              
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 94, 24, 24)   0           concatenate_35[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_36[0][0]             
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 94, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 48, 24, 24)   4512        activation_87[0][0]              
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 48, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_88[0][0]              
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 106, 24, 24)  0           concatenate_36[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_37[0][0]             
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 106, 24, 24)  0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 48, 24, 24)   5088        activation_89[0][0]              
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 48, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_90[0][0]              
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 118, 24, 24)  0           concatenate_37[0][0]             
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_5_bn (BatchNormalizatio (None, 118, 24, 24)  472         concatenate_38[0][0]             
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 118, 24, 24)  0           dense_2_5_bn[0][0]               
__________________________________________________________________________________________________
dense_2_5_bottleneck_conv2D (Co (None, 48, 24, 24)   5664        activation_91[0][0]              
__________________________________________________________________________________________________
dense_2_5_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_5_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 48, 24, 24)   0           dense_2_5_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_5_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_92[0][0]              
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 130, 24, 24)  0           concatenate_38[0][0]             
                                                                 dense_2_5_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 130, 24, 24)  520         concatenate_39[0][0]             
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 130, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 130)          0           activation_93[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            131         global_average_pooling2d_5[0][0] 
==================================================================================================
Total params: 174,019
Trainable params: 169,127
Non-trainable params: 4,892
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 98s - loss: 0.6172 - acc: 0.7889 - val_loss: 0.5960 - val_acc: 0.7696

Epoch 00001: val_loss improved from inf to 0.59603, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 88s - loss: 0.4883 - acc: 0.8539 - val_loss: 0.5702 - val_acc: 0.8114

Epoch 00002: val_loss improved from 0.59603 to 0.57018, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 88s - loss: 0.4186 - acc: 0.8864 - val_loss: 0.6995 - val_acc: 0.7710

Epoch 00003: val_loss did not improve from 0.57018
Epoch 4/30
 - 88s - loss: 0.3726 - acc: 0.9071 - val_loss: 0.5842 - val_acc: 0.8023

Epoch 00004: val_loss did not improve from 0.57018
Epoch 5/30
 - 88s - loss: 0.3407 - acc: 0.9204 - val_loss: 0.6668 - val_acc: 0.7991

Epoch 00005: val_loss did not improve from 0.57018
Epoch 6/30
 - 88s - loss: 0.3151 - acc: 0.9292 - val_loss: 0.6291 - val_acc: 0.7954

Epoch 00006: val_loss did not improve from 0.57018
Epoch 7/30
 - 88s - loss: 0.2889 - acc: 0.9392 - val_loss: 0.7719 - val_acc: 0.7815

Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00007: val_loss did not improve from 0.57018
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 5s
 128/7440 [..............................] - ETA: 5s
 224/7440 [..............................] - ETA: 5s
 320/7440 [>.............................] - ETA: 5s
 416/7440 [>.............................] - ETA: 5s
 512/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 5s
 704/7440 [=>............................] - ETA: 5s
 800/7440 [==>...........................] - ETA: 4s
 896/7440 [==>...........................] - ETA: 4s
 992/7440 [===>..........................] - ETA: 4s
1088/7440 [===>..........................] - ETA: 4s
1184/7440 [===>..........................] - ETA: 4s
1280/7440 [====>.........................] - ETA: 4s
1376/7440 [====>.........................] - ETA: 4s
1472/7440 [====>.........................] - ETA: 4s
1568/7440 [=====>........................] - ETA: 4s
1664/7440 [=====>........................] - ETA: 4s
1760/7440 [======>.......................] - ETA: 4s
1856/7440 [======>.......................] - ETA: 4s
1952/7440 [======>.......................] - ETA: 4s
2048/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 3s
2432/7440 [========>.....................] - ETA: 3s
2528/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 3s
2720/7440 [=========>....................] - ETA: 3s
2816/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 3s
3008/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3200/7440 [===========>..................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3392/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4352/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4544/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4736/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 746us/step
current Test accuracy: 0.7814516129032258
current auc_score ------------------>  0.8751290972944848

  32/7440 [..............................] - ETA: 7:09
  96/7440 [..............................] - ETA: 2:26
 160/7440 [..............................] - ETA: 1:29
 256/7440 [>.............................] - ETA: 57s 
 352/7440 [>.............................] - ETA: 42s
 448/7440 [>.............................] - ETA: 33s
 544/7440 [=>............................] - ETA: 28s
 640/7440 [=>............................] - ETA: 24s
 736/7440 [=>............................] - ETA: 21s
 832/7440 [==>...........................] - ETA: 19s
 928/7440 [==>...........................] - ETA: 17s
1024/7440 [===>..........................] - ETA: 16s
1120/7440 [===>..........................] - ETA: 15s
1216/7440 [===>..........................] - ETA: 14s
1312/7440 [====>.........................] - ETA: 13s
1408/7440 [====>.........................] - ETA: 12s
1504/7440 [=====>........................] - ETA: 11s
1600/7440 [=====>........................] - ETA: 11s
1696/7440 [=====>........................] - ETA: 10s
1792/7440 [======>.......................] - ETA: 10s
1888/7440 [======>.......................] - ETA: 9s 
1984/7440 [=======>......................] - ETA: 9s
2080/7440 [=======>......................] - ETA: 8s
2176/7440 [=======>......................] - ETA: 8s
2272/7440 [========>.....................] - ETA: 8s
2368/7440 [========>.....................] - ETA: 7s
2464/7440 [========>.....................] - ETA: 7s
2560/7440 [=========>....................] - ETA: 7s
2656/7440 [=========>....................] - ETA: 6s
2752/7440 [==========>...................] - ETA: 6s
2848/7440 [==========>...................] - ETA: 6s
2944/7440 [==========>...................] - ETA: 6s
3040/7440 [===========>..................] - ETA: 5s
3136/7440 [===========>..................] - ETA: 5s
3232/7440 [============>.................] - ETA: 5s
3328/7440 [============>.................] - ETA: 5s
3424/7440 [============>.................] - ETA: 5s
3520/7440 [=============>................] - ETA: 5s
3616/7440 [=============>................] - ETA: 4s
3712/7440 [=============>................] - ETA: 4s
3808/7440 [==============>...............] - ETA: 4s
3904/7440 [==============>...............] - ETA: 4s
4000/7440 [===============>..............] - ETA: 4s
4096/7440 [===============>..............] - ETA: 4s
4192/7440 [===============>..............] - ETA: 3s
4288/7440 [================>.............] - ETA: 3s
4384/7440 [================>.............] - ETA: 3s
4480/7440 [=================>............] - ETA: 3s
4576/7440 [=================>............] - ETA: 3s
4672/7440 [=================>............] - ETA: 3s
4768/7440 [==================>...........] - ETA: 3s
4864/7440 [==================>...........] - ETA: 2s
4960/7440 [===================>..........] - ETA: 2s
5056/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 2s
5248/7440 [====================>.........] - ETA: 2s
5344/7440 [====================>.........] - ETA: 2s
5440/7440 [====================>.........] - ETA: 2s
5536/7440 [=====================>........] - ETA: 2s
5632/7440 [=====================>........] - ETA: 1s
5728/7440 [======================>.......] - ETA: 1s
5824/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
6016/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6208/7440 [========================>.....] - ETA: 1s
6304/7440 [========================>.....] - ETA: 1s
6400/7440 [========================>.....] - ETA: 1s
6496/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 7s 1ms/step
Best saved model Test accuracy: 0.8114247311827957
best saved model auc_score ------------------>  0.909010868308475
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_6[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_94[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_95[0][0]              
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_40[0][0]             
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_96[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_97[0][0]              
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 36, 96, 96)   0           concatenate_40[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 36, 96, 96)   144         concatenate_41[0][0]             
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 36, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 40, 96, 96)   1440        activation_98[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 40, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_99[0][0]              
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 46, 96, 96)   0           concatenate_41[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 46, 96, 96)   184         concatenate_42[0][0]             
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 46, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 40, 96, 96)   1840        activation_100[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 40, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_101[0][0]             
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 56, 96, 96)   0           concatenate_42[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 56, 96, 96)   224         concatenate_43[0][0]             
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 56, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 40, 96, 96)   2240        activation_102[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_103[0][0]             
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 66, 96, 96)   0           concatenate_43[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 66, 96, 96)   264         concatenate_44[0][0]             
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 66, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 33, 96, 96)   2178        activation_104[0][0]             
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 33, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 33, 48, 48)   132         average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 33, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   1320        activation_105[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_106[0][0]             
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 43, 48, 48)   0           average_pooling2d_11[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_45[0][0]             
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1720        activation_107[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_108[0][0]             
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 53, 48, 48)   0           concatenate_45[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 53, 48, 48)   212         concatenate_46[0][0]             
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 53, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 40, 48, 48)   2120        activation_109[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_110[0][0]             
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 63, 48, 48)   0           concatenate_46[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 63, 48, 48)   252         concatenate_47[0][0]             
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 63, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 40, 48, 48)   2520        activation_111[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 40, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_112[0][0]             
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 73, 48, 48)   0           concatenate_47[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 73, 48, 48)   292         concatenate_48[0][0]             
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 73, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 40, 48, 48)   2920        activation_113[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 40, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_114[0][0]             
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 83, 48, 48)   0           concatenate_48[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 83, 48, 48)   332         concatenate_49[0][0]             
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 83, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 41, 48, 48)   3403        activation_115[0][0]             
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 41, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 41, 24, 24)   164         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 41, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   1640        activation_116[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_117[0][0]             
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 51, 24, 24)   0           average_pooling2d_12[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 51, 24, 24)   204         concatenate_50[0][0]             
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 51, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   2040        activation_118[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_119[0][0]             
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 61, 24, 24)   0           concatenate_50[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 61, 24, 24)   244         concatenate_51[0][0]             
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 61, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 40, 24, 24)   2440        activation_120[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 40, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_121[0][0]             
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 71, 24, 24)   0           concatenate_51[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 71, 24, 24)   284         concatenate_52[0][0]             
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 71, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 40, 24, 24)   2840        activation_122[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 40, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_123[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 81, 24, 24)   0           concatenate_52[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 81, 24, 24)   324         concatenate_53[0][0]             
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 81, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 40, 24, 24)   3240        activation_124[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 40, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_125[0][0]             
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 91, 24, 24)   0           concatenate_53[0][0]             
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 91, 24, 24)   364         concatenate_54[0][0]             
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 91, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 91)           0           activation_126[0][0]             
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            92          global_average_pooling2d_6[0][0] 
==================================================================================================
Total params: 96,321
Trainable params: 93,141
Non-trainable params: 3,180
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 74s - loss: 0.5739 - acc: 0.7829 - val_loss: 0.9541 - val_acc: 0.6731

Epoch 00001: val_loss improved from inf to 0.95414, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 65s - loss: 0.4596 - acc: 0.8479 - val_loss: 0.4798 - val_acc: 0.8499

Epoch 00002: val_loss improved from 0.95414 to 0.47977, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 64s - loss: 0.4055 - acc: 0.8743 - val_loss: 0.5735 - val_acc: 0.7976

Epoch 00003: val_loss did not improve from 0.47977
Epoch 4/30
 - 64s - loss: 0.3663 - acc: 0.8915 - val_loss: 0.6189 - val_acc: 0.7683

Epoch 00004: val_loss did not improve from 0.47977
Epoch 5/30
 - 64s - loss: 0.3382 - acc: 0.9032 - val_loss: 0.5211 - val_acc: 0.8083

Epoch 00005: val_loss did not improve from 0.47977
Epoch 6/30
 - 64s - loss: 0.3154 - acc: 0.9151 - val_loss: 0.5874 - val_acc: 0.7780

Epoch 00006: val_loss did not improve from 0.47977
Epoch 7/30
 - 65s - loss: 0.2948 - acc: 0.9224 - val_loss: 0.5465 - val_acc: 0.8106

Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00007: val_loss did not improve from 0.47977
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 4s
 128/7440 [..............................] - ETA: 4s
 224/7440 [..............................] - ETA: 4s
 320/7440 [>.............................] - ETA: 4s
 416/7440 [>.............................] - ETA: 4s
 512/7440 [=>............................] - ETA: 4s
 608/7440 [=>............................] - ETA: 4s
 704/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
 992/7440 [===>..........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 2s
2528/7440 [=========>....................] - ETA: 2s
2624/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2816/7440 [==========>...................] - ETA: 2s
2912/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 1s
4160/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4448/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 586us/step
current Test accuracy: 0.8106182795698925
current auc_score ------------------>  0.8971141895016764

  32/7440 [..............................] - ETA: 10:06
 128/7440 [..............................] - ETA: 2:33 
 224/7440 [..............................] - ETA: 1:28
 320/7440 [>.............................] - ETA: 1:02
 416/7440 [>.............................] - ETA: 48s 
 512/7440 [=>............................] - ETA: 39s
 608/7440 [=>............................] - ETA: 33s
 704/7440 [=>............................] - ETA: 28s
 800/7440 [==>...........................] - ETA: 25s
 896/7440 [==>...........................] - ETA: 22s
 992/7440 [===>..........................] - ETA: 20s
1088/7440 [===>..........................] - ETA: 18s
1184/7440 [===>..........................] - ETA: 17s
1280/7440 [====>.........................] - ETA: 16s
1376/7440 [====>.........................] - ETA: 15s
1472/7440 [====>.........................] - ETA: 14s
1568/7440 [=====>........................] - ETA: 13s
1664/7440 [=====>........................] - ETA: 12s
1760/7440 [======>.......................] - ETA: 11s
1856/7440 [======>.......................] - ETA: 11s
1952/7440 [======>.......................] - ETA: 10s
2048/7440 [=======>......................] - ETA: 10s
2144/7440 [=======>......................] - ETA: 9s 
2240/7440 [========>.....................] - ETA: 9s
2336/7440 [========>.....................] - ETA: 8s
2432/7440 [========>.....................] - ETA: 8s
2528/7440 [=========>....................] - ETA: 7s
2624/7440 [=========>....................] - ETA: 7s
2720/7440 [=========>....................] - ETA: 7s
2816/7440 [==========>...................] - ETA: 7s
2912/7440 [==========>...................] - ETA: 6s
3008/7440 [===========>..................] - ETA: 6s
3104/7440 [===========>..................] - ETA: 6s
3200/7440 [===========>..................] - ETA: 5s
3296/7440 [============>.................] - ETA: 5s
3392/7440 [============>.................] - ETA: 5s
3488/7440 [=============>................] - ETA: 5s
3584/7440 [=============>................] - ETA: 5s
3680/7440 [=============>................] - ETA: 4s
3776/7440 [==============>...............] - ETA: 4s
3872/7440 [==============>...............] - ETA: 4s
3968/7440 [===============>..............] - ETA: 4s
4064/7440 [===============>..............] - ETA: 4s
4160/7440 [===============>..............] - ETA: 3s
4256/7440 [================>.............] - ETA: 3s
4352/7440 [================>.............] - ETA: 3s
4448/7440 [================>.............] - ETA: 3s
4544/7440 [=================>............] - ETA: 3s
4640/7440 [=================>............] - ETA: 3s
4736/7440 [==================>...........] - ETA: 3s
4832/7440 [==================>...........] - ETA: 2s
4928/7440 [==================>...........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 2s
5120/7440 [===================>..........] - ETA: 2s
5216/7440 [====================>.........] - ETA: 2s
5312/7440 [====================>.........] - ETA: 2s
5408/7440 [====================>.........] - ETA: 2s
5504/7440 [=====================>........] - ETA: 2s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6272/7440 [========================>.....] - ETA: 1s
6368/7440 [========================>.....] - ETA: 1s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 7s 939us/step
Best saved model Test accuracy: 0.8498655913978495
best saved model auc_score ------------------>  0.9220523326396115
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_7[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 48, 96, 96)   768         activation_127[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 48, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_128[0][0]             
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 28, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_55[0][0]             
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 28, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 48, 96, 96)   1344        activation_129[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 48, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_130[0][0]             
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 40, 96, 96)   0           concatenate_55[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 96, 96)   160         concatenate_56[0][0]             
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 40, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 96, 96)   800         activation_131[0][0]             
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 20, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 48, 48)   80          average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 20, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 48, 48, 48)   960         activation_132[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 48, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_133[0][0]             
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 32, 48, 48)   0           average_pooling2d_13[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 48, 48)   128         concatenate_57[0][0]             
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 32, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 48, 48, 48)   1536        activation_134[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 48, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_135[0][0]             
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 44, 48, 48)   0           concatenate_57[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 44, 48, 48)   176         concatenate_58[0][0]             
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 44, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 22, 48, 48)   968         activation_136[0][0]             
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 22, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 22, 24, 24)   88          average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 22, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 48, 24, 24)   1056        activation_137[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 48, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_138[0][0]             
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 34, 24, 24)   0           average_pooling2d_14[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_59[0][0]             
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 34, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 48, 24, 24)   1632        activation_139[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 48, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_140[0][0]             
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 46, 24, 24)   0           concatenate_59[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 46, 24, 24)   184         concatenate_60[0][0]             
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 46, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 46)           0           activation_141[0][0]             
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 1)            47          global_average_pooling2d_7[0][0] 
==================================================================================================
Total params: 42,783
Trainable params: 41,643
Non-trainable params: 1,140
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 37s - loss: 0.5577 - acc: 0.7613 - val_loss: 0.6642 - val_acc: 0.7206

Epoch 00001: val_loss improved from inf to 0.66417, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 28s - loss: 0.4781 - acc: 0.8019 - val_loss: 0.6945 - val_acc: 0.7000

Epoch 00002: val_loss did not improve from 0.66417
Epoch 3/30
 - 29s - loss: 0.4431 - acc: 0.8205 - val_loss: 0.5073 - val_acc: 0.8188

Epoch 00003: val_loss improved from 0.66417 to 0.50729, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 28s - loss: 0.4173 - acc: 0.8343 - val_loss: 0.4824 - val_acc: 0.8335

Epoch 00004: val_loss improved from 0.50729 to 0.48241, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 28s - loss: 0.3967 - acc: 0.8469 - val_loss: 0.4623 - val_acc: 0.8582

Epoch 00005: val_loss improved from 0.48241 to 0.46234, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 28s - loss: 0.3807 - acc: 0.8544 - val_loss: 0.4727 - val_acc: 0.8202

Epoch 00006: val_loss did not improve from 0.46234
Epoch 7/30
 - 28s - loss: 0.3637 - acc: 0.8647 - val_loss: 0.4686 - val_acc: 0.8353

Epoch 00007: val_loss did not improve from 0.46234
Epoch 8/30
 - 28s - loss: 0.3478 - acc: 0.8724 - val_loss: 0.5476 - val_acc: 0.8056

Epoch 00008: val_loss did not improve from 0.46234
Epoch 9/30
 - 28s - loss: 0.3319 - acc: 0.8800 - val_loss: 0.5850 - val_acc: 0.7653

Epoch 00009: val_loss did not improve from 0.46234
Epoch 10/30
 - 28s - loss: 0.3204 - acc: 0.8853 - val_loss: 0.5152 - val_acc: 0.8195

Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00010: val_loss did not improve from 0.46234
Epoch 00010: early stopping

  32/7440 [..............................] - ETA: 3s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 2s
 768/7440 [==>...........................] - ETA: 2s
 960/7440 [==>...........................] - ETA: 2s
1152/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1536/7440 [=====>........................] - ETA: 1s
1728/7440 [=====>........................] - ETA: 1s
1920/7440 [======>.......................] - ETA: 1s
2112/7440 [=======>......................] - ETA: 1s
2304/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2880/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3264/7440 [============>.................] - ETA: 1s
3456/7440 [============>.................] - ETA: 1s
3648/7440 [=============>................] - ETA: 1s
3840/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4224/7440 [================>.............] - ETA: 0s
4416/7440 [================>.............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
4800/7440 [==================>...........] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 307us/step
current Test accuracy: 0.8194892473118279
current auc_score ------------------>  0.904669976297838

  32/7440 [..............................] - ETA: 10:32
 192/7440 [..............................] - ETA: 1:45 
 352/7440 [>.............................] - ETA: 57s 
 512/7440 [=>............................] - ETA: 39s
 672/7440 [=>............................] - ETA: 29s
 832/7440 [==>...........................] - ETA: 23s
 992/7440 [===>..........................] - ETA: 19s
1152/7440 [===>..........................] - ETA: 16s
1312/7440 [====>.........................] - ETA: 14s
1472/7440 [====>.........................] - ETA: 12s
1632/7440 [=====>........................] - ETA: 11s
1792/7440 [======>.......................] - ETA: 10s
1952/7440 [======>.......................] - ETA: 9s 
2112/7440 [=======>......................] - ETA: 8s
2272/7440 [========>.....................] - ETA: 7s
2432/7440 [========>.....................] - ETA: 7s
2592/7440 [=========>....................] - ETA: 6s
2752/7440 [==========>...................] - ETA: 6s
2912/7440 [==========>...................] - ETA: 5s
3072/7440 [===========>..................] - ETA: 5s
3232/7440 [============>.................] - ETA: 4s
3392/7440 [============>.................] - ETA: 4s
3552/7440 [=============>................] - ETA: 4s
3712/7440 [=============>................] - ETA: 3s
3872/7440 [==============>...............] - ETA: 3s
4032/7440 [===============>..............] - ETA: 3s
4192/7440 [===============>..............] - ETA: 3s
4352/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 2s
4672/7440 [=================>............] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4992/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5632/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5952/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6272/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 5s 685us/step
Best saved model Test accuracy: 0.8581989247311828
best saved model auc_score ------------------>  0.9154249046132501
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_8 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_8[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_142[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_143[0][0]             
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_61[0][0]             
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_144[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_145[0][0]             
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 36, 96, 96)   0           concatenate_61[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 36, 96, 96)   144         concatenate_62[0][0]             
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 36, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 40, 96, 96)   1440        activation_146[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 40, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_147[0][0]             
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 46, 96, 96)   0           concatenate_62[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_63[0][0]             
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_148[0][0]             
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   920         activation_149[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_150[0][0]             
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 33, 48, 48)   0           average_pooling2d_15[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 33, 48, 48)   132         concatenate_64[0][0]             
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 33, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1320        activation_151[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_152[0][0]             
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 43, 48, 48)   0           concatenate_64[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_65[0][0]             
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 43, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 40, 48, 48)   1720        activation_153[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_154[0][0]             
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 53, 48, 48)   0           concatenate_65[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_66[0][0]             
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_155[0][0]             
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   1040        activation_156[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_157[0][0]             
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 36, 24, 24)   0           average_pooling2d_16[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 36, 24, 24)   144         concatenate_67[0][0]             
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 36, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   1440        activation_158[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_159[0][0]             
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 46, 24, 24)   0           concatenate_67[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_68[0][0]             
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 46, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 40, 24, 24)   1840        activation_160[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 40, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_161[0][0]             
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 56, 24, 24)   0           concatenate_68[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 56, 24, 24)   224         concatenate_69[0][0]             
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 56, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 56)           0           activation_162[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            57          global_average_pooling2d_8[0][0] 
==================================================================================================
Total params: 49,781
Trainable params: 48,181
Non-trainable params: 1,600
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 45s - loss: 0.5757 - acc: 0.7621 - val_loss: 1.1725 - val_acc: 0.6122

Epoch 00001: val_loss improved from inf to 1.17254, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 35s - loss: 0.4763 - acc: 0.8108 - val_loss: 0.8878 - val_acc: 0.6820

Epoch 00002: val_loss improved from 1.17254 to 0.88778, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 35s - loss: 0.4361 - acc: 0.8330 - val_loss: 0.4899 - val_acc: 0.8411

Epoch 00003: val_loss improved from 0.88778 to 0.48988, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 35s - loss: 0.4017 - acc: 0.8546 - val_loss: 0.5351 - val_acc: 0.7902

Epoch 00004: val_loss did not improve from 0.48988
Epoch 5/30
 - 35s - loss: 0.3762 - acc: 0.8683 - val_loss: 0.5178 - val_acc: 0.8423

Epoch 00005: val_loss did not improve from 0.48988
Epoch 6/30
 - 35s - loss: 0.3603 - acc: 0.8764 - val_loss: 0.7703 - val_acc: 0.7485

Epoch 00006: val_loss did not improve from 0.48988
Epoch 7/30
 - 35s - loss: 0.3443 - acc: 0.8839 - val_loss: 0.5198 - val_acc: 0.8147

Epoch 00007: val_loss did not improve from 0.48988
Epoch 8/30
 - 35s - loss: 0.3287 - acc: 0.8900 - val_loss: 0.4926 - val_acc: 0.8043

Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00008: val_loss did not improve from 0.48988
Epoch 00008: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 2s
 544/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2848/7440 [==========>...................] - ETA: 1s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 400us/step
current Test accuracy: 0.8043010752688172
current auc_score ------------------>  0.9008369103364551

  32/7440 [..............................] - ETA: 13:16
 160/7440 [..............................] - ETA: 2:39 
 288/7440 [>.............................] - ETA: 1:28
 416/7440 [>.............................] - ETA: 1:00
 544/7440 [=>............................] - ETA: 46s 
 672/7440 [=>............................] - ETA: 37s
 800/7440 [==>...........................] - ETA: 31s
 928/7440 [==>...........................] - ETA: 26s
1056/7440 [===>..........................] - ETA: 23s
1184/7440 [===>..........................] - ETA: 20s
1312/7440 [====>.........................] - ETA: 18s
1440/7440 [====>.........................] - ETA: 16s
1568/7440 [=====>........................] - ETA: 15s
1696/7440 [=====>........................] - ETA: 13s
1824/7440 [======>.......................] - ETA: 12s
1952/7440 [======>.......................] - ETA: 11s
2080/7440 [=======>......................] - ETA: 11s
2208/7440 [=======>......................] - ETA: 10s
2336/7440 [========>.....................] - ETA: 9s 
2464/7440 [========>.....................] - ETA: 8s
2592/7440 [=========>....................] - ETA: 8s
2720/7440 [=========>....................] - ETA: 7s
2848/7440 [==========>...................] - ETA: 7s
2976/7440 [===========>..................] - ETA: 6s
3104/7440 [===========>..................] - ETA: 6s
3232/7440 [============>.................] - ETA: 6s
3360/7440 [============>.................] - ETA: 5s
3488/7440 [=============>................] - ETA: 5s
3616/7440 [=============>................] - ETA: 5s
3744/7440 [==============>...............] - ETA: 4s
3872/7440 [==============>...............] - ETA: 4s
4000/7440 [===============>..............] - ETA: 4s
4128/7440 [===============>..............] - ETA: 4s
4256/7440 [================>.............] - ETA: 3s
4384/7440 [================>.............] - ETA: 3s
4512/7440 [=================>............] - ETA: 3s
4640/7440 [=================>............] - ETA: 3s
4768/7440 [==================>...........] - ETA: 3s
4896/7440 [==================>...........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 2s
5280/7440 [====================>.........] - ETA: 2s
5408/7440 [====================>.........] - ETA: 2s
5536/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
6048/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6304/7440 [========================>.....] - ETA: 1s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 868us/step
Best saved model Test accuracy: 0.8411290322580646
best saved model auc_score ------------------>  0.9043967872008325
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_9[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_163[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_164[0][0]             
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_70[0][0]             
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_165[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_166[0][0]             
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 44, 96, 96)   0           concatenate_70[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_71[0][0]             
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_167[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_168[0][0]             
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 58, 96, 96)   0           concatenate_71[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 58, 96, 96)   232         concatenate_72[0][0]             
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 58, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 56, 96, 96)   3248        activation_169[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 56, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_170[0][0]             
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 72, 96, 96)   0           concatenate_72[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 72, 96, 96)   288         concatenate_73[0][0]             
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 72, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 36, 96, 96)   2592        activation_171[0][0]             
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 36, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 36, 48, 48)   144         average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 36, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   2016        activation_172[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_173[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 50, 48, 48)   0           average_pooling2d_17[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 50, 48, 48)   200         concatenate_74[0][0]             
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 50, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   2800        activation_174[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_175[0][0]             
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 64, 48, 48)   0           concatenate_74[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 64, 48, 48)   256         concatenate_75[0][0]             
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 64, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3584        activation_176[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_177[0][0]             
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 78, 48, 48)   0           concatenate_75[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_76[0][0]             
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 78, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 56, 48, 48)   4368        activation_178[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 56, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_179[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 92, 48, 48)   0           concatenate_76[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 92, 48, 48)   368         concatenate_77[0][0]             
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 92, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 46, 48, 48)   4232        activation_180[0][0]             
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 46, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 46, 24, 24)   184         average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 46, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 56, 24, 24)   2576        activation_181[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 56, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_182[0][0]             
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 60, 24, 24)   0           average_pooling2d_18[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 60, 24, 24)   240         concatenate_78[0][0]             
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 60, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 56, 24, 24)   3360        activation_183[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 56, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_184[0][0]             
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 74, 24, 24)   0           concatenate_78[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 74, 24, 24)   296         concatenate_79[0][0]             
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 74, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 56, 24, 24)   4144        activation_185[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 56, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_186[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 88, 24, 24)   0           concatenate_79[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_80[0][0]             
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 88, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 56, 24, 24)   4928        activation_187[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 56, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_188[0][0]             
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 102, 24, 24)  0           concatenate_80[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 102, 24, 24)  408         concatenate_81[0][0]             
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 102, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 102)          0           activation_189[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1)            103         global_average_pooling2d_9[0][0] 
==================================================================================================
Total params: 134,279
Trainable params: 131,115
Non-trainable params: 3,164
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 71s - loss: 0.6098 - acc: 0.7778 - val_loss: 0.6623 - val_acc: 0.7509

Epoch 00001: val_loss improved from inf to 0.66234, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 58s - loss: 0.5039 - acc: 0.8308 - val_loss: 0.5171 - val_acc: 0.8421

Epoch 00002: val_loss improved from 0.66234 to 0.51708, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 58s - loss: 0.4472 - acc: 0.8606 - val_loss: 0.5229 - val_acc: 0.8384

Epoch 00003: val_loss did not improve from 0.51708
Epoch 4/30
 - 58s - loss: 0.4079 - acc: 0.8778 - val_loss: 0.5442 - val_acc: 0.8129

Epoch 00004: val_loss did not improve from 0.51708
Epoch 5/30
 - 58s - loss: 0.3730 - acc: 0.8950 - val_loss: 0.5417 - val_acc: 0.8336

Epoch 00005: val_loss did not improve from 0.51708
Epoch 6/30
 - 58s - loss: 0.3487 - acc: 0.9063 - val_loss: 0.6333 - val_acc: 0.7626

Epoch 00006: val_loss did not improve from 0.51708
Epoch 7/30
 - 58s - loss: 0.3252 - acc: 0.9170 - val_loss: 0.5597 - val_acc: 0.8044

Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00007: val_loss did not improve from 0.51708
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 5s
 128/7440 [..............................] - ETA: 4s
 224/7440 [..............................] - ETA: 4s
 320/7440 [>.............................] - ETA: 4s
 416/7440 [>.............................] - ETA: 4s
 512/7440 [=>............................] - ETA: 4s
 608/7440 [=>............................] - ETA: 4s
 704/7440 [=>............................] - ETA: 4s
 800/7440 [==>...........................] - ETA: 4s
 896/7440 [==>...........................] - ETA: 4s
 992/7440 [===>..........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 3s
2432/7440 [========>.....................] - ETA: 3s
2528/7440 [=========>....................] - ETA: 2s
2624/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2816/7440 [==========>...................] - ETA: 2s
2912/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4448/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 5s 605us/step
current Test accuracy: 0.8044354838709677
current auc_score ------------------>  0.9194930772343624

  32/7440 [..............................] - ETA: 17:05
 128/7440 [..............................] - ETA: 4:16 
 224/7440 [..............................] - ETA: 2:26
 320/7440 [>.............................] - ETA: 1:42
 416/7440 [>.............................] - ETA: 1:18
 512/7440 [=>............................] - ETA: 1:04
 608/7440 [=>............................] - ETA: 53s 
 704/7440 [=>............................] - ETA: 46s
 800/7440 [==>...........................] - ETA: 40s
 896/7440 [==>...........................] - ETA: 36s
 992/7440 [===>..........................] - ETA: 32s
1088/7440 [===>..........................] - ETA: 29s
1184/7440 [===>..........................] - ETA: 27s
1280/7440 [====>.........................] - ETA: 25s
1376/7440 [====>.........................] - ETA: 23s
1472/7440 [====>.........................] - ETA: 21s
1568/7440 [=====>........................] - ETA: 20s
1664/7440 [=====>........................] - ETA: 18s
1760/7440 [======>.......................] - ETA: 17s
1856/7440 [======>.......................] - ETA: 16s
1952/7440 [======>.......................] - ETA: 15s
2048/7440 [=======>......................] - ETA: 14s
2144/7440 [=======>......................] - ETA: 14s
2240/7440 [========>.....................] - ETA: 13s
2336/7440 [========>.....................] - ETA: 12s
2432/7440 [========>.....................] - ETA: 12s
2528/7440 [=========>....................] - ETA: 11s
2624/7440 [=========>....................] - ETA: 11s
2720/7440 [=========>....................] - ETA: 10s
2816/7440 [==========>...................] - ETA: 10s
2912/7440 [==========>...................] - ETA: 9s 
3008/7440 [===========>..................] - ETA: 9s
3104/7440 [===========>..................] - ETA: 8s
3200/7440 [===========>..................] - ETA: 8s
3296/7440 [============>.................] - ETA: 8s
3392/7440 [============>.................] - ETA: 7s
3488/7440 [=============>................] - ETA: 7s
3584/7440 [=============>................] - ETA: 7s
3680/7440 [=============>................] - ETA: 6s
3776/7440 [==============>...............] - ETA: 6s
3872/7440 [==============>...............] - ETA: 6s
3968/7440 [===============>..............] - ETA: 5s
4064/7440 [===============>..............] - ETA: 5s
4160/7440 [===============>..............] - ETA: 5s
4256/7440 [================>.............] - ETA: 5s
4352/7440 [================>.............] - ETA: 5s
4448/7440 [================>.............] - ETA: 4s
4544/7440 [=================>............] - ETA: 4s
4640/7440 [=================>............] - ETA: 4s
4736/7440 [==================>...........] - ETA: 4s
4832/7440 [==================>...........] - ETA: 3s
4928/7440 [==================>...........] - ETA: 3s
5024/7440 [===================>..........] - ETA: 3s
5120/7440 [===================>..........] - ETA: 3s
5216/7440 [====================>.........] - ETA: 3s
5312/7440 [====================>.........] - ETA: 3s
5408/7440 [====================>.........] - ETA: 2s
5504/7440 [=====================>........] - ETA: 2s
5600/7440 [=====================>........] - ETA: 2s
5696/7440 [=====================>........] - ETA: 2s
5792/7440 [======================>.......] - ETA: 2s
5888/7440 [======================>.......] - ETA: 2s
5984/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6272/7440 [========================>.....] - ETA: 1s
6368/7440 [========================>.....] - ETA: 1s
6464/7440 [=========================>....] - ETA: 1s
6560/7440 [=========================>....] - ETA: 1s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 9s 1ms/step
Best saved model Test accuracy: 0.8420698924731183
best saved model auc_score ------------------>  0.915861877095618
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_190 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_19 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_191 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_20 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_192 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_10  (None, 4)                 0         
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 16s - loss: 0.6911 - acc: 0.5532 - val_loss: 0.6708 - val_acc: 0.5266

Epoch 00001: val_loss improved from inf to 0.67083, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 6s - loss: 0.6479 - acc: 0.6603 - val_loss: 0.5949 - val_acc: 0.7687

Epoch 00002: val_loss improved from 0.67083 to 0.59490, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 6s - loss: 0.6270 - acc: 0.6999 - val_loss: 0.5860 - val_acc: 0.7669

Epoch 00003: val_loss improved from 0.59490 to 0.58602, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 6s - loss: 0.6132 - acc: 0.7124 - val_loss: 0.5611 - val_acc: 0.7992

Epoch 00004: val_loss improved from 0.58602 to 0.56109, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 6s - loss: 0.5981 - acc: 0.7216 - val_loss: 0.5452 - val_acc: 0.8145

Epoch 00005: val_loss improved from 0.56109 to 0.54518, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 6s - loss: 0.5847 - acc: 0.7286 - val_loss: 0.5161 - val_acc: 0.8149

Epoch 00006: val_loss improved from 0.54518 to 0.51615, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 6s - loss: 0.5733 - acc: 0.7339 - val_loss: 0.5162 - val_acc: 0.8345

Epoch 00007: val_loss did not improve from 0.51615
Epoch 8/30
 - 6s - loss: 0.5636 - acc: 0.7399 - val_loss: 0.5010 - val_acc: 0.8524

Epoch 00008: val_loss improved from 0.51615 to 0.50098, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 9/30
 - 6s - loss: 0.5547 - acc: 0.7432 - val_loss: 0.5050 - val_acc: 0.8401

Epoch 00009: val_loss did not improve from 0.50098
Epoch 10/30
 - 6s - loss: 0.5472 - acc: 0.7478 - val_loss: 0.4931 - val_acc: 0.8567

Epoch 00010: val_loss improved from 0.50098 to 0.49311, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 11/30
 - 6s - loss: 0.5402 - acc: 0.7485 - val_loss: 0.4984 - val_acc: 0.8530

Epoch 00011: val_loss did not improve from 0.49311
Epoch 12/30
 - 6s - loss: 0.5356 - acc: 0.7514 - val_loss: 0.5017 - val_acc: 0.8477

Epoch 00012: val_loss did not improve from 0.49311
Epoch 13/30
 - 6s - loss: 0.5310 - acc: 0.7521 - val_loss: 0.4988 - val_acc: 0.8476

Epoch 00013: val_loss did not improve from 0.49311
Epoch 14/30
 - 6s - loss: 0.5267 - acc: 0.7527 - val_loss: 0.4945 - val_acc: 0.8362

Epoch 00014: val_loss did not improve from 0.49311
Epoch 15/30
 - 7s - loss: 0.5230 - acc: 0.7529 - val_loss: 0.5024 - val_acc: 0.8226

Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00015: val_loss did not improve from 0.49311
Epoch 00015: early stopping

  32/7440 [..............................] - ETA: 3s
 320/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 896/7440 [==>...........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1472/7440 [====>.........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 0s
2560/7440 [=========>....................] - ETA: 0s
2848/7440 [==========>...................] - ETA: 0s
3136/7440 [===========>..................] - ETA: 0s
3424/7440 [============>.................] - ETA: 0s
3712/7440 [=============>................] - ETA: 0s
4000/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4576/7440 [=================>............] - ETA: 0s
4864/7440 [==================>...........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 189us/step
current Test accuracy: 0.8225806451612904
current auc_score ------------------>  0.8521417215863105

  32/7440 [..............................] - ETA: 17:40
 160/7440 [..............................] - ETA: 3:30 
 448/7440 [>.............................] - ETA: 1:13
 736/7440 [=>............................] - ETA: 43s 
1024/7440 [===>..........................] - ETA: 29s
1344/7440 [====>.........................] - ETA: 21s
1632/7440 [=====>........................] - ETA: 17s
1824/7440 [======>.......................] - ETA: 15s
2080/7440 [=======>......................] - ETA: 12s
2368/7440 [========>.....................] - ETA: 10s
2656/7440 [=========>....................] - ETA: 9s 
2944/7440 [==========>...................] - ETA: 7s
3232/7440 [============>.................] - ETA: 6s
3520/7440 [=============>................] - ETA: 5s
3808/7440 [==============>...............] - ETA: 5s
4096/7440 [===============>..............] - ETA: 4s
4384/7440 [================>.............] - ETA: 3s
4672/7440 [=================>............] - ETA: 3s
4960/7440 [===================>..........] - ETA: 2s
5248/7440 [====================>.........] - ETA: 2s
5536/7440 [=====================>........] - ETA: 1s
5824/7440 [======================>.......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6400/7440 [========================>.....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 805us/step
Best saved model Test accuracy: 0.8567204301075269
best saved model auc_score ------------------>  0.8738500838247196
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_11[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 32, 96, 96)   512         activation_193[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 32, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_194[0][0]             
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 24, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 24, 96, 96)   96          concatenate_82[0][0]             
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 32, 96, 96)   768         activation_195[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 32, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_196[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 32, 96, 96)   0           concatenate_82[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 32, 96, 96)   128         concatenate_83[0][0]             
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 32, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 32, 96, 96)   1024        activation_197[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 32, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_198[0][0]             
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 40, 96, 96)   0           concatenate_83[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_84[0][0]             
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 40, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 32, 96, 96)   1280        activation_199[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 32, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_200[0][0]             
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 48, 96, 96)   0           concatenate_84[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 48, 96, 96)   192         concatenate_85[0][0]             
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 48, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 32, 96, 96)   1536        activation_201[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 32, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_202[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 56, 96, 96)   0           concatenate_85[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 56, 96, 96)   224         concatenate_86[0][0]             
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 56, 96, 96)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_bottleneck_conv2D (Co (None, 32, 96, 96)   1792        activation_203[0][0]             
__________________________________________________________________________________________________
dense_0_5_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_5_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 32, 96, 96)   0           dense_0_5_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_204[0][0]             
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 64, 96, 96)   0           concatenate_86[0][0]             
                                                                 dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 96, 96)   256         concatenate_87[0][0]             
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 64, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 96, 96)   2048        activation_205[0][0]             
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 32, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 48, 48)   128         average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 32, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 32, 48, 48)   1024        activation_206[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 32, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_207[0][0]             
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 40, 48, 48)   0           average_pooling2d_21[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 48, 48)   160         concatenate_88[0][0]             
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 32, 48, 48)   1280        activation_208[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 32, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_209[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 48, 48, 48)   0           concatenate_88[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 48, 48, 48)   192         concatenate_89[0][0]             
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 48, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 32, 48, 48)   1536        activation_210[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 32, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_211[0][0]             
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 56, 48, 48)   0           concatenate_89[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 56, 48, 48)   224         concatenate_90[0][0]             
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 56, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 32, 48, 48)   1792        activation_212[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 32, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_213[0][0]             
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 64, 48, 48)   0           concatenate_90[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 64, 48, 48)   256         concatenate_91[0][0]             
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 64, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 32, 48, 48)   2048        activation_214[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 32, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_215[0][0]             
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 72, 48, 48)   0           concatenate_91[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 72, 48, 48)   288         concatenate_92[0][0]             
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 72, 48, 48)   0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_bottleneck_conv2D (Co (None, 32, 48, 48)   2304        activation_216[0][0]             
__________________________________________________________________________________________________
dense_1_5_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_5_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 32, 48, 48)   0           dense_1_5_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_217[0][0]             
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 80, 48, 48)   0           concatenate_92[0][0]             
                                                                 dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 80, 48, 48)   320         concatenate_93[0][0]             
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 80, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 40, 48, 48)   3200        activation_218[0][0]             
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 40, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 40, 24, 24)   160         average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 32, 24, 24)   1280        activation_219[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 32, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_220[0][0]             
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 48, 24, 24)   0           average_pooling2d_22[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 48, 24, 24)   192         concatenate_94[0][0]             
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 48, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 32, 24, 24)   1536        activation_221[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_222[0][0]             
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 56, 24, 24)   0           concatenate_94[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 56, 24, 24)   224         concatenate_95[0][0]             
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 56, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 32, 24, 24)   1792        activation_223[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 32, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_224[0][0]             
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 64, 24, 24)   0           concatenate_95[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_96[0][0]             
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 64, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 32, 24, 24)   2048        activation_225[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 32, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_226[0][0]             
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 72, 24, 24)   0           concatenate_96[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 72, 24, 24)   288         concatenate_97[0][0]             
__________________________________________________________________________________________________
activation_227 (Activation)     (None, 72, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 32, 24, 24)   2304        activation_227[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_228 (Activation)     (None, 32, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_228[0][0]             
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 80, 24, 24)   0           concatenate_97[0][0]             
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_5_bn (BatchNormalizatio (None, 80, 24, 24)   320         concatenate_98[0][0]             
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 80, 24, 24)   0           dense_2_5_bn[0][0]               
__________________________________________________________________________________________________
dense_2_5_bottleneck_conv2D (Co (None, 32, 24, 24)   2560        activation_229[0][0]             
__________________________________________________________________________________________________
dense_2_5_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_5_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 32, 24, 24)   0           dense_2_5_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_5_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_230[0][0]             
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 88, 24, 24)   0           concatenate_98[0][0]             
                                                                 dense_2_5_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 88, 24, 24)   352         concatenate_99[0][0]             
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 88, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_11 (Gl (None, 88)           0           activation_231[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            89          global_average_pooling2d_11[0][0]
==================================================================================================
Total params: 82,297
Trainable params: 78,905
Non-trainable params: 3,392
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 83s - loss: 0.6239 - acc: 0.7531 - val_loss: 0.6702 - val_acc: 0.7754

Epoch 00001: val_loss improved from inf to 0.67019, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 63s - loss: 0.5109 - acc: 0.8152 - val_loss: 0.5536 - val_acc: 0.7906

Epoch 00002: val_loss improved from 0.67019 to 0.55364, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 62s - loss: 0.4599 - acc: 0.8435 - val_loss: 0.6340 - val_acc: 0.7224

Epoch 00003: val_loss did not improve from 0.55364
Epoch 4/30
 - 62s - loss: 0.4186 - acc: 0.8663 - val_loss: 0.6511 - val_acc: 0.7618

Epoch 00004: val_loss did not improve from 0.55364
Epoch 5/30
 - 62s - loss: 0.3878 - acc: 0.8832 - val_loss: 0.6359 - val_acc: 0.7940

Epoch 00005: val_loss did not improve from 0.55364
Epoch 6/30
 - 62s - loss: 0.3623 - acc: 0.8924 - val_loss: 0.5803 - val_acc: 0.8224

Epoch 00006: val_loss did not improve from 0.55364
Epoch 7/30
 - 62s - loss: 0.3406 - acc: 0.9011 - val_loss: 0.6896 - val_acc: 0.7703

Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00007: val_loss did not improve from 0.55364
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 6s
 128/7440 [..............................] - ETA: 5s
 224/7440 [..............................] - ETA: 5s
 320/7440 [>.............................] - ETA: 4s
 416/7440 [>.............................] - ETA: 4s
 512/7440 [=>............................] - ETA: 4s
 608/7440 [=>............................] - ETA: 4s
 704/7440 [=>............................] - ETA: 4s
 800/7440 [==>...........................] - ETA: 4s
 896/7440 [==>...........................] - ETA: 4s
 992/7440 [===>..........................] - ETA: 4s
1088/7440 [===>..........................] - ETA: 4s
1184/7440 [===>..........................] - ETA: 4s
1280/7440 [====>.........................] - ETA: 4s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 3s
2432/7440 [========>.....................] - ETA: 3s
2528/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 3s
2720/7440 [=========>....................] - ETA: 3s
2816/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4352/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 5s 653us/step
current Test accuracy: 0.7702956989247312
current auc_score ------------------>  0.8522194401086831

  32/7440 [..............................] - ETA: 22:59
  96/7440 [..............................] - ETA: 7:39 
 192/7440 [..............................] - ETA: 3:49
 288/7440 [>.............................] - ETA: 2:32
 384/7440 [>.............................] - ETA: 1:53
 480/7440 [>.............................] - ETA: 1:30
 576/7440 [=>............................] - ETA: 1:15
 672/7440 [=>............................] - ETA: 1:04
 768/7440 [==>...........................] - ETA: 56s 
 864/7440 [==>...........................] - ETA: 49s
 960/7440 [==>...........................] - ETA: 44s
1056/7440 [===>..........................] - ETA: 40s
1152/7440 [===>..........................] - ETA: 36s
1248/7440 [====>.........................] - ETA: 33s
1344/7440 [====>.........................] - ETA: 31s
1440/7440 [====>.........................] - ETA: 28s
1536/7440 [=====>........................] - ETA: 26s
1632/7440 [=====>........................] - ETA: 24s
1728/7440 [=====>........................] - ETA: 23s
1824/7440 [======>.......................] - ETA: 22s
1920/7440 [======>.......................] - ETA: 20s
2016/7440 [=======>......................] - ETA: 19s
2112/7440 [=======>......................] - ETA: 18s
2208/7440 [=======>......................] - ETA: 17s
2304/7440 [========>.....................] - ETA: 16s
2400/7440 [========>.....................] - ETA: 15s
2496/7440 [=========>....................] - ETA: 15s
2592/7440 [=========>....................] - ETA: 14s
2688/7440 [=========>....................] - ETA: 13s
2784/7440 [==========>...................] - ETA: 13s
2880/7440 [==========>...................] - ETA: 12s
2976/7440 [===========>..................] - ETA: 11s
3072/7440 [===========>..................] - ETA: 11s
3168/7440 [===========>..................] - ETA: 10s
3264/7440 [============>.................] - ETA: 10s
3360/7440 [============>.................] - ETA: 9s 
3456/7440 [============>.................] - ETA: 9s
3552/7440 [=============>................] - ETA: 9s
3648/7440 [=============>................] - ETA: 8s
3744/7440 [==============>...............] - ETA: 8s
3840/7440 [==============>...............] - ETA: 7s
3936/7440 [==============>...............] - ETA: 7s
4032/7440 [===============>..............] - ETA: 7s
4128/7440 [===============>..............] - ETA: 6s
4224/7440 [================>.............] - ETA: 6s
4320/7440 [================>.............] - ETA: 6s
4416/7440 [================>.............] - ETA: 6s
4512/7440 [=================>............] - ETA: 5s
4608/7440 [=================>............] - ETA: 5s
4704/7440 [=================>............] - ETA: 5s
4800/7440 [==================>...........] - ETA: 5s
4896/7440 [==================>...........] - ETA: 4s
4992/7440 [===================>..........] - ETA: 4s
5088/7440 [===================>..........] - ETA: 4s
5184/7440 [===================>..........] - ETA: 4s
5280/7440 [====================>.........] - ETA: 3s
5376/7440 [====================>.........] - ETA: 3s
5472/7440 [=====================>........] - ETA: 3s
5568/7440 [=====================>........] - ETA: 3s
5664/7440 [=====================>........] - ETA: 3s
5760/7440 [======================>.......] - ETA: 2s
5856/7440 [======================>.......] - ETA: 2s
5952/7440 [=======================>......] - ETA: 2s
6048/7440 [=======================>......] - ETA: 2s
6144/7440 [=======================>......] - ETA: 2s
6240/7440 [========================>.....] - ETA: 1s
6336/7440 [========================>.....] - ETA: 1s
6432/7440 [========================>.....] - ETA: 1s
6528/7440 [=========================>....] - ETA: 1s
6624/7440 [=========================>....] - ETA: 1s
6720/7440 [==========================>...] - ETA: 1s
6816/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 11s 1ms/step
Best saved model Test accuracy: 0.7905913978494624
best saved model auc_score ------------------>  0.8696947985316221
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_232 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_23 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_233 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_24 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_234 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_12  (None, 4)                 0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 22s - loss: 0.6743 - acc: 0.6132 - val_loss: 0.6081 - val_acc: 0.7367

Epoch 00001: val_loss improved from inf to 0.60814, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 8s - loss: 0.6488 - acc: 0.6906 - val_loss: 0.6032 - val_acc: 0.7995

Epoch 00002: val_loss improved from 0.60814 to 0.60323, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 8s - loss: 0.6278 - acc: 0.7103 - val_loss: 0.5423 - val_acc: 0.7859

Epoch 00003: val_loss improved from 0.60323 to 0.54229, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 8s - loss: 0.5913 - acc: 0.7243 - val_loss: 0.5306 - val_acc: 0.8438

Epoch 00004: val_loss improved from 0.54229 to 0.53059, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 8s - loss: 0.5703 - acc: 0.7361 - val_loss: 0.5036 - val_acc: 0.8657

Epoch 00005: val_loss improved from 0.53059 to 0.50355, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 8s - loss: 0.5531 - acc: 0.7431 - val_loss: 0.4936 - val_acc: 0.8683

Epoch 00006: val_loss improved from 0.50355 to 0.49362, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 8s - loss: 0.5405 - acc: 0.7498 - val_loss: 0.4796 - val_acc: 0.8653

Epoch 00007: val_loss improved from 0.49362 to 0.47963, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 8/30
 - 8s - loss: 0.5318 - acc: 0.7520 - val_loss: 0.4782 - val_acc: 0.8597

Epoch 00008: val_loss improved from 0.47963 to 0.47824, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 9/30
 - 8s - loss: 0.5234 - acc: 0.7541 - val_loss: 0.4743 - val_acc: 0.8540

Epoch 00009: val_loss improved from 0.47824 to 0.47429, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 10/30
 - 8s - loss: 0.5186 - acc: 0.7541 - val_loss: 0.4761 - val_acc: 0.8359

Epoch 00010: val_loss did not improve from 0.47429
Epoch 11/30
 - 8s - loss: 0.5136 - acc: 0.7553 - val_loss: 0.4735 - val_acc: 0.8262

Epoch 00011: val_loss improved from 0.47429 to 0.47354, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 12/30
 - 8s - loss: 0.5093 - acc: 0.7565 - val_loss: 0.4872 - val_acc: 0.8289

Epoch 00012: val_loss did not improve from 0.47354
Epoch 13/30
 - 8s - loss: 0.5047 - acc: 0.7588 - val_loss: 0.4911 - val_acc: 0.8285

Epoch 00013: val_loss did not improve from 0.47354
Epoch 14/30
 - 8s - loss: 0.5021 - acc: 0.7575 - val_loss: 0.4623 - val_acc: 0.8356

Epoch 00014: val_loss improved from 0.47354 to 0.46225, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 15/30
 - 8s - loss: 0.4996 - acc: 0.7600 - val_loss: 0.4601 - val_acc: 0.8309

Epoch 00015: val_loss improved from 0.46225 to 0.46010, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 16/30
 - 8s - loss: 0.4972 - acc: 0.7601 - val_loss: 0.4584 - val_acc: 0.8345

Epoch 00016: val_loss improved from 0.46010 to 0.45835, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 17/30
 - 8s - loss: 0.4942 - acc: 0.7613 - val_loss: 0.4601 - val_acc: 0.8289

Epoch 00017: val_loss did not improve from 0.45835
Epoch 18/30
 - 8s - loss: 0.4940 - acc: 0.7614 - val_loss: 0.4623 - val_acc: 0.8292

Epoch 00018: val_loss did not improve from 0.45835
Epoch 19/30
 - 8s - loss: 0.4910 - acc: 0.7605 - val_loss: 0.4569 - val_acc: 0.8316

Epoch 00019: val_loss improved from 0.45835 to 0.45692, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 20/30
 - 8s - loss: 0.4897 - acc: 0.7625 - val_loss: 0.4793 - val_acc: 0.8320

Epoch 00020: val_loss did not improve from 0.45692
Epoch 21/30
 - 8s - loss: 0.4890 - acc: 0.7618 - val_loss: 0.4966 - val_acc: 0.8301

Epoch 00021: val_loss did not improve from 0.45692
Epoch 22/30
 - 8s - loss: 0.4859 - acc: 0.7627 - val_loss: 0.4767 - val_acc: 0.8101

Epoch 00022: val_loss did not improve from 0.45692
Epoch 23/30
 - 8s - loss: 0.4840 - acc: 0.7652 - val_loss: 0.4888 - val_acc: 0.8233

Epoch 00023: val_loss did not improve from 0.45692
Epoch 24/30
 - 8s - loss: 0.4831 - acc: 0.7665 - val_loss: 0.5059 - val_acc: 0.8286

Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00024: val_loss did not improve from 0.45692
Epoch 00024: early stopping

  32/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 1s
 576/7440 [=>............................] - ETA: 1s
 864/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1440/7440 [====>.........................] - ETA: 1s
1728/7440 [=====>........................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2304/7440 [========>.....................] - ETA: 0s
2592/7440 [=========>....................] - ETA: 0s
2880/7440 [==========>...................] - ETA: 0s
3168/7440 [===========>..................] - ETA: 0s
3456/7440 [============>.................] - ETA: 0s
3744/7440 [==============>...............] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4320/7440 [================>.............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
4896/7440 [==================>...........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 187us/step
current Test accuracy: 0.8286290322580645
current auc_score ------------------>  0.8837925627240144

  32/7440 [..............................] - ETA: 22:43
 256/7440 [>.............................] - ETA: 2:46 
 544/7440 [=>............................] - ETA: 1:16
 832/7440 [==>...........................] - ETA: 48s 
1120/7440 [===>..........................] - ETA: 34s
1376/7440 [====>.........................] - ETA: 27s
1664/7440 [=====>........................] - ETA: 21s
1952/7440 [======>.......................] - ETA: 17s
2240/7440 [========>.....................] - ETA: 14s
2528/7440 [=========>....................] - ETA: 12s
2816/7440 [==========>...................] - ETA: 10s
3104/7440 [===========>..................] - ETA: 9s 
3392/7440 [============>.................] - ETA: 7s
3680/7440 [=============>................] - ETA: 6s
3968/7440 [===============>..............] - ETA: 5s
4256/7440 [================>.............] - ETA: 5s
4544/7440 [=================>............] - ETA: 4s
4832/7440 [==================>...........] - ETA: 3s
5120/7440 [===================>..........] - ETA: 3s
5408/7440 [====================>.........] - ETA: 2s
5696/7440 [=====================>........] - ETA: 2s
5984/7440 [=======================>......] - ETA: 1s
6272/7440 [========================>.....] - ETA: 1s
6560/7440 [=========================>....] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 7s 979us/step
Best saved model Test accuracy: 0.8315860215053763
best saved model auc_score ------------------>  0.8837536853971558
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_13[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 48, 96, 96)   768         activation_235[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 48, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_236[0][0]             
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 28, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_100[0][0]            
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 28, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 48, 96, 96)   1344        activation_237[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 48, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_238[0][0]             
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 40, 96, 96)   0           concatenate_100[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_101[0][0]            
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 40, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 48, 96, 96)   1920        activation_239[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 48, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_240[0][0]             
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 52, 96, 96)   0           concatenate_101[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_102[0][0]            
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 52, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 48, 96, 96)   2496        activation_241[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 48, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_242[0][0]             
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 64, 96, 96)   0           concatenate_102[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 96, 96)   256         concatenate_103[0][0]            
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 64, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 48, 96, 96)   3072        activation_243[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 48, 96, 96)   192         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 48, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 96, 96)   5184        activation_244[0][0]             
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 76, 96, 96)   0           concatenate_103[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 96, 96)   304         concatenate_104[0][0]            
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 76, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 96, 96)   2888        activation_245[0][0]             
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 38, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 48, 48)   152         average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 38, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 48, 48, 48)   1824        activation_246[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 48, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_247[0][0]             
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 50, 48, 48)   0           average_pooling2d_25[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 50, 48, 48)   200         concatenate_105[0][0]            
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 50, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 48, 48, 48)   2400        activation_248[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 48, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_249[0][0]             
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 62, 48, 48)   0           concatenate_105[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 62, 48, 48)   248         concatenate_106[0][0]            
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 62, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 48, 48, 48)   2976        activation_250[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 48, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_251[0][0]             
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 74, 48, 48)   0           concatenate_106[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 74, 48, 48)   296         concatenate_107[0][0]            
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 74, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 48, 48, 48)   3552        activation_252[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 48, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_253[0][0]             
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 86, 48, 48)   0           concatenate_107[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 86, 48, 48)   344         concatenate_108[0][0]            
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 86, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 48, 48, 48)   4128        activation_254[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 48, 48, 48)   192         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 48, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 48, 48)   5184        activation_255[0][0]             
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 98, 48, 48)   0           concatenate_108[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 48, 48)   392         concatenate_109[0][0]            
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 98, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 48, 48)   4802        activation_256[0][0]             
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 49, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 24, 24)   196         average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 49, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 48, 24, 24)   2352        activation_257[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 48, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_258[0][0]             
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 61, 24, 24)   0           average_pooling2d_26[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 61, 24, 24)   244         concatenate_110[0][0]            
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 61, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 48, 24, 24)   2928        activation_259[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 48, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_260[0][0]             
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 73, 24, 24)   0           concatenate_110[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 73, 24, 24)   292         concatenate_111[0][0]            
__________________________________________________________________________________________________
activation_261 (Activation)     (None, 73, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 48, 24, 24)   3504        activation_261[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_262 (Activation)     (None, 48, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_262[0][0]             
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 85, 24, 24)   0           concatenate_111[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 85, 24, 24)   340         concatenate_112[0][0]            
__________________________________________________________________________________________________
activation_263 (Activation)     (None, 85, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 48, 24, 24)   4080        activation_263[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_264 (Activation)     (None, 48, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_264[0][0]             
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 97, 24, 24)   0           concatenate_112[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 97, 24, 24)   388         concatenate_113[0][0]            
__________________________________________________________________________________________________
activation_265 (Activation)     (None, 97, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 48, 24, 24)   4656        activation_265[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 48, 24, 24)   192         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_266 (Activation)     (None, 48, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 12, 24, 24)   5184        activation_266[0][0]             
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 109, 24, 24)  0           concatenate_113[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 24, 24)  436         concatenate_114[0][0]            
__________________________________________________________________________________________________
activation_267 (Activation)     (None, 109, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_13 (Gl (None, 109)          0           activation_267[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1)            110         global_average_pooling2d_13[0][0]
==================================================================================================
Total params: 135,360
Trainable params: 131,604
Non-trainable params: 3,756
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 89s - loss: 0.6238 - acc: 0.7719 - val_loss: 0.7736 - val_acc: 0.7683

Epoch 00001: val_loss improved from inf to 0.77357, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 68s - loss: 0.5109 - acc: 0.8334 - val_loss: 0.6273 - val_acc: 0.7578

Epoch 00002: val_loss improved from 0.77357 to 0.62726, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 68s - loss: 0.4510 - acc: 0.8626 - val_loss: 0.5599 - val_acc: 0.7933

Epoch 00003: val_loss improved from 0.62726 to 0.55993, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 68s - loss: 0.4087 - acc: 0.8844 - val_loss: 0.6918 - val_acc: 0.7738

Epoch 00004: val_loss did not improve from 0.55993
Epoch 5/30
 - 68s - loss: 0.3690 - acc: 0.9030 - val_loss: 0.6475 - val_acc: 0.7570

Epoch 00005: val_loss did not improve from 0.55993
Epoch 6/30
 - 68s - loss: 0.3411 - acc: 0.9155 - val_loss: 0.6690 - val_acc: 0.7956

Epoch 00006: val_loss did not improve from 0.55993
Epoch 7/30
 - 68s - loss: 0.3159 - acc: 0.9256 - val_loss: 0.5442 - val_acc: 0.8204

Epoch 00007: val_loss improved from 0.55993 to 0.54423, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 8/30
 - 68s - loss: 0.2934 - acc: 0.9361 - val_loss: 1.2107 - val_acc: 0.6629

Epoch 00008: val_loss did not improve from 0.54423
Epoch 9/30
 - 68s - loss: 0.2756 - acc: 0.9429 - val_loss: 1.0278 - val_acc: 0.6968

Epoch 00009: val_loss did not improve from 0.54423
Epoch 10/30
 - 68s - loss: 0.2602 - acc: 0.9480 - val_loss: 0.5613 - val_acc: 0.7984

Epoch 00010: val_loss did not improve from 0.54423
Epoch 11/30
 - 68s - loss: 0.2455 - acc: 0.9539 - val_loss: 1.0266 - val_acc: 0.7296

Epoch 00011: val_loss did not improve from 0.54423
Epoch 12/30
 - 68s - loss: 0.2377 - acc: 0.9560 - val_loss: 0.7113 - val_acc: 0.8184

Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00012: val_loss did not improve from 0.54423
Epoch 00012: early stopping

  32/7440 [..............................] - ETA: 7s
 128/7440 [..............................] - ETA: 5s
 224/7440 [..............................] - ETA: 5s
 320/7440 [>.............................] - ETA: 5s
 416/7440 [>.............................] - ETA: 5s
 512/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 4s
 704/7440 [=>............................] - ETA: 4s
 800/7440 [==>...........................] - ETA: 4s
 896/7440 [==>...........................] - ETA: 4s
 992/7440 [===>..........................] - ETA: 4s
1088/7440 [===>..........................] - ETA: 4s
1184/7440 [===>..........................] - ETA: 4s
1280/7440 [====>.........................] - ETA: 4s
1376/7440 [====>.........................] - ETA: 4s
1472/7440 [====>.........................] - ETA: 4s
1568/7440 [=====>........................] - ETA: 4s
1664/7440 [=====>........................] - ETA: 4s
1760/7440 [======>.......................] - ETA: 4s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 3s
2432/7440 [========>.....................] - ETA: 3s
2528/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 3s
2720/7440 [=========>....................] - ETA: 3s
2816/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 3s
3008/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4352/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4544/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 5s 705us/step
current Test accuracy: 0.8184139784946236
current auc_score ------------------>  0.8967209359463522

  32/7440 [..............................] - ETA: 28:01
  96/7440 [..............................] - ETA: 9:20 
 192/7440 [..............................] - ETA: 4:39
 288/7440 [>.............................] - ETA: 3:05
 384/7440 [>.............................] - ETA: 2:18
 480/7440 [>.............................] - ETA: 1:50
 576/7440 [=>............................] - ETA: 1:31
 672/7440 [=>............................] - ETA: 1:17
 768/7440 [==>...........................] - ETA: 1:07
 864/7440 [==>...........................] - ETA: 59s 
 960/7440 [==>...........................] - ETA: 53s
1056/7440 [===>..........................] - ETA: 48s
1152/7440 [===>..........................] - ETA: 44s
1248/7440 [====>.........................] - ETA: 40s
1344/7440 [====>.........................] - ETA: 37s
1440/7440 [====>.........................] - ETA: 34s
1536/7440 [=====>........................] - ETA: 32s
1632/7440 [=====>........................] - ETA: 29s
1728/7440 [=====>........................] - ETA: 28s
1824/7440 [======>.......................] - ETA: 26s
1920/7440 [======>.......................] - ETA: 24s
2016/7440 [=======>......................] - ETA: 23s
2112/7440 [=======>......................] - ETA: 22s
2208/7440 [=======>......................] - ETA: 20s
2304/7440 [========>.....................] - ETA: 19s
2400/7440 [========>.....................] - ETA: 18s
2496/7440 [=========>....................] - ETA: 17s
2592/7440 [=========>....................] - ETA: 17s
2688/7440 [=========>....................] - ETA: 16s
2784/7440 [==========>...................] - ETA: 15s
2880/7440 [==========>...................] - ETA: 14s
2976/7440 [===========>..................] - ETA: 14s
3072/7440 [===========>..................] - ETA: 13s
3168/7440 [===========>..................] - ETA: 12s
3264/7440 [============>.................] - ETA: 12s
3360/7440 [============>.................] - ETA: 11s
3456/7440 [============>.................] - ETA: 11s
3552/7440 [=============>................] - ETA: 10s
3648/7440 [=============>................] - ETA: 10s
3744/7440 [==============>...............] - ETA: 9s 
3840/7440 [==============>...............] - ETA: 9s
3936/7440 [==============>...............] - ETA: 8s
4032/7440 [===============>..............] - ETA: 8s
4128/7440 [===============>..............] - ETA: 8s
4224/7440 [================>.............] - ETA: 7s
4320/7440 [================>.............] - ETA: 7s
4416/7440 [================>.............] - ETA: 7s
4512/7440 [=================>............] - ETA: 6s
4608/7440 [=================>............] - ETA: 6s
4704/7440 [=================>............] - ETA: 6s
4800/7440 [==================>...........] - ETA: 5s
4896/7440 [==================>...........] - ETA: 5s
4992/7440 [===================>..........] - ETA: 5s
5088/7440 [===================>..........] - ETA: 5s
5184/7440 [===================>..........] - ETA: 4s
5280/7440 [====================>.........] - ETA: 4s
5376/7440 [====================>.........] - ETA: 4s
5472/7440 [=====================>........] - ETA: 4s
5568/7440 [=====================>........] - ETA: 3s
5664/7440 [=====================>........] - ETA: 3s
5760/7440 [======================>.......] - ETA: 3s
5856/7440 [======================>.......] - ETA: 3s
5952/7440 [=======================>......] - ETA: 2s
6048/7440 [=======================>......] - ETA: 2s
6144/7440 [=======================>......] - ETA: 2s
6240/7440 [========================>.....] - ETA: 2s
6336/7440 [========================>.....] - ETA: 2s
6432/7440 [========================>.....] - ETA: 1s
6528/7440 [=========================>....] - ETA: 1s
6624/7440 [=========================>....] - ETA: 1s
6720/7440 [==========================>...] - ETA: 1s
6816/7440 [==========================>...] - ETA: 1s
6912/7440 [==========================>...] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 13s 2ms/step
Best saved model Test accuracy: 0.8204301075268817
best saved model auc_score ------------------>  0.9129852439588392
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_14 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_14[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_268 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_268[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_269 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_269[0][0]             
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_115[0][0]            
__________________________________________________________________________________________________
activation_270 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_270[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_271 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_271[0][0]             
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 28, 96, 96)   0           concatenate_115[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_116[0][0]            
__________________________________________________________________________________________________
activation_272 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_272[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_273 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_273[0][0]             
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 34, 96, 96)   0           concatenate_116[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_117[0][0]            
__________________________________________________________________________________________________
activation_274 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_274[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_275 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_275[0][0]             
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 40, 96, 96)   0           concatenate_117[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_118[0][0]            
__________________________________________________________________________________________________
activation_276 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_276[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_277 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_277[0][0]             
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 46, 96, 96)   0           concatenate_118[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_119[0][0]            
__________________________________________________________________________________________________
activation_278 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_278[0][0]             
__________________________________________________________________________________________________
average_pooling2d_27 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_27[0][0]       
__________________________________________________________________________________________________
activation_279 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_279[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_280 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_280[0][0]             
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 29, 48, 48)   0           average_pooling2d_27[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_120[0][0]            
__________________________________________________________________________________________________
activation_281 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_281[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_282 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_282[0][0]             
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 35, 48, 48)   0           concatenate_120[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_121[0][0]            
__________________________________________________________________________________________________
activation_283 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_283[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_284 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_284[0][0]             
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 41, 48, 48)   0           concatenate_121[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_122[0][0]            
__________________________________________________________________________________________________
activation_285 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_285[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_286 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_286[0][0]             
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 47, 48, 48)   0           concatenate_122[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_123[0][0]            
__________________________________________________________________________________________________
activation_287 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_287[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_288 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_288[0][0]             
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 53, 48, 48)   0           concatenate_123[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_124[0][0]            
__________________________________________________________________________________________________
activation_289 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_289[0][0]             
__________________________________________________________________________________________________
average_pooling2d_28 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_28[0][0]       
__________________________________________________________________________________________________
activation_290 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   624         activation_290[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_291 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_291[0][0]             
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 32, 24, 24)   0           average_pooling2d_28[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 32, 24, 24)   128         concatenate_125[0][0]            
__________________________________________________________________________________________________
activation_292 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   768         activation_292[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_293 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_293[0][0]             
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 38, 24, 24)   0           concatenate_125[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_126[0][0]            
__________________________________________________________________________________________________
activation_294 (Activation)     (None, 38, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   912         activation_294[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_295 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_295[0][0]             
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 44, 24, 24)   0           concatenate_126[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_127[0][0]            
__________________________________________________________________________________________________
activation_296 (Activation)     (None, 44, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 24, 24, 24)   1056        activation_296[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_297 (Activation)     (None, 24, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_297[0][0]             
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 50, 24, 24)   0           concatenate_127[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_128[0][0]            
__________________________________________________________________________________________________
activation_298 (Activation)     (None, 50, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 24, 24, 24)   1200        activation_298[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_299 (Activation)     (None, 24, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_299[0][0]             
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 56, 24, 24)   0           concatenate_128[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 56, 24, 24)   224         concatenate_129[0][0]            
__________________________________________________________________________________________________
activation_300 (Activation)     (None, 56, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_14 (Gl (None, 56)           0           activation_300[0][0]             
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1)            57          global_average_pooling2d_14[0][0]
==================================================================================================
Total params: 38,421
Trainable params: 36,381
Non-trainable params: 2,040
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 77s - loss: 0.5655 - acc: 0.7665 - val_loss: 0.5092 - val_acc: 0.7977

Epoch 00001: val_loss improved from inf to 0.50916, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 52s - loss: 0.4745 - acc: 0.8117 - val_loss: 0.5173 - val_acc: 0.8454

Epoch 00002: val_loss did not improve from 0.50916
Epoch 3/30
 - 52s - loss: 0.4359 - acc: 0.8308 - val_loss: 0.5887 - val_acc: 0.7770

Epoch 00003: val_loss did not improve from 0.50916
Epoch 4/30
 - 52s - loss: 0.4054 - acc: 0.8479 - val_loss: 0.6074 - val_acc: 0.7965

Epoch 00004: val_loss did not improve from 0.50916
Epoch 5/30
 - 52s - loss: 0.3787 - acc: 0.8621 - val_loss: 0.4394 - val_acc: 0.8292

Epoch 00005: val_loss improved from 0.50916 to 0.43939, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 52s - loss: 0.3538 - acc: 0.8741 - val_loss: 0.4568 - val_acc: 0.8378

Epoch 00006: val_loss did not improve from 0.43939
Epoch 7/30
 - 52s - loss: 0.3349 - acc: 0.8852 - val_loss: 0.4503 - val_acc: 0.8305

Epoch 00007: val_loss did not improve from 0.43939
Epoch 8/30
 - 52s - loss: 0.3148 - acc: 0.8948 - val_loss: 0.8511 - val_acc: 0.6815

Epoch 00008: val_loss did not improve from 0.43939
Epoch 9/30
 - 52s - loss: 0.2995 - acc: 0.9016 - val_loss: 0.5372 - val_acc: 0.8167

Epoch 00009: val_loss did not improve from 0.43939
Epoch 10/30
 - 52s - loss: 0.2862 - acc: 0.9089 - val_loss: 0.9284 - val_acc: 0.6973

Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00010: val_loss did not improve from 0.43939
Epoch 00010: early stopping

  32/7440 [..............................] - ETA: 5s
 128/7440 [..............................] - ETA: 4s
 224/7440 [..............................] - ETA: 4s
 320/7440 [>.............................] - ETA: 4s
 416/7440 [>.............................] - ETA: 3s
 512/7440 [=>............................] - ETA: 3s
 608/7440 [=>............................] - ETA: 3s
 704/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
 992/7440 [===>..........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 3s
1984/7440 [=======>......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2176/7440 [=======>......................] - ETA: 2s
2272/7440 [========>.....................] - ETA: 2s
2368/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2560/7440 [=========>....................] - ETA: 2s
2656/7440 [=========>....................] - ETA: 2s
2752/7440 [==========>...................] - ETA: 2s
2880/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3072/7440 [===========>..................] - ETA: 2s
3168/7440 [===========>..................] - ETA: 2s
3264/7440 [============>.................] - ETA: 2s
3360/7440 [============>.................] - ETA: 2s
3456/7440 [============>.................] - ETA: 2s
3552/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3808/7440 [==============>...............] - ETA: 1s
3904/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4096/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4288/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4480/7440 [=================>............] - ETA: 1s
4576/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4864/7440 [==================>...........] - ETA: 1s
4960/7440 [===================>..........] - ETA: 1s
5056/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 0s
5696/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6240/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 529us/step
current Test accuracy: 0.6973118279569892
current auc_score ------------------>  0.826656838940918

  32/7440 [..............................] - ETA: 34:51
  96/7440 [..............................] - ETA: 11:35
 192/7440 [..............................] - ETA: 5:45 
 288/7440 [>.............................] - ETA: 3:48
 384/7440 [>.............................] - ETA: 2:49
 480/7440 [>.............................] - ETA: 2:14
 576/7440 [=>............................] - ETA: 1:51
 672/7440 [=>............................] - ETA: 1:34
 768/7440 [==>...........................] - ETA: 1:22
 864/7440 [==>...........................] - ETA: 1:12
 960/7440 [==>...........................] - ETA: 1:04
1056/7440 [===>..........................] - ETA: 58s 
1152/7440 [===>..........................] - ETA: 52s
1248/7440 [====>.........................] - ETA: 48s
1344/7440 [====>.........................] - ETA: 44s
1440/7440 [====>.........................] - ETA: 40s
1536/7440 [=====>........................] - ETA: 37s
1632/7440 [=====>........................] - ETA: 35s
1728/7440 [=====>........................] - ETA: 33s
1824/7440 [======>.......................] - ETA: 30s
1920/7440 [======>.......................] - ETA: 29s
2016/7440 [=======>......................] - ETA: 27s
2112/7440 [=======>......................] - ETA: 25s
2208/7440 [=======>......................] - ETA: 24s
2304/7440 [========>.....................] - ETA: 22s
2400/7440 [========>.....................] - ETA: 21s
2496/7440 [=========>....................] - ETA: 20s
2592/7440 [=========>....................] - ETA: 19s
2688/7440 [=========>....................] - ETA: 18s
2784/7440 [==========>...................] - ETA: 17s
2880/7440 [==========>...................] - ETA: 16s
2976/7440 [===========>..................] - ETA: 16s
3072/7440 [===========>..................] - ETA: 15s
3168/7440 [===========>..................] - ETA: 14s
3264/7440 [============>.................] - ETA: 13s
3360/7440 [============>.................] - ETA: 13s
3456/7440 [============>.................] - ETA: 12s
3552/7440 [=============>................] - ETA: 12s
3648/7440 [=============>................] - ETA: 11s
3744/7440 [==============>...............] - ETA: 10s
3840/7440 [==============>...............] - ETA: 10s
3936/7440 [==============>...............] - ETA: 9s 
4032/7440 [===============>..............] - ETA: 9s
4128/7440 [===============>..............] - ETA: 9s
4224/7440 [================>.............] - ETA: 8s
4320/7440 [================>.............] - ETA: 8s
4416/7440 [================>.............] - ETA: 7s
4512/7440 [=================>............] - ETA: 7s
4608/7440 [=================>............] - ETA: 7s
4704/7440 [=================>............] - ETA: 6s
4800/7440 [==================>...........] - ETA: 6s
4896/7440 [==================>...........] - ETA: 6s
4992/7440 [===================>..........] - ETA: 5s
5088/7440 [===================>..........] - ETA: 5s
5184/7440 [===================>..........] - ETA: 5s
5280/7440 [====================>.........] - ETA: 4s
5376/7440 [====================>.........] - ETA: 4s
5472/7440 [=====================>........] - ETA: 4s
5568/7440 [=====================>........] - ETA: 4s
5664/7440 [=====================>........] - ETA: 3s
5760/7440 [======================>.......] - ETA: 3s
5856/7440 [======================>.......] - ETA: 3s
5952/7440 [=======================>......] - ETA: 3s
6048/7440 [=======================>......] - ETA: 2s
6144/7440 [=======================>......] - ETA: 2s
6240/7440 [========================>.....] - ETA: 2s
6336/7440 [========================>.....] - ETA: 2s
6432/7440 [========================>.....] - ETA: 1s
6528/7440 [=========================>....] - ETA: 1s
6624/7440 [=========================>....] - ETA: 1s
6720/7440 [==========================>...] - ETA: 1s
6816/7440 [==========================>...] - ETA: 1s
6912/7440 [==========================>...] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 13s 2ms/step
Best saved model Test accuracy: 0.8291666666666667
best saved model auc_score ------------------>  0.9154223392877789
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_15[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_301 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 32, 96, 96)   512         activation_301[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_302 (Activation)     (None, 32, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_302[0][0]             
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 24, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 24, 96, 96)   96          concatenate_130[0][0]            
__________________________________________________________________________________________________
activation_303 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 32, 96, 96)   768         activation_303[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_304 (Activation)     (None, 32, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_304[0][0]             
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 32, 96, 96)   0           concatenate_130[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 32, 96, 96)   128         concatenate_131[0][0]            
__________________________________________________________________________________________________
activation_305 (Activation)     (None, 32, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 32, 96, 96)   1024        activation_305[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_306 (Activation)     (None, 32, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_306[0][0]             
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 40, 96, 96)   0           concatenate_131[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_132[0][0]            
__________________________________________________________________________________________________
activation_307 (Activation)     (None, 40, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 32, 96, 96)   1280        activation_307[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_308 (Activation)     (None, 32, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_308[0][0]             
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 48, 96, 96)   0           concatenate_132[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 48, 96, 96)   192         concatenate_133[0][0]            
__________________________________________________________________________________________________
activation_309 (Activation)     (None, 48, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 24, 96, 96)   1152        activation_309[0][0]             
__________________________________________________________________________________________________
average_pooling2d_29 (AveragePo (None, 24, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 24, 48, 48)   96          average_pooling2d_29[0][0]       
__________________________________________________________________________________________________
activation_310 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 32, 48, 48)   768         activation_310[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_311 (Activation)     (None, 32, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_311[0][0]             
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 32, 48, 48)   0           average_pooling2d_29[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 48, 48)   128         concatenate_134[0][0]            
__________________________________________________________________________________________________
activation_312 (Activation)     (None, 32, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 32, 48, 48)   1024        activation_312[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_313 (Activation)     (None, 32, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_313[0][0]             
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 40, 48, 48)   0           concatenate_134[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 40, 48, 48)   160         concatenate_135[0][0]            
__________________________________________________________________________________________________
activation_314 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 32, 48, 48)   1280        activation_314[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_315 (Activation)     (None, 32, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_315[0][0]             
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 48, 48, 48)   0           concatenate_135[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 48, 48, 48)   192         concatenate_136[0][0]            
__________________________________________________________________________________________________
activation_316 (Activation)     (None, 48, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 32, 48, 48)   1536        activation_316[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_317 (Activation)     (None, 32, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_317[0][0]             
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 56, 48, 48)   0           concatenate_136[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 56, 48, 48)   224         concatenate_137[0][0]            
__________________________________________________________________________________________________
activation_318 (Activation)     (None, 56, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 28, 48, 48)   1568        activation_318[0][0]             
__________________________________________________________________________________________________
average_pooling2d_30 (AveragePo (None, 28, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 28, 24, 24)   112         average_pooling2d_30[0][0]       
__________________________________________________________________________________________________
activation_319 (Activation)     (None, 28, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 32, 24, 24)   896         activation_319[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_320 (Activation)     (None, 32, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_320[0][0]             
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 36, 24, 24)   0           average_pooling2d_30[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 36, 24, 24)   144         concatenate_138[0][0]            
__________________________________________________________________________________________________
activation_321 (Activation)     (None, 36, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 32, 24, 24)   1152        activation_321[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_322 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_322[0][0]             
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 44, 24, 24)   0           concatenate_138[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_139[0][0]            
__________________________________________________________________________________________________
activation_323 (Activation)     (None, 44, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 32, 24, 24)   1408        activation_323[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_324 (Activation)     (None, 32, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_324[0][0]             
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 52, 24, 24)   0           concatenate_139[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_140[0][0]            
__________________________________________________________________________________________________
activation_325 (Activation)     (None, 52, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 32, 24, 24)   1664        activation_325[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_326 (Activation)     (None, 32, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_326[0][0]             
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 60, 24, 24)   0           concatenate_140[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 60, 24, 24)   240         concatenate_141[0][0]            
__________________________________________________________________________________________________
activation_327 (Activation)     (None, 60, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_15 (Gl (None, 60)           0           activation_327[0][0]             
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 1)            61          global_average_pooling2d_15[0][0]
==================================================================================================
Total params: 47,885
Trainable params: 45,957
Non-trainable params: 1,928
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 67s - loss: 0.5990 - acc: 0.7517 - val_loss: 0.6044 - val_acc: 0.7278

Epoch 00001: val_loss improved from inf to 0.60444, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 42s - loss: 0.4938 - acc: 0.8075 - val_loss: 0.5409 - val_acc: 0.8164

Epoch 00002: val_loss improved from 0.60444 to 0.54089, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 42s - loss: 0.4512 - acc: 0.8289 - val_loss: 0.5169 - val_acc: 0.8011

Epoch 00003: val_loss improved from 0.54089 to 0.51693, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 42s - loss: 0.4208 - acc: 0.8448 - val_loss: 0.5191 - val_acc: 0.8051

Epoch 00004: val_loss did not improve from 0.51693
Epoch 5/30
 - 42s - loss: 0.3951 - acc: 0.8587 - val_loss: 0.6266 - val_acc: 0.7859

Epoch 00005: val_loss did not improve from 0.51693
Epoch 6/30
 - 42s - loss: 0.3706 - acc: 0.8718 - val_loss: 0.5775 - val_acc: 0.7692

Epoch 00006: val_loss did not improve from 0.51693
Epoch 7/30
 - 42s - loss: 0.3518 - acc: 0.8821 - val_loss: 0.6459 - val_acc: 0.7741

Epoch 00007: val_loss did not improve from 0.51693
Epoch 8/30
 - 42s - loss: 0.3359 - acc: 0.8877 - val_loss: 0.5616 - val_acc: 0.7820

Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00008: val_loss did not improve from 0.51693
Epoch 00008: early stopping

  32/7440 [..............................] - ETA: 5s
 128/7440 [..............................] - ETA: 4s
 256/7440 [>.............................] - ETA: 4s
 352/7440 [>.............................] - ETA: 3s
 448/7440 [>.............................] - ETA: 3s
 576/7440 [=>............................] - ETA: 3s
 704/7440 [=>............................] - ETA: 3s
 832/7440 [==>...........................] - ETA: 3s
 960/7440 [==>...........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1216/7440 [===>..........................] - ETA: 3s
1344/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1600/7440 [=====>........................] - ETA: 3s
1728/7440 [=====>........................] - ETA: 2s
1856/7440 [======>.......................] - ETA: 2s
1984/7440 [=======>......................] - ETA: 2s
2112/7440 [=======>......................] - ETA: 2s
2240/7440 [========>.....................] - ETA: 2s
2368/7440 [========>.....................] - ETA: 2s
2496/7440 [=========>....................] - ETA: 2s
2624/7440 [=========>....................] - ETA: 2s
2752/7440 [==========>...................] - ETA: 2s
2880/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3136/7440 [===========>..................] - ETA: 2s
3264/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3520/7440 [=============>................] - ETA: 2s
3648/7440 [=============>................] - ETA: 1s
3776/7440 [==============>...............] - ETA: 1s
3904/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4160/7440 [===============>..............] - ETA: 1s
4288/7440 [================>.............] - ETA: 1s
4416/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4800/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5056/7440 [===================>..........] - ETA: 1s
5184/7440 [===================>..........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5440/7440 [====================>.........] - ETA: 1s
5568/7440 [=====================>........] - ETA: 0s
5696/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 514us/step
current Test accuracy: 0.781989247311828
current auc_score ------------------>  0.8853642039542143

  32/7440 [..............................] - ETA: 39:03
  96/7440 [..............................] - ETA: 12:58
 192/7440 [..............................] - ETA: 6:26 
 288/7440 [>.............................] - ETA: 4:15
 384/7440 [>.............................] - ETA: 3:09
 480/7440 [>.............................] - ETA: 2:30
 576/7440 [=>............................] - ETA: 2:04
 672/7440 [=>............................] - ETA: 1:45
 768/7440 [==>...........................] - ETA: 1:31
 864/7440 [==>...........................] - ETA: 1:20
 960/7440 [==>...........................] - ETA: 1:11
1056/7440 [===>..........................] - ETA: 1:04
1152/7440 [===>..........................] - ETA: 58s 
1248/7440 [====>.........................] - ETA: 53s
1344/7440 [====>.........................] - ETA: 49s
1440/7440 [====>.........................] - ETA: 45s
1536/7440 [=====>........................] - ETA: 42s
1632/7440 [=====>........................] - ETA: 39s
1728/7440 [=====>........................] - ETA: 36s
1824/7440 [======>.......................] - ETA: 34s
1920/7440 [======>.......................] - ETA: 32s
2016/7440 [=======>......................] - ETA: 30s
2112/7440 [=======>......................] - ETA: 28s
2208/7440 [=======>......................] - ETA: 26s
2304/7440 [========>.....................] - ETA: 25s
2400/7440 [========>.....................] - ETA: 23s
2496/7440 [=========>....................] - ETA: 22s
2592/7440 [=========>....................] - ETA: 21s
2688/7440 [=========>....................] - ETA: 20s
2784/7440 [==========>...................] - ETA: 19s
2880/7440 [==========>...................] - ETA: 18s
2976/7440 [===========>..................] - ETA: 17s
3072/7440 [===========>..................] - ETA: 16s
3168/7440 [===========>..................] - ETA: 15s
3264/7440 [============>.................] - ETA: 15s
3360/7440 [============>.................] - ETA: 14s
3456/7440 [============>.................] - ETA: 13s
3552/7440 [=============>................] - ETA: 13s
3648/7440 [=============>................] - ETA: 12s
3744/7440 [==============>...............] - ETA: 11s
3840/7440 [==============>...............] - ETA: 11s
3936/7440 [==============>...............] - ETA: 10s
4032/7440 [===============>..............] - ETA: 10s
4128/7440 [===============>..............] - ETA: 9s 
4224/7440 [================>.............] - ETA: 9s
4320/7440 [================>.............] - ETA: 8s
4416/7440 [================>.............] - ETA: 8s
4512/7440 [=================>............] - ETA: 8s
4608/7440 [=================>............] - ETA: 7s
4704/7440 [=================>............] - ETA: 7s
4800/7440 [==================>...........] - ETA: 6s
4896/7440 [==================>...........] - ETA: 6s
4992/7440 [===================>..........] - ETA: 6s
5088/7440 [===================>..........] - ETA: 5s
5184/7440 [===================>..........] - ETA: 5s
5280/7440 [====================>.........] - ETA: 5s
5376/7440 [====================>.........] - ETA: 4s
5472/7440 [=====================>........] - ETA: 4s
5568/7440 [=====================>........] - ETA: 4s
5664/7440 [=====================>........] - ETA: 4s
5760/7440 [======================>.......] - ETA: 3s
5856/7440 [======================>.......] - ETA: 3s
5952/7440 [=======================>......] - ETA: 3s
6048/7440 [=======================>......] - ETA: 3s
6144/7440 [=======================>......] - ETA: 2s
6240/7440 [========================>.....] - ETA: 2s
6336/7440 [========================>.....] - ETA: 2s
6432/7440 [========================>.....] - ETA: 2s
6528/7440 [=========================>....] - ETA: 1s
6624/7440 [=========================>....] - ETA: 1s
6720/7440 [==========================>...] - ETA: 1s
6816/7440 [==========================>...] - ETA: 1s
6912/7440 [==========================>...] - ETA: 1s
7008/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 14s 2ms/step
Best saved model Test accuracy: 0.8010752688172043
best saved model auc_score ------------------>  0.8889096282807261
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_16 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_16[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_328 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 32, 96, 96)   512         activation_328[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_329 (Activation)     (None, 32, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_329[0][0]             
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 24, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 24, 96, 96)   96          concatenate_142[0][0]            
__________________________________________________________________________________________________
activation_330 (Activation)     (None, 24, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 12, 96, 96)   288         activation_330[0][0]             
__________________________________________________________________________________________________
average_pooling2d_31 (AveragePo (None, 12, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 12, 48, 48)   48          average_pooling2d_31[0][0]       
__________________________________________________________________________________________________
activation_331 (Activation)     (None, 12, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 32, 48, 48)   384         activation_331[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_332 (Activation)     (None, 32, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_332[0][0]             
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_31[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 20, 48, 48)   80          concatenate_143[0][0]            
__________________________________________________________________________________________________
activation_333 (Activation)     (None, 20, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 10, 48, 48)   200         activation_333[0][0]             
__________________________________________________________________________________________________
average_pooling2d_32 (AveragePo (None, 10, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 10, 24, 24)   40          average_pooling2d_32[0][0]       
__________________________________________________________________________________________________
activation_334 (Activation)     (None, 10, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 32, 24, 24)   320         activation_334[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_335 (Activation)     (None, 32, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_335[0][0]             
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 18, 24, 24)   0           average_pooling2d_32[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 18, 24, 24)   72          concatenate_144[0][0]            
__________________________________________________________________________________________________
activation_336 (Activation)     (None, 18, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_16 (Gl (None, 18)           0           activation_336[0][0]             
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 1)            19          global_average_pooling2d_16[0][0]
==================================================================================================
Total params: 9,707
Trainable params: 9,315
Non-trainable params: 392
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 41s - loss: 0.6034 - acc: 0.7188 - val_loss: 0.5377 - val_acc: 0.7746

Epoch 00001: val_loss improved from inf to 0.53767, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 18s - loss: 0.5123 - acc: 0.7740 - val_loss: 0.5130 - val_acc: 0.8183

Epoch 00002: val_loss improved from 0.53767 to 0.51296, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 17s - loss: 0.4742 - acc: 0.7884 - val_loss: 0.4955 - val_acc: 0.7573

Epoch 00003: val_loss improved from 0.51296 to 0.49554, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 17s - loss: 0.4527 - acc: 0.7950 - val_loss: 0.5074 - val_acc: 0.8085

Epoch 00004: val_loss did not improve from 0.49554
Epoch 5/30
 - 17s - loss: 0.4356 - acc: 0.8055 - val_loss: 0.5087 - val_acc: 0.7728

Epoch 00005: val_loss did not improve from 0.49554
Epoch 6/30
 - 17s - loss: 0.4219 - acc: 0.8141 - val_loss: 0.7158 - val_acc: 0.7267

Epoch 00006: val_loss did not improve from 0.49554
Epoch 7/30
 - 17s - loss: 0.4122 - acc: 0.8175 - val_loss: 0.5053 - val_acc: 0.7759

Epoch 00007: val_loss did not improve from 0.49554
Epoch 8/30
 - 17s - loss: 0.4053 - acc: 0.8218 - val_loss: 0.5806 - val_acc: 0.7531

Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00008: val_loss did not improve from 0.49554
Epoch 00008: early stopping

  32/7440 [..............................] - ETA: 4s
 192/7440 [..............................] - ETA: 2s
 384/7440 [>.............................] - ETA: 2s
 576/7440 [=>............................] - ETA: 2s
 768/7440 [==>...........................] - ETA: 2s
 960/7440 [==>...........................] - ETA: 2s
1152/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1536/7440 [=====>........................] - ETA: 1s
1728/7440 [=====>........................] - ETA: 1s
1920/7440 [======>.......................] - ETA: 1s
2112/7440 [=======>......................] - ETA: 1s
2304/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2880/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3264/7440 [============>.................] - ETA: 1s
3456/7440 [============>.................] - ETA: 1s
3648/7440 [=============>................] - ETA: 1s
3840/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4224/7440 [================>.............] - ETA: 0s
4416/7440 [================>.............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
4800/7440 [==================>...........] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 299us/step
current Test accuracy: 0.7530913978494623
current auc_score ------------------>  0.8202331194357728

  32/7440 [..............................] - ETA: 38:34
 160/7440 [..............................] - ETA: 7:37 
 320/7440 [>.............................] - ETA: 3:44
 480/7440 [>.............................] - ETA: 2:27
 672/7440 [=>............................] - ETA: 1:42
 864/7440 [==>...........................] - ETA: 1:18
1056/7440 [===>..........................] - ETA: 1:02
1248/7440 [====>.........................] - ETA: 51s 
1440/7440 [====>.........................] - ETA: 43s
1632/7440 [=====>........................] - ETA: 37s
1824/7440 [======>.......................] - ETA: 32s
1984/7440 [=======>......................] - ETA: 29s
2176/7440 [=======>......................] - ETA: 25s
2336/7440 [========>.....................] - ETA: 23s
2528/7440 [=========>....................] - ETA: 20s
2720/7440 [=========>....................] - ETA: 18s
2912/7440 [==========>...................] - ETA: 16s
3104/7440 [===========>..................] - ETA: 15s
3296/7440 [============>.................] - ETA: 13s
3456/7440 [============>.................] - ETA: 12s
3648/7440 [=============>................] - ETA: 11s
3840/7440 [==============>...............] - ETA: 10s
4032/7440 [===============>..............] - ETA: 9s 
4224/7440 [================>.............] - ETA: 8s
4416/7440 [================>.............] - ETA: 7s
4608/7440 [=================>............] - ETA: 7s
4800/7440 [==================>...........] - ETA: 6s
4992/7440 [===================>..........] - ETA: 5s
5184/7440 [===================>..........] - ETA: 5s
5376/7440 [====================>.........] - ETA: 4s
5568/7440 [=====================>........] - ETA: 3s
5760/7440 [======================>.......] - ETA: 3s
5952/7440 [=======================>......] - ETA: 2s
6144/7440 [=======================>......] - ETA: 2s
6336/7440 [========================>.....] - ETA: 2s
6528/7440 [=========================>....] - ETA: 1s
6720/7440 [==========================>...] - ETA: 1s
6912/7440 [==========================>...] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 12s 2ms/step
Best saved model Test accuracy: 0.757258064516129
best saved model auc_score ------------------>  0.8621060238177825
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_17[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_337 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 32, 96, 96)   512         activation_337[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 32, 96, 96)   128         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_338 (Activation)     (None, 32, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 8, 96, 96)    2304        activation_338[0][0]             
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 24, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 24, 96, 96)   96          concatenate_145[0][0]            
__________________________________________________________________________________________________
activation_339 (Activation)     (None, 24, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 12, 96, 96)   288         activation_339[0][0]             
__________________________________________________________________________________________________
average_pooling2d_33 (AveragePo (None, 12, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 12, 48, 48)   48          average_pooling2d_33[0][0]       
__________________________________________________________________________________________________
activation_340 (Activation)     (None, 12, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 32, 48, 48)   384         activation_340[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 32, 48, 48)   128         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_341 (Activation)     (None, 32, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 8, 48, 48)    2304        activation_341[0][0]             
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_33[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 20, 48, 48)   80          concatenate_146[0][0]            
__________________________________________________________________________________________________
activation_342 (Activation)     (None, 20, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 10, 48, 48)   200         activation_342[0][0]             
__________________________________________________________________________________________________
average_pooling2d_34 (AveragePo (None, 10, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 10, 24, 24)   40          average_pooling2d_34[0][0]       
__________________________________________________________________________________________________
activation_343 (Activation)     (None, 10, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 32, 24, 24)   320         activation_343[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 32, 24, 24)   128         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_344 (Activation)     (None, 32, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 8, 24, 24)    2304        activation_344[0][0]             
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 18, 24, 24)   0           average_pooling2d_34[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 18, 24, 24)   72          concatenate_147[0][0]            
__________________________________________________________________________________________________
activation_345 (Activation)     (None, 18, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_17 (Gl (None, 18)           0           activation_345[0][0]             
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 1)            19          global_average_pooling2d_17[0][0]
==================================================================================================
Total params: 9,707
Trainable params: 9,315
Non-trainable params: 392
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 40s - loss: 0.6353 - acc: 0.6779 - val_loss: 0.8618 - val_acc: 0.5024

Epoch 00001: val_loss improved from inf to 0.86179, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 15s - loss: 0.5381 - acc: 0.7635 - val_loss: 0.5226 - val_acc: 0.7840

Epoch 00002: val_loss improved from 0.86179 to 0.52264, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 15s - loss: 0.4986 - acc: 0.7802 - val_loss: 0.4800 - val_acc: 0.8055

Epoch 00003: val_loss improved from 0.52264 to 0.48002, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 15s - loss: 0.4708 - acc: 0.7886 - val_loss: 0.4850 - val_acc: 0.8200

Epoch 00004: val_loss did not improve from 0.48002
Epoch 5/30
 - 15s - loss: 0.4512 - acc: 0.7974 - val_loss: 0.4290 - val_acc: 0.8461

Epoch 00005: val_loss improved from 0.48002 to 0.42896, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 6/30
 - 15s - loss: 0.4342 - acc: 0.8064 - val_loss: 0.5349 - val_acc: 0.7817

Epoch 00006: val_loss did not improve from 0.42896
Epoch 7/30
 - 15s - loss: 0.4212 - acc: 0.8121 - val_loss: 0.5275 - val_acc: 0.7899

Epoch 00007: val_loss did not improve from 0.42896
Epoch 8/30
 - 15s - loss: 0.4105 - acc: 0.8204 - val_loss: 0.4601 - val_acc: 0.8050

Epoch 00008: val_loss did not improve from 0.42896
Epoch 9/30
 - 15s - loss: 0.4014 - acc: 0.8244 - val_loss: 0.3940 - val_acc: 0.8582

Epoch 00009: val_loss improved from 0.42896 to 0.39397, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 10/30
 - 15s - loss: 0.3941 - acc: 0.8263 - val_loss: 0.5097 - val_acc: 0.7579

Epoch 00010: val_loss did not improve from 0.39397
Epoch 11/30
 - 15s - loss: 0.3869 - acc: 0.8321 - val_loss: 0.4382 - val_acc: 0.8302

Epoch 00011: val_loss did not improve from 0.39397
Epoch 12/30
 - 15s - loss: 0.3837 - acc: 0.8349 - val_loss: 0.4116 - val_acc: 0.8138

Epoch 00012: val_loss did not improve from 0.39397
Epoch 13/30
 - 15s - loss: 0.3776 - acc: 0.8363 - val_loss: 0.4762 - val_acc: 0.7570

Epoch 00013: val_loss did not improve from 0.39397
Epoch 14/30
 - 15s - loss: 0.3734 - acc: 0.8400 - val_loss: 0.4021 - val_acc: 0.8433

Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00014: val_loss did not improve from 0.39397
Epoch 00014: early stopping

  32/7440 [..............................] - ETA: 4s
 192/7440 [..............................] - ETA: 2s
 384/7440 [>.............................] - ETA: 2s
 544/7440 [=>............................] - ETA: 2s
 736/7440 [=>............................] - ETA: 2s
 896/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1216/7440 [===>..........................] - ETA: 2s
1376/7440 [====>.........................] - ETA: 1s
1536/7440 [=====>........................] - ETA: 1s
1696/7440 [=====>........................] - ETA: 1s
1856/7440 [======>.......................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2176/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2656/7440 [=========>....................] - ETA: 1s
2848/7440 [==========>...................] - ETA: 1s
3040/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3424/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3808/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4384/7440 [================>.............] - ETA: 0s
4576/7440 [=================>............] - ETA: 0s
4768/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5120/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 315us/step
current Test accuracy: 0.8432795698924731
current auc_score ------------------>  0.9119961483986587

  32/7440 [..............................] - ETA: 39:31
 160/7440 [..............................] - ETA: 7:48 
 320/7440 [>.............................] - ETA: 3:50
 480/7440 [>.............................] - ETA: 2:30
 672/7440 [=>............................] - ETA: 1:45
 864/7440 [==>...........................] - ETA: 1:20
1056/7440 [===>..........................] - ETA: 1:03
1248/7440 [====>.........................] - ETA: 52s 
1408/7440 [====>.........................] - ETA: 45s
1568/7440 [=====>........................] - ETA: 40s
1728/7440 [=====>........................] - ETA: 35s
1888/7440 [======>.......................] - ETA: 31s
2048/7440 [=======>......................] - ETA: 28s
2208/7440 [=======>......................] - ETA: 25s
2368/7440 [========>.....................] - ETA: 23s
2560/7440 [=========>....................] - ETA: 21s
2752/7440 [==========>...................] - ETA: 18s
2944/7440 [==========>...................] - ETA: 17s
3136/7440 [===========>..................] - ETA: 15s
3328/7440 [============>.................] - ETA: 13s
3520/7440 [=============>................] - ETA: 12s
3712/7440 [=============>................] - ETA: 11s
3904/7440 [==============>...............] - ETA: 10s
4096/7440 [===============>..............] - ETA: 9s 
4288/7440 [================>.............] - ETA: 8s
4480/7440 [=================>............] - ETA: 7s
4672/7440 [=================>............] - ETA: 6s
4832/7440 [==================>...........] - ETA: 6s
5024/7440 [===================>..........] - ETA: 5s
5216/7440 [====================>.........] - ETA: 5s
5408/7440 [====================>.........] - ETA: 4s
5600/7440 [=====================>........] - ETA: 3s
5792/7440 [======================>.......] - ETA: 3s
5984/7440 [=======================>......] - ETA: 2s
6176/7440 [=======================>......] - ETA: 2s
6336/7440 [========================>.....] - ETA: 2s
6528/7440 [=========================>....] - ETA: 1s
6688/7440 [=========================>....] - ETA: 1s
6880/7440 [==========================>...] - ETA: 1s
7072/7440 [===========================>..] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 13s 2ms/step
Best saved model Test accuracy: 0.8581989247311828
best saved model auc_score ------------------>  0.9172098291710024
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_346 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_35 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_347 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_36 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_348 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_18  (None, 4)                 0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 33s - loss: 0.6770 - acc: 0.5174 - val_loss: 0.6309 - val_acc: 0.6410

Epoch 00001: val_loss improved from inf to 0.63092, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 7s - loss: 0.6574 - acc: 0.5974 - val_loss: 0.6146 - val_acc: 0.7309

Epoch 00002: val_loss improved from 0.63092 to 0.61462, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 7s - loss: 0.6488 - acc: 0.6752 - val_loss: 0.6093 - val_acc: 0.7551

Epoch 00003: val_loss improved from 0.61462 to 0.60935, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 7s - loss: 0.6411 - acc: 0.6972 - val_loss: 0.6064 - val_acc: 0.7509

Epoch 00004: val_loss improved from 0.60935 to 0.60639, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 7s - loss: 0.6331 - acc: 0.7139 - val_loss: 0.6090 - val_acc: 0.6922

Epoch 00005: val_loss did not improve from 0.60639
Epoch 6/30
 - 7s - loss: 0.6163 - acc: 0.7201 - val_loss: 0.5932 - val_acc: 0.7296

Epoch 00006: val_loss improved from 0.60639 to 0.59317, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 7s - loss: 0.5914 - acc: 0.7302 - val_loss: 0.5589 - val_acc: 0.8007

Epoch 00007: val_loss improved from 0.59317 to 0.55891, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 8/30
 - 7s - loss: 0.5765 - acc: 0.7358 - val_loss: 0.5608 - val_acc: 0.7679

Epoch 00008: val_loss did not improve from 0.55891
Epoch 9/30
 - 7s - loss: 0.5649 - acc: 0.7386 - val_loss: 0.5168 - val_acc: 0.8444

Epoch 00009: val_loss improved from 0.55891 to 0.51676, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 10/30
 - 7s - loss: 0.5546 - acc: 0.7427 - val_loss: 0.5186 - val_acc: 0.7915

Epoch 00010: val_loss did not improve from 0.51676
Epoch 11/30
 - 7s - loss: 0.5448 - acc: 0.7478 - val_loss: 0.5019 - val_acc: 0.8511

Epoch 00011: val_loss improved from 0.51676 to 0.50194, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 12/30
 - 7s - loss: 0.5374 - acc: 0.7509 - val_loss: 0.5060 - val_acc: 0.8313

Epoch 00012: val_loss did not improve from 0.50194
Epoch 13/30
 - 7s - loss: 0.5302 - acc: 0.7556 - val_loss: 0.4958 - val_acc: 0.8195

Epoch 00013: val_loss improved from 0.50194 to 0.49583, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 14/30
 - 7s - loss: 0.5247 - acc: 0.7568 - val_loss: 0.5079 - val_acc: 0.8017

Epoch 00014: val_loss did not improve from 0.49583
Epoch 15/30
 - 7s - loss: 0.5202 - acc: 0.7562 - val_loss: 0.5207 - val_acc: 0.8122

Epoch 00015: val_loss did not improve from 0.49583
Epoch 16/30
 - 7s - loss: 0.5159 - acc: 0.7587 - val_loss: 0.5077 - val_acc: 0.8284

Epoch 00016: val_loss did not improve from 0.49583
Epoch 17/30
 - 7s - loss: 0.5130 - acc: 0.7606 - val_loss: 0.4899 - val_acc: 0.8165

Epoch 00017: val_loss improved from 0.49583 to 0.48988, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 18/30
 - 7s - loss: 0.5091 - acc: 0.7609 - val_loss: 0.5057 - val_acc: 0.8147

Epoch 00018: val_loss did not improve from 0.48988
Epoch 19/30
 - 7s - loss: 0.5060 - acc: 0.7632 - val_loss: 0.4972 - val_acc: 0.8157

Epoch 00019: val_loss did not improve from 0.48988
Epoch 20/30
 - 7s - loss: 0.5049 - acc: 0.7616 - val_loss: 0.5402 - val_acc: 0.7931

Epoch 00020: val_loss did not improve from 0.48988
Epoch 21/30
 - 7s - loss: 0.5017 - acc: 0.7626 - val_loss: 0.5284 - val_acc: 0.7899

Epoch 00021: val_loss did not improve from 0.48988
Epoch 22/30
 - 7s - loss: 0.4995 - acc: 0.7635 - val_loss: 0.5113 - val_acc: 0.8054

Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00022: val_loss did not improve from 0.48988
Epoch 00022: early stopping

  32/7440 [..............................] - ETA: 5s
 256/7440 [>.............................] - ETA: 2s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 242us/step
current Test accuracy: 0.8053763440860215
current auc_score ------------------>  0.8466652214128801

  32/7440 [..............................] - ETA: 41:10
 192/7440 [..............................] - ETA: 6:44 
 416/7440 [>.............................] - ETA: 3:01
 640/7440 [=>............................] - ETA: 1:55
 864/7440 [==>...........................] - ETA: 1:22
1088/7440 [===>..........................] - ETA: 1:03
1312/7440 [====>.........................] - ETA: 51s 
1536/7440 [=====>........................] - ETA: 42s
1760/7440 [======>.......................] - ETA: 35s
1984/7440 [=======>......................] - ETA: 30s
2208/7440 [=======>......................] - ETA: 26s
2432/7440 [========>.....................] - ETA: 23s
2656/7440 [=========>....................] - ETA: 20s
2880/7440 [==========>...................] - ETA: 18s
3104/7440 [===========>..................] - ETA: 15s
3328/7440 [============>.................] - ETA: 14s
3552/7440 [=============>................] - ETA: 12s
3776/7440 [==============>...............] - ETA: 11s
4000/7440 [===============>..............] - ETA: 10s
4224/7440 [================>.............] - ETA: 8s 
4448/7440 [================>.............] - ETA: 7s
4672/7440 [=================>............] - ETA: 7s
4896/7440 [==================>...........] - ETA: 6s
5120/7440 [===================>..........] - ETA: 5s
5344/7440 [====================>.........] - ETA: 4s
5568/7440 [=====================>........] - ETA: 4s
5792/7440 [======================>.......] - ETA: 3s
6016/7440 [=======================>......] - ETA: 2s
6240/7440 [========================>.....] - ETA: 2s
6464/7440 [=========================>....] - ETA: 1s
6688/7440 [=========================>....] - ETA: 1s
6912/7440 [==========================>...] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 12s 2ms/step
Best saved model Test accuracy: 0.8165322580645161
best saved model auc_score ------------------>  0.8587179514972829
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_349 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_37 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_350 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_38 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_351 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_19  (None, 4)                 0         
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 34s - loss: 0.7113 - acc: 0.5036 - val_loss: 0.6613 - val_acc: 0.5383

Epoch 00001: val_loss improved from inf to 0.66131, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 9s - loss: 0.6713 - acc: 0.6218 - val_loss: 0.6279 - val_acc: 0.7617

Epoch 00002: val_loss improved from 0.66131 to 0.62790, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 9s - loss: 0.6525 - acc: 0.6668 - val_loss: 0.6015 - val_acc: 0.7616

Epoch 00003: val_loss improved from 0.62790 to 0.60149, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 9s - loss: 0.6211 - acc: 0.6949 - val_loss: 0.5816 - val_acc: 0.7652

Epoch 00004: val_loss improved from 0.60149 to 0.58159, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 9s - loss: 0.5976 - acc: 0.7141 - val_loss: 0.5957 - val_acc: 0.6626

Epoch 00005: val_loss did not improve from 0.58159
Epoch 6/30
 - 9s - loss: 0.5773 - acc: 0.7282 - val_loss: 0.5374 - val_acc: 0.8081

Epoch 00006: val_loss improved from 0.58159 to 0.53744, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 9s - loss: 0.5607 - acc: 0.7377 - val_loss: 0.5550 - val_acc: 0.7456

Epoch 00007: val_loss did not improve from 0.53744
Epoch 8/30
 - 9s - loss: 0.5481 - acc: 0.7442 - val_loss: 0.4888 - val_acc: 0.8399

Epoch 00008: val_loss improved from 0.53744 to 0.48876, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 9/30
 - 9s - loss: 0.5372 - acc: 0.7472 - val_loss: 0.4798 - val_acc: 0.8349

Epoch 00009: val_loss improved from 0.48876 to 0.47977, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 10/30
 - 9s - loss: 0.5286 - acc: 0.7495 - val_loss: 0.4933 - val_acc: 0.8152

Epoch 00010: val_loss did not improve from 0.47977
Epoch 11/30
 - 9s - loss: 0.5210 - acc: 0.7566 - val_loss: 0.4902 - val_acc: 0.8126

Epoch 00011: val_loss did not improve from 0.47977
Epoch 12/30
 - 9s - loss: 0.5147 - acc: 0.7581 - val_loss: 0.5061 - val_acc: 0.7921

Epoch 00012: val_loss did not improve from 0.47977
Epoch 13/30
 - 10s - loss: 0.5109 - acc: 0.7594 - val_loss: 0.5125 - val_acc: 0.7921

Epoch 00013: val_loss did not improve from 0.47977
Epoch 14/30
 - 9s - loss: 0.5077 - acc: 0.7591 - val_loss: 0.4804 - val_acc: 0.8245

Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00014: val_loss did not improve from 0.47977
Epoch 00014: early stopping

  32/7440 [..............................] - ETA: 3s
 224/7440 [..............................] - ETA: 2s
 448/7440 [>.............................] - ETA: 1s
 672/7440 [=>............................] - ETA: 1s
 896/7440 [==>...........................] - ETA: 1s
1120/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1792/7440 [======>.......................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2240/7440 [========>.....................] - ETA: 1s
2464/7440 [========>.....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3136/7440 [===========>..................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3584/7440 [=============>................] - ETA: 0s
3808/7440 [==============>...............] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4480/7440 [=================>............] - ETA: 0s
4704/7440 [=================>............] - ETA: 0s
4928/7440 [==================>...........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 253us/step
current Test accuracy: 0.8244623655913978
current auc_score ------------------>  0.87455572898601

  32/7440 [..............................] - ETA: 43:28
 192/7440 [..............................] - ETA: 7:07 
 416/7440 [>.............................] - ETA: 3:12
 640/7440 [=>............................] - ETA: 2:01
 864/7440 [==>...........................] - ETA: 1:27
1088/7440 [===>..........................] - ETA: 1:07
1312/7440 [====>.........................] - ETA: 54s 
1536/7440 [=====>........................] - ETA: 44s
1760/7440 [======>.......................] - ETA: 37s
1984/7440 [=======>......................] - ETA: 32s
2208/7440 [=======>......................] - ETA: 28s
2432/7440 [========>.....................] - ETA: 24s
2624/7440 [=========>....................] - ETA: 21s
2848/7440 [==========>...................] - ETA: 19s
3072/7440 [===========>..................] - ETA: 17s
3296/7440 [============>.................] - ETA: 15s
3520/7440 [=============>................] - ETA: 13s
3744/7440 [==============>...............] - ETA: 12s
3968/7440 [===============>..............] - ETA: 10s
4192/7440 [===============>..............] - ETA: 9s 
4416/7440 [================>.............] - ETA: 8s
4640/7440 [=================>............] - ETA: 7s
4864/7440 [==================>...........] - ETA: 6s
5088/7440 [===================>..........] - ETA: 5s
5312/7440 [====================>.........] - ETA: 5s
5536/7440 [=====================>........] - ETA: 4s
5760/7440 [======================>.......] - ETA: 3s
5984/7440 [=======================>......] - ETA: 3s
6208/7440 [========================>.....] - ETA: 2s
6432/7440 [========================>.....] - ETA: 2s
6656/7440 [=========================>....] - ETA: 1s
6880/7440 [==========================>...] - ETA: 1s
7104/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 13s 2ms/step
Best saved model Test accuracy: 0.8349462365591398
best saved model auc_score ------------------>  0.882215574054804
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_352 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_39 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_353 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_40 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_354 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_20  (None, 4)                 0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 36s - loss: 0.6522 - acc: 0.6595 - val_loss: 0.5669 - val_acc: 0.8023

Epoch 00001: val_loss improved from inf to 0.56691, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 10s - loss: 0.6191 - acc: 0.7029 - val_loss: 0.5580 - val_acc: 0.7827

Epoch 00002: val_loss improved from 0.56691 to 0.55801, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 10s - loss: 0.6032 - acc: 0.7132 - val_loss: 0.5450 - val_acc: 0.7981

Epoch 00003: val_loss improved from 0.55801 to 0.54500, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 10s - loss: 0.5888 - acc: 0.7217 - val_loss: 0.5275 - val_acc: 0.7888

Epoch 00004: val_loss improved from 0.54500 to 0.52754, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 10s - loss: 0.5747 - acc: 0.7279 - val_loss: 0.6013 - val_acc: 0.7380

Epoch 00005: val_loss did not improve from 0.52754
Epoch 6/30
 - 10s - loss: 0.5624 - acc: 0.7351 - val_loss: 0.5059 - val_acc: 0.8636

Epoch 00006: val_loss improved from 0.52754 to 0.50585, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 10s - loss: 0.5513 - acc: 0.7403 - val_loss: 0.5055 - val_acc: 0.8453

Epoch 00007: val_loss improved from 0.50585 to 0.50548, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 8/30
 - 10s - loss: 0.5417 - acc: 0.7454 - val_loss: 0.4972 - val_acc: 0.8462

Epoch 00008: val_loss improved from 0.50548 to 0.49723, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 9/30
 - 10s - loss: 0.5339 - acc: 0.7493 - val_loss: 0.6286 - val_acc: 0.8035

Epoch 00009: val_loss did not improve from 0.49723
Epoch 10/30
 - 10s - loss: 0.5263 - acc: 0.7517 - val_loss: 0.5290 - val_acc: 0.8233

Epoch 00010: val_loss did not improve from 0.49723
Epoch 11/30
 - 10s - loss: 0.5200 - acc: 0.7546 - val_loss: 0.5075 - val_acc: 0.8315

Epoch 00011: val_loss did not improve from 0.49723
Epoch 12/30
 - 10s - loss: 0.5157 - acc: 0.7568 - val_loss: 0.5668 - val_acc: 0.8137

Epoch 00012: val_loss did not improve from 0.49723
Epoch 13/30
 - 10s - loss: 0.5111 - acc: 0.7566 - val_loss: 0.5008 - val_acc: 0.8281

Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00013: val_loss did not improve from 0.49723
Epoch 00013: early stopping

  32/7440 [..............................] - ETA: 3s
 256/7440 [>.............................] - ETA: 2s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4480/7440 [=================>............] - ETA: 0s
4704/7440 [=================>............] - ETA: 0s
4928/7440 [==================>...........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 250us/step
current Test accuracy: 0.8280913978494624
current auc_score ------------------>  0.8722700239912129

  32/7440 [..............................] - ETA: 42:39
 224/7440 [..............................] - ETA: 5:57 
 448/7440 [>.............................] - ETA: 2:54
 672/7440 [=>............................] - ETA: 1:52
 896/7440 [==>...........................] - ETA: 1:22
1120/7440 [===>..........................] - ETA: 1:03
1344/7440 [====>.........................] - ETA: 51s 
1568/7440 [=====>........................] - ETA: 42s
1792/7440 [======>.......................] - ETA: 36s
2016/7440 [=======>......................] - ETA: 31s
2240/7440 [========>.....................] - ETA: 26s
2464/7440 [========>.....................] - ETA: 23s
2688/7440 [=========>....................] - ETA: 20s
2912/7440 [==========>...................] - ETA: 18s
3136/7440 [===========>..................] - ETA: 16s
3360/7440 [============>.................] - ETA: 14s
3584/7440 [=============>................] - ETA: 12s
3808/7440 [==============>...............] - ETA: 11s
4032/7440 [===============>..............] - ETA: 10s
4256/7440 [================>.............] - ETA: 9s 
4480/7440 [=================>............] - ETA: 8s
4704/7440 [=================>............] - ETA: 7s
4928/7440 [==================>...........] - ETA: 6s
5152/7440 [===================>..........] - ETA: 5s
5376/7440 [====================>.........] - ETA: 4s
5600/7440 [=====================>........] - ETA: 4s
5824/7440 [======================>.......] - ETA: 3s
6048/7440 [=======================>......] - ETA: 2s
6272/7440 [========================>.....] - ETA: 2s
6496/7440 [=========================>....] - ETA: 1s
6720/7440 [==========================>...] - ETA: 1s
6944/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 13s 2ms/step
Best saved model Test accuracy: 0.8462365591397849
best saved model auc_score ------------------>  0.8671850069372181
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_21[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_355 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_355[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_356 (Activation)     (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_356[0][0]             
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_148[0][0]            
__________________________________________________________________________________________________
activation_357 (Activation)     (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_357[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_358 (Activation)     (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_358[0][0]             
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 36, 96, 96)   0           concatenate_148[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 36, 96, 96)   144         concatenate_149[0][0]            
__________________________________________________________________________________________________
activation_359 (Activation)     (None, 36, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 40, 96, 96)   1440        activation_359[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_360 (Activation)     (None, 40, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_360[0][0]             
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 46, 96, 96)   0           concatenate_149[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 46, 96, 96)   184         concatenate_150[0][0]            
__________________________________________________________________________________________________
activation_361 (Activation)     (None, 46, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 40, 96, 96)   1840        activation_361[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_362 (Activation)     (None, 40, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_362[0][0]             
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 56, 96, 96)   0           concatenate_150[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 56, 96, 96)   224         concatenate_151[0][0]            
__________________________________________________________________________________________________
activation_363 (Activation)     (None, 56, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 40, 96, 96)   2240        activation_363[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_364 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_364[0][0]             
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 66, 96, 96)   0           concatenate_151[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 66, 96, 96)   264         concatenate_152[0][0]            
__________________________________________________________________________________________________
activation_365 (Activation)     (None, 66, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 33, 96, 96)   2178        activation_365[0][0]             
__________________________________________________________________________________________________
average_pooling2d_41 (AveragePo (None, 33, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 33, 48, 48)   132         average_pooling2d_41[0][0]       
__________________________________________________________________________________________________
activation_366 (Activation)     (None, 33, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   1320        activation_366[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_367 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_367[0][0]             
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 43, 48, 48)   0           average_pooling2d_41[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_153[0][0]            
__________________________________________________________________________________________________
activation_368 (Activation)     (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1720        activation_368[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_369 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_369[0][0]             
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 53, 48, 48)   0           concatenate_153[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 53, 48, 48)   212         concatenate_154[0][0]            
__________________________________________________________________________________________________
activation_370 (Activation)     (None, 53, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 40, 48, 48)   2120        activation_370[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_371 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_371[0][0]             
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 63, 48, 48)   0           concatenate_154[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 63, 48, 48)   252         concatenate_155[0][0]            
__________________________________________________________________________________________________
activation_372 (Activation)     (None, 63, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 40, 48, 48)   2520        activation_372[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_373 (Activation)     (None, 40, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_373[0][0]             
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 73, 48, 48)   0           concatenate_155[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 73, 48, 48)   292         concatenate_156[0][0]            
__________________________________________________________________________________________________
activation_374 (Activation)     (None, 73, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 40, 48, 48)   2920        activation_374[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_375 (Activation)     (None, 40, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_375[0][0]             
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 83, 48, 48)   0           concatenate_156[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 83, 48, 48)   332         concatenate_157[0][0]            
__________________________________________________________________________________________________
activation_376 (Activation)     (None, 83, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 41, 48, 48)   3403        activation_376[0][0]             
__________________________________________________________________________________________________
average_pooling2d_42 (AveragePo (None, 41, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 41, 24, 24)   164         average_pooling2d_42[0][0]       
__________________________________________________________________________________________________
activation_377 (Activation)     (None, 41, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   1640        activation_377[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_378 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_378[0][0]             
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 51, 24, 24)   0           average_pooling2d_42[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 51, 24, 24)   204         concatenate_158[0][0]            
__________________________________________________________________________________________________
activation_379 (Activation)     (None, 51, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   2040        activation_379[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_380 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_380[0][0]             
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 61, 24, 24)   0           concatenate_158[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 61, 24, 24)   244         concatenate_159[0][0]            
__________________________________________________________________________________________________
activation_381 (Activation)     (None, 61, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 40, 24, 24)   2440        activation_381[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_382 (Activation)     (None, 40, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_382[0][0]             
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 71, 24, 24)   0           concatenate_159[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 71, 24, 24)   284         concatenate_160[0][0]            
__________________________________________________________________________________________________
activation_383 (Activation)     (None, 71, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 40, 24, 24)   2840        activation_383[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_384 (Activation)     (None, 40, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_384[0][0]             
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 81, 24, 24)   0           concatenate_160[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 81, 24, 24)   324         concatenate_161[0][0]            
__________________________________________________________________________________________________
activation_385 (Activation)     (None, 81, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 40, 24, 24)   3240        activation_385[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_386 (Activation)     (None, 40, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_386[0][0]             
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 91, 24, 24)   0           concatenate_161[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 91, 24, 24)   364         concatenate_162[0][0]            
__________________________________________________________________________________________________
activation_387 (Activation)     (None, 91, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_21 (Gl (None, 91)           0           activation_387[0][0]             
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 1)            92          global_average_pooling2d_21[0][0]
==================================================================================================
Total params: 96,321
Trainable params: 93,141
Non-trainable params: 3,180
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 93s - loss: 0.6058 - acc: 0.7716 - val_loss: 0.6418 - val_acc: 0.7685

Epoch 00001: val_loss improved from inf to 0.64177, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 61s - loss: 0.4960 - acc: 0.8251 - val_loss: 0.6178 - val_acc: 0.7948

Epoch 00002: val_loss improved from 0.64177 to 0.61779, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 61s - loss: 0.4407 - acc: 0.8566 - val_loss: 0.7213 - val_acc: 0.7491

Epoch 00003: val_loss did not improve from 0.61779
Epoch 4/30
 - 61s - loss: 0.3968 - acc: 0.8798 - val_loss: 0.6047 - val_acc: 0.7985

Epoch 00004: val_loss improved from 0.61779 to 0.60473, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 61s - loss: 0.3643 - acc: 0.8945 - val_loss: 0.6190 - val_acc: 0.8128

Epoch 00005: val_loss did not improve from 0.60473
Epoch 6/30
 - 61s - loss: 0.3348 - acc: 0.9097 - val_loss: 0.5215 - val_acc: 0.8380

Epoch 00006: val_loss improved from 0.60473 to 0.52148, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 61s - loss: 0.3129 - acc: 0.9183 - val_loss: 0.4976 - val_acc: 0.8347

Epoch 00007: val_loss improved from 0.52148 to 0.49763, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 8/30
 - 61s - loss: 0.2947 - acc: 0.9269 - val_loss: 0.8026 - val_acc: 0.7825

Epoch 00008: val_loss did not improve from 0.49763
Epoch 9/30
 - 61s - loss: 0.2797 - acc: 0.9321 - val_loss: 0.5918 - val_acc: 0.8297

Epoch 00009: val_loss did not improve from 0.49763
Epoch 10/30
 - 61s - loss: 0.2615 - acc: 0.9397 - val_loss: 0.5756 - val_acc: 0.8333

Epoch 00010: val_loss did not improve from 0.49763
Epoch 11/30
 - 61s - loss: 0.2510 - acc: 0.9433 - val_loss: 0.4995 - val_acc: 0.8509

Epoch 00011: val_loss did not improve from 0.49763
Epoch 12/30
 - 61s - loss: 0.2386 - acc: 0.9490 - val_loss: 0.5399 - val_acc: 0.8247

Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00012: val_loss did not improve from 0.49763
Epoch 00012: early stopping

  32/7440 [..............................] - ETA: 8s
 128/7440 [..............................] - ETA: 6s
 224/7440 [..............................] - ETA: 5s
 320/7440 [>.............................] - ETA: 5s
 416/7440 [>.............................] - ETA: 5s
 512/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 4s
 704/7440 [=>............................] - ETA: 4s
 800/7440 [==>...........................] - ETA: 4s
 896/7440 [==>...........................] - ETA: 4s
 992/7440 [===>..........................] - ETA: 4s
1088/7440 [===>..........................] - ETA: 4s
1184/7440 [===>..........................] - ETA: 4s
1280/7440 [====>.........................] - ETA: 4s
1376/7440 [====>.........................] - ETA: 4s
1472/7440 [====>.........................] - ETA: 4s
1568/7440 [=====>........................] - ETA: 4s
1664/7440 [=====>........................] - ETA: 4s
1760/7440 [======>.......................] - ETA: 4s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 3s
2432/7440 [========>.....................] - ETA: 3s
2528/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 3s
2720/7440 [=========>....................] - ETA: 3s
2816/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 3s
3008/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4352/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4544/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 5s 695us/step
current Test accuracy: 0.8247311827956989
current auc_score ------------------>  0.917703961440629

  32/7440 [..............................] - ETA: 48:40
  96/7440 [..............................] - ETA: 16:09
 192/7440 [..............................] - ETA: 8:00 
 288/7440 [>.............................] - ETA: 5:18
 384/7440 [>.............................] - ETA: 3:56
 480/7440 [>.............................] - ETA: 3:07
 576/7440 [=>............................] - ETA: 2:35
 672/7440 [=>............................] - ETA: 2:11
 768/7440 [==>...........................] - ETA: 1:54
 864/7440 [==>...........................] - ETA: 1:40
 960/7440 [==>...........................] - ETA: 1:29
1056/7440 [===>..........................] - ETA: 1:20
1152/7440 [===>..........................] - ETA: 1:13
1248/7440 [====>.........................] - ETA: 1:06
1344/7440 [====>.........................] - ETA: 1:01
1440/7440 [====>.........................] - ETA: 56s 
1536/7440 [=====>........................] - ETA: 52s
1632/7440 [=====>........................] - ETA: 48s
1728/7440 [=====>........................] - ETA: 45s
1824/7440 [======>.......................] - ETA: 42s
1920/7440 [======>.......................] - ETA: 40s
2016/7440 [=======>......................] - ETA: 37s
2112/7440 [=======>......................] - ETA: 35s
2208/7440 [=======>......................] - ETA: 33s
2304/7440 [========>.....................] - ETA: 31s
2400/7440 [========>.....................] - ETA: 29s
2496/7440 [=========>....................] - ETA: 28s
2592/7440 [=========>....................] - ETA: 26s
2688/7440 [=========>....................] - ETA: 25s
2784/7440 [==========>...................] - ETA: 24s
2880/7440 [==========>...................] - ETA: 23s
2976/7440 [===========>..................] - ETA: 21s
3072/7440 [===========>..................] - ETA: 20s
3168/7440 [===========>..................] - ETA: 19s
3264/7440 [============>.................] - ETA: 19s
3360/7440 [============>.................] - ETA: 18s
3456/7440 [============>.................] - ETA: 17s
3552/7440 [=============>................] - ETA: 16s
3648/7440 [=============>................] - ETA: 15s
3744/7440 [==============>...............] - ETA: 15s
3840/7440 [==============>...............] - ETA: 14s
3936/7440 [==============>...............] - ETA: 13s
4032/7440 [===============>..............] - ETA: 13s
4128/7440 [===============>..............] - ETA: 12s
4224/7440 [================>.............] - ETA: 11s
4320/7440 [================>.............] - ETA: 11s
4416/7440 [================>.............] - ETA: 10s
4512/7440 [=================>............] - ETA: 10s
4608/7440 [=================>............] - ETA: 9s 
4704/7440 [=================>............] - ETA: 9s
4800/7440 [==================>...........] - ETA: 8s
4896/7440 [==================>...........] - ETA: 8s
4992/7440 [===================>..........] - ETA: 7s
5088/7440 [===================>..........] - ETA: 7s
5184/7440 [===================>..........] - ETA: 7s
5280/7440 [====================>.........] - ETA: 6s
5376/7440 [====================>.........] - ETA: 6s
5472/7440 [=====================>........] - ETA: 5s
5568/7440 [=====================>........] - ETA: 5s
5664/7440 [=====================>........] - ETA: 5s
5760/7440 [======================>.......] - ETA: 4s
5856/7440 [======================>.......] - ETA: 4s
5952/7440 [=======================>......] - ETA: 4s
6048/7440 [=======================>......] - ETA: 3s
6144/7440 [=======================>......] - ETA: 3s
6240/7440 [========================>.....] - ETA: 3s
6336/7440 [========================>.....] - ETA: 2s
6432/7440 [========================>.....] - ETA: 2s
6528/7440 [=========================>....] - ETA: 2s
6624/7440 [=========================>....] - ETA: 2s
6720/7440 [==========================>...] - ETA: 1s
6816/7440 [==========================>...] - ETA: 1s
6912/7440 [==========================>...] - ETA: 1s
7008/7440 [===========================>..] - ETA: 1s
7104/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 18s 2ms/step
Best saved model Test accuracy: 0.8346774193548387
best saved model auc_score ------------------>  0.9144718320037
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_22 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_22[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_388 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_388[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_389 (Activation)     (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_389[0][0]             
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_163[0][0]            
__________________________________________________________________________________________________
activation_390 (Activation)     (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_390[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_391 (Activation)     (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_391[0][0]             
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 36, 96, 96)   0           concatenate_163[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 36, 96, 96)   144         concatenate_164[0][0]            
__________________________________________________________________________________________________
activation_392 (Activation)     (None, 36, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 40, 96, 96)   1440        activation_392[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_393 (Activation)     (None, 40, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_393[0][0]             
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 46, 96, 96)   0           concatenate_164[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_165[0][0]            
__________________________________________________________________________________________________
activation_394 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_394[0][0]             
__________________________________________________________________________________________________
average_pooling2d_43 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_43[0][0]       
__________________________________________________________________________________________________
activation_395 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   920         activation_395[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_396 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_396[0][0]             
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 33, 48, 48)   0           average_pooling2d_43[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 33, 48, 48)   132         concatenate_166[0][0]            
__________________________________________________________________________________________________
activation_397 (Activation)     (None, 33, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1320        activation_397[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_398 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_398[0][0]             
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 43, 48, 48)   0           concatenate_166[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_167[0][0]            
__________________________________________________________________________________________________
activation_399 (Activation)     (None, 43, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 40, 48, 48)   1720        activation_399[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_400 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_400[0][0]             
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 53, 48, 48)   0           concatenate_167[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_168[0][0]            
__________________________________________________________________________________________________
activation_401 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_401[0][0]             
__________________________________________________________________________________________________
average_pooling2d_44 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_44[0][0]       
__________________________________________________________________________________________________
activation_402 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   1040        activation_402[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_403 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_403[0][0]             
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 36, 24, 24)   0           average_pooling2d_44[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 36, 24, 24)   144         concatenate_169[0][0]            
__________________________________________________________________________________________________
activation_404 (Activation)     (None, 36, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   1440        activation_404[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_405 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_405[0][0]             
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 46, 24, 24)   0           concatenate_169[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_170[0][0]            
__________________________________________________________________________________________________
activation_406 (Activation)     (None, 46, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 40, 24, 24)   1840        activation_406[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_407 (Activation)     (None, 40, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_407[0][0]             
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 56, 24, 24)   0           concatenate_170[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 56, 24, 24)   224         concatenate_171[0][0]            
__________________________________________________________________________________________________
activation_408 (Activation)     (None, 56, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_22 (Gl (None, 56)           0           activation_408[0][0]             
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 1)            57          global_average_pooling2d_22[0][0]
==================================================================================================
Total params: 49,781
Trainable params: 48,181
Non-trainable params: 1,600
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 75s - loss: 0.5637 - acc: 0.7658 - val_loss: 0.4860 - val_acc: 0.8172

Epoch 00001: val_loss improved from inf to 0.48597, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 41s - loss: 0.4731 - acc: 0.8138 - val_loss: 0.5884 - val_acc: 0.7441

Epoch 00002: val_loss did not improve from 0.48597
Epoch 3/30
 - 41s - loss: 0.4325 - acc: 0.8315 - val_loss: 0.5715 - val_acc: 0.8172

Epoch 00003: val_loss did not improve from 0.48597
Epoch 4/30
 - 41s - loss: 0.4032 - acc: 0.8495 - val_loss: 0.6515 - val_acc: 0.7595

Epoch 00004: val_loss did not improve from 0.48597
Epoch 5/30
 - 41s - loss: 0.3770 - acc: 0.8626 - val_loss: 0.7942 - val_acc: 0.7464

Epoch 00005: val_loss did not improve from 0.48597
Epoch 6/30
 - 41s - loss: 0.3580 - acc: 0.8728 - val_loss: 0.4958 - val_acc: 0.8199

Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00006: val_loss did not improve from 0.48597
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 5s
 128/7440 [..............................] - ETA: 4s
 256/7440 [>.............................] - ETA: 3s
 384/7440 [>.............................] - ETA: 3s
 512/7440 [=>............................] - ETA: 3s
 640/7440 [=>............................] - ETA: 3s
 768/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
1024/7440 [===>..........................] - ETA: 3s
1152/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1408/7440 [====>.........................] - ETA: 3s
1536/7440 [=====>........................] - ETA: 2s
1664/7440 [=====>........................] - ETA: 2s
1792/7440 [======>.......................] - ETA: 2s
1920/7440 [======>.......................] - ETA: 2s
2048/7440 [=======>......................] - ETA: 2s
2176/7440 [=======>......................] - ETA: 2s
2304/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 2s
2560/7440 [=========>....................] - ETA: 2s
2688/7440 [=========>....................] - ETA: 2s
2816/7440 [==========>...................] - ETA: 2s
2944/7440 [==========>...................] - ETA: 2s
3072/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3328/7440 [============>.................] - ETA: 2s
3456/7440 [============>.................] - ETA: 1s
3584/7440 [=============>................] - ETA: 1s
3712/7440 [=============>................] - ETA: 1s
3840/7440 [==============>...............] - ETA: 1s
3968/7440 [===============>..............] - ETA: 1s
4096/7440 [===============>..............] - ETA: 1s
4224/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4480/7440 [=================>............] - ETA: 1s
4608/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4864/7440 [==================>...........] - ETA: 1s
4992/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5248/7440 [====================>.........] - ETA: 1s
5376/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 491us/step
current Test accuracy: 0.8198924731182796
current auc_score ------------------>  0.9056854838709678

  32/7440 [..............................] - ETA: 54:09
 128/7440 [..............................] - ETA: 13:25
 256/7440 [>.............................] - ETA: 6:37 
 384/7440 [>.............................] - ETA: 4:21
 512/7440 [=>............................] - ETA: 3:13
 640/7440 [=>............................] - ETA: 2:32
 768/7440 [==>...........................] - ETA: 2:05
 896/7440 [==>...........................] - ETA: 1:45
1024/7440 [===>..........................] - ETA: 1:31
1152/7440 [===>..........................] - ETA: 1:19
1280/7440 [====>.........................] - ETA: 1:10
1408/7440 [====>.........................] - ETA: 1:03
1536/7440 [=====>........................] - ETA: 56s 
1664/7440 [=====>........................] - ETA: 51s
1792/7440 [======>.......................] - ETA: 47s
1920/7440 [======>.......................] - ETA: 43s
2048/7440 [=======>......................] - ETA: 39s
2176/7440 [=======>......................] - ETA: 36s
2304/7440 [========>.....................] - ETA: 33s
2432/7440 [========>.....................] - ETA: 31s
2560/7440 [=========>....................] - ETA: 29s
2688/7440 [=========>....................] - ETA: 27s
2816/7440 [==========>...................] - ETA: 25s
2944/7440 [==========>...................] - ETA: 23s
3072/7440 [===========>..................] - ETA: 22s
3200/7440 [===========>..................] - ETA: 20s
3328/7440 [============>.................] - ETA: 19s
3456/7440 [============>.................] - ETA: 18s
3584/7440 [=============>................] - ETA: 17s
3712/7440 [=============>................] - ETA: 15s
3840/7440 [==============>...............] - ETA: 14s
3968/7440 [===============>..............] - ETA: 13s
4096/7440 [===============>..............] - ETA: 13s
4224/7440 [================>.............] - ETA: 12s
4352/7440 [================>.............] - ETA: 11s
4480/7440 [=================>............] - ETA: 10s
4608/7440 [=================>............] - ETA: 10s
4736/7440 [==================>...........] - ETA: 9s 
4864/7440 [==================>...........] - ETA: 8s
4992/7440 [===================>..........] - ETA: 8s
5120/7440 [===================>..........] - ETA: 7s
5248/7440 [====================>.........] - ETA: 6s
5376/7440 [====================>.........] - ETA: 6s
5504/7440 [=====================>........] - ETA: 5s
5632/7440 [=====================>........] - ETA: 5s
5760/7440 [======================>.......] - ETA: 4s
5888/7440 [======================>.......] - ETA: 4s
6016/7440 [=======================>......] - ETA: 4s
6144/7440 [=======================>......] - ETA: 3s
6272/7440 [========================>.....] - ETA: 3s
6400/7440 [========================>.....] - ETA: 2s
6528/7440 [=========================>....] - ETA: 2s
6656/7440 [=========================>....] - ETA: 2s
6784/7440 [==========================>...] - ETA: 1s
6912/7440 [==========================>...] - ETA: 1s
7040/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 18s 2ms/step
Best saved model Test accuracy: 0.8172043010752689
best saved model auc_score ------------------>  0.8966767834431725
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_23[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_409 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 64, 96, 96)   1024        activation_409[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_410 (Activation)     (None, 64, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_410[0][0]             
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 32, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 32, 96, 96)   128         concatenate_172[0][0]            
__________________________________________________________________________________________________
activation_411 (Activation)     (None, 32, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 64, 96, 96)   2048        activation_411[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_412 (Activation)     (None, 64, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_412[0][0]             
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 48, 96, 96)   0           concatenate_172[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 48, 96, 96)   192         concatenate_173[0][0]            
__________________________________________________________________________________________________
activation_413 (Activation)     (None, 48, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 64, 96, 96)   3072        activation_413[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_414 (Activation)     (None, 64, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_414[0][0]             
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 64, 96, 96)   0           concatenate_173[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 64, 96, 96)   256         concatenate_174[0][0]            
__________________________________________________________________________________________________
activation_415 (Activation)     (None, 64, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 64, 96, 96)   4096        activation_415[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_416 (Activation)     (None, 64, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_416[0][0]             
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 80, 96, 96)   0           concatenate_174[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 80, 96, 96)   320         concatenate_175[0][0]            
__________________________________________________________________________________________________
activation_417 (Activation)     (None, 80, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 64, 96, 96)   5120        activation_417[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_418 (Activation)     (None, 64, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_418[0][0]             
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 96, 96, 96)   0           concatenate_175[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 96, 96, 96)   384         concatenate_176[0][0]            
__________________________________________________________________________________________________
activation_419 (Activation)     (None, 96, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 48, 96, 96)   4608        activation_419[0][0]             
__________________________________________________________________________________________________
average_pooling2d_45 (AveragePo (None, 48, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 48, 48, 48)   192         average_pooling2d_45[0][0]       
__________________________________________________________________________________________________
activation_420 (Activation)     (None, 48, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 64, 48, 48)   3072        activation_420[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_421 (Activation)     (None, 64, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_421[0][0]             
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 64, 48, 48)   0           average_pooling2d_45[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 48, 48)   256         concatenate_177[0][0]            
__________________________________________________________________________________________________
activation_422 (Activation)     (None, 64, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 64, 48, 48)   4096        activation_422[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_423 (Activation)     (None, 64, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_423[0][0]             
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 80, 48, 48)   0           concatenate_177[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 48, 48)   320         concatenate_178[0][0]            
__________________________________________________________________________________________________
activation_424 (Activation)     (None, 80, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 64, 48, 48)   5120        activation_424[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_425 (Activation)     (None, 64, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_425[0][0]             
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 96, 48, 48)   0           concatenate_178[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 96, 48, 48)   384         concatenate_179[0][0]            
__________________________________________________________________________________________________
activation_426 (Activation)     (None, 96, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 64, 48, 48)   6144        activation_426[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_427 (Activation)     (None, 64, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_427[0][0]             
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 112, 48, 48)  0           concatenate_179[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 112, 48, 48)  448         concatenate_180[0][0]            
__________________________________________________________________________________________________
activation_428 (Activation)     (None, 112, 48, 48)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 64, 48, 48)   7168        activation_428[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_429 (Activation)     (None, 64, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_429[0][0]             
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 128, 48, 48)  0           concatenate_180[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 128, 48, 48)  512         concatenate_181[0][0]            
__________________________________________________________________________________________________
activation_430 (Activation)     (None, 128, 48, 48)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 64, 48, 48)   8192        activation_430[0][0]             
__________________________________________________________________________________________________
average_pooling2d_46 (AveragePo (None, 64, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         average_pooling2d_46[0][0]       
__________________________________________________________________________________________________
activation_431 (Activation)     (None, 64, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 64, 24, 24)   4096        activation_431[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_432 (Activation)     (None, 64, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_432[0][0]             
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 80, 24, 24)   0           average_pooling2d_46[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 80, 24, 24)   320         concatenate_182[0][0]            
__________________________________________________________________________________________________
activation_433 (Activation)     (None, 80, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 64, 24, 24)   5120        activation_433[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_434 (Activation)     (None, 64, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_434[0][0]             
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 96, 24, 24)   0           concatenate_182[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 96, 24, 24)   384         concatenate_183[0][0]            
__________________________________________________________________________________________________
activation_435 (Activation)     (None, 96, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 64, 24, 24)   6144        activation_435[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_436 (Activation)     (None, 64, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_436[0][0]             
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 112, 24, 24)  0           concatenate_183[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_184[0][0]            
__________________________________________________________________________________________________
activation_437 (Activation)     (None, 112, 24, 24)  0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 64, 24, 24)   7168        activation_437[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_438 (Activation)     (None, 64, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_438[0][0]             
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 128, 24, 24)  0           concatenate_184[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 128, 24, 24)  512         concatenate_185[0][0]            
__________________________________________________________________________________________________
activation_439 (Activation)     (None, 128, 24, 24)  0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 64, 24, 24)   8192        activation_439[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_440 (Activation)     (None, 64, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_440[0][0]             
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 144, 24, 24)  0           concatenate_185[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 144, 24, 24)  576         concatenate_186[0][0]            
__________________________________________________________________________________________________
activation_441 (Activation)     (None, 144, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_23 (Gl (None, 144)          0           activation_441[0][0]             
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 1)            145         global_average_pooling2d_23[0][0]
==================================================================================================
Total params: 232,945
Trainable params: 228,049
Non-trainable params: 4,896
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 129s - loss: 0.6267 - acc: 0.7937 - val_loss: 0.7881 - val_acc: 0.7921

Epoch 00001: val_loss improved from inf to 0.78814, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 91s - loss: 0.5028 - acc: 0.8533 - val_loss: 0.8191 - val_acc: 0.7429

Epoch 00002: val_loss did not improve from 0.78814
Epoch 3/30
 - 91s - loss: 0.4347 - acc: 0.8832 - val_loss: 0.5750 - val_acc: 0.8234

Epoch 00003: val_loss improved from 0.78814 to 0.57503, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 91s - loss: 0.3832 - acc: 0.9068 - val_loss: 0.7752 - val_acc: 0.7664

Epoch 00004: val_loss did not improve from 0.57503
Epoch 5/30
 - 91s - loss: 0.3476 - acc: 0.9209 - val_loss: 0.8563 - val_acc: 0.7547

Epoch 00005: val_loss did not improve from 0.57503
Epoch 6/30
 - 90s - loss: 0.3189 - acc: 0.9323 - val_loss: 0.5625 - val_acc: 0.8427

Epoch 00006: val_loss improved from 0.57503 to 0.56253, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 91s - loss: 0.2930 - acc: 0.9422 - val_loss: 0.7384 - val_acc: 0.7946

Epoch 00007: val_loss did not improve from 0.56253
Epoch 8/30
 - 91s - loss: 0.2716 - acc: 0.9497 - val_loss: 0.7050 - val_acc: 0.8133

Epoch 00008: val_loss did not improve from 0.56253
Epoch 9/30
 - 91s - loss: 0.2538 - acc: 0.9565 - val_loss: 0.8118 - val_acc: 0.7931

Epoch 00009: val_loss did not improve from 0.56253
Epoch 10/30
 - 91s - loss: 0.2358 - acc: 0.9619 - val_loss: 1.2729 - val_acc: 0.7032

Epoch 00010: val_loss did not improve from 0.56253
Epoch 11/30
 - 91s - loss: 0.2255 - acc: 0.9651 - val_loss: 0.9883 - val_acc: 0.8032

Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00011: val_loss did not improve from 0.56253
Epoch 00011: early stopping

  32/7440 [..............................] - ETA: 9s
  96/7440 [..............................] - ETA: 7s
 160/7440 [..............................] - ETA: 7s
 224/7440 [..............................] - ETA: 7s
 288/7440 [>.............................] - ETA: 6s
 352/7440 [>.............................] - ETA: 6s
 416/7440 [>.............................] - ETA: 6s
 480/7440 [>.............................] - ETA: 6s
 544/7440 [=>............................] - ETA: 6s
 608/7440 [=>............................] - ETA: 6s
 672/7440 [=>............................] - ETA: 6s
 736/7440 [=>............................] - ETA: 6s
 800/7440 [==>...........................] - ETA: 6s
 864/7440 [==>...........................] - ETA: 5s
 928/7440 [==>...........................] - ETA: 5s
 992/7440 [===>..........................] - ETA: 5s
1056/7440 [===>..........................] - ETA: 5s
1120/7440 [===>..........................] - ETA: 5s
1184/7440 [===>..........................] - ETA: 5s
1248/7440 [====>.........................] - ETA: 5s
1312/7440 [====>.........................] - ETA: 5s
1376/7440 [====>.........................] - ETA: 5s
1440/7440 [====>.........................] - ETA: 5s
1504/7440 [=====>........................] - ETA: 5s
1568/7440 [=====>........................] - ETA: 5s
1632/7440 [=====>........................] - ETA: 5s
1696/7440 [=====>........................] - ETA: 5s
1760/7440 [======>.......................] - ETA: 5s
1824/7440 [======>.......................] - ETA: 5s
1888/7440 [======>.......................] - ETA: 5s
1952/7440 [======>.......................] - ETA: 4s
2016/7440 [=======>......................] - ETA: 4s
2080/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 4s
2208/7440 [=======>......................] - ETA: 4s
2272/7440 [========>.....................] - ETA: 4s
2336/7440 [========>.....................] - ETA: 4s
2400/7440 [========>.....................] - ETA: 4s
2464/7440 [========>.....................] - ETA: 4s
2528/7440 [=========>....................] - ETA: 4s
2592/7440 [=========>....................] - ETA: 4s
2656/7440 [=========>....................] - ETA: 4s
2720/7440 [=========>....................] - ETA: 4s
2784/7440 [==========>...................] - ETA: 4s
2848/7440 [==========>...................] - ETA: 4s
2912/7440 [==========>...................] - ETA: 4s
2976/7440 [===========>..................] - ETA: 4s
3040/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3168/7440 [===========>..................] - ETA: 3s
3232/7440 [============>.................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3360/7440 [============>.................] - ETA: 3s
3424/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 3s
3552/7440 [=============>................] - ETA: 3s
3616/7440 [=============>................] - ETA: 3s
3680/7440 [=============>................] - ETA: 3s
3744/7440 [==============>...............] - ETA: 3s
3808/7440 [==============>...............] - ETA: 3s
3872/7440 [==============>...............] - ETA: 3s
3936/7440 [==============>...............] - ETA: 3s
4000/7440 [===============>..............] - ETA: 3s
4064/7440 [===============>..............] - ETA: 3s
4128/7440 [===============>..............] - ETA: 2s
4192/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4320/7440 [================>.............] - ETA: 2s
4384/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 2s
4576/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4704/7440 [=================>............] - ETA: 2s
4768/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4896/7440 [==================>...........] - ETA: 2s
4960/7440 [===================>..........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 2s
5088/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 2s
5216/7440 [====================>.........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5344/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5728/7440 [======================>.......] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5856/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6048/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6240/7440 [========================>.....] - ETA: 1s
6304/7440 [========================>.....] - ETA: 1s
6368/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 7s 895us/step
current Test accuracy: 0.8032258064516129
current auc_score ------------------>  0.9165615605850388

  32/7440 [..............................] - ETA: 1:00:15
  96/7440 [..............................] - ETA: 20:00  
 160/7440 [..............................] - ETA: 11:56
 224/7440 [..............................] - ETA: 8:29 
 288/7440 [>.............................] - ETA: 6:33
 352/7440 [>.............................] - ETA: 5:20
 416/7440 [>.............................] - ETA: 4:29
 480/7440 [>.............................] - ETA: 3:52
 544/7440 [=>............................] - ETA: 3:23
 608/7440 [=>............................] - ETA: 3:01
 672/7440 [=>............................] - ETA: 2:43
 736/7440 [=>............................] - ETA: 2:28
 800/7440 [==>...........................] - ETA: 2:15
 864/7440 [==>...........................] - ETA: 2:04
 928/7440 [==>...........................] - ETA: 1:55
 992/7440 [===>..........................] - ETA: 1:47
1056/7440 [===>..........................] - ETA: 1:40
1120/7440 [===>..........................] - ETA: 1:33
1184/7440 [===>..........................] - ETA: 1:28
1248/7440 [====>.........................] - ETA: 1:22
1312/7440 [====>.........................] - ETA: 1:18
1376/7440 [====>.........................] - ETA: 1:14
1440/7440 [====>.........................] - ETA: 1:10
1504/7440 [=====>........................] - ETA: 1:06
1568/7440 [=====>........................] - ETA: 1:03
1632/7440 [=====>........................] - ETA: 1:00
1696/7440 [=====>........................] - ETA: 57s 
1760/7440 [======>.......................] - ETA: 55s
1824/7440 [======>.......................] - ETA: 53s
1888/7440 [======>.......................] - ETA: 50s
1952/7440 [======>.......................] - ETA: 48s
2016/7440 [=======>......................] - ETA: 46s
2080/7440 [=======>......................] - ETA: 44s
2144/7440 [=======>......................] - ETA: 43s
2208/7440 [=======>......................] - ETA: 41s
2272/7440 [========>.....................] - ETA: 40s
2336/7440 [========>.....................] - ETA: 38s
2400/7440 [========>.....................] - ETA: 37s
2464/7440 [========>.....................] - ETA: 35s
2528/7440 [=========>....................] - ETA: 34s
2592/7440 [=========>....................] - ETA: 33s
2656/7440 [=========>....................] - ETA: 32s
2720/7440 [=========>....................] - ETA: 31s
2784/7440 [==========>...................] - ETA: 30s
2848/7440 [==========>...................] - ETA: 29s
2912/7440 [==========>...................] - ETA: 28s
2976/7440 [===========>..................] - ETA: 27s
3040/7440 [===========>..................] - ETA: 26s
3104/7440 [===========>..................] - ETA: 25s
3168/7440 [===========>..................] - ETA: 24s
3232/7440 [============>.................] - ETA: 24s
3296/7440 [============>.................] - ETA: 23s
3360/7440 [============>.................] - ETA: 22s
3424/7440 [============>.................] - ETA: 21s
3488/7440 [=============>................] - ETA: 21s
3552/7440 [=============>................] - ETA: 20s
3616/7440 [=============>................] - ETA: 19s
3680/7440 [=============>................] - ETA: 19s
3744/7440 [==============>...............] - ETA: 18s
3808/7440 [==============>...............] - ETA: 18s
3872/7440 [==============>...............] - ETA: 17s
3936/7440 [==============>...............] - ETA: 17s
4000/7440 [===============>..............] - ETA: 16s
4064/7440 [===============>..............] - ETA: 15s
4128/7440 [===============>..............] - ETA: 15s
4192/7440 [===============>..............] - ETA: 14s
4256/7440 [================>.............] - ETA: 14s
4320/7440 [================>.............] - ETA: 14s
4384/7440 [================>.............] - ETA: 13s
4448/7440 [================>.............] - ETA: 13s
4512/7440 [=================>............] - ETA: 12s
4576/7440 [=================>............] - ETA: 12s
4640/7440 [=================>............] - ETA: 11s
4704/7440 [=================>............] - ETA: 11s
4768/7440 [==================>...........] - ETA: 11s
4832/7440 [==================>...........] - ETA: 10s
4896/7440 [==================>...........] - ETA: 10s
4960/7440 [===================>..........] - ETA: 10s
5024/7440 [===================>..........] - ETA: 9s 
5088/7440 [===================>..........] - ETA: 9s
5152/7440 [===================>..........] - ETA: 8s
5216/7440 [====================>.........] - ETA: 8s
5280/7440 [====================>.........] - ETA: 8s
5344/7440 [====================>.........] - ETA: 7s
5408/7440 [====================>.........] - ETA: 7s
5472/7440 [=====================>........] - ETA: 7s
5536/7440 [=====================>........] - ETA: 7s
5600/7440 [=====================>........] - ETA: 6s
5664/7440 [=====================>........] - ETA: 6s
5728/7440 [======================>.......] - ETA: 6s
5792/7440 [======================>.......] - ETA: 5s
5856/7440 [======================>.......] - ETA: 5s
5920/7440 [======================>.......] - ETA: 5s
5984/7440 [=======================>......] - ETA: 5s
6048/7440 [=======================>......] - ETA: 4s
6112/7440 [=======================>......] - ETA: 4s
6176/7440 [=======================>......] - ETA: 4s
6240/7440 [========================>.....] - ETA: 4s
6304/7440 [========================>.....] - ETA: 3s
6368/7440 [========================>.....] - ETA: 3s
6432/7440 [========================>.....] - ETA: 3s
6496/7440 [=========================>....] - ETA: 3s
6560/7440 [=========================>....] - ETA: 2s
6624/7440 [=========================>....] - ETA: 2s
6688/7440 [=========================>....] - ETA: 2s
6752/7440 [==========================>...] - ETA: 2s
6816/7440 [==========================>...] - ETA: 1s
6880/7440 [==========================>...] - ETA: 1s
6944/7440 [===========================>..] - ETA: 1s
7008/7440 [===========================>..] - ETA: 1s
7072/7440 [===========================>..] - ETA: 1s
7136/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 22s 3ms/step
Best saved model Test accuracy: 0.842741935483871
best saved model auc_score ------------------>  0.9265168299803447
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_24 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_24[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_442 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 64, 96, 96)   1024        activation_442[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_443 (Activation)     (None, 64, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_443[0][0]             
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 32, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 32, 96, 96)   128         concatenate_187[0][0]            
__________________________________________________________________________________________________
activation_444 (Activation)     (None, 32, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 64, 96, 96)   2048        activation_444[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_445 (Activation)     (None, 64, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_445[0][0]             
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 48, 96, 96)   0           concatenate_187[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 48, 96, 96)   192         concatenate_188[0][0]            
__________________________________________________________________________________________________
activation_446 (Activation)     (None, 48, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 64, 96, 96)   3072        activation_446[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_447 (Activation)     (None, 64, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_447[0][0]             
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 64, 96, 96)   0           concatenate_188[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 64, 96, 96)   256         concatenate_189[0][0]            
__________________________________________________________________________________________________
activation_448 (Activation)     (None, 64, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 64, 96, 96)   4096        activation_448[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_449 (Activation)     (None, 64, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_449[0][0]             
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 80, 96, 96)   0           concatenate_189[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 80, 96, 96)   320         concatenate_190[0][0]            
__________________________________________________________________________________________________
activation_450 (Activation)     (None, 80, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 64, 96, 96)   5120        activation_450[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 64, 96, 96)   256         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_451 (Activation)     (None, 64, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 16, 96, 96)   9216        activation_451[0][0]             
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 96, 96, 96)   0           concatenate_190[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 96, 96, 96)   384         concatenate_191[0][0]            
__________________________________________________________________________________________________
activation_452 (Activation)     (None, 96, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 48, 96, 96)   4608        activation_452[0][0]             
__________________________________________________________________________________________________
average_pooling2d_47 (AveragePo (None, 48, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 48, 48, 48)   192         average_pooling2d_47[0][0]       
__________________________________________________________________________________________________
activation_453 (Activation)     (None, 48, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 64, 48, 48)   3072        activation_453[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_454 (Activation)     (None, 64, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_454[0][0]             
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 64, 48, 48)   0           average_pooling2d_47[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 48, 48)   256         concatenate_192[0][0]            
__________________________________________________________________________________________________
activation_455 (Activation)     (None, 64, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 64, 48, 48)   4096        activation_455[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_456 (Activation)     (None, 64, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_456[0][0]             
__________________________________________________________________________________________________
concatenate_193 (Concatenate)   (None, 80, 48, 48)   0           concatenate_192[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 48, 48)   320         concatenate_193[0][0]            
__________________________________________________________________________________________________
activation_457 (Activation)     (None, 80, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 64, 48, 48)   5120        activation_457[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_458 (Activation)     (None, 64, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_458[0][0]             
__________________________________________________________________________________________________
concatenate_194 (Concatenate)   (None, 96, 48, 48)   0           concatenate_193[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 96, 48, 48)   384         concatenate_194[0][0]            
__________________________________________________________________________________________________
activation_459 (Activation)     (None, 96, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 64, 48, 48)   6144        activation_459[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_460 (Activation)     (None, 64, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_460[0][0]             
__________________________________________________________________________________________________
concatenate_195 (Concatenate)   (None, 112, 48, 48)  0           concatenate_194[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 112, 48, 48)  448         concatenate_195[0][0]            
__________________________________________________________________________________________________
activation_461 (Activation)     (None, 112, 48, 48)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 64, 48, 48)   7168        activation_461[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 64, 48, 48)   256         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_462 (Activation)     (None, 64, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 16, 48, 48)   9216        activation_462[0][0]             
__________________________________________________________________________________________________
concatenate_196 (Concatenate)   (None, 128, 48, 48)  0           concatenate_195[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 128, 48, 48)  512         concatenate_196[0][0]            
__________________________________________________________________________________________________
activation_463 (Activation)     (None, 128, 48, 48)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 64, 48, 48)   8192        activation_463[0][0]             
__________________________________________________________________________________________________
average_pooling2d_48 (AveragePo (None, 64, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         average_pooling2d_48[0][0]       
__________________________________________________________________________________________________
activation_464 (Activation)     (None, 64, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 64, 24, 24)   4096        activation_464[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_465 (Activation)     (None, 64, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_465[0][0]             
__________________________________________________________________________________________________
concatenate_197 (Concatenate)   (None, 80, 24, 24)   0           average_pooling2d_48[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 80, 24, 24)   320         concatenate_197[0][0]            
__________________________________________________________________________________________________
activation_466 (Activation)     (None, 80, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 64, 24, 24)   5120        activation_466[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_467 (Activation)     (None, 64, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_467[0][0]             
__________________________________________________________________________________________________
concatenate_198 (Concatenate)   (None, 96, 24, 24)   0           concatenate_197[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 96, 24, 24)   384         concatenate_198[0][0]            
__________________________________________________________________________________________________
activation_468 (Activation)     (None, 96, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 64, 24, 24)   6144        activation_468[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_469 (Activation)     (None, 64, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_469[0][0]             
__________________________________________________________________________________________________
concatenate_199 (Concatenate)   (None, 112, 24, 24)  0           concatenate_198[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_199[0][0]            
__________________________________________________________________________________________________
activation_470 (Activation)     (None, 112, 24, 24)  0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 64, 24, 24)   7168        activation_470[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_471 (Activation)     (None, 64, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_471[0][0]             
__________________________________________________________________________________________________
concatenate_200 (Concatenate)   (None, 128, 24, 24)  0           concatenate_199[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 128, 24, 24)  512         concatenate_200[0][0]            
__________________________________________________________________________________________________
activation_472 (Activation)     (None, 128, 24, 24)  0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 64, 24, 24)   8192        activation_472[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 64, 24, 24)   256         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_473 (Activation)     (None, 64, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 16, 24, 24)   9216        activation_473[0][0]             
__________________________________________________________________________________________________
concatenate_201 (Concatenate)   (None, 144, 24, 24)  0           concatenate_200[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 144, 24, 24)  576         concatenate_201[0][0]            
__________________________________________________________________________________________________
activation_474 (Activation)     (None, 144, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_24 (Gl (None, 144)          0           activation_474[0][0]             
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 1)            145         global_average_pooling2d_24[0][0]
==================================================================================================
Total params: 232,945
Trainable params: 228,049
Non-trainable params: 4,896
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/30
 - 133s - loss: 0.6337 - acc: 0.7900 - val_loss: 0.9519 - val_acc: 0.6680

Epoch 00001: val_loss improved from inf to 0.95192, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 2/30
 - 91s - loss: 0.5071 - acc: 0.8530 - val_loss: 0.9392 - val_acc: 0.7433

Epoch 00002: val_loss improved from 0.95192 to 0.93917, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 3/30
 - 92s - loss: 0.4333 - acc: 0.8879 - val_loss: 0.6126 - val_acc: 0.8152

Epoch 00003: val_loss improved from 0.93917 to 0.61259, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 4/30
 - 91s - loss: 0.3844 - acc: 0.9082 - val_loss: 0.5999 - val_acc: 0.8324

Epoch 00004: val_loss improved from 0.61259 to 0.59993, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 5/30
 - 91s - loss: 0.3462 - acc: 0.9236 - val_loss: 0.8480 - val_acc: 0.7554

Epoch 00005: val_loss did not improve from 0.59993
Epoch 6/30
 - 91s - loss: 0.3140 - acc: 0.9356 - val_loss: 0.5268 - val_acc: 0.8352

Epoch 00006: val_loss improved from 0.59993 to 0.52675, saving model to keras_densenet_simple_wt_28Sept_519am.h5
Epoch 7/30
 - 91s - loss: 0.2866 - acc: 0.9473 - val_loss: 0.6516 - val_acc: 0.8141

Epoch 00007: val_loss did not improve from 0.52675
Epoch 8/30
 - 91s - loss: 0.2722 - acc: 0.9510 - val_loss: 0.8229 - val_acc: 0.7765

Epoch 00008: val_loss did not improve from 0.52675
Epoch 9/30
 - 91s - loss: 0.2540 - acc: 0.9573 - val_loss: 0.8891 - val_acc: 0.7325

Epoch 00009: val_loss did not improve from 0.52675
Epoch 10/30
 - 91s - loss: 0.2391 - acc: 0.9624 - val_loss: 1.0238 - val_acc: 0.7622

Epoch 00010: val_loss did not improve from 0.52675
Epoch 11/30
 - 91s - loss: 0.2233 - acc: 0.9679 - val_loss: 0.9757 - val_acc: 0.7804

Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.486833431105525e-05.

Epoch 00011: val_loss did not improve from 0.52675
Epoch 00011: early stopping

  32/7440 [..............................] - ETA: 8s
  96/7440 [..............................] - ETA: 7s
 160/7440 [..............................] - ETA: 7s
 224/7440 [..............................] - ETA: 6s
 288/7440 [>.............................] - ETA: 6s
 352/7440 [>.............................] - ETA: 6s
 416/7440 [>.............................] - ETA: 6s
 480/7440 [>.............................] - ETA: 6s
 544/7440 [=>............................] - ETA: 6s
 608/7440 [=>............................] - ETA: 6s
 672/7440 [=>............................] - ETA: 6s
 736/7440 [=>............................] - ETA: 6s
 800/7440 [==>...........................] - ETA: 6s
 864/7440 [==>...........................] - ETA: 6s
 928/7440 [==>...........................] - ETA: 5s
 992/7440 [===>..........................] - ETA: 5s
1056/7440 [===>..........................] - ETA: 5s
1120/7440 [===>..........................] - ETA: 5s
1184/7440 [===>..........................] - ETA: 5s
1248/7440 [====>.........................] - ETA: 5s
1312/7440 [====>.........................] - ETA: 5s
1376/7440 [====>.........................] - ETA: 5s
1440/7440 [====>.........................] - ETA: 5s
1504/7440 [=====>........................] - ETA: 5s
1568/7440 [=====>........................] - ETA: 5s
1632/7440 [=====>........................] - ETA: 5s
1696/7440 [=====>........................] - ETA: 5s
1760/7440 [======>.......................] - ETA: 5s
1824/7440 [======>.......................] - ETA: 5s
1888/7440 [======>.......................] - ETA: 5s
1952/7440 [======>.......................] - ETA: 4s
2016/7440 [=======>......................] - ETA: 4s
2080/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 4s
2208/7440 [=======>......................] - ETA: 4s
2272/7440 [========>.....................] - ETA: 4s
2336/7440 [========>.....................] - ETA: 4s
2400/7440 [========>.....................] - ETA: 4s
2464/7440 [========>.....................] - ETA: 4s
2528/7440 [=========>....................] - ETA: 4s
2592/7440 [=========>....................] - ETA: 4s
2656/7440 [=========>....................] - ETA: 4s
2720/7440 [=========>....................] - ETA: 4s
2784/7440 [==========>...................] - ETA: 4s
2848/7440 [==========>...................] - ETA: 4s
2912/7440 [==========>...................] - ETA: 4s
2976/7440 [===========>..................] - ETA: 4s
3040/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3168/7440 [===========>..................] - ETA: 3s
3232/7440 [============>.................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3360/7440 [============>.................] - ETA: 3s
3424/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 3s
3552/7440 [=============>................] - ETA: 3s
3616/7440 [=============>................] - ETA: 3s
3680/7440 [=============>................] - ETA: 3s
3744/7440 [==============>...............] - ETA: 3s
3808/7440 [==============>...............] - ETA: 3s
3872/7440 [==============>...............] - ETA: 3s
3936/7440 [==============>...............] - ETA: 3s
4000/7440 [===============>..............] - ETA: 3s
4064/7440 [===============>..............] - ETA: 3s
4128/7440 [===============>..............] - ETA: 3s
4192/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4320/7440 [================>.............] - ETA: 2s
4384/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 2s
4576/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4704/7440 [=================>............] - ETA: 2s
4768/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4896/7440 [==================>...........] - ETA: 2s
4960/7440 [===================>..........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 2s
5088/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 2s
5216/7440 [====================>.........] - ETA: 2s
5280/7440 [====================>.........] - ETA: 1s
5344/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5728/7440 [======================>.......] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5856/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6048/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6240/7440 [========================>.....] - ETA: 1s
6304/7440 [========================>.....] - ETA: 1s
6368/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 7s 905us/step
