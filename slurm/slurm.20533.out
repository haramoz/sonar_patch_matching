python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
Column names are layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs
['2', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.3981 - acc: 0.8339 - val_loss: 0.2125 - val_acc: 0.9324
Epoch 2/5
 - 16s - loss: 0.1810 - acc: 0.9391 - val_loss: 0.1165 - val_acc: 0.9728
Epoch 3/5
 - 17s - loss: 0.1123 - acc: 0.9698 - val_loss: 0.0768 - val_acc: 0.9789
Epoch 4/5
 - 16s - loss: 0.0819 - acc: 0.9803 - val_loss: 0.0549 - val_acc: 0.9898
Epoch 5/5
 - 17s - loss: 0.0608 - acc: 0.9877 - val_loss: 0.0494 - val_acc: 0.9922
Test accuracy:0.645
current auc_score ------------------> 0.849
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.3867 - acc: 0.8381 - val_loss: 0.2132 - val_acc: 0.9224
Epoch 2/5
 - 17s - loss: 0.1721 - acc: 0.9445 - val_loss: 0.1036 - val_acc: 0.9760
Epoch 3/5
 - 17s - loss: 0.1088 - acc: 0.9706 - val_loss: 0.0792 - val_acc: 0.9853
Epoch 4/5
 - 17s - loss: 0.0759 - acc: 0.9824 - val_loss: 0.0795 - val_acc: 0.9837
Epoch 5/5
 - 17s - loss: 0.0616 - acc: 0.9871 - val_loss: 0.0481 - val_acc: 0.9955
Test accuracy:0.661
current auc_score ------------------> 0.896
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.4075 - acc: 0.8317 - val_loss: 0.2084 - val_acc: 0.9223
Epoch 2/5
 - 16s - loss: 0.1772 - acc: 0.9395 - val_loss: 0.1148 - val_acc: 0.9778
Epoch 3/5
 - 16s - loss: 0.1062 - acc: 0.9711 - val_loss: 0.0721 - val_acc: 0.9868
Epoch 4/5
 - 16s - loss: 0.0699 - acc: 0.9840 - val_loss: 0.0502 - val_acc: 0.9945
Epoch 5/5
 - 16s - loss: 0.0516 - acc: 0.9896 - val_loss: 0.0379 - val_acc: 0.9940
Test accuracy:0.700
current auc_score ------------------> 0.878
accuracies:  [0.6448924731182796, 0.660752688172043, 0.7001344086021506]
['2', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 21s - loss: 0.4264 - acc: 0.8250 - val_loss: 0.2379 - val_acc: 0.9236
Epoch 2/5
 - 18s - loss: 0.2014 - acc: 0.9357 - val_loss: 0.1223 - val_acc: 0.9723
Epoch 3/5
 - 17s - loss: 0.1237 - acc: 0.9691 - val_loss: 0.0820 - val_acc: 0.9822
Epoch 4/5
 - 18s - loss: 0.0897 - acc: 0.9812 - val_loss: 0.0617 - val_acc: 0.9927
Epoch 5/5
 - 17s - loss: 0.0705 - acc: 0.9869 - val_loss: 0.0524 - val_acc: 0.9937
Test accuracy:0.700
current auc_score ------------------> 0.861
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4470 - acc: 0.8108 - val_loss: 0.2435 - val_acc: 0.9183
Epoch 2/5
 - 17s - loss: 0.1991 - acc: 0.9342 - val_loss: 0.1364 - val_acc: 0.9622
Epoch 3/5
 - 17s - loss: 0.1277 - acc: 0.9669 - val_loss: 0.0859 - val_acc: 0.9838
Epoch 4/5
 - 17s - loss: 0.0919 - acc: 0.9800 - val_loss: 0.0643 - val_acc: 0.9868
Epoch 5/5
 - 17s - loss: 0.0687 - acc: 0.9870 - val_loss: 0.0522 - val_acc: 0.9942
Test accuracy:0.727
current auc_score ------------------> 0.882
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4504 - acc: 0.8086 - val_loss: 0.2585 - val_acc: 0.9101
Epoch 2/5
 - 18s - loss: 0.2032 - acc: 0.9357 - val_loss: 0.1290 - val_acc: 0.9716
Epoch 3/5
 - 18s - loss: 0.1243 - acc: 0.9693 - val_loss: 0.0882 - val_acc: 0.9828
Epoch 4/5
 - 18s - loss: 0.0864 - acc: 0.9825 - val_loss: 0.0613 - val_acc: 0.9905
Epoch 5/5
 - 18s - loss: 0.0646 - acc: 0.9894 - val_loss: 0.0458 - val_acc: 0.9961
Test accuracy:0.727
current auc_score ------------------> 0.878
accuracies:  [0.7, 0.7272849462365591, 0.7270161290322581]
['2', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 21s - loss: 0.4316 - acc: 0.8238 - val_loss: 0.2393 - val_acc: 0.9265
Epoch 2/5
 - 18s - loss: 0.1950 - acc: 0.9425 - val_loss: 0.1178 - val_acc: 0.9735
Epoch 3/5
 - 18s - loss: 0.1181 - acc: 0.9746 - val_loss: 0.0805 - val_acc: 0.9869
Epoch 4/5
 - 18s - loss: 0.0844 - acc: 0.9857 - val_loss: 0.0563 - val_acc: 0.9925
Epoch 5/5
 - 18s - loss: 0.0660 - acc: 0.9916 - val_loss: 0.0484 - val_acc: 0.9950
Test accuracy:0.701
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.4749 - acc: 0.8005 - val_loss: 0.2542 - val_acc: 0.9139
Epoch 2/5
 - 19s - loss: 0.2273 - acc: 0.9280 - val_loss: 0.1571 - val_acc: 0.9636
Epoch 3/5
 - 19s - loss: 0.1427 - acc: 0.9668 - val_loss: 0.0993 - val_acc: 0.9881
Epoch 4/5
 - 19s - loss: 0.0987 - acc: 0.9818 - val_loss: 0.0695 - val_acc: 0.9895
Epoch 5/5
 - 19s - loss: 0.0740 - acc: 0.9884 - val_loss: 0.0579 - val_acc: 0.9931
Test accuracy:0.701
current auc_score ------------------> 0.903
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 21s - loss: 0.4625 - acc: 0.8090 - val_loss: 0.2595 - val_acc: 0.9093
Epoch 2/5
 - 19s - loss: 0.2179 - acc: 0.9302 - val_loss: 0.1551 - val_acc: 0.9705
Epoch 3/5
 - 19s - loss: 0.1285 - acc: 0.9714 - val_loss: 0.0869 - val_acc: 0.9878
Epoch 4/5
 - 19s - loss: 0.0895 - acc: 0.9838 - val_loss: 0.0709 - val_acc: 0.9880
Epoch 5/5
 - 19s - loss: 0.0721 - acc: 0.9900 - val_loss: 0.0521 - val_acc: 0.9955
Test accuracy:0.692
current auc_score ------------------> 0.876
accuracies:  [0.7006720430107527, 0.7013440860215053, 0.6916666666666667]
['3', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.4397 - acc: 0.8136 - val_loss: 0.2296 - val_acc: 0.9178
Epoch 2/5
 - 20s - loss: 0.1938 - acc: 0.9358 - val_loss: 0.1319 - val_acc: 0.9639
Epoch 3/5
 - 20s - loss: 0.1197 - acc: 0.9686 - val_loss: 0.0848 - val_acc: 0.9824
Epoch 4/5
 - 20s - loss: 0.0856 - acc: 0.9807 - val_loss: 0.0553 - val_acc: 0.9908
Epoch 5/5
 - 19s - loss: 0.0646 - acc: 0.9872 - val_loss: 0.0473 - val_acc: 0.9903
Test accuracy:0.713
current auc_score ------------------> 0.858
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 23s - loss: 0.4150 - acc: 0.8287 - val_loss: 0.2173 - val_acc: 0.9324
Epoch 2/5
 - 20s - loss: 0.1920 - acc: 0.9368 - val_loss: 0.1192 - val_acc: 0.9695
Epoch 3/5
 - 20s - loss: 0.1159 - acc: 0.9695 - val_loss: 0.0728 - val_acc: 0.9843
Epoch 4/5
 - 20s - loss: 0.0807 - acc: 0.9829 - val_loss: 0.0613 - val_acc: 0.9883
Epoch 5/5
 - 20s - loss: 0.0679 - acc: 0.9858 - val_loss: 0.0482 - val_acc: 0.9931
Test accuracy:0.706
current auc_score ------------------> 0.865
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 23s - loss: 0.4186 - acc: 0.8266 - val_loss: 0.2190 - val_acc: 0.9233
Epoch 2/5
 - 20s - loss: 0.2002 - acc: 0.9346 - val_loss: 0.1320 - val_acc: 0.9691
Epoch 3/5
 - 20s - loss: 0.1278 - acc: 0.9656 - val_loss: 0.0927 - val_acc: 0.9872
Epoch 4/5
 - 20s - loss: 0.0885 - acc: 0.9811 - val_loss: 0.0610 - val_acc: 0.9913
Epoch 5/5
 - 20s - loss: 0.0683 - acc: 0.9872 - val_loss: 0.0486 - val_acc: 0.9905
Test accuracy:0.693
current auc_score ------------------> 0.897
accuracies:  [0.7129032258064516, 0.7055107526881721, 0.6934139784946236]
['3', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 24s - loss: 0.4390 - acc: 0.8208 - val_loss: 0.2551 - val_acc: 0.9170
Epoch 2/5
 - 21s - loss: 0.2168 - acc: 0.9318 - val_loss: 0.1423 - val_acc: 0.9659
Epoch 3/5
 - 21s - loss: 0.1401 - acc: 0.9655 - val_loss: 0.1064 - val_acc: 0.9767
Epoch 4/5
 - 21s - loss: 0.0975 - acc: 0.9819 - val_loss: 0.0650 - val_acc: 0.9921
Epoch 5/5
 - 21s - loss: 0.0758 - acc: 0.9882 - val_loss: 0.0564 - val_acc: 0.9927
Test accuracy:0.742
current auc_score ------------------> 0.888
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 24s - loss: 0.4405 - acc: 0.8221 - val_loss: 0.2994 - val_acc: 0.8894
Epoch 2/5
 - 21s - loss: 0.2118 - acc: 0.9352 - val_loss: 0.1347 - val_acc: 0.9741
Epoch 3/5
 - 21s - loss: 0.1340 - acc: 0.9675 - val_loss: 0.0800 - val_acc: 0.9895
Epoch 4/5
 - 21s - loss: 0.0948 - acc: 0.9828 - val_loss: 0.0631 - val_acc: 0.9931
Epoch 5/5
 - 21s - loss: 0.0767 - acc: 0.9877 - val_loss: 0.0529 - val_acc: 0.9950
Test accuracy:0.661
current auc_score ------------------> 0.908
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 24s - loss: 0.4299 - acc: 0.8286 - val_loss: 0.2148 - val_acc: 0.9312
Epoch 2/5
 - 21s - loss: 0.1932 - acc: 0.9425 - val_loss: 0.1254 - val_acc: 0.9746
Epoch 3/5
 - 21s - loss: 0.1291 - acc: 0.9696 - val_loss: 0.0973 - val_acc: 0.9803
Epoch 4/5
 - 21s - loss: 0.0937 - acc: 0.9823 - val_loss: 0.0633 - val_acc: 0.9917
Epoch 5/5
 - 21s - loss: 0.0746 - acc: 0.9880 - val_loss: 0.0519 - val_acc: 0.9945
Test accuracy:0.697
current auc_score ------------------> 0.878
accuracies:  [0.7416666666666667, 0.6614247311827957, 0.6966397849462366]
['3', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.5247 - acc: 0.7816 - val_loss: 0.3085 - val_acc: 0.8996
Epoch 2/5
 - 22s - loss: 0.2564 - acc: 0.9196 - val_loss: 0.1560 - val_acc: 0.9718
Epoch 3/5
 - 22s - loss: 0.1614 - acc: 0.9629 - val_loss: 0.1048 - val_acc: 0.9829
Epoch 4/5
 - 22s - loss: 0.1192 - acc: 0.9779 - val_loss: 0.0873 - val_acc: 0.9933
Epoch 5/5
 - 22s - loss: 0.0933 - acc: 0.9871 - val_loss: 0.0682 - val_acc: 0.9945
Test accuracy:0.638
current auc_score ------------------> 0.873
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4855 - acc: 0.8016 - val_loss: 0.3512 - val_acc: 0.8607
Epoch 2/5
 - 22s - loss: 0.2460 - acc: 0.9247 - val_loss: 0.1622 - val_acc: 0.9651
Epoch 3/5
 - 22s - loss: 0.1431 - acc: 0.9711 - val_loss: 0.0912 - val_acc: 0.9902
Epoch 4/5
 - 22s - loss: 0.1024 - acc: 0.9846 - val_loss: 0.0796 - val_acc: 0.9901
Epoch 5/5
 - 22s - loss: 0.0817 - acc: 0.9900 - val_loss: 0.0685 - val_acc: 0.9940
Test accuracy:0.560
current auc_score ------------------> 0.877
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.5456 - acc: 0.7715 - val_loss: 0.3619 - val_acc: 0.8632
Epoch 2/5
 - 22s - loss: 0.2904 - acc: 0.9048 - val_loss: 0.1964 - val_acc: 0.9568
Epoch 3/5
 - 22s - loss: 0.1715 - acc: 0.9610 - val_loss: 0.1185 - val_acc: 0.9861
Epoch 4/5
 - 22s - loss: 0.1143 - acc: 0.9807 - val_loss: 0.0817 - val_acc: 0.9927
Epoch 5/5
 - 22s - loss: 0.0888 - acc: 0.9885 - val_loss: 0.0633 - val_acc: 0.9955
Test accuracy:0.712
current auc_score ------------------> 0.868
accuracies:  [0.6384408602150538, 0.5600806451612903, 0.7120967741935483]
['4', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4711 - acc: 0.7951 - val_loss: 0.2777 - val_acc: 0.9032
Epoch 2/5
 - 23s - loss: 0.2355 - acc: 0.9197 - val_loss: 0.1673 - val_acc: 0.9618
Epoch 3/5
 - 23s - loss: 0.1437 - acc: 0.9618 - val_loss: 0.1027 - val_acc: 0.9733
Epoch 4/5
 - 23s - loss: 0.0946 - acc: 0.9802 - val_loss: 0.0819 - val_acc: 0.9836
Epoch 5/5
 - 23s - loss: 0.0781 - acc: 0.9845 - val_loss: 0.0643 - val_acc: 0.9916
Test accuracy:0.732
current auc_score ------------------> 0.900
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4071 - acc: 0.8336 - val_loss: 0.2382 - val_acc: 0.9239
Epoch 2/5
 - 22s - loss: 0.1967 - acc: 0.9369 - val_loss: 0.1212 - val_acc: 0.9740
Epoch 3/5
 - 23s - loss: 0.1223 - acc: 0.9700 - val_loss: 0.0886 - val_acc: 0.9834
Epoch 4/5
 - 23s - loss: 0.0914 - acc: 0.9805 - val_loss: 0.0705 - val_acc: 0.9892
Epoch 5/5
 - 23s - loss: 0.0803 - acc: 0.9831 - val_loss: 0.0501 - val_acc: 0.9925
Test accuracy:0.722
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4577 - acc: 0.8067 - val_loss: 0.2829 - val_acc: 0.8926
Epoch 2/5
 - 23s - loss: 0.2133 - acc: 0.9310 - val_loss: 0.1330 - val_acc: 0.9667
Epoch 3/5
 - 23s - loss: 0.1298 - acc: 0.9674 - val_loss: 0.0875 - val_acc: 0.9866
Epoch 4/5
 - 23s - loss: 0.0929 - acc: 0.9813 - val_loss: 0.0876 - val_acc: 0.9826
Epoch 5/5
 - 23s - loss: 0.0738 - acc: 0.9870 - val_loss: 0.0521 - val_acc: 0.9941
Test accuracy:0.726
current auc_score ------------------> 0.884
accuracies:  [0.7321236559139785, 0.7217741935483871, 0.7256720430107527]
['4', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.4843 - acc: 0.7997 - val_loss: 0.3071 - val_acc: 0.8883
Epoch 2/5
 - 24s - loss: 0.2501 - acc: 0.9215 - val_loss: 0.1714 - val_acc: 0.9603
Epoch 3/5
 - 24s - loss: 0.1623 - acc: 0.9609 - val_loss: 0.1155 - val_acc: 0.9847
Epoch 4/5
 - 24s - loss: 0.1172 - acc: 0.9784 - val_loss: 0.0842 - val_acc: 0.9901
Epoch 5/5
 - 25s - loss: 0.0867 - acc: 0.9875 - val_loss: 0.0593 - val_acc: 0.9937
Test accuracy:0.670
current auc_score ------------------> 0.872
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 28s - loss: 0.4398 - acc: 0.8242 - val_loss: 0.2407 - val_acc: 0.9275
Epoch 2/5
 - 24s - loss: 0.2202 - acc: 0.9356 - val_loss: 0.1402 - val_acc: 0.9716
Epoch 3/5
 - 24s - loss: 0.1441 - acc: 0.9679 - val_loss: 0.0970 - val_acc: 0.9853
Epoch 4/5
 - 24s - loss: 0.1027 - acc: 0.9826 - val_loss: 0.0748 - val_acc: 0.9917
Epoch 5/5
 - 24s - loss: 0.0813 - acc: 0.9896 - val_loss: 0.0608 - val_acc: 0.9942
Test accuracy:0.674
current auc_score ------------------> 0.907
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.4640 - acc: 0.8115 - val_loss: 0.2975 - val_acc: 0.8906
Epoch 2/5
 - 23s - loss: 0.2291 - acc: 0.9294 - val_loss: 0.1533 - val_acc: 0.9706
Epoch 3/5
 - 23s - loss: 0.1478 - acc: 0.9665 - val_loss: 0.0956 - val_acc: 0.9882
Epoch 4/5
 - 23s - loss: 0.1060 - acc: 0.9807 - val_loss: 0.0746 - val_acc: 0.9931
Epoch 5/5
 - 23s - loss: 0.0871 - acc: 0.9869 - val_loss: 0.0626 - val_acc: 0.9936
Test accuracy:0.685
current auc_score ------------------> 0.870
accuracies:  [0.6702956989247312, 0.6736559139784947, 0.6850806451612903]
['4', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.5091 - acc: 0.8016 - val_loss: 0.3106 - val_acc: 0.8912
Epoch 2/5
 - 25s - loss: 0.2500 - acc: 0.9316 - val_loss: 0.1805 - val_acc: 0.9666
Epoch 3/5
 - 25s - loss: 0.1606 - acc: 0.9700 - val_loss: 0.1116 - val_acc: 0.9872
Epoch 4/5
 - 25s - loss: 0.1175 - acc: 0.9829 - val_loss: 0.0963 - val_acc: 0.9928
Epoch 5/5
 - 25s - loss: 0.0950 - acc: 0.9897 - val_loss: 0.0707 - val_acc: 0.9971
Test accuracy:0.722
current auc_score ------------------> 0.913
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 29s - loss: 0.5084 - acc: 0.8010 - val_loss: 0.3001 - val_acc: 0.9099
Epoch 2/5
 - 25s - loss: 0.2570 - acc: 0.9245 - val_loss: 0.1789 - val_acc: 0.9644
Epoch 3/5
 - 25s - loss: 0.1662 - acc: 0.9663 - val_loss: 0.1278 - val_acc: 0.9764
Epoch 4/5
 - 25s - loss: 0.1297 - acc: 0.9778 - val_loss: 0.0933 - val_acc: 0.9910
Epoch 5/5
 - 25s - loss: 0.1045 - acc: 0.9864 - val_loss: 0.0778 - val_acc: 0.9946
Test accuracy:0.639
current auc_score ------------------> 0.889
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 29s - loss: 0.4975 - acc: 0.8062 - val_loss: 0.3282 - val_acc: 0.8924
Epoch 2/5
 - 25s - loss: 0.2451 - acc: 0.9323 - val_loss: 0.1617 - val_acc: 0.9681
Epoch 3/5
 - 25s - loss: 0.1624 - acc: 0.9674 - val_loss: 0.1269 - val_acc: 0.9856
Epoch 4/5
 - 25s - loss: 0.1203 - acc: 0.9828 - val_loss: 0.0881 - val_acc: 0.9906
Epoch 5/5
 - 25s - loss: 0.0971 - acc: 0.9887 - val_loss: 0.0792 - val_acc: 0.9915
Test accuracy:0.734
current auc_score ------------------> 0.907
accuracies:  [0.7223118279569892, 0.638978494623656, 0.7341397849462366]
['6', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4564 - acc: 0.8127 - val_loss: 0.2435 - val_acc: 0.9219
Epoch 2/5
 - 26s - loss: 0.2191 - acc: 0.9306 - val_loss: 0.1524 - val_acc: 0.9676
Epoch 3/5
 - 26s - loss: 0.1494 - acc: 0.9627 - val_loss: 0.1083 - val_acc: 0.9784
Epoch 4/5
 - 26s - loss: 0.1047 - acc: 0.9790 - val_loss: 0.0725 - val_acc: 0.9890
Epoch 5/5
 - 26s - loss: 0.0833 - acc: 0.9855 - val_loss: 0.0643 - val_acc: 0.9920
Test accuracy:0.658
current auc_score ------------------> 0.848
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4828 - acc: 0.7965 - val_loss: 1.9624 - val_acc: 0.5472
Epoch 2/5
 - 26s - loss: 0.2366 - acc: 0.9245 - val_loss: 0.8053 - val_acc: 0.6649
Epoch 3/5
 - 26s - loss: 0.1521 - acc: 0.9621 - val_loss: 0.1433 - val_acc: 0.9730
Epoch 4/5
 - 26s - loss: 0.1091 - acc: 0.9779 - val_loss: 0.0868 - val_acc: 0.9872
Epoch 5/5
 - 26s - loss: 0.0875 - acc: 0.9842 - val_loss: 0.0584 - val_acc: 0.9917
Test accuracy:0.750
current auc_score ------------------> 0.871
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4615 - acc: 0.8085 - val_loss: 0.2617 - val_acc: 0.9090
Epoch 2/5
 - 26s - loss: 0.2342 - acc: 0.9255 - val_loss: 0.1671 - val_acc: 0.9531
Epoch 3/5
 - 26s - loss: 0.1530 - acc: 0.9613 - val_loss: 0.1059 - val_acc: 0.9738
Epoch 4/5
 - 26s - loss: 0.1116 - acc: 0.9767 - val_loss: 0.0835 - val_acc: 0.9810
Epoch 5/5
 - 26s - loss: 0.0869 - acc: 0.9838 - val_loss: 0.0722 - val_acc: 0.9871
Test accuracy:0.640
current auc_score ------------------> 0.875
accuracies:  [0.6576612903225807, 0.7501344086021505, 0.6399193548387097]
['6', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5107 - acc: 0.7962 - val_loss: 0.4736 - val_acc: 0.8169
Epoch 2/5
 - 29s - loss: 0.2700 - acc: 0.9205 - val_loss: 0.1958 - val_acc: 0.9521
Epoch 3/5
 - 29s - loss: 0.1890 - acc: 0.9575 - val_loss: 0.1327 - val_acc: 0.9810
Epoch 4/5
 - 29s - loss: 0.1391 - acc: 0.9765 - val_loss: 0.1052 - val_acc: 0.9905
Epoch 5/5
 - 29s - loss: 0.1106 - acc: 0.9849 - val_loss: 0.0857 - val_acc: 0.9951
Test accuracy:0.641
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5225 - acc: 0.7880 - val_loss: 0.3083 - val_acc: 0.9068
Epoch 2/5
 - 28s - loss: 0.2715 - acc: 0.9217 - val_loss: 0.1860 - val_acc: 0.9615
Epoch 3/5
 - 28s - loss: 0.1805 - acc: 0.9625 - val_loss: 0.1292 - val_acc: 0.9823
Epoch 4/5
 - 28s - loss: 0.1358 - acc: 0.9790 - val_loss: 0.1006 - val_acc: 0.9912
Epoch 5/5
 - 28s - loss: 0.1099 - acc: 0.9859 - val_loss: 0.1132 - val_acc: 0.9838
Test accuracy:0.629
current auc_score ------------------> 0.889
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5596 - acc: 0.7657 - val_loss: 0.3852 - val_acc: 0.8563
Epoch 2/5
 - 29s - loss: 0.3187 - acc: 0.8956 - val_loss: 0.2171 - val_acc: 0.9498
Epoch 3/5
 - 28s - loss: 0.2169 - acc: 0.9465 - val_loss: 0.1529 - val_acc: 0.9785
Epoch 4/5
 - 28s - loss: 0.1616 - acc: 0.9687 - val_loss: 0.1167 - val_acc: 0.9804
Epoch 5/5
 - 28s - loss: 0.1250 - acc: 0.9805 - val_loss: 0.0935 - val_acc: 0.9916
Test accuracy:0.594
current auc_score ------------------> 0.867
accuracies:  [0.641263440860215, 0.6290322580645161, 0.5935483870967742]
['6', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6100 - acc: 0.7584 - val_loss: 0.3747 - val_acc: 0.8838
Epoch 2/5
 - 34s - loss: 0.3298 - acc: 0.9031 - val_loss: 0.2247 - val_acc: 0.9592
Epoch 3/5
 - 34s - loss: 0.2129 - acc: 0.9590 - val_loss: 0.1592 - val_acc: 0.9780
Epoch 4/5
 - 33s - loss: 0.1635 - acc: 0.9759 - val_loss: 0.1174 - val_acc: 0.9921
Epoch 5/5
 - 34s - loss: 0.1301 - acc: 0.9858 - val_loss: 0.0983 - val_acc: 0.9957
Test accuracy:0.736
current auc_score ------------------> 0.900
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.5430 - acc: 0.7980 - val_loss: 3.8166 - val_acc: 0.5035
Epoch 2/5
 - 32s - loss: 0.2773 - acc: 0.9324 - val_loss: 2.3424 - val_acc: 0.5294
Epoch 3/5
 - 32s - loss: 0.1925 - acc: 0.9674 - val_loss: 1.6114 - val_acc: 0.5574
Epoch 4/5
 - 32s - loss: 0.1518 - acc: 0.9800 - val_loss: 2.0198 - val_acc: 0.5425
Epoch 5/5
 - 32s - loss: 0.1220 - acc: 0.9880 - val_loss: 2.2634 - val_acc: 0.5314

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.530
current auc_score ------------------> 0.703
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.5553 - acc: 0.7845 - val_loss: 0.3282 - val_acc: 0.9091
Epoch 2/5
 - 34s - loss: 0.3037 - acc: 0.9190 - val_loss: 0.2048 - val_acc: 0.9642
Epoch 3/5
 - 33s - loss: 0.2056 - acc: 0.9618 - val_loss: 0.1393 - val_acc: 0.9871
Epoch 4/5
 - 33s - loss: 0.1532 - acc: 0.9792 - val_loss: 0.1122 - val_acc: 0.9918
Epoch 5/5
 - 33s - loss: 0.1228 - acc: 0.9879 - val_loss: 0.0960 - val_acc: 0.9947
Test accuracy:0.704
current auc_score ------------------> 0.904
accuracies:  [0.735752688172043, 0.5301075268817205, 0.7038978494623656]
['2-2', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4465 - acc: 0.8183 - val_loss: 0.2291 - val_acc: 0.9179
Epoch 2/5
 - 23s - loss: 0.2046 - acc: 0.9314 - val_loss: 0.1276 - val_acc: 0.9685
Epoch 3/5
 - 23s - loss: 0.1310 - acc: 0.9641 - val_loss: 0.0879 - val_acc: 0.9819
Epoch 4/5
 - 23s - loss: 0.0916 - acc: 0.9807 - val_loss: 0.0634 - val_acc: 0.9891
Epoch 5/5
 - 23s - loss: 0.0719 - acc: 0.9864 - val_loss: 0.0535 - val_acc: 0.9910
Test accuracy:0.672
current auc_score ------------------> 0.907
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4528 - acc: 0.8104 - val_loss: 0.2182 - val_acc: 0.9282
Epoch 2/5
 - 22s - loss: 0.2049 - acc: 0.9320 - val_loss: 0.1267 - val_acc: 0.9665
Epoch 3/5
 - 22s - loss: 0.1284 - acc: 0.9653 - val_loss: 0.0852 - val_acc: 0.9794
Epoch 4/5
 - 22s - loss: 0.0935 - acc: 0.9796 - val_loss: 0.0687 - val_acc: 0.9880
Epoch 5/5
 - 22s - loss: 0.0747 - acc: 0.9857 - val_loss: 0.0551 - val_acc: 0.9926
Test accuracy:0.746
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4878 - acc: 0.7940 - val_loss: 0.2584 - val_acc: 0.9039
Epoch 2/5
 - 23s - loss: 0.2315 - acc: 0.9194 - val_loss: 0.1376 - val_acc: 0.9622
Epoch 3/5
 - 23s - loss: 0.1467 - acc: 0.9590 - val_loss: 0.0933 - val_acc: 0.9833
Epoch 4/5
 - 22s - loss: 0.1031 - acc: 0.9766 - val_loss: 0.0689 - val_acc: 0.9872
Epoch 5/5
 - 22s - loss: 0.0846 - acc: 0.9818 - val_loss: 0.0571 - val_acc: 0.9917
Test accuracy:0.755
current auc_score ------------------> 0.904
accuracies:  [0.6717741935483871, 0.7461021505376344, 0.7547043010752689]
['2-2', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4778 - acc: 0.8147 - val_loss: 0.2396 - val_acc: 0.9251
Epoch 2/5
 - 22s - loss: 0.2263 - acc: 0.9330 - val_loss: 0.1388 - val_acc: 0.9714
Epoch 3/5
 - 22s - loss: 0.1430 - acc: 0.9682 - val_loss: 0.0994 - val_acc: 0.9872
Epoch 4/5
 - 21s - loss: 0.1098 - acc: 0.9804 - val_loss: 0.0836 - val_acc: 0.9898
Epoch 5/5
 - 21s - loss: 0.0897 - acc: 0.9872 - val_loss: 0.0691 - val_acc: 0.9927
Test accuracy:0.718
current auc_score ------------------> 0.931
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.5023 - acc: 0.7985 - val_loss: 0.7697 - val_acc: 0.6446
Epoch 2/5
 - 21s - loss: 0.2348 - acc: 0.9283 - val_loss: 0.1519 - val_acc: 0.9685
Epoch 3/5
 - 21s - loss: 0.1492 - acc: 0.9669 - val_loss: 0.1035 - val_acc: 0.9834
Epoch 4/5
 - 21s - loss: 0.1114 - acc: 0.9807 - val_loss: 0.0773 - val_acc: 0.9922
Epoch 5/5
 - 22s - loss: 0.0890 - acc: 0.9881 - val_loss: 0.0651 - val_acc: 0.9969
Test accuracy:0.716
current auc_score ------------------> 0.887
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4802 - acc: 0.8099 - val_loss: 0.2544 - val_acc: 0.9222
Epoch 2/5
 - 22s - loss: 0.2261 - acc: 0.9324 - val_loss: 0.1509 - val_acc: 0.9709
Epoch 3/5
 - 22s - loss: 0.1461 - acc: 0.9674 - val_loss: 0.1261 - val_acc: 0.9760
Epoch 4/5
 - 22s - loss: 0.1123 - acc: 0.9806 - val_loss: 0.0876 - val_acc: 0.9880
Epoch 5/5
 - 22s - loss: 0.0920 - acc: 0.9864 - val_loss: 0.0685 - val_acc: 0.9932
Test accuracy:0.731
current auc_score ------------------> 0.917
accuracies:  [0.7176075268817205, 0.7159946236559139, 0.730510752688172]
['2-2', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.5026 - acc: 0.8089 - val_loss: 0.2770 - val_acc: 0.9232
Epoch 2/5
 - 23s - loss: 0.2434 - acc: 0.9336 - val_loss: 0.1633 - val_acc: 0.9709
Epoch 3/5
 - 23s - loss: 0.1656 - acc: 0.9683 - val_loss: 0.1168 - val_acc: 0.9873
Epoch 4/5
 - 23s - loss: 0.1213 - acc: 0.9842 - val_loss: 0.0945 - val_acc: 0.9937
Epoch 5/5
 - 23s - loss: 0.1007 - acc: 0.9911 - val_loss: 0.0830 - val_acc: 0.9950
Test accuracy:0.653
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.5009 - acc: 0.8106 - val_loss: 0.2743 - val_acc: 0.9246
Epoch 2/5
 - 22s - loss: 0.2459 - acc: 0.9341 - val_loss: 0.1733 - val_acc: 0.9710
Epoch 3/5
 - 23s - loss: 0.1653 - acc: 0.9685 - val_loss: 0.1224 - val_acc: 0.9859
Epoch 4/5
 - 22s - loss: 0.1292 - acc: 0.9815 - val_loss: 0.1028 - val_acc: 0.9920
Epoch 5/5
 - 22s - loss: 0.1060 - acc: 0.9888 - val_loss: 0.0875 - val_acc: 0.9944
Test accuracy:0.634
current auc_score ------------------> 0.890
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.5471 - acc: 0.7823 - val_loss: 0.3101 - val_acc: 0.9057
Epoch 2/5
 - 22s - loss: 0.2746 - acc: 0.9197 - val_loss: 0.1901 - val_acc: 0.9642
Epoch 3/5
 - 22s - loss: 0.1771 - acc: 0.9648 - val_loss: 0.1428 - val_acc: 0.9782
Epoch 4/5
 - 22s - loss: 0.1306 - acc: 0.9816 - val_loss: 0.1017 - val_acc: 0.9917
Epoch 5/5
 - 22s - loss: 0.1092 - acc: 0.9872 - val_loss: 0.0908 - val_acc: 0.9962
Test accuracy:0.642
current auc_score ------------------> 0.858
accuracies:  [0.6526881720430108, 0.6344086021505376, 0.6420698924731183]
['3-3', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4689 - acc: 0.8073 - val_loss: 0.2658 - val_acc: 0.9127
Epoch 2/5
 - 28s - loss: 0.2228 - acc: 0.9287 - val_loss: 0.1834 - val_acc: 0.9549
Epoch 3/5
 - 27s - loss: 0.1474 - acc: 0.9641 - val_loss: 0.1044 - val_acc: 0.9834
Epoch 4/5
 - 27s - loss: 0.1130 - acc: 0.9767 - val_loss: 0.1059 - val_acc: 0.9827
Epoch 5/5
 - 27s - loss: 0.0908 - acc: 0.9838 - val_loss: 0.0695 - val_acc: 0.9922
Test accuracy:0.639
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5027 - acc: 0.7899 - val_loss: 2.9051 - val_acc: 0.5054
Epoch 2/5
 - 26s - loss: 0.2529 - acc: 0.9147 - val_loss: 0.1812 - val_acc: 0.9538
Epoch 3/5
 - 26s - loss: 0.1676 - acc: 0.9537 - val_loss: 0.1334 - val_acc: 0.9694
Epoch 4/5
 - 26s - loss: 0.1260 - acc: 0.9704 - val_loss: 0.0887 - val_acc: 0.9854
Epoch 5/5
 - 26s - loss: 0.0963 - acc: 0.9815 - val_loss: 0.0733 - val_acc: 0.9893
Test accuracy:0.710
current auc_score ------------------> 0.877
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4412 - acc: 0.8296 - val_loss: 0.2332 - val_acc: 0.9360
Epoch 2/5
 - 26s - loss: 0.2065 - acc: 0.9379 - val_loss: 0.1641 - val_acc: 0.9622
Epoch 3/5
 - 26s - loss: 0.1345 - acc: 0.9669 - val_loss: 0.1010 - val_acc: 0.9824
Epoch 4/5
 - 26s - loss: 0.1016 - acc: 0.9803 - val_loss: 0.0717 - val_acc: 0.9898
Epoch 5/5
 - 26s - loss: 0.0799 - acc: 0.9873 - val_loss: 0.0579 - val_acc: 0.9941
Test accuracy:0.671
current auc_score ------------------> 0.899
accuracies:  [0.6385752688172043, 0.7100806451612903, 0.671236559139785]
['3-3', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5110 - acc: 0.8045 - val_loss: 0.3112 - val_acc: 0.9046
Epoch 2/5
 - 26s - loss: 0.2531 - acc: 0.9286 - val_loss: 0.1721 - val_acc: 0.9726
Epoch 3/5
 - 26s - loss: 0.1713 - acc: 0.9660 - val_loss: 0.1221 - val_acc: 0.9848
Epoch 4/5
 - 26s - loss: 0.1298 - acc: 0.9813 - val_loss: 0.0980 - val_acc: 0.9911
Epoch 5/5
 - 26s - loss: 0.1084 - acc: 0.9876 - val_loss: 0.0864 - val_acc: 0.9954
Test accuracy:0.700
current auc_score ------------------> 0.908
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5556 - acc: 0.7841 - val_loss: 0.3217 - val_acc: 0.9044
Epoch 2/5
 - 26s - loss: 0.2765 - acc: 0.9191 - val_loss: 0.2152 - val_acc: 0.9637
Epoch 3/5
 - 26s - loss: 0.1838 - acc: 0.9612 - val_loss: 0.1526 - val_acc: 0.9790
Epoch 4/5
 - 26s - loss: 0.1386 - acc: 0.9773 - val_loss: 0.1820 - val_acc: 0.9676
Epoch 5/5
 - 26s - loss: 0.1151 - acc: 0.9854 - val_loss: 0.1251 - val_acc: 0.9907
Test accuracy:0.653
current auc_score ------------------> 0.839
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5397 - acc: 0.7892 - val_loss: 0.3362 - val_acc: 0.8869
Epoch 2/5
 - 27s - loss: 0.2688 - acc: 0.9241 - val_loss: 0.2134 - val_acc: 0.9541
Epoch 3/5
 - 26s - loss: 0.1783 - acc: 0.9627 - val_loss: 0.1283 - val_acc: 0.9847
Epoch 4/5
 - 27s - loss: 0.1347 - acc: 0.9793 - val_loss: 0.1178 - val_acc: 0.9896
Epoch 5/5
 - 27s - loss: 0.1112 - acc: 0.9869 - val_loss: 0.0862 - val_acc: 0.9954
Test accuracy:0.658
current auc_score ------------------> 0.878
accuracies:  [0.7, 0.6525537634408602, 0.6577956989247312]
['3-3', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.5797 - acc: 0.7822 - val_loss: 0.3515 - val_acc: 0.8955
Epoch 2/5
 - 28s - loss: 0.3081 - acc: 0.9187 - val_loss: 0.2199 - val_acc: 0.9686
Epoch 3/5
 - 28s - loss: 0.2162 - acc: 0.9617 - val_loss: 0.1577 - val_acc: 0.9841
Epoch 4/5
 - 28s - loss: 0.1738 - acc: 0.9767 - val_loss: 0.1355 - val_acc: 0.9913
Epoch 5/5
 - 28s - loss: 0.1442 - acc: 0.9857 - val_loss: 0.1152 - val_acc: 0.9922
Test accuracy:0.740
current auc_score ------------------> 0.901
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.5393 - acc: 0.8021 - val_loss: 0.3253 - val_acc: 0.9148
Epoch 2/5
 - 27s - loss: 0.2883 - acc: 0.9289 - val_loss: 0.2086 - val_acc: 0.9711
Epoch 3/5
 - 27s - loss: 0.2013 - acc: 0.9680 - val_loss: 0.1510 - val_acc: 0.9854
Epoch 4/5
 - 27s - loss: 0.1649 - acc: 0.9799 - val_loss: 0.1295 - val_acc: 0.9913
Epoch 5/5
 - 27s - loss: 0.1430 - acc: 0.9851 - val_loss: 0.1163 - val_acc: 0.9936
Test accuracy:0.615
current auc_score ------------------> 0.897
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5246 - acc: 0.8104 - val_loss: 0.3054 - val_acc: 0.9249
Epoch 2/5
 - 27s - loss: 0.2845 - acc: 0.9306 - val_loss: 0.2366 - val_acc: 0.9573
Epoch 3/5
 - 27s - loss: 0.2015 - acc: 0.9659 - val_loss: 0.1754 - val_acc: 0.9848
Epoch 4/5
 - 27s - loss: 0.1655 - acc: 0.9786 - val_loss: 0.1488 - val_acc: 0.9872
Epoch 5/5
 - 26s - loss: 0.1425 - acc: 0.9862 - val_loss: 0.1168 - val_acc: 0.9944
Test accuracy:0.607
current auc_score ------------------> 0.864
accuracies:  [0.7401881720430108, 0.6146505376344086, 0.6071236559139785]
['4-4', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 35s - loss: 0.4872 - acc: 0.8067 - val_loss: 0.8027 - val_acc: 0.6003
Epoch 2/5
 - 29s - loss: 0.2321 - acc: 0.9296 - val_loss: 0.1584 - val_acc: 0.9704
Epoch 3/5
 - 29s - loss: 0.1540 - acc: 0.9642 - val_loss: 0.1130 - val_acc: 0.9808
Epoch 4/5
 - 29s - loss: 0.1157 - acc: 0.9789 - val_loss: 0.0781 - val_acc: 0.9915
Epoch 5/5
 - 30s - loss: 0.0964 - acc: 0.9848 - val_loss: 0.0776 - val_acc: 0.9907
Test accuracy:0.700
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 35s - loss: 0.4787 - acc: 0.8108 - val_loss: 1.7431 - val_acc: 0.5099
Epoch 2/5
 - 29s - loss: 0.2294 - acc: 0.9330 - val_loss: 0.1574 - val_acc: 0.9701
Epoch 3/5
 - 29s - loss: 0.1482 - acc: 0.9679 - val_loss: 0.1092 - val_acc: 0.9821
Epoch 4/5
 - 29s - loss: 0.1132 - acc: 0.9802 - val_loss: 0.0866 - val_acc: 0.9892
Epoch 5/5
 - 30s - loss: 0.0920 - acc: 0.9876 - val_loss: 0.0732 - val_acc: 0.9939
Test accuracy:0.667
current auc_score ------------------> 0.920
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.4738 - acc: 0.8143 - val_loss: 0.2794 - val_acc: 0.9093
Epoch 2/5
 - 32s - loss: 0.2522 - acc: 0.9190 - val_loss: 0.1631 - val_acc: 0.9608
Epoch 3/5
 - 32s - loss: 0.1699 - acc: 0.9592 - val_loss: 0.1175 - val_acc: 0.9798
Epoch 4/5
 - 32s - loss: 0.1284 - acc: 0.9746 - val_loss: 0.1009 - val_acc: 0.9862
Epoch 5/5
 - 32s - loss: 0.1030 - acc: 0.9831 - val_loss: 0.0844 - val_acc: 0.9901
Test accuracy:0.679
current auc_score ------------------> 0.864
accuracies:  [0.7004032258064516, 0.6666666666666666, 0.6791666666666667]
['4-4', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.4997 - acc: 0.8171 - val_loss: 1.4861 - val_acc: 0.5297
Epoch 2/5
 - 30s - loss: 0.2695 - acc: 0.9326 - val_loss: 1.3267 - val_acc: 0.5410
Epoch 3/5
 - 30s - loss: 0.1904 - acc: 0.9683 - val_loss: 0.7536 - val_acc: 0.6431
Epoch 4/5
 - 30s - loss: 0.1510 - acc: 0.9813 - val_loss: 0.4934 - val_acc: 0.8232
Epoch 5/5
 - 30s - loss: 0.1277 - acc: 0.9885 - val_loss: 0.4767 - val_acc: 0.8215
Test accuracy:0.665
current auc_score ------------------> 0.792
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.5618 - acc: 0.7885 - val_loss: 0.3354 - val_acc: 0.8945
Epoch 2/5
 - 30s - loss: 0.2912 - acc: 0.9219 - val_loss: 0.2039 - val_acc: 0.9630
Epoch 3/5
 - 30s - loss: 0.1945 - acc: 0.9660 - val_loss: 0.1661 - val_acc: 0.9822
Epoch 4/5
 - 30s - loss: 0.1545 - acc: 0.9799 - val_loss: 0.1293 - val_acc: 0.9873
Epoch 5/5
 - 29s - loss: 0.1287 - acc: 0.9881 - val_loss: 0.1244 - val_acc: 0.9882
Test accuracy:0.645
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.5620 - acc: 0.7846 - val_loss: 1.5113 - val_acc: 0.5361
Epoch 2/5
 - 30s - loss: 0.3018 - acc: 0.9196 - val_loss: 0.8374 - val_acc: 0.6106
Epoch 3/5
 - 30s - loss: 0.2120 - acc: 0.9591 - val_loss: 0.9834 - val_acc: 0.5394
Epoch 4/5
 - 30s - loss: 0.1639 - acc: 0.9767 - val_loss: 0.6952 - val_acc: 0.6822
Epoch 5/5
 - 30s - loss: 0.1360 - acc: 0.9850 - val_loss: 0.6443 - val_acc: 0.7323
Test accuracy:0.607
current auc_score ------------------> 0.682
accuracies:  [0.6651881720430107, 0.6451612903225806, 0.6068548387096774]
['4-4', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5724 - acc: 0.8015 - val_loss: 3.2322 - val_acc: 0.4965
Epoch 2/5
 - 31s - loss: 0.3281 - acc: 0.9233 - val_loss: 1.0222 - val_acc: 0.5902
Epoch 3/5
 - 30s - loss: 0.2357 - acc: 0.9652 - val_loss: 0.2053 - val_acc: 0.9794
Epoch 4/5
 - 30s - loss: 0.1968 - acc: 0.9786 - val_loss: 0.1723 - val_acc: 0.9905
Epoch 5/5
 - 30s - loss: 0.1685 - acc: 0.9858 - val_loss: 0.1391 - val_acc: 0.9966
Test accuracy:0.686
current auc_score ------------------> 0.919
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.5974 - acc: 0.7918 - val_loss: 0.4386 - val_acc: 0.8696
Epoch 2/5
 - 32s - loss: 0.3377 - acc: 0.9188 - val_loss: 0.2576 - val_acc: 0.9577
Epoch 3/5
 - 32s - loss: 0.2435 - acc: 0.9617 - val_loss: 0.1978 - val_acc: 0.9817
Epoch 4/5
 - 32s - loss: 0.1958 - acc: 0.9785 - val_loss: 0.1685 - val_acc: 0.9897
Epoch 5/5
 - 32s - loss: 0.1707 - acc: 0.9851 - val_loss: 0.1454 - val_acc: 0.9942
Test accuracy:0.701
current auc_score ------------------> 0.885
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.6138 - acc: 0.7759 - val_loss: 0.4314 - val_acc: 0.8765
Epoch 2/5
 - 30s - loss: 0.3489 - acc: 0.9143 - val_loss: 0.2769 - val_acc: 0.9487
Epoch 3/5
 - 30s - loss: 0.2547 - acc: 0.9573 - val_loss: 0.2174 - val_acc: 0.9757
Epoch 4/5
 - 31s - loss: 0.2050 - acc: 0.9738 - val_loss: 0.1676 - val_acc: 0.9892
Epoch 5/5
 - 31s - loss: 0.1726 - acc: 0.9850 - val_loss: 0.1510 - val_acc: 0.9906
Test accuracy:0.695
current auc_score ------------------> 0.862
accuracies:  [0.6858870967741936, 0.701478494623656, 0.6950268817204301]
['6-6', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.5220 - acc: 0.7962 - val_loss: 0.7614 - val_acc: 0.6059
Epoch 2/5
 - 36s - loss: 0.2698 - acc: 0.9219 - val_loss: 0.5231 - val_acc: 0.7544
Epoch 3/5
 - 36s - loss: 0.1865 - acc: 0.9594 - val_loss: 0.1497 - val_acc: 0.9799
Epoch 4/5
 - 36s - loss: 0.1413 - acc: 0.9771 - val_loss: 0.1107 - val_acc: 0.9917
Epoch 5/5
 - 36s - loss: 0.1168 - acc: 0.9851 - val_loss: 0.0988 - val_acc: 0.9916
Test accuracy:0.708
current auc_score ------------------> 0.891
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.5051 - acc: 0.8077 - val_loss: 0.3344 - val_acc: 0.8992
Epoch 2/5
 - 37s - loss: 0.2656 - acc: 0.9245 - val_loss: 0.2071 - val_acc: 0.9562
Epoch 3/5
 - 37s - loss: 0.1868 - acc: 0.9614 - val_loss: 0.1391 - val_acc: 0.9824
Epoch 4/5
 - 38s - loss: 0.1444 - acc: 0.9750 - val_loss: 0.1106 - val_acc: 0.9892
Epoch 5/5
 - 38s - loss: 0.1217 - acc: 0.9836 - val_loss: 0.0933 - val_acc: 0.9926
Test accuracy:0.686
current auc_score ------------------> 0.857
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.5018 - acc: 0.8066 - val_loss: 0.3237 - val_acc: 0.9041
Epoch 2/5
 - 36s - loss: 0.2722 - acc: 0.9213 - val_loss: 0.2111 - val_acc: 0.9489
Epoch 3/5
 - 36s - loss: 0.1913 - acc: 0.9593 - val_loss: 0.1471 - val_acc: 0.9797
Epoch 4/5
 - 36s - loss: 0.1478 - acc: 0.9751 - val_loss: 0.1013 - val_acc: 0.9900
Epoch 5/5
 - 36s - loss: 0.1209 - acc: 0.9843 - val_loss: 0.0912 - val_acc: 0.9942
Test accuracy:0.681
current auc_score ------------------> 0.886
accuracies:  [0.7077956989247312, 0.6864247311827957, 0.6809139784946237]
['6-6', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.5670 - acc: 0.8026 - val_loss: 0.3976 - val_acc: 0.8908
Epoch 2/5
 - 37s - loss: 0.3225 - acc: 0.9277 - val_loss: 0.2972 - val_acc: 0.9374
Epoch 3/5
 - 37s - loss: 0.2332 - acc: 0.9660 - val_loss: 0.1896 - val_acc: 0.9847
Epoch 4/5
 - 37s - loss: 0.1933 - acc: 0.9788 - val_loss: 0.1607 - val_acc: 0.9898
Epoch 5/5
 - 37s - loss: 0.1649 - acc: 0.9872 - val_loss: 0.1381 - val_acc: 0.9966
Test accuracy:0.724
current auc_score ------------------> 0.863
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.6098 - acc: 0.7818 - val_loss: 0.7921 - val_acc: 0.6800
Epoch 2/5
 - 38s - loss: 0.3381 - acc: 0.9181 - val_loss: 0.7008 - val_acc: 0.7341
Epoch 3/5
 - 38s - loss: 0.2510 - acc: 0.9570 - val_loss: 0.2076 - val_acc: 0.9839
Epoch 4/5
 - 38s - loss: 0.1988 - acc: 0.9781 - val_loss: 0.1980 - val_acc: 0.9876
Epoch 5/5
 - 38s - loss: 0.1767 - acc: 0.9832 - val_loss: 0.1664 - val_acc: 0.9912
Test accuracy:0.672
current auc_score ------------------> 0.874
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.5943 - acc: 0.7845 - val_loss: 1.3729 - val_acc: 0.5217
Epoch 2/5
 - 38s - loss: 0.3535 - acc: 0.9106 - val_loss: 1.7142 - val_acc: 0.4970
Epoch 3/5
 - 38s - loss: 0.2601 - acc: 0.9537 - val_loss: 0.7544 - val_acc: 0.6575
Epoch 4/5
 - 38s - loss: 0.2062 - acc: 0.9758 - val_loss: 0.9058 - val_acc: 0.6349
Epoch 5/5
 - 38s - loss: 0.1781 - acc: 0.9834 - val_loss: 0.6295 - val_acc: 0.7638
Test accuracy:0.704
current auc_score ------------------> 0.792
accuracies:  [0.7240591397849462, 0.6723118279569893, 0.7044354838709678]
['6-6', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.6521 - acc: 0.7893 - val_loss: 0.4747 - val_acc: 0.8887
Epoch 2/5
 - 40s - loss: 0.4018 - acc: 0.9165 - val_loss: 0.3369 - val_acc: 0.9563
Epoch 3/5
 - 40s - loss: 0.2988 - acc: 0.9622 - val_loss: 0.2562 - val_acc: 0.9843
Epoch 4/5
 - 40s - loss: 0.2502 - acc: 0.9781 - val_loss: 0.2077 - val_acc: 0.9945
Epoch 5/5
 - 40s - loss: 0.2182 - acc: 0.9859 - val_loss: 0.1994 - val_acc: 0.9935
Test accuracy:0.597
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 52s - loss: 0.6154 - acc: 0.8131 - val_loss: 0.5195 - val_acc: 0.8623
Epoch 2/5
 - 43s - loss: 0.3851 - acc: 0.9261 - val_loss: 0.3235 - val_acc: 0.9642
Epoch 3/5
 - 43s - loss: 0.2946 - acc: 0.9638 - val_loss: 0.3004 - val_acc: 0.9674
Epoch 4/5
 - 44s - loss: 0.2528 - acc: 0.9778 - val_loss: 0.2364 - val_acc: 0.9861
Epoch 5/5
 - 43s - loss: 0.2194 - acc: 0.9862 - val_loss: 0.1929 - val_acc: 0.9950
Test accuracy:0.740
current auc_score ------------------> 0.860
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 52s - loss: 0.6862 - acc: 0.7789 - val_loss: 0.6003 - val_acc: 0.8065
Epoch 2/5
 - 42s - loss: 0.4280 - acc: 0.9044 - val_loss: 0.3510 - val_acc: 0.9463
Epoch 3/5
 - 42s - loss: 0.3091 - acc: 0.9576 - val_loss: 0.2850 - val_acc: 0.9716
Epoch 4/5
 - 42s - loss: 0.2563 - acc: 0.9756 - val_loss: 0.2204 - val_acc: 0.9933
Epoch 5/5
 - 42s - loss: 0.2274 - acc: 0.9834 - val_loss: 0.1985 - val_acc: 0.9949
Test accuracy:0.685
current auc_score ------------------> 0.872
accuracies:  [0.5966397849462366, 0.7399193548387096, 0.6846774193548387]
['2-2-2', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.6314 - acc: 0.7311 - val_loss: 0.4367 - val_acc: 0.8139
Epoch 2/5
 - 27s - loss: 0.4115 - acc: 0.8330 - val_loss: 0.2923 - val_acc: 0.8952
Epoch 3/5
 - 26s - loss: 0.3014 - acc: 0.8883 - val_loss: 0.2177 - val_acc: 0.9332
Epoch 4/5
 - 26s - loss: 0.2319 - acc: 0.9241 - val_loss: 0.1659 - val_acc: 0.9578
Epoch 5/5
 - 27s - loss: 0.1789 - acc: 0.9467 - val_loss: 0.1327 - val_acc: 0.9677
Test accuracy:0.663
current auc_score ------------------> 0.881
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.6319 - acc: 0.7260 - val_loss: 0.3934 - val_acc: 0.8419
Epoch 2/5
 - 29s - loss: 0.3889 - acc: 0.8456 - val_loss: 0.2953 - val_acc: 0.8941
Epoch 3/5
 - 29s - loss: 0.2797 - acc: 0.8990 - val_loss: 0.2004 - val_acc: 0.9414
Epoch 4/5
 - 29s - loss: 0.2078 - acc: 0.9346 - val_loss: 0.1445 - val_acc: 0.9655
Epoch 5/5
 - 29s - loss: 0.1564 - acc: 0.9581 - val_loss: 0.1067 - val_acc: 0.9777
Test accuracy:0.658
current auc_score ------------------> 0.827
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.6194 - acc: 0.7355 - val_loss: 0.3656 - val_acc: 0.8578
Epoch 2/5
 - 29s - loss: 0.3716 - acc: 0.8540 - val_loss: 0.2833 - val_acc: 0.9016
Epoch 3/5
 - 29s - loss: 0.2621 - acc: 0.9090 - val_loss: 0.2021 - val_acc: 0.9404
Epoch 4/5
 - 29s - loss: 0.1995 - acc: 0.9379 - val_loss: 0.1380 - val_acc: 0.9666
Epoch 5/5
 - 29s - loss: 0.1522 - acc: 0.9590 - val_loss: 0.1212 - val_acc: 0.9735
Test accuracy:0.754
current auc_score ------------------> 0.923
accuracies:  [0.6631720430107527, 0.6581989247311828, 0.7541666666666667]
['2-2-2', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.6324 - acc: 0.7460 - val_loss: 0.4448 - val_acc: 0.8272
Epoch 2/5
 - 28s - loss: 0.3676 - acc: 0.8711 - val_loss: 0.3048 - val_acc: 0.9099
Epoch 3/5
 - 28s - loss: 0.2665 - acc: 0.9211 - val_loss: 0.2161 - val_acc: 0.9493
Epoch 4/5
 - 28s - loss: 0.1969 - acc: 0.9528 - val_loss: 0.1551 - val_acc: 0.9713
Epoch 5/5
 - 28s - loss: 0.1570 - acc: 0.9686 - val_loss: 0.1148 - val_acc: 0.9856
Test accuracy:0.602
current auc_score ------------------> 0.855
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5943 - acc: 0.7669 - val_loss: 0.4134 - val_acc: 0.8468
Epoch 2/5
 - 29s - loss: 0.3562 - acc: 0.8785 - val_loss: 0.3040 - val_acc: 0.9098
Epoch 3/5
 - 29s - loss: 0.2559 - acc: 0.9276 - val_loss: 0.2103 - val_acc: 0.9554
Epoch 4/5
 - 28s - loss: 0.1900 - acc: 0.9556 - val_loss: 0.1592 - val_acc: 0.9703
Epoch 5/5
 - 28s - loss: 0.1538 - acc: 0.9730 - val_loss: 0.1105 - val_acc: 0.9888
Test accuracy:0.643
current auc_score ------------------> 0.847
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.6456 - acc: 0.7362 - val_loss: 0.4596 - val_acc: 0.8139
Epoch 2/5
 - 27s - loss: 0.3905 - acc: 0.8605 - val_loss: 0.2905 - val_acc: 0.9147
Epoch 3/5
 - 27s - loss: 0.2770 - acc: 0.9180 - val_loss: 0.2403 - val_acc: 0.9436
Epoch 4/5
 - 27s - loss: 0.2093 - acc: 0.9484 - val_loss: 0.1647 - val_acc: 0.9719
Epoch 5/5
 - 26s - loss: 0.1701 - acc: 0.9648 - val_loss: 0.1261 - val_acc: 0.9827
Test accuracy:0.715
current auc_score ------------------> 0.921
accuracies:  [0.6016129032258064, 0.6431451612903226, 0.714516129032258]
['2-2-2', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.6519 - acc: 0.7473 - val_loss: 1.1985 - val_acc: 0.5614
Epoch 2/5
 - 28s - loss: 0.3790 - acc: 0.8813 - val_loss: 1.1580 - val_acc: 0.5163
Epoch 3/5
 - 28s - loss: 0.2648 - acc: 0.9366 - val_loss: 0.2155 - val_acc: 0.9695
Epoch 4/5
 - 28s - loss: 0.1994 - acc: 0.9658 - val_loss: 0.1638 - val_acc: 0.9856
Epoch 5/5
 - 27s - loss: 0.1678 - acc: 0.9779 - val_loss: 0.1356 - val_acc: 0.9920
Test accuracy:0.632
current auc_score ------------------> 0.874
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.6384 - acc: 0.7576 - val_loss: 0.3998 - val_acc: 0.8694
Epoch 2/5
 - 28s - loss: 0.3779 - acc: 0.8809 - val_loss: 0.2809 - val_acc: 0.9360
Epoch 3/5
 - 28s - loss: 0.2686 - acc: 0.9364 - val_loss: 0.2075 - val_acc: 0.9626
Epoch 4/5
 - 27s - loss: 0.2075 - acc: 0.9626 - val_loss: 0.1585 - val_acc: 0.9817
Epoch 5/5
 - 27s - loss: 0.1678 - acc: 0.9775 - val_loss: 0.1440 - val_acc: 0.9864
Test accuracy:0.685
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.6350 - acc: 0.7602 - val_loss: 1.3912 - val_acc: 0.4984
Epoch 2/5
 - 27s - loss: 0.3871 - acc: 0.8807 - val_loss: 0.3360 - val_acc: 0.9149
Epoch 3/5
 - 27s - loss: 0.2717 - acc: 0.9368 - val_loss: 0.2088 - val_acc: 0.9642
Epoch 4/5
 - 27s - loss: 0.2029 - acc: 0.9643 - val_loss: 0.1913 - val_acc: 0.9730
Epoch 5/5
 - 27s - loss: 0.1675 - acc: 0.9787 - val_loss: 0.1334 - val_acc: 0.9897
Test accuracy:0.614
current auc_score ------------------> 0.878
accuracies:  [0.6315860215053763, 0.6853494623655914, 0.6138440860215054]
['3-3-3', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6270 - acc: 0.7419 - val_loss: 3.0276 - val_acc: 0.5078
Epoch 2/5
 - 32s - loss: 0.3877 - acc: 0.8546 - val_loss: 5.4516 - val_acc: 0.5035
Epoch 3/5
 - 32s - loss: 0.2843 - acc: 0.9057 - val_loss: 3.7299 - val_acc: 0.5038

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 32s - loss: 0.2232 - acc: 0.9356 - val_loss: 4.5639 - val_acc: 0.5035
Epoch 5/5
 - 32s - loss: 0.1977 - acc: 0.9466 - val_loss: 3.6798 - val_acc: 0.5035

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 00005: early stopping
Test accuracy:0.500
current auc_score ------------------> 0.534
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6832 - acc: 0.7074 - val_loss: 0.4500 - val_acc: 0.8219
Epoch 2/5
 - 32s - loss: 0.4286 - acc: 0.8333 - val_loss: 0.3014 - val_acc: 0.9027
Epoch 3/5
 - 32s - loss: 0.3003 - acc: 0.8984 - val_loss: 0.2425 - val_acc: 0.9324
Epoch 4/5
 - 32s - loss: 0.2249 - acc: 0.9369 - val_loss: 0.1887 - val_acc: 0.9558
Epoch 5/5
 - 32s - loss: 0.1752 - acc: 0.9558 - val_loss: 0.1540 - val_acc: 0.9652
Test accuracy:0.599
current auc_score ------------------> 0.838
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6585 - acc: 0.7224 - val_loss: 4.2908 - val_acc: 0.4970
Epoch 2/5
 - 31s - loss: 0.4270 - acc: 0.8329 - val_loss: 1.4002 - val_acc: 0.5353
Epoch 3/5
 - 31s - loss: 0.3108 - acc: 0.8935 - val_loss: 0.8428 - val_acc: 0.5730
Epoch 4/5
 - 31s - loss: 0.2425 - acc: 0.9249 - val_loss: 1.0972 - val_acc: 0.5388
Epoch 5/5
 - 31s - loss: 0.1910 - acc: 0.9500 - val_loss: 1.0220 - val_acc: 0.5466

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.520
current auc_score ------------------> 0.764
accuracies:  [0.5, 0.5986559139784946, 0.5196236559139785]
['3-3-3', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6613 - acc: 0.7456 - val_loss: 0.4606 - val_acc: 0.8377
Epoch 2/5
 - 35s - loss: 0.4016 - acc: 0.8700 - val_loss: 0.3439 - val_acc: 0.9009
Epoch 3/5
 - 35s - loss: 0.2915 - acc: 0.9257 - val_loss: 0.2517 - val_acc: 0.9474
Epoch 4/5
 - 35s - loss: 0.2207 - acc: 0.9572 - val_loss: 0.1808 - val_acc: 0.9724
Epoch 5/5
 - 35s - loss: 0.1817 - acc: 0.9718 - val_loss: 0.1385 - val_acc: 0.9883
Test accuracy:0.617
current auc_score ------------------> 0.892
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6658 - acc: 0.7450 - val_loss: 0.5318 - val_acc: 0.7958
Epoch 2/5
 - 32s - loss: 0.4209 - acc: 0.8586 - val_loss: 0.3724 - val_acc: 0.8894
Epoch 3/5
 - 33s - loss: 0.3038 - acc: 0.9179 - val_loss: 0.2451 - val_acc: 0.9551
Epoch 4/5
 - 33s - loss: 0.2281 - acc: 0.9539 - val_loss: 0.1923 - val_acc: 0.9705
Epoch 5/5
 - 32s - loss: 0.1863 - acc: 0.9714 - val_loss: 0.1564 - val_acc: 0.9848
Test accuracy:0.567
current auc_score ------------------> 0.849
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.6440 - acc: 0.7582 - val_loss: 0.5253 - val_acc: 0.8067
Epoch 2/5
 - 35s - loss: 0.3952 - acc: 0.8734 - val_loss: 0.3119 - val_acc: 0.9204
Epoch 3/5
 - 35s - loss: 0.2866 - acc: 0.9270 - val_loss: 0.2727 - val_acc: 0.9364
Epoch 4/5
 - 35s - loss: 0.2240 - acc: 0.9543 - val_loss: 0.1750 - val_acc: 0.9773
Epoch 5/5
 - 35s - loss: 0.1825 - acc: 0.9714 - val_loss: 0.1484 - val_acc: 0.9852
Test accuracy:0.691
current auc_score ------------------> 0.885
accuracies:  [0.6174731182795699, 0.5669354838709677, 0.690994623655914]
['3-3-3', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6581 - acc: 0.7742 - val_loss: 0.4930 - val_acc: 0.8496
Epoch 2/5
 - 33s - loss: 0.4152 - acc: 0.8864 - val_loss: 0.4050 - val_acc: 0.9006
Epoch 3/5
 - 33s - loss: 0.3103 - acc: 0.9393 - val_loss: 0.2554 - val_acc: 0.9684
Epoch 4/5
 - 33s - loss: 0.2444 - acc: 0.9668 - val_loss: 0.2252 - val_acc: 0.9738
Epoch 5/5
 - 33s - loss: 0.2085 - acc: 0.9789 - val_loss: 0.1781 - val_acc: 0.9895
Test accuracy:0.757
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6692 - acc: 0.7657 - val_loss: 0.5403 - val_acc: 0.8338
Epoch 2/5
 - 33s - loss: 0.4284 - acc: 0.8816 - val_loss: 0.4060 - val_acc: 0.9189
Epoch 3/5
 - 33s - loss: 0.3186 - acc: 0.9342 - val_loss: 0.3314 - val_acc: 0.9334
Epoch 4/5
 - 32s - loss: 0.2508 - acc: 0.9654 - val_loss: 0.2871 - val_acc: 0.9675
Epoch 5/5
 - 33s - loss: 0.2098 - acc: 0.9797 - val_loss: 0.1735 - val_acc: 0.9922
Test accuracy:0.628
current auc_score ------------------> 0.859
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6775 - acc: 0.7634 - val_loss: 1.1876 - val_acc: 0.5141
Epoch 2/5
 - 33s - loss: 0.4166 - acc: 0.8890 - val_loss: 0.8277 - val_acc: 0.6012
Epoch 3/5
 - 33s - loss: 0.3066 - acc: 0.9423 - val_loss: 0.2469 - val_acc: 0.9730
Epoch 4/5
 - 33s - loss: 0.2450 - acc: 0.9674 - val_loss: 0.2034 - val_acc: 0.9854
Epoch 5/5
 - 33s - loss: 0.2102 - acc: 0.9802 - val_loss: 0.1893 - val_acc: 0.9901
Test accuracy:0.664
current auc_score ------------------> 0.893
accuracies:  [0.7565860215053763, 0.6276881720430108, 0.6641129032258064]
['4-4-4', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.6342 - acc: 0.7443 - val_loss: 0.4633 - val_acc: 0.8064
Epoch 2/5
 - 36s - loss: 0.3937 - acc: 0.8578 - val_loss: 0.3309 - val_acc: 0.8988
Epoch 3/5
 - 36s - loss: 0.2863 - acc: 0.9122 - val_loss: 0.2367 - val_acc: 0.9411
Epoch 4/5
 - 36s - loss: 0.2266 - acc: 0.9404 - val_loss: 0.1822 - val_acc: 0.9615
Epoch 5/5
 - 36s - loss: 0.1800 - acc: 0.9616 - val_loss: 0.1401 - val_acc: 0.9789
Test accuracy:0.627
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6937 - acc: 0.7161 - val_loss: 2.2524 - val_acc: 0.4758
Epoch 2/5
 - 37s - loss: 0.4475 - acc: 0.8278 - val_loss: 1.2083 - val_acc: 0.5131
Epoch 3/5
 - 37s - loss: 0.3300 - acc: 0.8885 - val_loss: 1.4562 - val_acc: 0.5080
Epoch 4/5
 - 37s - loss: 0.2510 - acc: 0.9289 - val_loss: 1.2507 - val_acc: 0.5213

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 36s - loss: 0.2047 - acc: 0.9490 - val_loss: 1.4722 - val_acc: 0.5132
Test accuracy:0.500
current auc_score ------------------> 0.589
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.6818 - acc: 0.7188 - val_loss: 1.3914 - val_acc: 0.5395
Epoch 2/5
 - 36s - loss: 0.4395 - acc: 0.8360 - val_loss: 1.4483 - val_acc: 0.5439
Epoch 3/5
 - 36s - loss: 0.3243 - acc: 0.8930 - val_loss: 0.6999 - val_acc: 0.6451
Epoch 4/5
 - 36s - loss: 0.2481 - acc: 0.9317 - val_loss: 0.6835 - val_acc: 0.6305
Epoch 5/5
 - 36s - loss: 0.1958 - acc: 0.9548 - val_loss: 0.6448 - val_acc: 0.6921
Test accuracy:0.632
current auc_score ------------------> 0.820
accuracies:  [0.6270161290322581, 0.5, 0.6323924731182796]
['4-4-4', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 49s - loss: 0.6735 - acc: 0.7530 - val_loss: 0.5337 - val_acc: 0.8176
Epoch 2/5
 - 39s - loss: 0.4277 - acc: 0.8732 - val_loss: 0.4043 - val_acc: 0.8819
Epoch 3/5
 - 40s - loss: 0.3165 - acc: 0.9311 - val_loss: 0.2724 - val_acc: 0.9492
Epoch 4/5
 - 40s - loss: 0.2495 - acc: 0.9592 - val_loss: 0.2074 - val_acc: 0.9753
Epoch 5/5
 - 39s - loss: 0.2091 - acc: 0.9760 - val_loss: 0.1874 - val_acc: 0.9793
Test accuracy:0.652
current auc_score ------------------> 0.872
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6535 - acc: 0.7707 - val_loss: 3.5044 - val_acc: 0.4970
Epoch 2/5
 - 36s - loss: 0.4156 - acc: 0.8778 - val_loss: 2.5516 - val_acc: 0.4965
Epoch 3/5
 - 37s - loss: 0.3055 - acc: 0.9336 - val_loss: 0.8374 - val_acc: 0.5723
Epoch 4/5
 - 37s - loss: 0.2425 - acc: 0.9593 - val_loss: 1.2634 - val_acc: 0.5247
Epoch 5/5
 - 37s - loss: 0.2036 - acc: 0.9754 - val_loss: 1.1388 - val_acc: 0.5251

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.498
current auc_score ------------------> 0.616
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6539 - acc: 0.7681 - val_loss: 0.4785 - val_acc: 0.8424
Epoch 2/5
 - 37s - loss: 0.4131 - acc: 0.8801 - val_loss: 0.3512 - val_acc: 0.9125
Epoch 3/5
 - 37s - loss: 0.3091 - acc: 0.9296 - val_loss: 0.2489 - val_acc: 0.9576
Epoch 4/5
 - 37s - loss: 0.2468 - acc: 0.9592 - val_loss: 0.2035 - val_acc: 0.9759
Epoch 5/5
 - 37s - loss: 0.2045 - acc: 0.9757 - val_loss: 0.1660 - val_acc: 0.9892
Test accuracy:0.630
current auc_score ------------------> 0.827
accuracies:  [0.6518817204301075, 0.49798387096774194, 0.6299731182795699]
['4-4-4', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.7121 - acc: 0.7657 - val_loss: 2.1413 - val_acc: 0.5060
Epoch 2/5
 - 38s - loss: 0.4727 - acc: 0.8828 - val_loss: 1.1961 - val_acc: 0.5451
Epoch 3/5
 - 38s - loss: 0.3527 - acc: 0.9419 - val_loss: 0.9156 - val_acc: 0.6509
Epoch 4/5
 - 38s - loss: 0.2898 - acc: 0.9681 - val_loss: 0.8122 - val_acc: 0.6566
Epoch 5/5
 - 38s - loss: 0.2518 - acc: 0.9812 - val_loss: 0.9051 - val_acc: 0.6519
Test accuracy:0.724
current auc_score ------------------> 0.695
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.7303 - acc: 0.7583 - val_loss: 1.0668 - val_acc: 0.5020
Epoch 2/5
 - 38s - loss: 0.5010 - acc: 0.8685 - val_loss: 0.9763 - val_acc: 0.5264
Epoch 3/5
 - 38s - loss: 0.3793 - acc: 0.9274 - val_loss: 1.0942 - val_acc: 0.5860
Epoch 4/5
 - 39s - loss: 0.3036 - acc: 0.9607 - val_loss: 1.1091 - val_acc: 0.5773

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 39s - loss: 0.2597 - acc: 0.9773 - val_loss: 1.3567 - val_acc: 0.5412
Test accuracy:0.522
current auc_score ------------------> 0.619
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 49s - loss: 0.7742 - acc: 0.7337 - val_loss: 0.6666 - val_acc: 0.7789
Epoch 2/5
 - 40s - loss: 0.4997 - acc: 0.8686 - val_loss: 0.4773 - val_acc: 0.8833
Epoch 3/5
 - 40s - loss: 0.3806 - acc: 0.9282 - val_loss: 0.3405 - val_acc: 0.9468
Epoch 4/5
 - 40s - loss: 0.3096 - acc: 0.9598 - val_loss: 0.2790 - val_acc: 0.9753
Epoch 5/5
 - 40s - loss: 0.2654 - acc: 0.9760 - val_loss: 0.2473 - val_acc: 0.9843
Test accuracy:0.638
current auc_score ------------------> 0.840
accuracies:  [0.7244623655913979, 0.5219086021505376, 0.6384408602150538]
['6-6-6', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.6657 - acc: 0.7379 - val_loss: 0.6127 - val_acc: 0.7385
Epoch 2/5
 - 45s - loss: 0.4256 - acc: 0.8572 - val_loss: 0.4083 - val_acc: 0.8725
Epoch 3/5
 - 45s - loss: 0.3158 - acc: 0.9139 - val_loss: 0.2706 - val_acc: 0.9378
Epoch 4/5
 - 44s - loss: 0.2495 - acc: 0.9442 - val_loss: 0.2362 - val_acc: 0.9557
Epoch 5/5
 - 43s - loss: 0.2030 - acc: 0.9639 - val_loss: 0.1847 - val_acc: 0.9738
Test accuracy:0.681
current auc_score ------------------> 0.848
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6511 - acc: 0.7518 - val_loss: 1.1418 - val_acc: 0.5173
Epoch 2/5
 - 46s - loss: 0.4010 - acc: 0.8734 - val_loss: 1.9718 - val_acc: 0.5038
Epoch 3/5
 - 46s - loss: 0.3014 - acc: 0.9229 - val_loss: 0.7543 - val_acc: 0.6225
Epoch 4/5
 - 45s - loss: 0.2380 - acc: 0.9505 - val_loss: 1.6057 - val_acc: 0.5080
Epoch 5/5
 - 46s - loss: 0.2015 - acc: 0.9653 - val_loss: 0.8130 - val_acc: 0.5633

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.512
current auc_score ------------------> 0.527
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6592 - acc: 0.7500 - val_loss: 0.6038 - val_acc: 0.7633
Epoch 2/5
 - 46s - loss: 0.4355 - acc: 0.8539 - val_loss: 0.5053 - val_acc: 0.8120
Epoch 3/5
 - 46s - loss: 0.3357 - acc: 0.9041 - val_loss: 0.2854 - val_acc: 0.9359
Epoch 4/5
 - 46s - loss: 0.2644 - acc: 0.9398 - val_loss: 0.2237 - val_acc: 0.9598
Epoch 5/5
 - 46s - loss: 0.2141 - acc: 0.9614 - val_loss: 0.1895 - val_acc: 0.9731
Test accuracy:0.597
current auc_score ------------------> 0.811
accuracies:  [0.6813172043010752, 0.5122311827956989, 0.5973118279569892]
['6-6-6', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.7467 - acc: 0.7535 - val_loss: 1.7836 - val_acc: 0.5025
Epoch 2/5
 - 49s - loss: 0.4907 - acc: 0.8742 - val_loss: 1.2697 - val_acc: 0.5087
Epoch 3/5
 - 49s - loss: 0.3735 - acc: 0.9331 - val_loss: 0.8873 - val_acc: 0.5646
Epoch 4/5
 - 49s - loss: 0.3054 - acc: 0.9611 - val_loss: 0.2764 - val_acc: 0.9724
Epoch 5/5
 - 49s - loss: 0.2654 - acc: 0.9752 - val_loss: 0.2420 - val_acc: 0.9852
Test accuracy:0.652
current auc_score ------------------> 0.899
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 62s - loss: 0.7111 - acc: 0.7646 - val_loss: 3.5184 - val_acc: 0.4965
Epoch 2/5
 - 48s - loss: 0.4685 - acc: 0.8857 - val_loss: 0.9609 - val_acc: 0.5675
Epoch 3/5
 - 49s - loss: 0.3633 - acc: 0.9374 - val_loss: 1.2016 - val_acc: 0.5437
Epoch 4/5
 - 48s - loss: 0.2979 - acc: 0.9647 - val_loss: 1.4808 - val_acc: 0.5028

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 48s - loss: 0.2605 - acc: 0.9789 - val_loss: 0.8556 - val_acc: 0.6680
Test accuracy:0.550
current auc_score ------------------> 0.635
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.7193 - acc: 0.7629 - val_loss: 0.5914 - val_acc: 0.8209
Epoch 2/5
 - 49s - loss: 0.4864 - acc: 0.8761 - val_loss: 0.4004 - val_acc: 0.9212
Epoch 3/5
 - 50s - loss: 0.3754 - acc: 0.9313 - val_loss: 0.3389 - val_acc: 0.9490
Epoch 4/5
 - 49s - loss: 0.3085 - acc: 0.9611 - val_loss: 0.2534 - val_acc: 0.9824
Epoch 5/5
 - 48s - loss: 0.2680 - acc: 0.9749 - val_loss: 0.2253 - val_acc: 0.9893
Test accuracy:0.686
current auc_score ------------------> 0.873
accuracies:  [0.6518817204301075, 0.55, 0.6860215053763441]
['6-6-6', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 67s - loss: 0.7904 - acc: 0.7723 - val_loss: 0.8867 - val_acc: 0.7164
Epoch 2/5
 - 51s - loss: 0.5588 - acc: 0.8885 - val_loss: 0.6051 - val_acc: 0.8672
Epoch 3/5
 - 49s - loss: 0.4394 - acc: 0.9445 - val_loss: 0.4489 - val_acc: 0.9366
Epoch 4/5
 - 49s - loss: 0.3761 - acc: 0.9706 - val_loss: 0.3721 - val_acc: 0.9682
Epoch 5/5
 - 49s - loss: 0.3339 - acc: 0.9823 - val_loss: 0.3135 - val_acc: 0.9882
Test accuracy:0.649
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.7849 - acc: 0.7767 - val_loss: 3.1119 - val_acc: 0.5021
Epoch 2/5
 - 49s - loss: 0.5518 - acc: 0.8920 - val_loss: 1.3520 - val_acc: 0.4833
Epoch 3/5
 - 48s - loss: 0.4414 - acc: 0.9426 - val_loss: 2.7398 - val_acc: 0.5045
Epoch 4/5
 - 48s - loss: 0.3754 - acc: 0.9685 - val_loss: 2.2467 - val_acc: 0.5060

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 48s - loss: 0.3341 - acc: 0.9836 - val_loss: 2.0706 - val_acc: 0.5078
Test accuracy:0.497
current auc_score ------------------> 0.484
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 64s - loss: 0.7711 - acc: 0.7850 - val_loss: 1.1499 - val_acc: 0.5506
Epoch 2/5
 - 50s - loss: 0.5389 - acc: 0.8973 - val_loss: 0.9726 - val_acc: 0.5945
Epoch 3/5
 - 50s - loss: 0.4325 - acc: 0.9468 - val_loss: 1.0730 - val_acc: 0.5812
Epoch 4/5
 - 50s - loss: 0.3710 - acc: 0.9712 - val_loss: 1.4073 - val_acc: 0.5110

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 50s - loss: 0.3352 - acc: 0.9834 - val_loss: 0.9967 - val_acc: 0.6406
Test accuracy:0.622
current auc_score ------------------> 0.748
accuracies:  [0.6491935483870968, 0.4969086021505376, 0.6217741935483871]
['2-2-2-2', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.8449 - acc: 0.6172 - val_loss: 0.6928 - val_acc: 0.6344
Epoch 2/5
 - 32s - loss: 0.6970 - acc: 0.6782 - val_loss: 0.7033 - val_acc: 0.6403
Epoch 3/5
 - 32s - loss: 0.6151 - acc: 0.7143 - val_loss: 0.5455 - val_acc: 0.7494
Epoch 4/5
 - 32s - loss: 0.5372 - acc: 0.7600 - val_loss: 0.4935 - val_acc: 0.7923
Epoch 5/5
 - 32s - loss: 0.4673 - acc: 0.8022 - val_loss: 0.4342 - val_acc: 0.8315
Test accuracy:0.706
current auc_score ------------------> 0.796
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.8225 - acc: 0.6281 - val_loss: 2.0730 - val_acc: 0.4970
Epoch 2/5
 - 30s - loss: 0.6535 - acc: 0.7013 - val_loss: 0.5602 - val_acc: 0.7451
Epoch 3/5
 - 30s - loss: 0.5615 - acc: 0.7514 - val_loss: 0.4777 - val_acc: 0.7968
Epoch 4/5
 - 30s - loss: 0.4901 - acc: 0.7904 - val_loss: 0.4427 - val_acc: 0.8150
Epoch 5/5
 - 31s - loss: 0.4255 - acc: 0.8280 - val_loss: 0.3634 - val_acc: 0.8587
Test accuracy:0.728
current auc_score ------------------> 0.841
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.8219 - acc: 0.6292 - val_loss: 0.9575 - val_acc: 0.5286
Epoch 2/5
 - 30s - loss: 0.6774 - acc: 0.6879 - val_loss: 0.6452 - val_acc: 0.6878
Epoch 3/5
 - 30s - loss: 0.5831 - acc: 0.7331 - val_loss: 0.5852 - val_acc: 0.7323
Epoch 4/5
 - 30s - loss: 0.5070 - acc: 0.7760 - val_loss: 0.5781 - val_acc: 0.7462
Epoch 5/5
 - 31s - loss: 0.4515 - acc: 0.8076 - val_loss: 0.4085 - val_acc: 0.8315
Test accuracy:0.699
current auc_score ------------------> 0.820
accuracies:  [0.7060483870967742, 0.728225806451613, 0.698521505376344]
['2-2-2-2', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.8384 - acc: 0.6424 - val_loss: 0.8043 - val_acc: 0.6195
Epoch 2/5
 - 34s - loss: 0.6596 - acc: 0.7255 - val_loss: 0.6580 - val_acc: 0.7224
Epoch 3/5
 - 34s - loss: 0.5440 - acc: 0.7885 - val_loss: 0.4966 - val_acc: 0.8233
Epoch 4/5
 - 34s - loss: 0.4614 - acc: 0.8347 - val_loss: 0.4958 - val_acc: 0.8323
Epoch 5/5
 - 34s - loss: 0.3871 - acc: 0.8724 - val_loss: 0.4471 - val_acc: 0.8606
Test accuracy:0.637
current auc_score ------------------> 0.818
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.8176 - acc: 0.6474 - val_loss: 0.8049 - val_acc: 0.5963
Epoch 2/5
 - 31s - loss: 0.6404 - acc: 0.7315 - val_loss: 0.6018 - val_acc: 0.7688
Epoch 3/5
 - 31s - loss: 0.5205 - acc: 0.8029 - val_loss: 0.5560 - val_acc: 0.7954
Epoch 4/5
 - 31s - loss: 0.4377 - acc: 0.8471 - val_loss: 0.4245 - val_acc: 0.8604
Epoch 5/5
 - 31s - loss: 0.3746 - acc: 0.8805 - val_loss: 0.3655 - val_acc: 0.8873
Test accuracy:0.644
current auc_score ------------------> 0.835
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.8255 - acc: 0.6556 - val_loss: 0.7241 - val_acc: 0.6619
Epoch 2/5
 - 32s - loss: 0.6338 - acc: 0.7417 - val_loss: 0.5806 - val_acc: 0.7561
Epoch 3/5
 - 31s - loss: 0.5191 - acc: 0.7994 - val_loss: 0.5091 - val_acc: 0.8159
Epoch 4/5
 - 31s - loss: 0.4332 - acc: 0.8472 - val_loss: 0.5052 - val_acc: 0.8322
Epoch 5/5
 - 31s - loss: 0.3644 - acc: 0.8830 - val_loss: 0.3301 - val_acc: 0.9085
Test accuracy:0.681
current auc_score ------------------> 0.818
accuracies:  [0.6368279569892473, 0.6442204301075268, 0.6810483870967742]
['2-2-2-2', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.8983 - acc: 0.6345 - val_loss: 0.9605 - val_acc: 0.5769
Epoch 2/5
 - 34s - loss: 0.7019 - acc: 0.7226 - val_loss: 0.7298 - val_acc: 0.7196
Epoch 3/5
 - 34s - loss: 0.5445 - acc: 0.8097 - val_loss: 0.5294 - val_acc: 0.8220
Epoch 4/5
 - 35s - loss: 0.4312 - acc: 0.8719 - val_loss: 0.4687 - val_acc: 0.8576
Epoch 5/5
 - 34s - loss: 0.3564 - acc: 0.9106 - val_loss: 0.3345 - val_acc: 0.9177
Test accuracy:0.637
current auc_score ------------------> 0.820
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.8312 - acc: 0.6692 - val_loss: 1.2922 - val_acc: 0.5265
Epoch 2/5
 - 31s - loss: 0.6163 - acc: 0.7705 - val_loss: 0.8556 - val_acc: 0.5739
Epoch 3/5
 - 31s - loss: 0.4873 - acc: 0.8405 - val_loss: 0.8296 - val_acc: 0.6067
Epoch 4/5
 - 31s - loss: 0.4014 - acc: 0.8863 - val_loss: 0.9972 - val_acc: 0.5419
Epoch 5/5
 - 32s - loss: 0.3296 - acc: 0.9228 - val_loss: 0.8896 - val_acc: 0.5730

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.538
current auc_score ------------------> 0.584
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.8803 - acc: 0.6448 - val_loss: 0.7262 - val_acc: 0.6864
Epoch 2/5
 - 31s - loss: 0.6891 - acc: 0.7292 - val_loss: 0.6390 - val_acc: 0.7600
Epoch 3/5
 - 31s - loss: 0.5481 - acc: 0.8096 - val_loss: 0.5271 - val_acc: 0.8323
Epoch 4/5
 - 31s - loss: 0.4443 - acc: 0.8683 - val_loss: 0.3724 - val_acc: 0.9060
Epoch 5/5
 - 31s - loss: 0.3673 - acc: 0.9059 - val_loss: 0.3161 - val_acc: 0.9301
Test accuracy:0.604
current auc_score ------------------> 0.810
accuracies:  [0.6365591397849463, 0.5383064516129032, 0.6040322580645161]
['3-3-3-3', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8025 - acc: 0.6516 - val_loss: 0.6830 - val_acc: 0.6786
Epoch 2/5
 - 39s - loss: 0.6488 - acc: 0.7192 - val_loss: 0.6271 - val_acc: 0.7431
Epoch 3/5
 - 38s - loss: 0.5478 - acc: 0.7718 - val_loss: 0.5296 - val_acc: 0.8021
Epoch 4/5
 - 38s - loss: 0.4681 - acc: 0.8133 - val_loss: 0.4349 - val_acc: 0.8480
Epoch 5/5
 - 39s - loss: 0.4174 - acc: 0.8473 - val_loss: 0.3687 - val_acc: 0.8769
Test accuracy:0.718
current auc_score ------------------> 0.829
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8142 - acc: 0.6490 - val_loss: 0.6565 - val_acc: 0.6688
Epoch 2/5
 - 37s - loss: 0.6707 - acc: 0.7027 - val_loss: 0.6026 - val_acc: 0.7254
Epoch 3/5
 - 37s - loss: 0.5732 - acc: 0.7532 - val_loss: 0.5414 - val_acc: 0.7879
Epoch 4/5
 - 37s - loss: 0.4944 - acc: 0.8020 - val_loss: 0.4947 - val_acc: 0.8144
Epoch 5/5
 - 37s - loss: 0.4342 - acc: 0.8378 - val_loss: 0.3912 - val_acc: 0.8677
Test accuracy:0.652
current auc_score ------------------> 0.761
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8695 - acc: 0.6057 - val_loss: 0.6810 - val_acc: 0.6485
Epoch 2/5
 - 39s - loss: 0.7189 - acc: 0.6748 - val_loss: 0.7115 - val_acc: 0.6532
Epoch 3/5
 - 39s - loss: 0.6337 - acc: 0.7199 - val_loss: 0.6245 - val_acc: 0.7113
Epoch 4/5
 - 38s - loss: 0.5628 - acc: 0.7609 - val_loss: 0.6248 - val_acc: 0.7520
Epoch 5/5
 - 38s - loss: 0.5053 - acc: 0.7942 - val_loss: 0.5130 - val_acc: 0.8105
Test accuracy:0.682
current auc_score ------------------> 0.783
accuracies:  [0.718010752688172, 0.6518817204301075, 0.6823924731182796]
['3-3-3-3', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.8041 - acc: 0.6882 - val_loss: 0.6198 - val_acc: 0.7745
Epoch 2/5
 - 40s - loss: 0.5957 - acc: 0.7885 - val_loss: 0.5118 - val_acc: 0.8315
Epoch 3/5
 - 41s - loss: 0.4894 - acc: 0.8436 - val_loss: 0.4778 - val_acc: 0.8636
Epoch 4/5
 - 41s - loss: 0.4118 - acc: 0.8815 - val_loss: 0.3652 - val_acc: 0.9060
Epoch 5/5
 - 41s - loss: 0.3544 - acc: 0.9116 - val_loss: 0.2807 - val_acc: 0.9467
Test accuracy:0.666
current auc_score ------------------> 0.851
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 49s - loss: 0.8873 - acc: 0.6468 - val_loss: 0.9729 - val_acc: 0.5784
Epoch 2/5
 - 41s - loss: 0.6995 - acc: 0.7253 - val_loss: 0.8288 - val_acc: 0.6916
Epoch 3/5
 - 40s - loss: 0.5784 - acc: 0.7893 - val_loss: 0.5535 - val_acc: 0.8117
Epoch 4/5
 - 40s - loss: 0.4843 - acc: 0.8406 - val_loss: 0.4899 - val_acc: 0.8534
Epoch 5/5
 - 40s - loss: 0.4100 - acc: 0.8803 - val_loss: 0.4095 - val_acc: 0.8883
Test accuracy:0.708
current auc_score ------------------> 0.852
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8531 - acc: 0.6684 - val_loss: 1.8137 - val_acc: 0.4964
Epoch 2/5
 - 38s - loss: 0.6501 - acc: 0.7556 - val_loss: 2.5564 - val_acc: 0.4972
Epoch 3/5
 - 38s - loss: 0.5240 - acc: 0.8202 - val_loss: 1.2209 - val_acc: 0.5236
Epoch 4/5
 - 38s - loss: 0.4448 - acc: 0.8630 - val_loss: 1.0157 - val_acc: 0.5540
Epoch 5/5
 - 38s - loss: 0.3757 - acc: 0.8994 - val_loss: 0.9690 - val_acc: 0.5999
Test accuracy:0.507
current auc_score ------------------> 0.524
accuracies:  [0.665994623655914, 0.7077956989247312, 0.5065860215053763]
['3-3-3-3', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 49s - loss: 0.9531 - acc: 0.6487 - val_loss: 6.2573 - val_acc: 0.4965
Epoch 2/5
 - 39s - loss: 0.7448 - acc: 0.7433 - val_loss: 1.1147 - val_acc: 0.5197
Epoch 3/5
 - 39s - loss: 0.6057 - acc: 0.8112 - val_loss: 2.3254 - val_acc: 0.4976
Epoch 4/5
 - 39s - loss: 0.5102 - acc: 0.8655 - val_loss: 2.4688 - val_acc: 0.4964

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 39s - loss: 0.4506 - acc: 0.8971 - val_loss: 2.3360 - val_acc: 0.4964
Test accuracy:0.500
current auc_score ------------------> 0.604
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.8875 - acc: 0.6788 - val_loss: 0.9758 - val_acc: 0.6276
Epoch 2/5
 - 39s - loss: 0.6563 - acc: 0.7878 - val_loss: 1.1154 - val_acc: 0.5343
Epoch 3/5
 - 39s - loss: 0.5383 - acc: 0.8526 - val_loss: 0.8914 - val_acc: 0.6030
Epoch 4/5
 - 39s - loss: 0.4516 - acc: 0.8961 - val_loss: 0.8748 - val_acc: 0.6219
Epoch 5/5
 - 39s - loss: 0.3760 - acc: 0.9320 - val_loss: 0.8070 - val_acc: 0.6569
Test accuracy:0.714
current auc_score ------------------> 0.759
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.8881 - acc: 0.6726 - val_loss: 1.8686 - val_acc: 0.5004
Epoch 2/5
 - 39s - loss: 0.6684 - acc: 0.7788 - val_loss: 0.7034 - val_acc: 0.7695
Epoch 3/5
 - 40s - loss: 0.5434 - acc: 0.8455 - val_loss: 0.6073 - val_acc: 0.8185
Epoch 4/5
 - 39s - loss: 0.4549 - acc: 0.8933 - val_loss: 0.4771 - val_acc: 0.8813
Epoch 5/5
 - 39s - loss: 0.3909 - acc: 0.9238 - val_loss: 0.3480 - val_acc: 0.9431
Test accuracy:0.725
current auc_score ------------------> 0.865
accuracies:  [0.5, 0.7135752688172043, 0.725]
['4-4-4-4', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 56s - loss: 0.8400 - acc: 0.6392 - val_loss: 0.7754 - val_acc: 0.6240
Epoch 2/5
 - 44s - loss: 0.6770 - acc: 0.7078 - val_loss: 0.7533 - val_acc: 0.6524
Epoch 3/5
 - 43s - loss: 0.5803 - acc: 0.7636 - val_loss: 0.6215 - val_acc: 0.7418
Epoch 4/5
 - 43s - loss: 0.4968 - acc: 0.8098 - val_loss: 0.5208 - val_acc: 0.8173
Epoch 5/5
 - 43s - loss: 0.4305 - acc: 0.8486 - val_loss: 0.3983 - val_acc: 0.8676
Test accuracy:0.683
current auc_score ------------------> 0.828
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 57s - loss: 0.8419 - acc: 0.6466 - val_loss: 0.9097 - val_acc: 0.5894
Epoch 2/5
 - 43s - loss: 0.6788 - acc: 0.7084 - val_loss: 0.9536 - val_acc: 0.6170
Epoch 3/5
 - 44s - loss: 0.5828 - acc: 0.7618 - val_loss: 0.7372 - val_acc: 0.7034
Epoch 4/5
 - 44s - loss: 0.5014 - acc: 0.8081 - val_loss: 0.7125 - val_acc: 0.7348
Epoch 5/5
 - 44s - loss: 0.4409 - acc: 0.8435 - val_loss: 0.5873 - val_acc: 0.7811
Test accuracy:0.650
current auc_score ------------------> 0.806
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 56s - loss: 0.8508 - acc: 0.6403 - val_loss: 1.7098 - val_acc: 0.5003
Epoch 2/5
 - 44s - loss: 0.6894 - acc: 0.7066 - val_loss: 0.8798 - val_acc: 0.5643
Epoch 3/5
 - 43s - loss: 0.5808 - acc: 0.7657 - val_loss: 1.0266 - val_acc: 0.5083
Epoch 4/5
 - 44s - loss: 0.4919 - acc: 0.8158 - val_loss: 1.4678 - val_acc: 0.5108

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 43s - loss: 0.4507 - acc: 0.8412 - val_loss: 1.4820 - val_acc: 0.5082
Test accuracy:0.500
current auc_score ------------------> 0.486
accuracies:  [0.6826612903225806, 0.6501344086021505, 0.49973118279569895]
['4-4-4-4', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 56s - loss: 0.8906 - acc: 0.6662 - val_loss: 3.2218 - val_acc: 0.4959
Epoch 2/5
 - 44s - loss: 0.6972 - acc: 0.7503 - val_loss: 1.8833 - val_acc: 0.5089
Epoch 3/5
 - 44s - loss: 0.5868 - acc: 0.8105 - val_loss: 1.0748 - val_acc: 0.5110
Epoch 4/5
 - 44s - loss: 0.5041 - acc: 0.8567 - val_loss: 1.5599 - val_acc: 0.5073
Epoch 5/5
 - 44s - loss: 0.4306 - acc: 0.8941 - val_loss: 1.5770 - val_acc: 0.5053

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.501
current auc_score ------------------> 0.616
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 56s - loss: 0.8833 - acc: 0.6759 - val_loss: 1.2975 - val_acc: 0.5316
Epoch 2/5
 - 44s - loss: 0.6594 - acc: 0.7812 - val_loss: 2.4114 - val_acc: 0.5023
Epoch 3/5
 - 44s - loss: 0.5418 - acc: 0.8376 - val_loss: 0.9971 - val_acc: 0.5228
Epoch 4/5
 - 44s - loss: 0.4764 - acc: 0.8734 - val_loss: 0.8759 - val_acc: 0.6177
Epoch 5/5
 - 44s - loss: 0.4217 - acc: 0.9000 - val_loss: 0.4051 - val_acc: 0.9079
Test accuracy:0.713
current auc_score ------------------> 0.862
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 56s - loss: 0.8731 - acc: 0.6724 - val_loss: 1.3403 - val_acc: 0.4287
Epoch 2/5
 - 44s - loss: 0.6802 - acc: 0.7626 - val_loss: 1.6384 - val_acc: 0.5126
Epoch 3/5
 - 44s - loss: 0.5786 - acc: 0.8157 - val_loss: 1.6791 - val_acc: 0.5029

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 44s - loss: 0.5079 - acc: 0.8563 - val_loss: 1.1771 - val_acc: 0.5147
Epoch 5/5
 - 44s - loss: 0.4834 - acc: 0.8688 - val_loss: 0.9291 - val_acc: 0.5378
Test accuracy:0.532
current auc_score ------------------> 0.617
accuracies:  [0.5008064516129033, 0.7125, 0.5315860215053764]
['4-4-4-4', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.9719 - acc: 0.6685 - val_loss: 1.0970 - val_acc: 0.5592
Epoch 2/5
 - 46s - loss: 0.7444 - acc: 0.7764 - val_loss: 1.2879 - val_acc: 0.5166
Epoch 3/5
 - 45s - loss: 0.6216 - acc: 0.8404 - val_loss: 1.0972 - val_acc: 0.5468

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 45s - loss: 0.5515 - acc: 0.8774 - val_loss: 0.6223 - val_acc: 0.8503
Epoch 5/5
 - 45s - loss: 0.5142 - acc: 0.8955 - val_loss: 0.6352 - val_acc: 0.8446
Test accuracy:0.677
current auc_score ------------------> 0.798
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.9409 - acc: 0.6899 - val_loss: 1.6811 - val_acc: 0.5019
Epoch 2/5
 - 48s - loss: 0.7217 - acc: 0.7857 - val_loss: 1.8810 - val_acc: 0.4964
Epoch 3/5
 - 46s - loss: 0.5918 - acc: 0.8567 - val_loss: 1.1383 - val_acc: 0.5502
Epoch 4/5
 - 46s - loss: 0.5008 - acc: 0.9020 - val_loss: 0.5790 - val_acc: 0.8557
Epoch 5/5
 - 46s - loss: 0.4291 - acc: 0.9327 - val_loss: 0.4262 - val_acc: 0.9321
Test accuracy:0.599
current auc_score ------------------> 0.821
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.9474 - acc: 0.6828 - val_loss: 0.8782 - val_acc: 0.6850
Epoch 2/5
 - 46s - loss: 0.7497 - acc: 0.7668 - val_loss: 0.7355 - val_acc: 0.7806
Epoch 3/5
 - 46s - loss: 0.6256 - acc: 0.8379 - val_loss: 0.6193 - val_acc: 0.8389
Epoch 4/5
 - 47s - loss: 0.5282 - acc: 0.8864 - val_loss: 0.5495 - val_acc: 0.8760
Epoch 5/5
 - 47s - loss: 0.4568 - acc: 0.9222 - val_loss: 0.4368 - val_acc: 0.9292
Test accuracy:0.678
current auc_score ------------------> 0.846
accuracies:  [0.6768817204301075, 0.5985215053763441, 0.6779569892473118]
['6-6-6-6', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 76s - loss: 0.8778 - acc: 0.6485 - val_loss: 1.4671 - val_acc: 0.4944
Epoch 2/5
 - 58s - loss: 0.7111 - acc: 0.7180 - val_loss: 1.0566 - val_acc: 0.4765
Epoch 3/5
 - 58s - loss: 0.6051 - acc: 0.7742 - val_loss: 1.0026 - val_acc: 0.5098
Epoch 4/5
 - 58s - loss: 0.5209 - acc: 0.8248 - val_loss: 1.1916 - val_acc: 0.5152
Epoch 5/5
 - 58s - loss: 0.4482 - acc: 0.8647 - val_loss: 2.0867 - val_acc: 0.5138

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.503
current auc_score ------------------> 0.542
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 75s - loss: 0.8719 - acc: 0.6577 - val_loss: 2.2925 - val_acc: 0.4984
Epoch 2/5
 - 57s - loss: 0.6922 - acc: 0.7316 - val_loss: 1.1507 - val_acc: 0.4962
Epoch 3/5
 - 58s - loss: 0.5894 - acc: 0.7878 - val_loss: 0.6074 - val_acc: 0.7809
Epoch 4/5
 - 58s - loss: 0.5179 - acc: 0.8266 - val_loss: 0.4925 - val_acc: 0.8464
Epoch 5/5
 - 57s - loss: 0.4565 - acc: 0.8593 - val_loss: 0.4450 - val_acc: 0.8701
Test accuracy:0.679
current auc_score ------------------> 0.813
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 76s - loss: 0.8729 - acc: 0.6500 - val_loss: 2.9018 - val_acc: 0.5025
Epoch 2/5
 - 58s - loss: 0.7322 - acc: 0.7061 - val_loss: 3.3319 - val_acc: 0.5035
Epoch 3/5
 - 59s - loss: 0.6352 - acc: 0.7583 - val_loss: 1.4572 - val_acc: 0.5072
Epoch 4/5
 - 59s - loss: 0.5491 - acc: 0.8085 - val_loss: 2.1840 - val_acc: 0.5035
Epoch 5/5
 - 58s - loss: 0.4701 - acc: 0.8504 - val_loss: 1.2683 - val_acc: 0.5070
Test accuracy:0.515
current auc_score ------------------> 0.542
accuracies:  [0.5026881720430108, 0.6788978494623656, 0.5145161290322581]
['6-6-6-6', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 79s - loss: 0.9673 - acc: 0.6674 - val_loss: 2.7096 - val_acc: 0.4975
Epoch 2/5
 - 61s - loss: 0.7602 - acc: 0.7645 - val_loss: 1.0058 - val_acc: 0.5351
Epoch 3/5
 - 61s - loss: 0.6501 - acc: 0.8240 - val_loss: 1.1081 - val_acc: 0.5385
Epoch 4/5
 - 61s - loss: 0.5645 - acc: 0.8703 - val_loss: 1.2725 - val_acc: 0.5251

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 60s - loss: 0.5071 - acc: 0.9001 - val_loss: 2.3651 - val_acc: 0.5040
Test accuracy:0.500
current auc_score ------------------> 0.612
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 83s - loss: 0.9790 - acc: 0.6699 - val_loss: 1.0489 - val_acc: 0.5777
Epoch 2/5
 - 61s - loss: 0.7972 - acc: 0.7488 - val_loss: 1.0631 - val_acc: 0.6069
Epoch 3/5
 - 60s - loss: 0.6769 - acc: 0.8085 - val_loss: 0.7861 - val_acc: 0.7526
Epoch 4/5
 - 60s - loss: 0.5715 - acc: 0.8661 - val_loss: 0.6354 - val_acc: 0.8338
Epoch 5/5
 - 61s - loss: 0.4962 - acc: 0.9034 - val_loss: 0.5735 - val_acc: 0.8657
Test accuracy:0.612
current auc_score ------------------> 0.812
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 78s - loss: 0.9594 - acc: 0.6712 - val_loss: 2.4405 - val_acc: 0.5051
Epoch 2/5
 - 60s - loss: 0.7684 - acc: 0.7626 - val_loss: 1.0429 - val_acc: 0.5540
Epoch 3/5
 - 60s - loss: 0.6418 - acc: 0.8280 - val_loss: 1.2721 - val_acc: 0.5310
Epoch 4/5
 - 60s - loss: 0.5531 - acc: 0.8750 - val_loss: 1.0069 - val_acc: 0.5679
Epoch 5/5
 - 59s - loss: 0.4843 - acc: 0.9081 - val_loss: 0.9901 - val_acc: 0.5577
Test accuracy:0.539
current auc_score ------------------> 0.662
accuracies:  [0.5, 0.6115591397849462, 0.5389784946236559]
['6-6-6-6', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 82s - loss: 1.0950 - acc: 0.6741 - val_loss: 2.9696 - val_acc: 0.5016
Epoch 2/5
 - 63s - loss: 0.8907 - acc: 0.7683 - val_loss: 1.1898 - val_acc: 0.5737
Epoch 3/5
 - 63s - loss: 0.7527 - acc: 0.8356 - val_loss: 1.3273 - val_acc: 0.5151
Epoch 4/5
 - 63s - loss: 0.6583 - acc: 0.8860 - val_loss: 1.4908 - val_acc: 0.5005

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 62s - loss: 0.5896 - acc: 0.9184 - val_loss: 1.2971 - val_acc: 0.5127
Test accuracy:0.503
current auc_score ------------------> 0.765
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 81s - loss: 1.0864 - acc: 0.6776 - val_loss: 1.6357 - val_acc: 0.3704
Epoch 2/5
 - 62s - loss: 0.8784 - acc: 0.7763 - val_loss: 1.7494 - val_acc: 0.5016
Epoch 3/5
 - 63s - loss: 0.7378 - acc: 0.8473 - val_loss: 2.1402 - val_acc: 0.5005

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 63s - loss: 0.6584 - acc: 0.8863 - val_loss: 1.6771 - val_acc: 0.5099
Epoch 5/5
 - 63s - loss: 0.6205 - acc: 0.9054 - val_loss: 1.2279 - val_acc: 0.5585
Test accuracy:0.506
current auc_score ------------------> 0.637
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 81s - loss: 1.0406 - acc: 0.7064 - val_loss: 4.0053 - val_acc: 0.4965
Epoch 2/5
 - 62s - loss: 0.8087 - acc: 0.8106 - val_loss: 1.3556 - val_acc: 0.5625
Epoch 3/5
 - 62s - loss: 0.6900 - acc: 0.8723 - val_loss: 1.2883 - val_acc: 0.5394
Epoch 4/5
 - 63s - loss: 0.6075 - acc: 0.9128 - val_loss: 1.3221 - val_acc: 0.5462
Epoch 5/5
 - 63s - loss: 0.5311 - acc: 0.9466 - val_loss: 1.1960 - val_acc: 0.5471
Test accuracy:0.594
current auc_score ------------------> 0.621
accuracies:  [0.5026881720430108, 0.5064516129032258, 0.594489247311828]
['0.874+/-0.019', '0.874+/-0.009', '0.888+/-0.011', '0.873+/-0.017', '0.891+/-0.012', '0.873+/-0.004', '0.896+/-0.008', '0.883+/-0.017', '0.903+/-0.01', '0.865+/-0.012', '0.88+/-0.01', '0.836+/-0.094', '0.897+/-0.012', '0.911+/-0.018', '0.877+/-0.013', '0.887+/-0.009', '0.875+/-0.028', '0.887+/-0.016', '0.889+/-0.024', '0.786+/-0.083', '0.889+/-0.024', '0.878+/-0.015', '0.843+/-0.036', '0.878+/-0.018', '0.877+/-0.039', '0.875+/-0.033', '0.878+/-0.002', '0.712+/-0.13', '0.875+/-0.019', '0.877+/-0.014', '0.764+/-0.127', '0.772+/-0.112', '0.718+/-0.091', '0.729+/-0.143', '0.802+/-0.119', '0.705+/-0.165', '0.819+/-0.018', '0.824+/-0.008', '0.738+/-0.109', '0.791+/-0.028', '0.742+/-0.154', '0.743+/-0.107', '0.707+/-0.156', '0.698+/-0.116', '0.822+/-0.019', '0.632+/-0.128', '0.695+/-0.085', '0.675+/-0.065']
