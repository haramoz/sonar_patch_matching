python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, fc_dropout, fc_filter, fc_layers
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 48s - loss: 0.5456 - acc: 0.7589 - val_loss: 0.4027 - val_acc: 0.8035
Epoch 2/12
 - 43s - loss: 0.3053 - acc: 0.8740 - val_loss: 0.2272 - val_acc: 0.9238
Epoch 3/12
 - 43s - loss: 0.2099 - acc: 0.9199 - val_loss: 0.1465 - val_acc: 0.9590
Epoch 4/12
 - 43s - loss: 0.1564 - acc: 0.9463 - val_loss: 0.1288 - val_acc: 0.9618
Epoch 5/12
 - 43s - loss: 0.1177 - acc: 0.9631 - val_loss: 0.0896 - val_acc: 0.9783
Epoch 6/12
 - 43s - loss: 0.0929 - acc: 0.9713 - val_loss: 0.0795 - val_acc: 0.9822
Epoch 7/12
 - 43s - loss: 0.0771 - acc: 0.9790 - val_loss: 0.0596 - val_acc: 0.9882
Epoch 8/12
 - 43s - loss: 0.0641 - acc: 0.9830 - val_loss: 0.0547 - val_acc: 0.9874
Epoch 9/12
 - 42s - loss: 0.0543 - acc: 0.9862 - val_loss: 0.0359 - val_acc: 0.9927
Epoch 10/12
 - 43s - loss: 0.0460 - acc: 0.9895 - val_loss: 0.0274 - val_acc: 0.9947
Epoch 11/12
 - 42s - loss: 0.0417 - acc: 0.9910 - val_loss: 0.0233 - val_acc: 0.9964
Epoch 12/12
 - 42s - loss: 0.0365 - acc: 0.9921 - val_loss: 0.0226 - val_acc: 0.9959
Test accuracy:0.631
current auc_score ------------------> 0.877
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 45s - loss: 0.5409 - acc: 0.7584 - val_loss: 0.9553 - val_acc: 0.6138
Epoch 2/12
 - 43s - loss: 0.3173 - acc: 0.8668 - val_loss: 0.8088 - val_acc: 0.6294
Epoch 3/12
 - 42s - loss: 0.2215 - acc: 0.9141 - val_loss: 0.1529 - val_acc: 0.9542
Epoch 4/12
 - 43s - loss: 0.1586 - acc: 0.9438 - val_loss: 0.1123 - val_acc: 0.9730
Epoch 5/12
 - 42s - loss: 0.1205 - acc: 0.9600 - val_loss: 0.0869 - val_acc: 0.9833
Epoch 6/12
 - 43s - loss: 0.0932 - acc: 0.9720 - val_loss: 0.0617 - val_acc: 0.9867
Epoch 7/12
 - 44s - loss: 0.0753 - acc: 0.9788 - val_loss: 0.0444 - val_acc: 0.9921
Epoch 8/12
 - 44s - loss: 0.0606 - acc: 0.9838 - val_loss: 0.0401 - val_acc: 0.9921
Epoch 9/12
 - 43s - loss: 0.0497 - acc: 0.9882 - val_loss: 0.0297 - val_acc: 0.9949
Epoch 10/12
 - 43s - loss: 0.0440 - acc: 0.9900 - val_loss: 0.0253 - val_acc: 0.9957
Epoch 11/12
 - 43s - loss: 0.0386 - acc: 0.9914 - val_loss: 0.0219 - val_acc: 0.9965
Epoch 12/12
 - 43s - loss: 0.0350 - acc: 0.9923 - val_loss: 0.0188 - val_acc: 0.9965
Test accuracy:0.637
current auc_score ------------------> 0.924
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 46s - loss: 0.5233 - acc: 0.7705 - val_loss: 0.3361 - val_acc: 0.8646
Epoch 2/12
 - 43s - loss: 0.2970 - acc: 0.8782 - val_loss: 0.2154 - val_acc: 0.9271
Epoch 3/12
 - 43s - loss: 0.2071 - acc: 0.9215 - val_loss: 0.1559 - val_acc: 0.9561
Epoch 4/12
 - 43s - loss: 0.1520 - acc: 0.9486 - val_loss: 0.1239 - val_acc: 0.9666
Epoch 5/12
 - 43s - loss: 0.1161 - acc: 0.9627 - val_loss: 0.0916 - val_acc: 0.9759
Epoch 6/12
 - 43s - loss: 0.0933 - acc: 0.9728 - val_loss: 0.0757 - val_acc: 0.9824
Epoch 7/12
 - 43s - loss: 0.0749 - acc: 0.9794 - val_loss: 0.0573 - val_acc: 0.9876
Epoch 8/12
 - 43s - loss: 0.0644 - acc: 0.9820 - val_loss: 0.0512 - val_acc: 0.9893
Epoch 9/12
 - 43s - loss: 0.0536 - acc: 0.9871 - val_loss: 0.0355 - val_acc: 0.9940
Epoch 10/12
 - 43s - loss: 0.0467 - acc: 0.9891 - val_loss: 0.0292 - val_acc: 0.9940
Epoch 11/12
 - 43s - loss: 0.0414 - acc: 0.9904 - val_loss: 0.0245 - val_acc: 0.9957
Epoch 12/12
 - 43s - loss: 0.0361 - acc: 0.9921 - val_loss: 0.0244 - val_acc: 0.9964
Test accuracy:0.544
current auc_score ------------------> 0.846
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 47s - loss: 0.5871 - acc: 0.7298 - val_loss: 0.7797 - val_acc: 0.5949
Epoch 2/12
 - 43s - loss: 0.3391 - acc: 0.8552 - val_loss: 0.8236 - val_acc: 0.6264
Epoch 3/12
 - 43s - loss: 0.2372 - acc: 0.9057 - val_loss: 0.6130 - val_acc: 0.6782
Epoch 4/12
 - 43s - loss: 0.1761 - acc: 0.9372 - val_loss: 0.5477 - val_acc: 0.7179
Epoch 5/12
 - 42s - loss: 0.1347 - acc: 0.9555 - val_loss: 0.6070 - val_acc: 0.6663
Epoch 6/12
 - 43s - loss: 0.1059 - acc: 0.9675 - val_loss: 0.6429 - val_acc: 0.6939
Epoch 7/12
 - 42s - loss: 0.0890 - acc: 0.9748 - val_loss: 0.6207 - val_acc: 0.7214

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/12
 - 42s - loss: 0.0687 - acc: 0.9829 - val_loss: 0.6499 - val_acc: 0.6994
Epoch 9/12
 - 43s - loss: 0.0659 - acc: 0.9822 - val_loss: 0.6746 - val_acc: 0.6785
Epoch 10/12
 - 42s - loss: 0.0603 - acc: 0.9857 - val_loss: 0.6706 - val_acc: 0.6904

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 11/12
 - 44s - loss: 0.0565 - acc: 0.9869 - val_loss: 0.6598 - val_acc: 0.6983
Epoch 00011: early stopping
Test accuracy:0.576
current auc_score ------------------> 0.700
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 46s - loss: 0.5421 - acc: 0.7656 - val_loss: 0.6680 - val_acc: 0.6680
Epoch 2/12
 - 43s - loss: 0.3078 - acc: 0.8737 - val_loss: 1.6675 - val_acc: 0.5231
Epoch 3/12
 - 43s - loss: 0.2107 - acc: 0.9214 - val_loss: 0.4160 - val_acc: 0.8041
Epoch 4/12
 - 43s - loss: 0.1511 - acc: 0.9475 - val_loss: 0.0959 - val_acc: 0.9744
Epoch 5/12
 - 43s - loss: 0.1086 - acc: 0.9663 - val_loss: 0.0670 - val_acc: 0.9809
Epoch 6/12
 - 43s - loss: 0.0894 - acc: 0.9735 - val_loss: 0.0527 - val_acc: 0.9874
Epoch 7/12
 - 43s - loss: 0.0725 - acc: 0.9799 - val_loss: 0.0477 - val_acc: 0.9882
Epoch 8/12
 - 43s - loss: 0.0576 - acc: 0.9852 - val_loss: 0.0341 - val_acc: 0.9926
Epoch 9/12
 - 43s - loss: 0.0502 - acc: 0.9876 - val_loss: 0.0289 - val_acc: 0.9941
Epoch 10/12
 - 43s - loss: 0.0442 - acc: 0.9900 - val_loss: 0.0249 - val_acc: 0.9947
Epoch 11/12
 - 43s - loss: 0.0386 - acc: 0.9913 - val_loss: 0.0219 - val_acc: 0.9960
Epoch 12/12
 - 43s - loss: 0.0351 - acc: 0.9923 - val_loss: 0.0191 - val_acc: 0.9964
Test accuracy:0.607
current auc_score ------------------> 0.904
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 46s - loss: 0.5670 - acc: 0.7442 - val_loss: 0.4007 - val_acc: 0.8121
Epoch 2/12
 - 43s - loss: 0.3349 - acc: 0.8575 - val_loss: 0.2854 - val_acc: 0.8820
Epoch 3/12
 - 43s - loss: 0.2375 - acc: 0.9060 - val_loss: 0.1978 - val_acc: 0.9384
Epoch 4/12
 - 43s - loss: 0.1759 - acc: 0.9358 - val_loss: 0.1340 - val_acc: 0.9625
Epoch 5/12
 - 43s - loss: 0.1363 - acc: 0.9544 - val_loss: 0.0981 - val_acc: 0.9755
Epoch 6/12
 - 43s - loss: 0.1086 - acc: 0.9663 - val_loss: 0.0867 - val_acc: 0.9788
Epoch 7/12
 - 43s - loss: 0.0906 - acc: 0.9735 - val_loss: 0.0580 - val_acc: 0.9861
Epoch 8/12
 - 43s - loss: 0.0736 - acc: 0.9803 - val_loss: 0.0485 - val_acc: 0.9890
Epoch 9/12
 - 43s - loss: 0.0612 - acc: 0.9839 - val_loss: 0.0431 - val_acc: 0.9925
Epoch 10/12
 - 43s - loss: 0.0515 - acc: 0.9874 - val_loss: 0.0317 - val_acc: 0.9936
Epoch 11/12
 - 43s - loss: 0.0451 - acc: 0.9894 - val_loss: 0.0263 - val_acc: 0.9952
Epoch 12/12
 - 43s - loss: 0.0392 - acc: 0.9911 - val_loss: 0.0263 - val_acc: 0.9950
Test accuracy:0.624
current auc_score ------------------> 0.909
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 46s - loss: 0.5486 - acc: 0.7597 - val_loss: 0.4197 - val_acc: 0.7988
Epoch 2/12
 - 43s - loss: 0.3260 - acc: 0.8631 - val_loss: 0.2501 - val_acc: 0.9086
Epoch 3/12
 - 43s - loss: 0.2275 - acc: 0.9137 - val_loss: 0.2022 - val_acc: 0.9330
Epoch 4/12
 - 43s - loss: 0.1699 - acc: 0.9397 - val_loss: 0.1252 - val_acc: 0.9666
Epoch 5/12
 - 43s - loss: 0.1292 - acc: 0.9578 - val_loss: 0.1034 - val_acc: 0.9763
Epoch 6/12
 - 43s - loss: 0.1020 - acc: 0.9689 - val_loss: 0.0904 - val_acc: 0.9778
Epoch 7/12
 - 43s - loss: 0.0839 - acc: 0.9755 - val_loss: 0.0704 - val_acc: 0.9829
Epoch 8/12
 - 43s - loss: 0.0683 - acc: 0.9817 - val_loss: 0.0481 - val_acc: 0.9906
Epoch 9/12
 - 43s - loss: 0.0568 - acc: 0.9860 - val_loss: 0.0513 - val_acc: 0.9891
Epoch 10/12
 - 43s - loss: 0.0481 - acc: 0.9884 - val_loss: 0.0351 - val_acc: 0.9932
Epoch 11/12
 - 43s - loss: 0.0432 - acc: 0.9902 - val_loss: 0.0267 - val_acc: 0.9944
Epoch 12/12
 - 43s - loss: 0.0370 - acc: 0.9921 - val_loss: 0.0281 - val_acc: 0.9945
Test accuracy:0.593
current auc_score ------------------> 0.902
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 48s - loss: 0.5422 - acc: 0.7614 - val_loss: 0.3630 - val_acc: 0.8392
Epoch 2/12
 - 43s - loss: 0.3113 - acc: 0.8710 - val_loss: 0.2277 - val_acc: 0.9228
Epoch 3/12
 - 43s - loss: 0.2182 - acc: 0.9161 - val_loss: 0.1506 - val_acc: 0.9570
Epoch 4/12
 - 43s - loss: 0.1574 - acc: 0.9457 - val_loss: 0.1103 - val_acc: 0.9696
Epoch 5/12
 - 43s - loss: 0.1225 - acc: 0.9605 - val_loss: 0.0763 - val_acc: 0.9809
Epoch 6/12
 - 43s - loss: 0.0960 - acc: 0.9710 - val_loss: 0.0608 - val_acc: 0.9883
Epoch 7/12
 - 43s - loss: 0.0779 - acc: 0.9779 - val_loss: 0.0470 - val_acc: 0.9906
Epoch 8/12
 - 43s - loss: 0.0631 - acc: 0.9836 - val_loss: 0.0386 - val_acc: 0.9928
Epoch 9/12
 - 43s - loss: 0.0558 - acc: 0.9861 - val_loss: 0.0325 - val_acc: 0.9936
Epoch 10/12
 - 43s - loss: 0.0484 - acc: 0.9881 - val_loss: 0.0270 - val_acc: 0.9951
Epoch 11/12
 - 43s - loss: 0.0411 - acc: 0.9911 - val_loss: 0.0235 - val_acc: 0.9957
Epoch 12/12
 - 43s - loss: 0.0371 - acc: 0.9925 - val_loss: 0.0225 - val_acc: 0.9962
Test accuracy:0.638
current auc_score ------------------> 0.903
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 46s - loss: 0.5621 - acc: 0.7481 - val_loss: 0.3639 - val_acc: 0.8445
Epoch 2/12
 - 43s - loss: 0.3181 - acc: 0.8667 - val_loss: 0.2933 - val_acc: 0.8766
Epoch 3/12
 - 43s - loss: 0.2201 - acc: 0.9159 - val_loss: 0.1764 - val_acc: 0.9423
Epoch 4/12
 - 43s - loss: 0.1618 - acc: 0.9415 - val_loss: 0.1198 - val_acc: 0.9675
Epoch 5/12
 - 43s - loss: 0.1227 - acc: 0.9610 - val_loss: 0.0859 - val_acc: 0.9785
Epoch 6/12
 - 43s - loss: 0.0979 - acc: 0.9707 - val_loss: 0.0843 - val_acc: 0.9793
Epoch 7/12
 - 44s - loss: 0.0798 - acc: 0.9772 - val_loss: 0.0496 - val_acc: 0.9898
Epoch 8/12
 - 43s - loss: 0.0650 - acc: 0.9841 - val_loss: 0.0406 - val_acc: 0.9926
Epoch 9/12
 - 43s - loss: 0.0561 - acc: 0.9863 - val_loss: 0.0346 - val_acc: 0.9930
Epoch 10/12
 - 42s - loss: 0.0482 - acc: 0.9886 - val_loss: 0.0357 - val_acc: 0.9936
Epoch 11/12
 - 42s - loss: 0.0447 - acc: 0.9898 - val_loss: 0.0270 - val_acc: 0.9952
Epoch 12/12
 - 42s - loss: 0.0362 - acc: 0.9922 - val_loss: 0.0245 - val_acc: 0.9966
Test accuracy:0.604
current auc_score ------------------> 0.927
Epochs  12  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.5  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.7  bottleneck:  False
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   1672        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   5940        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   14040       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 82, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 82, 12, 12)   328         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 82, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11808)        0           activation_7[0][0]               
==================================================================================================
Total params: 40,416
Trainable params: 39,796
Non-trainable params: 620
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11808)        40416       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23616)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12091904    merge_features[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,134,881
Trainable params: 12,133,237
Non-trainable params: 1,644
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/12
 - 45s - loss: 0.5916 - acc: 0.7317 - val_loss: 0.4621 - val_acc: 0.7544
Epoch 2/12
 - 43s - loss: 0.3430 - acc: 0.8526 - val_loss: 0.2567 - val_acc: 0.9036
Epoch 3/12
 - 44s - loss: 0.2376 - acc: 0.9068 - val_loss: 0.1710 - val_acc: 0.9435
Epoch 4/12
 - 43s - loss: 0.1737 - acc: 0.9387 - val_loss: 0.1243 - val_acc: 0.9641
Epoch 5/12
 - 43s - loss: 0.1324 - acc: 0.9574 - val_loss: 0.0911 - val_acc: 0.9746
Epoch 6/12
 - 43s - loss: 0.1041 - acc: 0.9677 - val_loss: 0.0692 - val_acc: 0.9809
Epoch 7/12
 - 43s - loss: 0.0849 - acc: 0.9752 - val_loss: 0.0565 - val_acc: 0.9873
Epoch 8/12
 - 43s - loss: 0.0704 - acc: 0.9807 - val_loss: 0.0423 - val_acc: 0.9908
Epoch 9/12
 - 44s - loss: 0.0610 - acc: 0.9846 - val_loss: 0.0420 - val_acc: 0.9912
Epoch 10/12
 - 43s - loss: 0.0519 - acc: 0.9872 - val_loss: 0.0319 - val_acc: 0.9932
Epoch 11/12
 - 43s - loss: 0.0454 - acc: 0.9890 - val_loss: 0.0293 - val_acc: 0.9937
Epoch 12/12
 - 43s - loss: 0.0389 - acc: 0.9918 - val_loss: 0.0266 - val_acc: 0.9946
Test accuracy:0.591
current auc_score ------------------> 0.911
accuracies:  [0.6314516129032258, 0.6368279569892473, 0.5444892473118279, 0.576478494623656, 0.6068548387096774, 0.6239247311827957, 0.5931451612903226, 0.6384408602150538, 0.6043010752688172, 0.5909946236559139]
aucs:  [0.8771, 0.9239, 0.8464, 0.7003, 0.9045, 0.9091, 0.9025, 0.903, 0.9274, 0.911]
mean and std AUC:  0.881+/-0.064  max:   0.9274
(['2-2', '30', '2', '16', '0.4', '0.07', '12', 'adadelta', '0.7', 'FALSE', '64', '0.5', '512', '1'], '0.881+/-0.064', 0.927)
