python hello-world.py
python hyperas_simple.py
python hyperas_contrastive_loss.py
python densenet_siamese_best_run.py
python hyperas_densenet.py
python hyperas_densenet_siamese.py
python densenet_simple.py
python keras_densenet_siamese.py
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_1[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 96, 96)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 96, 96)   0           concatenate_2[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 66, 48, 48)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 78, 48, 48)   0           concatenate_4[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_7[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 90, 48, 48)   0           concatenate_5[0][0]              
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 90)           0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            91          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 28s - loss: 0.4940 - acc: 0.7623 - val_loss: 2.3663 - val_acc: 0.6343
Epoch 2/15
 - 25s - loss: 0.4415 - acc: 0.7857 - val_loss: 0.4242 - val_acc: 0.8355
Epoch 3/15
 - 25s - loss: 0.4175 - acc: 0.7998 - val_loss: 1.1733 - val_acc: 0.7304
Epoch 4/15
 - 25s - loss: 0.3929 - acc: 0.8166 - val_loss: 0.5453 - val_acc: 0.7517
Epoch 5/15
 - 25s - loss: 0.3744 - acc: 0.8264 - val_loss: 0.4236 - val_acc: 0.8110
Epoch 00005: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 247us/step
Test accuracy: 0.8110215053763441
Test accuracy 0.6: 0.7823924731182795
auc_score ------------------>  0.908119941611747
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_2[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_10[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 42, 96, 96)   0           concatenate_7[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 54, 96, 96)   0           concatenate_8[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_12[0][0]              
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_2[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 78, 48, 48)   0           concatenate_10[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_15[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 90, 48, 48)   0           concatenate_11[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 90)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            91          global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5045 - acc: 0.7627 - val_loss: 0.5026 - val_acc: 0.8145
Epoch 2/15
 - 26s - loss: 0.4374 - acc: 0.7917 - val_loss: 0.4239 - val_acc: 0.8108
Epoch 3/15
 - 26s - loss: 0.4093 - acc: 0.8061 - val_loss: 0.4912 - val_acc: 0.7449
Epoch 4/15
 - 26s - loss: 0.3874 - acc: 0.8199 - val_loss: 0.4413 - val_acc: 0.8055
Epoch 00004: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 251us/step
Test accuracy: 0.8055107526881721
Test accuracy 0.6: 0.7701612903225806
auc_score ------------------>  0.913659960689097
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_3[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_17[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_13[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_18[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 42, 96, 96)   0           concatenate_13[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_14[0][0]             
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_19[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 54, 96, 96)   0           concatenate_14[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_15[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_20[0][0]              
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_21[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_3[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_16[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_22[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 78, 48, 48)   0           concatenate_16[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_17[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_23[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 90, 48, 48)   0           concatenate_17[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_18[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 90)           0           activation_24[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            91          global_average_pooling2d_3[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5045 - acc: 0.7607 - val_loss: 0.5699 - val_acc: 0.6952
Epoch 2/15
 - 26s - loss: 0.4405 - acc: 0.7916 - val_loss: 0.5561 - val_acc: 0.6946
Epoch 3/15
 - 26s - loss: 0.4158 - acc: 0.8047 - val_loss: 0.8508 - val_acc: 0.7095
Epoch 4/15
 - 26s - loss: 0.3897 - acc: 0.8176 - val_loss: 0.4843 - val_acc: 0.7899
Epoch 5/15
 - 26s - loss: 0.3693 - acc: 0.8321 - val_loss: 0.5457 - val_acc: 0.7429
Epoch 6/15
 - 26s - loss: 0.3529 - acc: 0.8452 - val_loss: 0.5984 - val_acc: 0.7434
Epoch 7/15
 - 26s - loss: 0.3422 - acc: 0.8513 - val_loss: 0.7536 - val_acc: 0.6465
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 246us/step
Test accuracy: 0.646505376344086
Test accuracy 0.6: 0.619758064516129
auc_score ------------------>  0.8851376242918256
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_4[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_19[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_26[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 42, 96, 96)   0           concatenate_19[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_20[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_27[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 54, 96, 96)   0           concatenate_20[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_21[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_28[0][0]              
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_29[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_4[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_30[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 78, 48, 48)   0           concatenate_22[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_23[0][0]             
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_31[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 90, 48, 48)   0           concatenate_23[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_24[0][0]             
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 90)           0           activation_32[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            91          global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.5028 - acc: 0.7611 - val_loss: 0.7641 - val_acc: 0.7005
Epoch 2/15
 - 25s - loss: 0.4375 - acc: 0.7918 - val_loss: 0.4649 - val_acc: 0.7796
Epoch 3/15
 - 25s - loss: 0.4101 - acc: 0.8074 - val_loss: 0.5713 - val_acc: 0.7540
Epoch 4/15
 - 25s - loss: 0.3853 - acc: 0.8220 - val_loss: 0.4764 - val_acc: 0.8039
Epoch 5/15
 - 25s - loss: 0.3645 - acc: 0.8367 - val_loss: 0.4976 - val_acc: 0.7608
Epoch 6/15
 - 25s - loss: 0.3460 - acc: 0.8464 - val_loss: 1.3838 - val_acc: 0.6315
Epoch 7/15
 - 25s - loss: 0.3324 - acc: 0.8531 - val_loss: 0.3894 - val_acc: 0.8148
Epoch 8/15
 - 25s - loss: 0.3168 - acc: 0.8637 - val_loss: 0.4202 - val_acc: 0.8012
Epoch 9/15
 - 25s - loss: 0.3078 - acc: 0.8693 - val_loss: 0.5502 - val_acc: 0.7587
Epoch 10/15
 - 25s - loss: 0.2970 - acc: 0.8750 - val_loss: 0.5312 - val_acc: 0.7976
Epoch 00010: early stopping

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1792/7440 [======>.......................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2240/7440 [========>.....................] - ETA: 1s
2464/7440 [========>.....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3136/7440 [===========>..................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3584/7440 [=============>................] - ETA: 0s
3808/7440 [==============>...............] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4480/7440 [=================>............] - ETA: 0s
4704/7440 [=================>............] - ETA: 0s
4928/7440 [==================>...........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 251us/step
Test accuracy: 0.7975806451612903
Test accuracy 0.6: 0.8038978494623656
auc_score ------------------>  0.8721894510926119
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_5[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_33[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_25[0][0]             
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_34[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 42, 96, 96)   0           concatenate_25[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_35[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 54, 96, 96)   0           concatenate_26[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_27[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_36[0][0]              
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_37[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_5[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_28[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_38[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 78, 48, 48)   0           concatenate_28[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_29[0][0]             
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_39[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 90, 48, 48)   0           concatenate_29[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 90, 48, 48)   360         concatenate_30[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 90, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 90)           0           activation_40[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            91          global_average_pooling2d_5[0][0] 
==================================================================================================
Total params: 36,163
Trainable params: 35,299
Non-trainable params: 864
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/15
 - 27s - loss: 0.4896 - acc: 0.7632 - val_loss: 0.6029 - val_acc: 0.7257
Epoch 2/15
 - 25s - loss: 0.4333 - acc: 0.7917 - val_loss: 0.4956 - val_acc: 0.7317
Epoch 3/15
 - 25s - loss: 0.4109 - acc: 0.8043 - val_loss: 0.4917 - val_acc: 0.7599
Epoch 4/15
 - 25s - loss: 0.3879 - acc: 0.8189 - val_loss: 0.7710 - val_acc: 0.7070
Epoch 5/15
 - 25s - loss: 0.3718 - acc: 0.8291 - val_loss: 0.6791 - val_acc: 0.7507
Epoch 6/15
 - 25s - loss: 0.3492 - acc: 0.8420 - val_loss: 0.9516 - val_acc: 0.8079
Epoch 7/15
 - 25s - loss: 0.3368 - acc: 0.8523 - val_loss: 1.0786 - val_acc: 0.7755
Epoch 8/15
 - 25s - loss: 0.3219 - acc: 0.8616 - val_loss: 0.5172 - val_acc: 0.8060

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009486833062967954.
Epoch 9/15
 - 25s - loss: 0.2803 - acc: 0.8851 - val_loss: 0.5626 - val_acc: 0.7780
Epoch 00009: early stopping

  32/7440 [..............................] - ETA: 2s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 253us/step
Test accuracy: 0.7779569892473118
Test accuracy 0.6: 0.7920698924731183
auc_score ------------------>  0.8924464172158632
[0.908, 0.914, 0.885, 0.872, 0.892]
0.894  0.015
