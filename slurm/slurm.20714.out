python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
Column names are layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs
['2', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.3919 - acc: 0.8358 - val_loss: 0.1960 - val_acc: 0.9371
Epoch 2/5
 - 17s - loss: 0.1731 - acc: 0.9430 - val_loss: 0.1200 - val_acc: 0.9709
Epoch 3/5
 - 17s - loss: 0.1114 - acc: 0.9690 - val_loss: 0.0777 - val_acc: 0.9837
Epoch 4/5
 - 17s - loss: 0.0792 - acc: 0.9812 - val_loss: 0.0486 - val_acc: 0.9890
Epoch 5/5
 - 17s - loss: 0.0598 - acc: 0.9875 - val_loss: 0.0432 - val_acc: 0.9927
Test accuracy:0.649
current auc_score ------------------> 0.869
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.3906 - acc: 0.8366 - val_loss: 0.2139 - val_acc: 0.9182
Epoch 2/5
 - 17s - loss: 0.1760 - acc: 0.9415 - val_loss: 0.1045 - val_acc: 0.9752
Epoch 3/5
 - 17s - loss: 0.1050 - acc: 0.9717 - val_loss: 0.0707 - val_acc: 0.9876
Epoch 4/5
 - 17s - loss: 0.0790 - acc: 0.9805 - val_loss: 0.0573 - val_acc: 0.9898
Epoch 5/5
 - 17s - loss: 0.0583 - acc: 0.9884 - val_loss: 0.0487 - val_acc: 0.9937
Test accuracy:0.660
current auc_score ------------------> 0.872
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.4067 - acc: 0.8321 - val_loss: 0.2251 - val_acc: 0.9144
Epoch 2/5
 - 17s - loss: 0.1777 - acc: 0.9400 - val_loss: 0.1193 - val_acc: 0.9763
Epoch 3/5
 - 17s - loss: 0.1095 - acc: 0.9703 - val_loss: 0.0755 - val_acc: 0.9872
Epoch 4/5
 - 16s - loss: 0.0758 - acc: 0.9818 - val_loss: 0.0476 - val_acc: 0.9933
Epoch 5/5
 - 17s - loss: 0.0556 - acc: 0.9879 - val_loss: 0.0475 - val_acc: 0.9882
Test accuracy:0.730
current auc_score ------------------> 0.888
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 18s - loss: 0.3957 - acc: 0.8369 - val_loss: 0.2148 - val_acc: 0.9231
Epoch 2/5
 - 16s - loss: 0.1802 - acc: 0.9406 - val_loss: 0.1154 - val_acc: 0.9698
Epoch 3/5
 - 16s - loss: 0.1127 - acc: 0.9688 - val_loss: 0.0817 - val_acc: 0.9833
Epoch 4/5
 - 16s - loss: 0.0768 - acc: 0.9828 - val_loss: 0.0523 - val_acc: 0.9917
Epoch 5/5
 - 16s - loss: 0.0605 - acc: 0.9871 - val_loss: 0.0393 - val_acc: 0.9936
Test accuracy:0.710
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16128)        4808        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32256)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16515584    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 16,522,953
Trainable params: 16,521,669
Non-trainable params: 1,284
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.4259 - acc: 0.8195 - val_loss: 0.2682 - val_acc: 0.9032
Epoch 2/5
 - 16s - loss: 0.1976 - acc: 0.9322 - val_loss: 0.1430 - val_acc: 0.9558
Epoch 3/5
 - 16s - loss: 0.1246 - acc: 0.9655 - val_loss: 0.0833 - val_acc: 0.9800
Epoch 4/5
 - 16s - loss: 0.0849 - acc: 0.9806 - val_loss: 0.0627 - val_acc: 0.9868
Epoch 5/5
 - 16s - loss: 0.0632 - acc: 0.9864 - val_loss: 0.0472 - val_acc: 0.9927
Test accuracy:0.723
current auc_score ------------------> 0.880
accuracies:  [0.6493279569892473, 0.6600806451612903, 0.730241935483871, 0.7104838709677419, 0.7233870967741935]
aucs:  [0.8690742788183606, 0.8719884524222452, 0.8878676003006127, 0.884185888542028, 0.8800345415654989]
['2', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.4548 - acc: 0.8060 - val_loss: 0.2664 - val_acc: 0.8968
Epoch 2/5
 - 17s - loss: 0.2061 - acc: 0.9343 - val_loss: 0.1337 - val_acc: 0.9693
Epoch 3/5
 - 17s - loss: 0.1299 - acc: 0.9668 - val_loss: 0.0825 - val_acc: 0.9863
Epoch 4/5
 - 17s - loss: 0.0883 - acc: 0.9814 - val_loss: 0.0715 - val_acc: 0.9874
Epoch 5/5
 - 17s - loss: 0.0646 - acc: 0.9893 - val_loss: 0.0567 - val_acc: 0.9940
Test accuracy:0.662
current auc_score ------------------> 0.860
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4255 - acc: 0.8265 - val_loss: 0.2298 - val_acc: 0.9159
Epoch 2/5
 - 18s - loss: 0.1936 - acc: 0.9387 - val_loss: 0.1188 - val_acc: 0.9735
Epoch 3/5
 - 18s - loss: 0.1162 - acc: 0.9725 - val_loss: 0.0783 - val_acc: 0.9880
Epoch 4/5
 - 18s - loss: 0.0819 - acc: 0.9840 - val_loss: 0.0507 - val_acc: 0.9935
Epoch 5/5
 - 18s - loss: 0.0613 - acc: 0.9898 - val_loss: 0.0507 - val_acc: 0.9942
Test accuracy:0.673
current auc_score ------------------> 0.886
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4626 - acc: 0.8016 - val_loss: 0.2491 - val_acc: 0.9109
Epoch 2/5
 - 17s - loss: 0.2149 - acc: 0.9287 - val_loss: 0.1380 - val_acc: 0.9669
Epoch 3/5
 - 17s - loss: 0.1260 - acc: 0.9685 - val_loss: 0.0806 - val_acc: 0.9838
Epoch 4/5
 - 17s - loss: 0.0887 - acc: 0.9813 - val_loss: 0.0670 - val_acc: 0.9866
Epoch 5/5
 - 17s - loss: 0.0678 - acc: 0.9880 - val_loss: 0.0454 - val_acc: 0.9941
Test accuracy:0.609
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 19s - loss: 0.4443 - acc: 0.8120 - val_loss: 0.2529 - val_acc: 0.9175
Epoch 2/5
 - 17s - loss: 0.2064 - acc: 0.9330 - val_loss: 0.1297 - val_acc: 0.9709
Epoch 3/5
 - 17s - loss: 0.1266 - acc: 0.9679 - val_loss: 0.0874 - val_acc: 0.9826
Epoch 4/5
 - 17s - loss: 0.0917 - acc: 0.9807 - val_loss: 0.0621 - val_acc: 0.9906
Epoch 5/5
 - 17s - loss: 0.0707 - acc: 0.9879 - val_loss: 0.0509 - val_acc: 0.9931
Test accuracy:0.686
current auc_score ------------------> 0.867
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        14048       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 23,610,081
Trainable params: 23,608,665
Non-trainable params: 1,416
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4077 - acc: 0.8336 - val_loss: 0.2285 - val_acc: 0.9244
Epoch 2/5
 - 17s - loss: 0.1994 - acc: 0.9359 - val_loss: 0.1432 - val_acc: 0.9681
Epoch 3/5
 - 17s - loss: 0.1227 - acc: 0.9692 - val_loss: 0.0795 - val_acc: 0.9883
Epoch 4/5
 - 17s - loss: 0.0901 - acc: 0.9805 - val_loss: 0.0659 - val_acc: 0.9910
Epoch 5/5
 - 17s - loss: 0.0631 - acc: 0.9896 - val_loss: 0.0504 - val_acc: 0.9925
Test accuracy:0.700
current auc_score ------------------> 0.871
accuracies:  [0.6622311827956989, 0.673252688172043, 0.6091397849462366, 0.6856182795698925, 0.7002688172043011]
aucs:  [0.8602344924268702, 0.886403485952133, 0.8838535524338074, 0.8668020146837785, 0.8708668632211817]
['2', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4742 - acc: 0.8007 - val_loss: 0.2775 - val_acc: 0.9059
Epoch 2/5
 - 17s - loss: 0.2363 - acc: 0.9242 - val_loss: 0.1589 - val_acc: 0.9592
Epoch 3/5
 - 18s - loss: 0.1470 - acc: 0.9644 - val_loss: 0.1155 - val_acc: 0.9711
Epoch 4/5
 - 18s - loss: 0.1003 - acc: 0.9801 - val_loss: 0.0647 - val_acc: 0.9923
Epoch 5/5
 - 18s - loss: 0.0741 - acc: 0.9886 - val_loss: 0.0532 - val_acc: 0.9956
Test accuracy:0.639
current auc_score ------------------> 0.895
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4577 - acc: 0.8112 - val_loss: 0.2369 - val_acc: 0.9165
Epoch 2/5
 - 18s - loss: 0.2086 - acc: 0.9362 - val_loss: 0.1521 - val_acc: 0.9690
Epoch 3/5
 - 18s - loss: 0.1348 - acc: 0.9678 - val_loss: 0.0884 - val_acc: 0.9846
Epoch 4/5
 - 18s - loss: 0.0934 - acc: 0.9828 - val_loss: 0.0653 - val_acc: 0.9923
Epoch 5/5
 - 18s - loss: 0.0746 - acc: 0.9886 - val_loss: 0.0565 - val_acc: 0.9941
Test accuracy:0.657
current auc_score ------------------> 0.888
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4323 - acc: 0.8256 - val_loss: 0.2575 - val_acc: 0.9139
Epoch 2/5
 - 18s - loss: 0.1962 - acc: 0.9429 - val_loss: 0.1203 - val_acc: 0.9749
Epoch 3/5
 - 18s - loss: 0.1221 - acc: 0.9721 - val_loss: 0.1537 - val_acc: 0.9467
Epoch 4/5
 - 18s - loss: 0.0889 - acc: 0.9844 - val_loss: 0.0579 - val_acc: 0.9933
Epoch 5/5
 - 18s - loss: 0.0683 - acc: 0.9902 - val_loss: 0.0510 - val_acc: 0.9949
Test accuracy:0.620
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 21s - loss: 0.4496 - acc: 0.8152 - val_loss: 0.2587 - val_acc: 0.9109
Epoch 2/5
 - 18s - loss: 0.2007 - acc: 0.9393 - val_loss: 0.1245 - val_acc: 0.9757
Epoch 3/5
 - 18s - loss: 0.1225 - acc: 0.9731 - val_loss: 0.0856 - val_acc: 0.9874
Epoch 4/5
 - 18s - loss: 0.0893 - acc: 0.9843 - val_loss: 0.0564 - val_acc: 0.9932
Epoch 5/5
 - 18s - loss: 0.0709 - acc: 0.9893 - val_loss: 0.0570 - val_acc: 0.9932
Test accuracy:0.760
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        28760       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_3[0][0]                  
==================================================================================================
Total params: 30,702,681
Trainable params: 30,701,133
Non-trainable params: 1,548
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 20s - loss: 0.4209 - acc: 0.8316 - val_loss: 0.2310 - val_acc: 0.9324
Epoch 2/5
 - 18s - loss: 0.1800 - acc: 0.9497 - val_loss: 0.1197 - val_acc: 0.9782
Epoch 3/5
 - 18s - loss: 0.1132 - acc: 0.9759 - val_loss: 0.0752 - val_acc: 0.9873
Epoch 4/5
 - 18s - loss: 0.0825 - acc: 0.9851 - val_loss: 0.0629 - val_acc: 0.9936
Epoch 5/5
 - 18s - loss: 0.0666 - acc: 0.9901 - val_loss: 0.0531 - val_acc: 0.9957
Test accuracy:0.705
current auc_score ------------------> 0.867
accuracies:  [0.6391129032258065, 0.6565860215053764, 0.6204301075268818, 0.7599462365591397, 0.7048387096774194]
aucs:  [0.894738409064632, 0.8881835689097006, 0.88304970227772, 0.9021621719273906, 0.866647697710718]
['3', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 21s - loss: 0.4460 - acc: 0.8103 - val_loss: 0.2518 - val_acc: 0.9094
Epoch 2/5
 - 19s - loss: 0.2213 - acc: 0.9255 - val_loss: 0.2731 - val_acc: 0.8803
Epoch 3/5
 - 19s - loss: 0.1385 - acc: 0.9626 - val_loss: 0.0947 - val_acc: 0.9758
Epoch 4/5
 - 18s - loss: 0.0991 - acc: 0.9770 - val_loss: 0.0629 - val_acc: 0.9898
Epoch 5/5
 - 19s - loss: 0.0768 - acc: 0.9842 - val_loss: 0.0523 - val_acc: 0.9912
Test accuracy:0.715
current auc_score ------------------> 0.873
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.3927 - acc: 0.8384 - val_loss: 0.2024 - val_acc: 0.9335
Epoch 2/5
 - 19s - loss: 0.1770 - acc: 0.9436 - val_loss: 0.1139 - val_acc: 0.9721
Epoch 3/5
 - 19s - loss: 0.1053 - acc: 0.9741 - val_loss: 0.0749 - val_acc: 0.9883
Epoch 4/5
 - 19s - loss: 0.0817 - acc: 0.9819 - val_loss: 0.0718 - val_acc: 0.9859
Epoch 5/5
 - 19s - loss: 0.0655 - acc: 0.9871 - val_loss: 0.0449 - val_acc: 0.9939
Test accuracy:0.673
current auc_score ------------------> 0.896
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.4327 - acc: 0.8145 - val_loss: 0.2429 - val_acc: 0.9135
Epoch 2/5
 - 19s - loss: 0.1984 - acc: 0.9335 - val_loss: 0.1288 - val_acc: 0.9711
Epoch 3/5
 - 19s - loss: 0.1170 - acc: 0.9704 - val_loss: 0.0775 - val_acc: 0.9831
Epoch 4/5
 - 19s - loss: 0.0779 - acc: 0.9833 - val_loss: 0.0667 - val_acc: 0.9917
Epoch 5/5
 - 19s - loss: 0.0633 - acc: 0.9881 - val_loss: 0.0484 - val_acc: 0.9920
Test accuracy:0.594
current auc_score ------------------> 0.865
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.4675 - acc: 0.7974 - val_loss: 0.3313 - val_acc: 0.8623
Epoch 2/5
 - 19s - loss: 0.2300 - acc: 0.9209 - val_loss: 0.1513 - val_acc: 0.9596
Epoch 3/5
 - 19s - loss: 0.1409 - acc: 0.9608 - val_loss: 0.0941 - val_acc: 0.9780
Epoch 4/5
 - 19s - loss: 0.0945 - acc: 0.9783 - val_loss: 0.0795 - val_acc: 0.9844
Epoch 5/5
 - 19s - loss: 0.0689 - acc: 0.9858 - val_loss: 0.0465 - val_acc: 0.9927
Test accuracy:0.680
current auc_score ------------------> 0.908
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 19584)        7008        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 39168)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          20054528    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 20,064,097
Trainable params: 20,062,697
Non-trainable params: 1,400
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 22s - loss: 0.4138 - acc: 0.8273 - val_loss: 0.2330 - val_acc: 0.9201
Epoch 2/5
 - 19s - loss: 0.1965 - acc: 0.9343 - val_loss: 0.1098 - val_acc: 0.9720
Epoch 3/5
 - 19s - loss: 0.1215 - acc: 0.9664 - val_loss: 0.0817 - val_acc: 0.9871
Epoch 4/5
 - 19s - loss: 0.0888 - acc: 0.9794 - val_loss: 0.0601 - val_acc: 0.9905
Epoch 5/5
 - 19s - loss: 0.0673 - acc: 0.9863 - val_loss: 0.0509 - val_acc: 0.9935
Test accuracy:0.527
current auc_score ------------------> 0.851
accuracies:  [0.7150537634408602, 0.6727150537634409, 0.594489247311828, 0.6799731182795699, 0.5272849462365592]
aucs:  [0.8733566741819863, 0.8963362093883687, 0.8651719490692565, 0.908301212567927, 0.8514095560180368]
['3', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 24s - loss: 0.4642 - acc: 0.8042 - val_loss: 0.2638 - val_acc: 0.9144
Epoch 2/5
 - 21s - loss: 0.2182 - acc: 0.9331 - val_loss: 0.1402 - val_acc: 0.9708
Epoch 3/5
 - 21s - loss: 0.1299 - acc: 0.9716 - val_loss: 0.0985 - val_acc: 0.9807
Epoch 4/5
 - 21s - loss: 0.0951 - acc: 0.9833 - val_loss: 0.0754 - val_acc: 0.9932
Epoch 5/5
 - 21s - loss: 0.0753 - acc: 0.9886 - val_loss: 0.0564 - val_acc: 0.9947
Test accuracy:0.713
current auc_score ------------------> 0.864
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 23s - loss: 0.4671 - acc: 0.8072 - val_loss: 0.2622 - val_acc: 0.9094
Epoch 2/5
 - 20s - loss: 0.2200 - acc: 0.9328 - val_loss: 0.1344 - val_acc: 0.9718
Epoch 3/5
 - 20s - loss: 0.1426 - acc: 0.9668 - val_loss: 0.0913 - val_acc: 0.9864
Epoch 4/5
 - 20s - loss: 0.0982 - acc: 0.9815 - val_loss: 0.0674 - val_acc: 0.9902
Epoch 5/5
 - 20s - loss: 0.0807 - acc: 0.9861 - val_loss: 0.0554 - val_acc: 0.9947
Test accuracy:0.673
current auc_score ------------------> 0.867
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 24s - loss: 0.4365 - acc: 0.8188 - val_loss: 0.2396 - val_acc: 0.9222
Epoch 2/5
 - 21s - loss: 0.2123 - acc: 0.9335 - val_loss: 0.1491 - val_acc: 0.9639
Epoch 3/5
 - 21s - loss: 0.1390 - acc: 0.9670 - val_loss: 0.0857 - val_acc: 0.9861
Epoch 4/5
 - 21s - loss: 0.0980 - acc: 0.9821 - val_loss: 0.0831 - val_acc: 0.9921
Epoch 5/5
 - 21s - loss: 0.0761 - acc: 0.9880 - val_loss: 0.0541 - val_acc: 0.9950
Test accuracy:0.688
current auc_score ------------------> 0.900
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 24s - loss: 0.4429 - acc: 0.8207 - val_loss: 0.2307 - val_acc: 0.9233
Epoch 2/5
 - 21s - loss: 0.2079 - acc: 0.9354 - val_loss: 0.1325 - val_acc: 0.9695
Epoch 3/5
 - 21s - loss: 0.1388 - acc: 0.9653 - val_loss: 0.1079 - val_acc: 0.9868
Epoch 4/5
 - 21s - loss: 0.0929 - acc: 0.9826 - val_loss: 0.0658 - val_acc: 0.9925
Epoch 5/5
 - 21s - loss: 0.0764 - acc: 0.9869 - val_loss: 0.0530 - val_acc: 0.9950
Test accuracy:0.701
current auc_score ------------------> 0.906
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        21552       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 30,695,473
Trainable params: 30,693,857
Non-trainable params: 1,616
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 23s - loss: 0.4539 - acc: 0.8148 - val_loss: 0.2533 - val_acc: 0.9180
Epoch 2/5
 - 20s - loss: 0.2081 - acc: 0.9373 - val_loss: 0.1463 - val_acc: 0.9705
Epoch 3/5
 - 20s - loss: 0.1353 - acc: 0.9694 - val_loss: 0.1090 - val_acc: 0.9733
Epoch 4/5
 - 20s - loss: 0.0971 - acc: 0.9823 - val_loss: 0.0682 - val_acc: 0.9907
Epoch 5/5
 - 20s - loss: 0.0772 - acc: 0.9875 - val_loss: 0.0595 - val_acc: 0.9937
Test accuracy:0.702
current auc_score ------------------> 0.863
accuracies:  [0.7133064516129032, 0.6725806451612903, 0.6884408602150538, 0.701478494623656, 0.7020161290322581]
aucs:  [0.8637654642155161, 0.8665049066366053, 0.8996603653601571, 0.905701164874552, 0.8632372962192161]
['3', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4821 - acc: 0.8056 - val_loss: 0.2706 - val_acc: 0.9149
Epoch 2/5
 - 22s - loss: 0.2242 - acc: 0.9360 - val_loss: 0.1640 - val_acc: 0.9684
Epoch 3/5
 - 23s - loss: 0.1464 - acc: 0.9696 - val_loss: 0.1200 - val_acc: 0.9735
Epoch 4/5
 - 22s - loss: 0.1059 - acc: 0.9833 - val_loss: 0.0774 - val_acc: 0.9921
Epoch 5/5
 - 22s - loss: 0.0848 - acc: 0.9888 - val_loss: 0.0696 - val_acc: 0.9942
Test accuracy:0.722
current auc_score ------------------> 0.882
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4731 - acc: 0.8122 - val_loss: 0.2834 - val_acc: 0.9032
Epoch 2/5
 - 22s - loss: 0.2216 - acc: 0.9376 - val_loss: 0.1518 - val_acc: 0.9711
Epoch 3/5
 - 22s - loss: 0.1420 - acc: 0.9723 - val_loss: 0.1015 - val_acc: 0.9881
Epoch 4/5
 - 22s - loss: 0.1107 - acc: 0.9805 - val_loss: 0.0749 - val_acc: 0.9918
Epoch 5/5
 - 22s - loss: 0.0848 - acc: 0.9891 - val_loss: 0.0645 - val_acc: 0.9955
Test accuracy:0.654
current auc_score ------------------> 0.916
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4683 - acc: 0.8154 - val_loss: 0.2960 - val_acc: 0.9115
Epoch 2/5
 - 22s - loss: 0.2408 - acc: 0.9273 - val_loss: 0.1850 - val_acc: 0.9418
Epoch 3/5
 - 23s - loss: 0.1571 - acc: 0.9653 - val_loss: 0.0999 - val_acc: 0.9859
Epoch 4/5
 - 23s - loss: 0.1090 - acc: 0.9813 - val_loss: 0.1017 - val_acc: 0.9849
Epoch 5/5
 - 23s - loss: 0.0847 - acc: 0.9885 - val_loss: 0.0668 - val_acc: 0.9918
Test accuracy:0.755
current auc_score ------------------> 0.905
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.5296 - acc: 0.7757 - val_loss: 0.2943 - val_acc: 0.9054
Epoch 2/5
 - 23s - loss: 0.2662 - acc: 0.9145 - val_loss: 0.1658 - val_acc: 0.9629
Epoch 3/5
 - 23s - loss: 0.1588 - acc: 0.9644 - val_loss: 0.1106 - val_acc: 0.9848
Epoch 4/5
 - 23s - loss: 0.1158 - acc: 0.9794 - val_loss: 0.0818 - val_acc: 0.9927
Epoch 5/5
 - 23s - loss: 0.0875 - acc: 0.9887 - val_loss: 0.0659 - val_acc: 0.9923
Test accuracy:0.706
current auc_score ------------------> 0.876
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 40320)        44736       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 80640)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          41288192    merge_features[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_4[0][0]                  
==================================================================================================
Total params: 41,335,489
Trainable params: 41,333,657
Non-trainable params: 1,832
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4713 - acc: 0.8151 - val_loss: 0.2691 - val_acc: 0.9130
Epoch 2/5
 - 23s - loss: 0.2391 - acc: 0.9283 - val_loss: 0.1617 - val_acc: 0.9709
Epoch 3/5
 - 23s - loss: 0.1531 - acc: 0.9671 - val_loss: 0.1142 - val_acc: 0.9867
Epoch 4/5
 - 22s - loss: 0.1158 - acc: 0.9798 - val_loss: 0.0774 - val_acc: 0.9923
Epoch 5/5
 - 22s - loss: 0.0951 - acc: 0.9859 - val_loss: 0.0673 - val_acc: 0.9940
Test accuracy:0.546
current auc_score ------------------> 0.874
accuracies:  [0.7221774193548387, 0.6544354838709677, 0.7547043010752689, 0.7059139784946237, 0.5458333333333333]
aucs:  [0.8820124436351022, 0.9155519785524336, 0.9049667230315643, 0.8762734131113424, 0.8742737599722512]
['4', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4266 - acc: 0.8259 - val_loss: 0.2348 - val_acc: 0.9238
Epoch 2/5
 - 22s - loss: 0.2019 - acc: 0.9369 - val_loss: 0.1271 - val_acc: 0.9671
Epoch 3/5
 - 22s - loss: 0.1253 - acc: 0.9681 - val_loss: 0.0947 - val_acc: 0.9814
Epoch 4/5
 - 22s - loss: 0.0912 - acc: 0.9811 - val_loss: 0.0688 - val_acc: 0.9890
Epoch 5/5
 - 22s - loss: 0.0731 - acc: 0.9857 - val_loss: 0.0490 - val_acc: 0.9922
Test accuracy:0.717
current auc_score ------------------> 0.843
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.3940 - acc: 0.8420 - val_loss: 0.2129 - val_acc: 0.9362
Epoch 2/5
 - 22s - loss: 0.1793 - acc: 0.9444 - val_loss: 0.1167 - val_acc: 0.9769
Epoch 3/5
 - 22s - loss: 0.1156 - acc: 0.9716 - val_loss: 0.0831 - val_acc: 0.9787
Epoch 4/5
 - 22s - loss: 0.0785 - acc: 0.9845 - val_loss: 0.0633 - val_acc: 0.9859
Epoch 5/5
 - 22s - loss: 0.0632 - acc: 0.9886 - val_loss: 0.0432 - val_acc: 0.9942
Test accuracy:0.714
current auc_score ------------------> 0.871
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4390 - acc: 0.8135 - val_loss: 0.2710 - val_acc: 0.8985
Epoch 2/5
 - 22s - loss: 0.2115 - acc: 0.9305 - val_loss: 0.1493 - val_acc: 0.9664
Epoch 3/5
 - 22s - loss: 0.1350 - acc: 0.9638 - val_loss: 0.1071 - val_acc: 0.9813
Epoch 4/5
 - 22s - loss: 0.0970 - acc: 0.9786 - val_loss: 0.0762 - val_acc: 0.9905
Epoch 5/5
 - 21s - loss: 0.0721 - acc: 0.9856 - val_loss: 0.0593 - val_acc: 0.9922
Test accuracy:0.654
current auc_score ------------------> 0.892
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4478 - acc: 0.8115 - val_loss: 0.2666 - val_acc: 0.9017
Epoch 2/5
 - 22s - loss: 0.2276 - acc: 0.9211 - val_loss: 0.1447 - val_acc: 0.9583
Epoch 3/5
 - 21s - loss: 0.1403 - acc: 0.9622 - val_loss: 0.1202 - val_acc: 0.9734
Epoch 4/5
 - 21s - loss: 0.0972 - acc: 0.9791 - val_loss: 0.0651 - val_acc: 0.9916
Epoch 5/5
 - 21s - loss: 0.0803 - acc: 0.9837 - val_loss: 0.0589 - val_acc: 0.9930
Test accuracy:0.710
current auc_score ------------------> 0.904
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 23040)        9376        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 46080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          23593472    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 23,605,409
Trainable params: 23,603,881
Non-trainable params: 1,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4087 - acc: 0.8309 - val_loss: 0.2076 - val_acc: 0.9298
Epoch 2/5
 - 22s - loss: 0.1886 - acc: 0.9403 - val_loss: 0.1182 - val_acc: 0.9729
Epoch 3/5
 - 22s - loss: 0.1188 - acc: 0.9702 - val_loss: 0.0892 - val_acc: 0.9793
Epoch 4/5
 - 22s - loss: 0.0892 - acc: 0.9807 - val_loss: 0.0629 - val_acc: 0.9916
Epoch 5/5
 - 22s - loss: 0.0694 - acc: 0.9871 - val_loss: 0.0482 - val_acc: 0.9922
Test accuracy:0.720
current auc_score ------------------> 0.884
accuracies:  [0.7168010752688172, 0.7138440860215054, 0.6544354838709677, 0.7104838709677419, 0.7204301075268817]
aucs:  [0.8428933258180136, 0.8706351890391952, 0.8923911362585271, 0.9043116617528038, 0.884206338883108]
['4', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.5113 - acc: 0.7852 - val_loss: 0.3332 - val_acc: 0.8810
Epoch 2/5
 - 24s - loss: 0.2602 - acc: 0.9170 - val_loss: 0.1835 - val_acc: 0.9636
Epoch 3/5
 - 24s - loss: 0.1648 - acc: 0.9599 - val_loss: 0.1078 - val_acc: 0.9813
Epoch 4/5
 - 24s - loss: 0.1179 - acc: 0.9788 - val_loss: 0.0842 - val_acc: 0.9896
Epoch 5/5
 - 24s - loss: 0.0984 - acc: 0.9845 - val_loss: 0.0643 - val_acc: 0.9959
Test accuracy:0.703
current auc_score ------------------> 0.903
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.4416 - acc: 0.8273 - val_loss: 0.2781 - val_acc: 0.9154
Epoch 2/5
 - 23s - loss: 0.2180 - acc: 0.9379 - val_loss: 0.1334 - val_acc: 0.9749
Epoch 3/5
 - 24s - loss: 0.1411 - acc: 0.9703 - val_loss: 0.1125 - val_acc: 0.9843
Epoch 4/5
 - 24s - loss: 0.1073 - acc: 0.9824 - val_loss: 0.0779 - val_acc: 0.9917
Epoch 5/5
 - 24s - loss: 0.0882 - acc: 0.9872 - val_loss: 0.0656 - val_acc: 0.9952
Test accuracy:0.603
current auc_score ------------------> 0.892
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 28s - loss: 0.4640 - acc: 0.8095 - val_loss: 0.2936 - val_acc: 0.8942
Epoch 2/5
 - 24s - loss: 0.2272 - acc: 0.9324 - val_loss: 0.1775 - val_acc: 0.9632
Epoch 3/5
 - 24s - loss: 0.1455 - acc: 0.9692 - val_loss: 0.1213 - val_acc: 0.9816
Epoch 4/5
 - 23s - loss: 0.1123 - acc: 0.9804 - val_loss: 0.0847 - val_acc: 0.9910
Epoch 5/5
 - 23s - loss: 0.0869 - acc: 0.9883 - val_loss: 0.0711 - val_acc: 0.9940
Test accuracy:0.632
current auc_score ------------------> 0.904
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 28s - loss: 0.4981 - acc: 0.7925 - val_loss: 0.2897 - val_acc: 0.9039
Epoch 2/5
 - 24s - loss: 0.2574 - acc: 0.9168 - val_loss: 0.1920 - val_acc: 0.9398
Epoch 3/5
 - 24s - loss: 0.1644 - acc: 0.9597 - val_loss: 0.1228 - val_acc: 0.9794
Epoch 4/5
 - 24s - loss: 0.1142 - acc: 0.9781 - val_loss: 0.0761 - val_acc: 0.9907
Epoch 5/5
 - 24s - loss: 0.0879 - acc: 0.9873 - val_loss: 0.0731 - val_acc: 0.9944
Test accuracy:0.664
current auc_score ------------------> 0.859
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 36864)        29680       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 73728)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          37749248    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 37,781,489
Trainable params: 37,779,649
Non-trainable params: 1,840
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.4619 - acc: 0.8142 - val_loss: 0.2917 - val_acc: 0.8983
Epoch 2/5
 - 24s - loss: 0.2287 - acc: 0.9312 - val_loss: 0.1494 - val_acc: 0.9699
Epoch 3/5
 - 24s - loss: 0.1438 - acc: 0.9688 - val_loss: 0.1009 - val_acc: 0.9861
Epoch 4/5
 - 24s - loss: 0.1071 - acc: 0.9818 - val_loss: 0.0742 - val_acc: 0.9936
Epoch 5/5
 - 24s - loss: 0.0826 - acc: 0.9895 - val_loss: 0.0594 - val_acc: 0.9951
Test accuracy:0.730
current auc_score ------------------> 0.905
accuracies:  [0.7029569892473119, 0.603494623655914, 0.632258064516129, 0.6641129032258064, 0.7299731182795699]
aucs:  [0.9025141996184531, 0.8917319921378193, 0.9040019077349982, 0.8588573823563417, 0.9051783443172621]
['4', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5209 - acc: 0.7915 - val_loss: 0.2970 - val_acc: 0.9036
Epoch 2/5
 - 25s - loss: 0.2582 - acc: 0.9247 - val_loss: 0.2095 - val_acc: 0.9396
Epoch 3/5
 - 25s - loss: 0.1706 - acc: 0.9655 - val_loss: 0.1233 - val_acc: 0.9827
Epoch 4/5
 - 25s - loss: 0.1249 - acc: 0.9813 - val_loss: 0.0887 - val_acc: 0.9936
Epoch 5/5
 - 25s - loss: 0.1079 - acc: 0.9855 - val_loss: 0.0860 - val_acc: 0.9935
Test accuracy:0.590
current auc_score ------------------> 0.867
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 29s - loss: 0.4793 - acc: 0.8135 - val_loss: 0.2920 - val_acc: 0.9197
Epoch 2/5
 - 25s - loss: 0.2504 - acc: 0.9317 - val_loss: 0.1804 - val_acc: 0.9711
Epoch 3/5
 - 25s - loss: 0.1642 - acc: 0.9671 - val_loss: 0.1067 - val_acc: 0.9877
Epoch 4/5
 - 25s - loss: 0.1197 - acc: 0.9826 - val_loss: 0.0871 - val_acc: 0.9939
Epoch 5/5
 - 25s - loss: 0.0908 - acc: 0.9913 - val_loss: 0.0712 - val_acc: 0.9955
Test accuracy:0.704
current auc_score ------------------> 0.872
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5206 - acc: 0.7921 - val_loss: 0.3119 - val_acc: 0.9016
Epoch 2/5
 - 27s - loss: 0.2751 - acc: 0.9183 - val_loss: 0.2747 - val_acc: 0.9079
Epoch 3/5
 - 26s - loss: 0.1873 - acc: 0.9580 - val_loss: 0.1332 - val_acc: 0.9839
Epoch 4/5
 - 26s - loss: 0.1387 - acc: 0.9763 - val_loss: 0.1034 - val_acc: 0.9915
Epoch 5/5
 - 26s - loss: 0.1110 - acc: 0.9845 - val_loss: 0.0793 - val_acc: 0.9944
Test accuracy:0.682
current auc_score ------------------> 0.916
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 29s - loss: 0.5117 - acc: 0.8007 - val_loss: 0.3045 - val_acc: 0.9000
Epoch 2/5
 - 25s - loss: 0.2492 - acc: 0.9303 - val_loss: 0.1655 - val_acc: 0.9632
Epoch 3/5
 - 25s - loss: 0.1643 - acc: 0.9670 - val_loss: 0.1196 - val_acc: 0.9809
Epoch 4/5
 - 25s - loss: 0.1241 - acc: 0.9802 - val_loss: 0.1015 - val_acc: 0.9930
Epoch 5/5
 - 25s - loss: 0.0993 - acc: 0.9883 - val_loss: 0.0732 - val_acc: 0.9954
Test accuracy:0.705
current auc_score ------------------> 0.873
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        62080       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 51,969,665
Trainable params: 51,967,513
Non-trainable params: 2,152
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.5191 - acc: 0.7910 - val_loss: 0.2999 - val_acc: 0.9055
Epoch 2/5
 - 26s - loss: 0.2576 - acc: 0.9303 - val_loss: 0.2191 - val_acc: 0.9334
Epoch 3/5
 - 26s - loss: 0.1671 - acc: 0.9676 - val_loss: 0.1204 - val_acc: 0.9872
Epoch 4/5
 - 26s - loss: 0.1275 - acc: 0.9797 - val_loss: 0.0909 - val_acc: 0.9930
Epoch 5/5
 - 26s - loss: 0.0985 - acc: 0.9886 - val_loss: 0.0716 - val_acc: 0.9960
Test accuracy:0.740
current auc_score ------------------> 0.903
accuracies:  [0.5897849462365592, 0.7044354838709678, 0.6817204301075269, 0.7048387096774194, 0.7401881720430108]
aucs:  [0.8669949560642849, 0.8723900161868424, 0.9159229390681003, 0.8730853277835587, 0.9029524366978842]
['6', '6', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4381 - acc: 0.8221 - val_loss: 0.2744 - val_acc: 0.9134
Epoch 2/5
 - 26s - loss: 0.2128 - acc: 0.9332 - val_loss: 0.2094 - val_acc: 0.9362
Epoch 3/5
 - 26s - loss: 0.1362 - acc: 0.9682 - val_loss: 0.1012 - val_acc: 0.9843
Epoch 4/5
 - 26s - loss: 0.0948 - acc: 0.9821 - val_loss: 0.0758 - val_acc: 0.9912
Epoch 5/5
 - 26s - loss: 0.0767 - acc: 0.9880 - val_loss: 0.0646 - val_acc: 0.9947
Test accuracy:0.681
current auc_score ------------------> 0.903
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5121 - acc: 0.7792 - val_loss: 0.3405 - val_acc: 0.8687
Epoch 2/5
 - 26s - loss: 0.2668 - acc: 0.9091 - val_loss: 0.1791 - val_acc: 0.9421
Epoch 3/5
 - 26s - loss: 0.1689 - acc: 0.9562 - val_loss: 0.1174 - val_acc: 0.9804
Epoch 4/5
 - 26s - loss: 0.1177 - acc: 0.9752 - val_loss: 0.0891 - val_acc: 0.9862
Epoch 5/5
 - 26s - loss: 0.0888 - acc: 0.9848 - val_loss: 0.0676 - val_acc: 0.9912
Test accuracy:0.695
current auc_score ------------------> 0.888
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4460 - acc: 0.8191 - val_loss: 2.9642 - val_acc: 0.5038
Epoch 2/5
 - 25s - loss: 0.2218 - acc: 0.9306 - val_loss: 1.4629 - val_acc: 0.5315
Epoch 3/5
 - 26s - loss: 0.1419 - acc: 0.9666 - val_loss: 3.1211 - val_acc: 0.5035
Epoch 4/5
 - 25s - loss: 0.1049 - acc: 0.9795 - val_loss: 0.0854 - val_acc: 0.9812
Epoch 5/5
 - 26s - loss: 0.0870 - acc: 0.9855 - val_loss: 0.0664 - val_acc: 0.9918
Test accuracy:0.703
current auc_score ------------------> 0.852
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4494 - acc: 0.8145 - val_loss: 0.2745 - val_acc: 0.8970
Epoch 2/5
 - 28s - loss: 0.2293 - acc: 0.9267 - val_loss: 0.1541 - val_acc: 0.9572
Epoch 3/5
 - 27s - loss: 0.1451 - acc: 0.9648 - val_loss: 0.1098 - val_acc: 0.9774
Epoch 4/5
 - 28s - loss: 0.1104 - acc: 0.9768 - val_loss: 0.0735 - val_acc: 0.9901
Epoch 5/5
 - 27s - loss: 0.0819 - acc: 0.9857 - val_loss: 0.0661 - val_acc: 0.9902
Test accuracy:0.676
current auc_score ------------------> 0.881
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 29952)        14616       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 59904)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          30671360    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 30,688,537
Trainable params: 30,686,717
Non-trainable params: 1,820
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.4744 - acc: 0.7992 - val_loss: 4.3592 - val_acc: 0.5035
Epoch 2/5
 - 26s - loss: 0.2486 - acc: 0.9174 - val_loss: 1.1171 - val_acc: 0.6029
Epoch 3/5
 - 26s - loss: 0.1589 - acc: 0.9588 - val_loss: 2.9306 - val_acc: 0.5043
Epoch 4/5
 - 27s - loss: 0.1156 - acc: 0.9757 - val_loss: 3.4922 - val_acc: 0.5045

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 26s - loss: 0.0877 - acc: 0.9856 - val_loss: 0.1400 - val_acc: 0.9773
Test accuracy:0.741
current auc_score ------------------> 0.876
accuracies:  [0.6810483870967742, 0.6948924731182796, 0.7028225806451613, 0.6760752688172043, 0.7413978494623656]
aucs:  [0.9034874335183257, 0.8883281304197017, 0.8516996184530004, 0.8805739464099896, 0.8757771852237253]
['6', '12', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5349 - acc: 0.7837 - val_loss: 1.3600 - val_acc: 0.5389
Epoch 2/5
 - 28s - loss: 0.2742 - acc: 0.9187 - val_loss: 2.0610 - val_acc: 0.5220
Epoch 3/5
 - 28s - loss: 0.1771 - acc: 0.9628 - val_loss: 2.5714 - val_acc: 0.5085

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 28s - loss: 0.1272 - acc: 0.9815 - val_loss: 0.1155 - val_acc: 0.9897
Epoch 5/5
 - 28s - loss: 0.1051 - acc: 0.9883 - val_loss: 0.1015 - val_acc: 0.9918
Test accuracy:0.731
current auc_score ------------------> 0.875
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 35s - loss: 0.5317 - acc: 0.7806 - val_loss: 0.3160 - val_acc: 0.8970
Epoch 2/5
 - 30s - loss: 0.2680 - acc: 0.9231 - val_loss: 0.1981 - val_acc: 0.9686
Epoch 3/5
 - 30s - loss: 0.1766 - acc: 0.9635 - val_loss: 0.1186 - val_acc: 0.9826
Epoch 4/5
 - 30s - loss: 0.1297 - acc: 0.9801 - val_loss: 0.2181 - val_acc: 0.9590
Epoch 5/5
 - 30s - loss: 0.1025 - acc: 0.9873 - val_loss: 0.0772 - val_acc: 0.9959
Test accuracy:0.714
current auc_score ------------------> 0.897
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5587 - acc: 0.7655 - val_loss: 4.3222 - val_acc: 0.5035
Epoch 2/5
 - 28s - loss: 0.3061 - acc: 0.9059 - val_loss: 3.1428 - val_acc: 0.5038
Epoch 3/5
 - 28s - loss: 0.1945 - acc: 0.9565 - val_loss: 3.3529 - val_acc: 0.5036
Epoch 4/5
 - 28s - loss: 0.1411 - acc: 0.9767 - val_loss: 4.0318 - val_acc: 0.5035

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 28s - loss: 0.1073 - acc: 0.9883 - val_loss: 0.0812 - val_acc: 0.9966
Test accuracy:0.726
current auc_score ------------------> 0.894
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.5427 - acc: 0.7772 - val_loss: 0.3574 - val_acc: 0.8694
Epoch 2/5
 - 28s - loss: 0.3002 - acc: 0.9073 - val_loss: 0.2309 - val_acc: 0.9396
Epoch 3/5
 - 28s - loss: 0.2008 - acc: 0.9534 - val_loss: 0.1673 - val_acc: 0.9715
Epoch 4/5
 - 28s - loss: 0.1481 - acc: 0.9739 - val_loss: 0.1248 - val_acc: 0.9817
Epoch 5/5
 - 28s - loss: 0.1204 - acc: 0.9815 - val_loss: 0.0860 - val_acc: 0.9901
Test accuracy:0.762
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 50688)        47808       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 101376)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          51905024    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 51,955,393
Trainable params: 51,953,033
Non-trainable params: 2,360
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.4996 - acc: 0.8043 - val_loss: 0.2996 - val_acc: 0.9198
Epoch 2/5
 - 31s - loss: 0.2474 - acc: 0.9317 - val_loss: 0.1731 - val_acc: 0.9695
Epoch 3/5
 - 31s - loss: 0.1569 - acc: 0.9708 - val_loss: 0.1098 - val_acc: 0.9903
Epoch 4/5
 - 30s - loss: 0.1203 - acc: 0.9819 - val_loss: 0.1036 - val_acc: 0.9862
Epoch 5/5
 - 31s - loss: 0.0998 - acc: 0.9872 - val_loss: 0.0737 - val_acc: 0.9961
Test accuracy:0.690
current auc_score ------------------> 0.865
accuracies:  [0.7309139784946237, 0.7143817204301075, 0.7259408602150538, 0.7625, 0.6901881720430108]
aucs:  [0.8752866660885651, 0.897276997340733, 0.8944163342582958, 0.9019388079546767, 0.8652942536709446]
['6', '18', '1', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.5224 - acc: 0.8042 - val_loss: 1.9688 - val_acc: 0.5141
Epoch 2/5
 - 32s - loss: 0.2743 - acc: 0.9330 - val_loss: 2.5564 - val_acc: 0.5054
Epoch 3/5
 - 31s - loss: 0.1881 - acc: 0.9685 - val_loss: 2.0346 - val_acc: 0.5205

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 31s - loss: 0.1353 - acc: 0.9870 - val_loss: 1.1543 - val_acc: 0.6214
Epoch 5/5
 - 32s - loss: 0.1210 - acc: 0.9908 - val_loss: 1.8868 - val_acc: 0.5693
Test accuracy:0.522
current auc_score ------------------> 0.714
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.6073 - acc: 0.7557 - val_loss: 0.4353 - val_acc: 0.8491
Epoch 2/5
 - 31s - loss: 0.3563 - acc: 0.8924 - val_loss: 0.2438 - val_acc: 0.9592
Epoch 3/5
 - 31s - loss: 0.2364 - acc: 0.9499 - val_loss: 0.1768 - val_acc: 0.9799
Epoch 4/5
 - 31s - loss: 0.1701 - acc: 0.9751 - val_loss: 0.1215 - val_acc: 0.9905
Epoch 5/5
 - 31s - loss: 0.1375 - acc: 0.9839 - val_loss: 0.1090 - val_acc: 0.9920
Test accuracy:0.737
current auc_score ------------------> 0.896
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5567 - acc: 0.7868 - val_loss: 0.3244 - val_acc: 0.9148
Epoch 2/5
 - 34s - loss: 0.2925 - acc: 0.9260 - val_loss: 0.1895 - val_acc: 0.9738
Epoch 3/5
 - 34s - loss: 0.1972 - acc: 0.9669 - val_loss: 0.1643 - val_acc: 0.9802
Epoch 4/5
 - 34s - loss: 0.1490 - acc: 0.9817 - val_loss: 0.1147 - val_acc: 0.9916
Epoch 5/5
 - 33s - loss: 0.1222 - acc: 0.9893 - val_loss: 0.1032 - val_acc: 0.9959
Test accuracy:0.573
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5442 - acc: 0.7936 - val_loss: 0.3642 - val_acc: 0.8860
Epoch 2/5
 - 34s - loss: 0.3034 - acc: 0.9190 - val_loss: 0.2126 - val_acc: 0.9711
Epoch 3/5
 - 34s - loss: 0.1974 - acc: 0.9638 - val_loss: 0.1459 - val_acc: 0.9818
Epoch 4/5
 - 34s - loss: 0.1453 - acc: 0.9821 - val_loss: 0.1058 - val_acc: 0.9926
Epoch 5/5
 - 34s - loss: 0.1191 - acc: 0.9881 - val_loss: 0.0976 - val_acc: 0.9941
Test accuracy:0.706
current auc_score ------------------> 0.893
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  1  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 71424)        100872      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 142848)       0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          73138688    merge_features[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_15[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 73,242,121
Trainable params: 73,239,221
Non-trainable params: 2,900
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.5168 - acc: 0.8102 - val_loss: 0.3385 - val_acc: 0.9165
Epoch 2/5
 - 31s - loss: 0.2821 - acc: 0.9308 - val_loss: 0.2019 - val_acc: 0.9699
Epoch 3/5
 - 31s - loss: 0.1907 - acc: 0.9679 - val_loss: 0.1459 - val_acc: 0.9829
Epoch 4/5
 - 31s - loss: 0.1462 - acc: 0.9810 - val_loss: 0.1185 - val_acc: 0.9893
Epoch 5/5
 - 32s - loss: 0.1195 - acc: 0.9885 - val_loss: 0.0924 - val_acc: 0.9960
Test accuracy:0.700
current auc_score ------------------> 0.919
accuracies:  [0.5224462365591398, 0.7370967741935484, 0.5733870967741935, 0.7057795698924731, 0.7002688172043011]
aucs:  [0.7143447580645161, 0.8964004870505261, 0.8834423777315297, 0.8927452595675801, 0.9189399063475546]
['2-2', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4527 - acc: 0.8110 - val_loss: 0.2353 - val_acc: 0.9164
Epoch 2/5
 - 23s - loss: 0.2120 - acc: 0.9299 - val_loss: 0.1382 - val_acc: 0.9649
Epoch 3/5
 - 23s - loss: 0.1350 - acc: 0.9640 - val_loss: 0.0947 - val_acc: 0.9804
Epoch 4/5
 - 23s - loss: 0.0993 - acc: 0.9781 - val_loss: 0.0672 - val_acc: 0.9886
Epoch 5/5
 - 23s - loss: 0.0769 - acc: 0.9853 - val_loss: 0.0539 - val_acc: 0.9926
Test accuracy:0.703
current auc_score ------------------> 0.908
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4558 - acc: 0.8135 - val_loss: 0.2223 - val_acc: 0.9271
Epoch 2/5
 - 22s - loss: 0.2080 - acc: 0.9305 - val_loss: 0.1388 - val_acc: 0.9636
Epoch 3/5
 - 22s - loss: 0.1257 - acc: 0.9664 - val_loss: 0.0899 - val_acc: 0.9838
Epoch 4/5
 - 21s - loss: 0.0932 - acc: 0.9794 - val_loss: 0.0628 - val_acc: 0.9902
Epoch 5/5
 - 21s - loss: 0.0726 - acc: 0.9864 - val_loss: 0.0525 - val_acc: 0.9925
Test accuracy:0.736
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4410 - acc: 0.8179 - val_loss: 0.2255 - val_acc: 0.9261
Epoch 2/5
 - 22s - loss: 0.2046 - acc: 0.9323 - val_loss: 0.1330 - val_acc: 0.9689
Epoch 3/5
 - 23s - loss: 0.1290 - acc: 0.9653 - val_loss: 0.1007 - val_acc: 0.9807
Epoch 4/5
 - 22s - loss: 0.0973 - acc: 0.9776 - val_loss: 0.0688 - val_acc: 0.9878
Epoch 5/5
 - 22s - loss: 0.0729 - acc: 0.9859 - val_loss: 0.0531 - val_acc: 0.9927
Test accuracy:0.690
current auc_score ------------------> 0.882
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4851 - acc: 0.7930 - val_loss: 0.2737 - val_acc: 0.8996
Epoch 2/5
 - 23s - loss: 0.2278 - acc: 0.9216 - val_loss: 0.1643 - val_acc: 0.9595
Epoch 3/5
 - 22s - loss: 0.1463 - acc: 0.9601 - val_loss: 0.0904 - val_acc: 0.9831
Epoch 4/5
 - 23s - loss: 0.1040 - acc: 0.9760 - val_loss: 0.0719 - val_acc: 0.9891
Epoch 5/5
 - 23s - loss: 0.0807 - acc: 0.9842 - val_loss: 0.0660 - val_acc: 0.9895
Test accuracy:0.730
current auc_score ------------------> 0.879
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3744)         9040        input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7488)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3834368     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 3,845,969
Trainable params: 3,844,469
Non-trainable params: 1,500
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4836 - acc: 0.7941 - val_loss: 0.2506 - val_acc: 0.9165
Epoch 2/5
 - 23s - loss: 0.2334 - acc: 0.9188 - val_loss: 0.1504 - val_acc: 0.9627
Epoch 3/5
 - 23s - loss: 0.1413 - acc: 0.9610 - val_loss: 0.1001 - val_acc: 0.9837
Epoch 4/5
 - 23s - loss: 0.1001 - acc: 0.9771 - val_loss: 0.0713 - val_acc: 0.9864
Epoch 5/5
 - 23s - loss: 0.0776 - acc: 0.9848 - val_loss: 0.0531 - val_acc: 0.9927
Test accuracy:0.626
current auc_score ------------------> 0.914
accuracies:  [0.7028225806451613, 0.7358870967741935, 0.6904569892473118, 0.7303763440860215, 0.6259408602150538]
aucs:  [0.9080225676378774, 0.9015985229506304, 0.8818972569083131, 0.8785256243496357, 0.9136298271476471]
['2-2', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4447 - acc: 0.8257 - val_loss: 0.2337 - val_acc: 0.9256
Epoch 2/5
 - 22s - loss: 0.2168 - acc: 0.9362 - val_loss: 0.1443 - val_acc: 0.9706
Epoch 3/5
 - 22s - loss: 0.1411 - acc: 0.9687 - val_loss: 0.0940 - val_acc: 0.9891
Epoch 4/5
 - 22s - loss: 0.1071 - acc: 0.9814 - val_loss: 0.0727 - val_acc: 0.9939
Epoch 5/5
 - 22s - loss: 0.0887 - acc: 0.9872 - val_loss: 0.0671 - val_acc: 0.9952
Test accuracy:0.674
current auc_score ------------------> 0.864
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4926 - acc: 0.8028 - val_loss: 0.2800 - val_acc: 0.9079
Epoch 2/5
 - 22s - loss: 0.2407 - acc: 0.9270 - val_loss: 0.1743 - val_acc: 0.9607
Epoch 3/5
 - 22s - loss: 0.1602 - acc: 0.9626 - val_loss: 0.1083 - val_acc: 0.9837
Epoch 4/5
 - 22s - loss: 0.1178 - acc: 0.9783 - val_loss: 0.0836 - val_acc: 0.9902
Epoch 5/5
 - 22s - loss: 0.0964 - acc: 0.9863 - val_loss: 0.0741 - val_acc: 0.9931
Test accuracy:0.626
current auc_score ------------------> 0.915
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.4806 - acc: 0.8088 - val_loss: 0.2600 - val_acc: 0.9202
Epoch 2/5
 - 23s - loss: 0.2342 - acc: 0.9287 - val_loss: 0.1593 - val_acc: 0.9693
Epoch 3/5
 - 23s - loss: 0.1489 - acc: 0.9660 - val_loss: 0.1295 - val_acc: 0.9778
Epoch 4/5
 - 23s - loss: 0.1096 - acc: 0.9812 - val_loss: 0.0878 - val_acc: 0.9902
Epoch 5/5
 - 23s - loss: 0.0894 - acc: 0.9872 - val_loss: 0.0748 - val_acc: 0.9950
Test accuracy:0.617
current auc_score ------------------> 0.908
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.4487 - acc: 0.8238 - val_loss: 0.2581 - val_acc: 0.9198
Epoch 2/5
 - 23s - loss: 0.2129 - acc: 0.9383 - val_loss: 0.1579 - val_acc: 0.9646
Epoch 3/5
 - 23s - loss: 0.1368 - acc: 0.9712 - val_loss: 0.0943 - val_acc: 0.9861
Epoch 4/5
 - 23s - loss: 0.1051 - acc: 0.9830 - val_loss: 0.0807 - val_acc: 0.9918
Epoch 5/5
 - 23s - loss: 0.0867 - acc: 0.9886 - val_loss: 0.0636 - val_acc: 0.9951
Test accuracy:0.647
current auc_score ------------------> 0.902
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         28480       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 6,519,617
Trainable params: 6,517,817
Non-trainable params: 1,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 27s - loss: 0.5040 - acc: 0.8003 - val_loss: 0.2743 - val_acc: 0.9192
Epoch 2/5
 - 23s - loss: 0.2436 - acc: 0.9248 - val_loss: 0.1528 - val_acc: 0.9705
Epoch 3/5
 - 23s - loss: 0.1542 - acc: 0.9638 - val_loss: 0.1157 - val_acc: 0.9848
Epoch 4/5
 - 24s - loss: 0.1122 - acc: 0.9805 - val_loss: 0.0809 - val_acc: 0.9898
Epoch 5/5
 - 23s - loss: 0.0923 - acc: 0.9873 - val_loss: 0.0700 - val_acc: 0.9933
Test accuracy:0.675
current auc_score ------------------> 0.866
accuracies:  [0.6744623655913978, 0.6256720430107527, 0.6169354838709677, 0.6466397849462365, 0.6745967741935484]
aucs:  [0.8638372210660192, 0.9151672881257948, 0.9084561076425021, 0.9016329199907503, 0.8655953722973755]
['2-2', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.5068 - acc: 0.8057 - val_loss: 0.3019 - val_acc: 0.9099
Epoch 2/5
 - 23s - loss: 0.2516 - acc: 0.9300 - val_loss: 0.1660 - val_acc: 0.9714
Epoch 3/5
 - 23s - loss: 0.1666 - acc: 0.9672 - val_loss: 0.1211 - val_acc: 0.9832
Epoch 4/5
 - 22s - loss: 0.1317 - acc: 0.9800 - val_loss: 0.1010 - val_acc: 0.9916
Epoch 5/5
 - 22s - loss: 0.1116 - acc: 0.9864 - val_loss: 0.0914 - val_acc: 0.9935
Test accuracy:0.608
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4938 - acc: 0.8154 - val_loss: 0.2860 - val_acc: 0.9197
Epoch 2/5
 - 23s - loss: 0.2485 - acc: 0.9309 - val_loss: 0.2036 - val_acc: 0.9607
Epoch 3/5
 - 23s - loss: 0.1599 - acc: 0.9698 - val_loss: 0.1234 - val_acc: 0.9857
Epoch 4/5
 - 22s - loss: 0.1258 - acc: 0.9819 - val_loss: 0.1076 - val_acc: 0.9895
Epoch 5/5
 - 22s - loss: 0.1048 - acc: 0.9895 - val_loss: 0.0815 - val_acc: 0.9964
Test accuracy:0.658
current auc_score ------------------> 0.917
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4808 - acc: 0.8191 - val_loss: 0.2964 - val_acc: 0.9213
Epoch 2/5
 - 23s - loss: 0.2411 - acc: 0.9359 - val_loss: 0.1740 - val_acc: 0.9734
Epoch 3/5
 - 23s - loss: 0.1648 - acc: 0.9690 - val_loss: 0.1194 - val_acc: 0.9897
Epoch 4/5
 - 23s - loss: 0.1248 - acc: 0.9842 - val_loss: 0.0996 - val_acc: 0.9945
Epoch 5/5
 - 23s - loss: 0.1032 - acc: 0.9891 - val_loss: 0.0812 - val_acc: 0.9949
Test accuracy:0.679
current auc_score ------------------> 0.898
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 26s - loss: 0.4839 - acc: 0.8203 - val_loss: 0.2666 - val_acc: 0.9314
Epoch 2/5
 - 23s - loss: 0.2296 - acc: 0.9411 - val_loss: 0.1523 - val_acc: 0.9777
Epoch 3/5
 - 23s - loss: 0.1514 - acc: 0.9735 - val_loss: 0.1196 - val_acc: 0.9868
Epoch 4/5
 - 23s - loss: 0.1219 - acc: 0.9843 - val_loss: 0.0991 - val_acc: 0.9920
Epoch 5/5
 - 23s - loss: 0.1040 - acc: 0.9889 - val_loss: 0.0923 - val_acc: 0.9941
Test accuracy:0.654
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 25s - loss: 0.4882 - acc: 0.8139 - val_loss: 0.2613 - val_acc: 0.9305
Epoch 2/5
 - 22s - loss: 0.2363 - acc: 0.9380 - val_loss: 0.1611 - val_acc: 0.9736
Epoch 3/5
 - 22s - loss: 0.1569 - acc: 0.9730 - val_loss: 0.1115 - val_acc: 0.9891
Epoch 4/5
 - 22s - loss: 0.1220 - acc: 0.9843 - val_loss: 0.1214 - val_acc: 0.9841
Epoch 5/5
 - 23s - loss: 0.1056 - acc: 0.9881 - val_loss: 0.0860 - val_acc: 0.9957
Test accuracy:0.645
current auc_score ------------------> 0.866
accuracies:  [0.6081989247311828, 0.6576612903225807, 0.6786290322580645, 0.6538978494623656, 0.6451612903225806]
aucs:  [0.8798895826107065, 0.9172949184876864, 0.898499898832235, 0.8833926248699271, 0.8656080905306972]
['3-3', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4858 - acc: 0.7999 - val_loss: 0.2770 - val_acc: 0.8962
Epoch 2/5
 - 28s - loss: 0.2525 - acc: 0.9159 - val_loss: 0.1587 - val_acc: 0.9641
Epoch 3/5
 - 28s - loss: 0.1643 - acc: 0.9572 - val_loss: 0.1067 - val_acc: 0.9798
Epoch 4/5
 - 28s - loss: 0.1204 - acc: 0.9732 - val_loss: 0.0790 - val_acc: 0.9876
Epoch 5/5
 - 28s - loss: 0.0925 - acc: 0.9834 - val_loss: 0.0708 - val_acc: 0.9900
Test accuracy:0.685
current auc_score ------------------> 0.896
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4850 - acc: 0.7999 - val_loss: 0.2699 - val_acc: 0.9108
Epoch 2/5
 - 28s - loss: 0.2512 - acc: 0.9148 - val_loss: 0.1601 - val_acc: 0.9602
Epoch 3/5
 - 28s - loss: 0.1619 - acc: 0.9564 - val_loss: 0.1157 - val_acc: 0.9785
Epoch 4/5
 - 27s - loss: 0.1184 - acc: 0.9737 - val_loss: 0.0852 - val_acc: 0.9881
Epoch 5/5
 - 28s - loss: 0.0925 - acc: 0.9833 - val_loss: 0.0738 - val_acc: 0.9902
Test accuracy:0.691
current auc_score ------------------> 0.875
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4556 - acc: 0.8169 - val_loss: 0.2342 - val_acc: 0.9260
Epoch 2/5
 - 28s - loss: 0.2184 - acc: 0.9308 - val_loss: 0.1481 - val_acc: 0.9659
Epoch 3/5
 - 28s - loss: 0.1450 - acc: 0.9629 - val_loss: 0.1102 - val_acc: 0.9803
Epoch 4/5
 - 28s - loss: 0.1050 - acc: 0.9795 - val_loss: 0.0705 - val_acc: 0.9906
Epoch 5/5
 - 28s - loss: 0.0866 - acc: 0.9850 - val_loss: 0.0599 - val_acc: 0.9946
Test accuracy:0.676
current auc_score ------------------> 0.907
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4598 - acc: 0.8149 - val_loss: 0.2591 - val_acc: 0.9192
Epoch 2/5
 - 26s - loss: 0.2231 - acc: 0.9281 - val_loss: 0.1474 - val_acc: 0.9601
Epoch 3/5
 - 25s - loss: 0.1440 - acc: 0.9653 - val_loss: 0.1111 - val_acc: 0.9861
Epoch 4/5
 - 26s - loss: 0.1071 - acc: 0.9795 - val_loss: 0.0825 - val_acc: 0.9913
Epoch 5/5
 - 26s - loss: 0.0864 - acc: 0.9848 - val_loss: 0.0760 - val_acc: 0.9891
Test accuracy:0.560
current auc_score ------------------> 0.809
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 5040)         13834       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 10080)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          5161472     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 5,177,867
Trainable params: 5,176,115
Non-trainable params: 1,752
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4815 - acc: 0.8028 - val_loss: 0.2757 - val_acc: 0.9080
Epoch 2/5
 - 26s - loss: 0.2335 - acc: 0.9219 - val_loss: 0.1629 - val_acc: 0.9671
Epoch 3/5
 - 26s - loss: 0.1482 - acc: 0.9635 - val_loss: 0.1016 - val_acc: 0.9833
Epoch 4/5
 - 25s - loss: 0.1095 - acc: 0.9773 - val_loss: 0.0831 - val_acc: 0.9881
Epoch 5/5
 - 26s - loss: 0.0866 - acc: 0.9846 - val_loss: 0.0824 - val_acc: 0.9852
Test accuracy:0.731
current auc_score ------------------> 0.834
accuracies:  [0.6848118279569892, 0.690994623655914, 0.6758064516129032, 0.5600806451612903, 0.7307795698924732]
aucs:  [0.8956617817088681, 0.8753042981847612, 0.9069167678344318, 0.8093143716036537, 0.83429970227772]
['3-3', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4893 - acc: 0.8162 - val_loss: 0.3419 - val_acc: 0.8781
Epoch 2/5
 - 28s - loss: 0.2445 - acc: 0.9330 - val_loss: 0.1751 - val_acc: 0.9681
Epoch 3/5
 - 28s - loss: 0.1629 - acc: 0.9683 - val_loss: 0.1224 - val_acc: 0.9842
Epoch 4/5
 - 28s - loss: 0.1252 - acc: 0.9824 - val_loss: 0.0904 - val_acc: 0.9931
Epoch 5/5
 - 28s - loss: 0.1058 - acc: 0.9880 - val_loss: 0.0801 - val_acc: 0.9965
Test accuracy:0.689
current auc_score ------------------> 0.878
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4780 - acc: 0.8223 - val_loss: 0.3134 - val_acc: 0.9019
Epoch 2/5
 - 28s - loss: 0.2483 - acc: 0.9309 - val_loss: 0.1954 - val_acc: 0.9616
Epoch 3/5
 - 28s - loss: 0.1694 - acc: 0.9643 - val_loss: 0.1252 - val_acc: 0.9841
Epoch 4/5
 - 28s - loss: 0.1317 - acc: 0.9789 - val_loss: 0.0993 - val_acc: 0.9923
Epoch 5/5
 - 28s - loss: 0.1103 - acc: 0.9868 - val_loss: 0.0916 - val_acc: 0.9941
Test accuracy:0.651
current auc_score ------------------> 0.870
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.4855 - acc: 0.8186 - val_loss: 0.2666 - val_acc: 0.9242
Epoch 2/5
 - 27s - loss: 0.2469 - acc: 0.9335 - val_loss: 0.1794 - val_acc: 0.9646
Epoch 3/5
 - 28s - loss: 0.1693 - acc: 0.9672 - val_loss: 0.1379 - val_acc: 0.9853
Epoch 4/5
 - 27s - loss: 0.1312 - acc: 0.9816 - val_loss: 0.1052 - val_acc: 0.9923
Epoch 5/5
 - 27s - loss: 0.1091 - acc: 0.9889 - val_loss: 0.0900 - val_acc: 0.9944
Test accuracy:0.691
current auc_score ------------------> 0.891
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 30s - loss: 0.4737 - acc: 0.8224 - val_loss: 0.2819 - val_acc: 0.9231
Epoch 2/5
 - 26s - loss: 0.2460 - acc: 0.9322 - val_loss: 0.1674 - val_acc: 0.9689
Epoch 3/5
 - 26s - loss: 0.1699 - acc: 0.9666 - val_loss: 0.1249 - val_acc: 0.9836
Epoch 4/5
 - 26s - loss: 0.1326 - acc: 0.9794 - val_loss: 0.1034 - val_acc: 0.9874
Epoch 5/5
 - 26s - loss: 0.1081 - acc: 0.9873 - val_loss: 0.0844 - val_acc: 0.9956
Test accuracy:0.673
current auc_score ------------------> 0.886
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         45208       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 9,190,553
Trainable params: 9,188,297
Non-trainable params: 2,256
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.5161 - acc: 0.8015 - val_loss: 0.3170 - val_acc: 0.8897
Epoch 2/5
 - 27s - loss: 0.2602 - acc: 0.9275 - val_loss: 0.1739 - val_acc: 0.9686
Epoch 3/5
 - 27s - loss: 0.1799 - acc: 0.9639 - val_loss: 0.1374 - val_acc: 0.9810
Epoch 4/5
 - 28s - loss: 0.1385 - acc: 0.9788 - val_loss: 0.1084 - val_acc: 0.9907
Epoch 5/5
 - 28s - loss: 0.1144 - acc: 0.9863 - val_loss: 0.0935 - val_acc: 0.9942
Test accuracy:0.726
current auc_score ------------------> 0.883
accuracies:  [0.689247311827957, 0.6512096774193549, 0.6908602150537635, 0.6731182795698925, 0.7256720430107527]
aucs:  [0.8776565209850851, 0.8698901968435657, 0.8914495895479247, 0.8857947450572321, 0.8833789310902995]
['3-3', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 31s - loss: 0.5501 - acc: 0.8005 - val_loss: 0.3558 - val_acc: 0.9031
Epoch 2/5
 - 28s - loss: 0.2975 - acc: 0.9228 - val_loss: 0.2334 - val_acc: 0.9580
Epoch 3/5
 - 28s - loss: 0.2103 - acc: 0.9618 - val_loss: 0.1603 - val_acc: 0.9861
Epoch 4/5
 - 28s - loss: 0.1611 - acc: 0.9796 - val_loss: 0.1409 - val_acc: 0.9900
Epoch 5/5
 - 28s - loss: 0.1346 - acc: 0.9881 - val_loss: 0.1091 - val_acc: 0.9960
Test accuracy:0.675
current auc_score ------------------> 0.898
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.5209 - acc: 0.8113 - val_loss: 0.3645 - val_acc: 0.8893
Epoch 2/5
 - 27s - loss: 0.2880 - acc: 0.9284 - val_loss: 0.2309 - val_acc: 0.9541
Epoch 3/5
 - 27s - loss: 0.2042 - acc: 0.9651 - val_loss: 0.1545 - val_acc: 0.9853
Epoch 4/5
 - 27s - loss: 0.1602 - acc: 0.9810 - val_loss: 0.1215 - val_acc: 0.9917
Epoch 5/5
 - 28s - loss: 0.1359 - acc: 0.9881 - val_loss: 0.1110 - val_acc: 0.9957
Test accuracy:0.600
current auc_score ------------------> 0.848
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.5229 - acc: 0.8128 - val_loss: 0.3260 - val_acc: 0.9229
Epoch 2/5
 - 29s - loss: 0.2739 - acc: 0.9349 - val_loss: 0.2065 - val_acc: 0.9724
Epoch 3/5
 - 29s - loss: 0.2004 - acc: 0.9672 - val_loss: 0.1538 - val_acc: 0.9851
Epoch 4/5
 - 28s - loss: 0.1531 - acc: 0.9841 - val_loss: 0.1252 - val_acc: 0.9936
Epoch 5/5
 - 28s - loss: 0.1320 - acc: 0.9889 - val_loss: 0.1098 - val_acc: 0.9961
Test accuracy:0.728
current auc_score ------------------> 0.898
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.5336 - acc: 0.8058 - val_loss: 0.3226 - val_acc: 0.9214
Epoch 2/5
 - 29s - loss: 0.2812 - acc: 0.9319 - val_loss: 0.2023 - val_acc: 0.9718
Epoch 3/5
 - 29s - loss: 0.1978 - acc: 0.9681 - val_loss: 0.1524 - val_acc: 0.9864
Epoch 4/5
 - 29s - loss: 0.1611 - acc: 0.9799 - val_loss: 0.1257 - val_acc: 0.9945
Epoch 5/5
 - 29s - loss: 0.1364 - acc: 0.9877 - val_loss: 0.1153 - val_acc: 0.9936
Test accuracy:0.708
current auc_score ------------------> 0.884
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12816)        95482       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 25632)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13124096    merge_features[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_16[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 13,222,139
Trainable params: 13,219,379
Non-trainable params: 2,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.5154 - acc: 0.8179 - val_loss: 0.3664 - val_acc: 0.8889
Epoch 2/5
 - 28s - loss: 0.2647 - acc: 0.9405 - val_loss: 0.2004 - val_acc: 0.9684
Epoch 3/5
 - 28s - loss: 0.1863 - acc: 0.9720 - val_loss: 0.1527 - val_acc: 0.9893
Epoch 4/5
 - 28s - loss: 0.1505 - acc: 0.9844 - val_loss: 0.1207 - val_acc: 0.9923
Epoch 5/5
 - 28s - loss: 0.1270 - acc: 0.9909 - val_loss: 0.1043 - val_acc: 0.9964
Test accuracy:0.622
current auc_score ------------------> 0.865
accuracies:  [0.6747311827956989, 0.6001344086021505, 0.728225806451613, 0.7077956989247312, 0.6224462365591398]
aucs:  [0.8980879292403747, 0.8478674557752341, 0.8980679486067754, 0.8840593204416696, 0.8651639640420857]
['4-4', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.4867 - acc: 0.8052 - val_loss: 0.2812 - val_acc: 0.9123
Epoch 2/5
 - 31s - loss: 0.2443 - acc: 0.9246 - val_loss: 0.1642 - val_acc: 0.9611
Epoch 3/5
 - 31s - loss: 0.1620 - acc: 0.9619 - val_loss: 0.1135 - val_acc: 0.9812
Epoch 4/5
 - 30s - loss: 0.1204 - acc: 0.9773 - val_loss: 0.1026 - val_acc: 0.9847
Epoch 5/5
 - 30s - loss: 0.0985 - acc: 0.9852 - val_loss: 0.0711 - val_acc: 0.9935
Test accuracy:0.716
current auc_score ------------------> 0.890
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.5389 - acc: 0.7785 - val_loss: 0.3026 - val_acc: 0.9000
Epoch 2/5
 - 33s - loss: 0.2808 - acc: 0.9060 - val_loss: 0.1887 - val_acc: 0.9499
Epoch 3/5
 - 33s - loss: 0.1851 - acc: 0.9534 - val_loss: 0.1355 - val_acc: 0.9749
Epoch 4/5
 - 33s - loss: 0.1387 - acc: 0.9701 - val_loss: 0.0995 - val_acc: 0.9838
Epoch 5/5
 - 33s - loss: 0.1065 - acc: 0.9818 - val_loss: 0.0833 - val_acc: 0.9895
Test accuracy:0.690
current auc_score ------------------> 0.893
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.5112 - acc: 0.7908 - val_loss: 0.2635 - val_acc: 0.9164
Epoch 2/5
 - 30s - loss: 0.2434 - acc: 0.9243 - val_loss: 0.1613 - val_acc: 0.9659
Epoch 3/5
 - 30s - loss: 0.1588 - acc: 0.9627 - val_loss: 0.1357 - val_acc: 0.9695
Epoch 4/5
 - 30s - loss: 0.1219 - acc: 0.9764 - val_loss: 0.0945 - val_acc: 0.9885
Epoch 5/5
 - 30s - loss: 0.0951 - acc: 0.9854 - val_loss: 0.0948 - val_acc: 0.9880
Test accuracy:0.607
current auc_score ------------------> 0.853
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 36s - loss: 0.4905 - acc: 0.8029 - val_loss: 0.2811 - val_acc: 0.9057
Epoch 2/5
 - 30s - loss: 0.2454 - acc: 0.9234 - val_loss: 0.2031 - val_acc: 0.9507
Epoch 3/5
 - 30s - loss: 0.1637 - acc: 0.9615 - val_loss: 0.1261 - val_acc: 0.9816
Epoch 4/5
 - 30s - loss: 0.1219 - acc: 0.9768 - val_loss: 0.0906 - val_acc: 0.9876
Epoch 5/5
 - 30s - loss: 0.0987 - acc: 0.9843 - val_loss: 0.0910 - val_acc: 0.9920
Test accuracy:0.605
current auc_score ------------------> 0.905
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6336)         19168       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 12672)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          6488576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 6,510,305
Trainable params: 6,508,265
Non-trainable params: 2,040
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.4661 - acc: 0.8139 - val_loss: 0.7185 - val_acc: 0.6904
Epoch 2/5
 - 31s - loss: 0.2278 - acc: 0.9310 - val_loss: 0.6601 - val_acc: 0.6963
Epoch 3/5
 - 30s - loss: 0.1532 - acc: 0.9647 - val_loss: 1.2341 - val_acc: 0.5739
Epoch 4/5
 - 31s - loss: 0.1182 - acc: 0.9780 - val_loss: 0.0850 - val_acc: 0.9886
Epoch 5/5
 - 31s - loss: 0.0946 - acc: 0.9857 - val_loss: 0.0733 - val_acc: 0.9925
Test accuracy:0.738
current auc_score ------------------> 0.906
accuracies:  [0.7157258064516129, 0.6901881720430108, 0.6067204301075269, 0.6049731182795699, 0.7376344086021506]
aucs:  [0.8904921811770148, 0.8926839085443403, 0.8529227367325702, 0.9046547288703896, 0.9062009336339462]
['4-4', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5733 - acc: 0.7846 - val_loss: 0.3539 - val_acc: 0.8909
Epoch 2/5
 - 33s - loss: 0.2917 - acc: 0.9205 - val_loss: 0.2099 - val_acc: 0.9641
Epoch 3/5
 - 33s - loss: 0.2013 - acc: 0.9613 - val_loss: 0.1452 - val_acc: 0.9858
Epoch 4/5
 - 33s - loss: 0.1547 - acc: 0.9795 - val_loss: 0.1269 - val_acc: 0.9892
Epoch 5/5
 - 33s - loss: 0.1299 - acc: 0.9868 - val_loss: 0.1086 - val_acc: 0.9950
Test accuracy:0.698
current auc_score ------------------> 0.879
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.5585 - acc: 0.7874 - val_loss: 0.3601 - val_acc: 0.8877
Epoch 2/5
 - 31s - loss: 0.2948 - acc: 0.9197 - val_loss: 0.2023 - val_acc: 0.9637
Epoch 3/5
 - 31s - loss: 0.2048 - acc: 0.9605 - val_loss: 0.1519 - val_acc: 0.9864
Epoch 4/5
 - 31s - loss: 0.1545 - acc: 0.9798 - val_loss: 0.1206 - val_acc: 0.9874
Epoch 5/5
 - 31s - loss: 0.1286 - acc: 0.9869 - val_loss: 0.1006 - val_acc: 0.9956
Test accuracy:0.653
current auc_score ------------------> 0.911
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.4913 - acc: 0.8242 - val_loss: 0.3107 - val_acc: 0.9078
Epoch 2/5
 - 33s - loss: 0.2633 - acc: 0.9342 - val_loss: 0.1986 - val_acc: 0.9686
Epoch 3/5
 - 34s - loss: 0.1857 - acc: 0.9675 - val_loss: 0.1426 - val_acc: 0.9864
Epoch 4/5
 - 34s - loss: 0.1518 - acc: 0.9803 - val_loss: 0.1181 - val_acc: 0.9956
Epoch 5/5
 - 33s - loss: 0.1267 - acc: 0.9878 - val_loss: 0.1041 - val_acc: 0.9960
Test accuracy:0.647
current auc_score ------------------> 0.910
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.5186 - acc: 0.8087 - val_loss: 1.0569 - val_acc: 0.5906
Epoch 2/5
 - 31s - loss: 0.2878 - acc: 0.9233 - val_loss: 1.6346 - val_acc: 0.5237
Epoch 3/5
 - 31s - loss: 0.1983 - acc: 0.9637 - val_loss: 2.1481 - val_acc: 0.5079

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 32s - loss: 0.1542 - acc: 0.9801 - val_loss: 1.5388 - val_acc: 0.5193
Epoch 5/5
 - 31s - loss: 0.1345 - acc: 0.9869 - val_loss: 1.2441 - val_acc: 0.5612

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 00005: early stopping
Test accuracy:0.540
current auc_score ------------------> 0.719
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 11520)        63952       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 23040)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          11796992    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 11,863,505
Trainable params: 11,860,721
Non-trainable params: 2,784
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5019 - acc: 0.8166 - val_loss: 0.3281 - val_acc: 0.9037
Epoch 2/5
 - 32s - loss: 0.2768 - acc: 0.9286 - val_loss: 0.2419 - val_acc: 0.9479
Epoch 3/5
 - 33s - loss: 0.1962 - acc: 0.9646 - val_loss: 0.1468 - val_acc: 0.9851
Epoch 4/5
 - 33s - loss: 0.1530 - acc: 0.9808 - val_loss: 0.1349 - val_acc: 0.9885
Epoch 5/5
 - 33s - loss: 0.1295 - acc: 0.9884 - val_loss: 0.1032 - val_acc: 0.9966
Test accuracy:0.685
current auc_score ------------------> 0.886
accuracies:  [0.6975806451612904, 0.6533602150537634, 0.6469086021505376, 0.5404569892473118, 0.6854838709677419]
aucs:  [0.8794271013990057, 0.9110413053532201, 0.9103562189270435, 0.7193252832697422, 0.8856745722048791]
['4-4', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.5768 - acc: 0.7994 - val_loss: 0.3877 - val_acc: 0.9017
Epoch 2/5
 - 32s - loss: 0.3258 - acc: 0.9255 - val_loss: 0.2614 - val_acc: 0.9608
Epoch 3/5
 - 32s - loss: 0.2355 - acc: 0.9633 - val_loss: 0.2108 - val_acc: 0.9836
Epoch 4/5
 - 32s - loss: 0.1950 - acc: 0.9792 - val_loss: 0.1544 - val_acc: 0.9930
Epoch 5/5
 - 32s - loss: 0.1648 - acc: 0.9880 - val_loss: 0.1369 - val_acc: 0.9972
Test accuracy:0.692
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 37s - loss: 0.5966 - acc: 0.7910 - val_loss: 0.9271 - val_acc: 0.6289
Epoch 2/5
 - 31s - loss: 0.3357 - acc: 0.9208 - val_loss: 0.8309 - val_acc: 0.5909
Epoch 3/5
 - 32s - loss: 0.2380 - acc: 0.9630 - val_loss: 0.9253 - val_acc: 0.6240
Epoch 4/5
 - 31s - loss: 0.1908 - acc: 0.9796 - val_loss: 1.4299 - val_acc: 0.5251

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 32s - loss: 0.1615 - acc: 0.9891 - val_loss: 0.1451 - val_acc: 0.9971
Test accuracy:0.681
current auc_score ------------------> 0.905
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6097 - acc: 0.7802 - val_loss: 0.3935 - val_acc: 0.9016
Epoch 2/5
 - 32s - loss: 0.3579 - acc: 0.9108 - val_loss: 0.2886 - val_acc: 0.9542
Epoch 3/5
 - 32s - loss: 0.2580 - acc: 0.9550 - val_loss: 0.2158 - val_acc: 0.9818
Epoch 4/5
 - 31s - loss: 0.2046 - acc: 0.9747 - val_loss: 0.1644 - val_acc: 0.9913
Epoch 5/5
 - 32s - loss: 0.1725 - acc: 0.9838 - val_loss: 0.1592 - val_acc: 0.9898
Test accuracy:0.629
current auc_score ------------------> 0.892
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.6169 - acc: 0.7761 - val_loss: 0.4528 - val_acc: 0.8621
Epoch 2/5
 - 32s - loss: 0.3546 - acc: 0.9115 - val_loss: 0.2923 - val_acc: 0.9494
Epoch 3/5
 - 32s - loss: 0.2501 - acc: 0.9600 - val_loss: 0.2201 - val_acc: 0.9734
Epoch 4/5
 - 32s - loss: 0.2022 - acc: 0.9755 - val_loss: 0.1804 - val_acc: 0.9873
Epoch 5/5
 - 32s - loss: 0.1750 - acc: 0.9842 - val_loss: 0.1512 - val_acc: 0.9930
Test accuracy:0.631
current auc_score ------------------> 0.847
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        135808      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_20[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 17,243,777
Trainable params: 17,240,249
Non-trainable params: 3,528
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6123 - acc: 0.7821 - val_loss: 0.4006 - val_acc: 0.8933
Epoch 2/5
 - 34s - loss: 0.3467 - acc: 0.9155 - val_loss: 0.2530 - val_acc: 0.9552
Epoch 3/5
 - 34s - loss: 0.2485 - acc: 0.9602 - val_loss: 0.1857 - val_acc: 0.9843
Epoch 4/5
 - 34s - loss: 0.2032 - acc: 0.9764 - val_loss: 0.1621 - val_acc: 0.9911
Epoch 5/5
 - 34s - loss: 0.1735 - acc: 0.9860 - val_loss: 0.1479 - val_acc: 0.9933
Test accuracy:0.629
current auc_score ------------------> 0.883
accuracies:  [0.6918010752688172, 0.6810483870967742, 0.6291666666666667, 0.6306451612903226, 0.6286290322580645]
aucs:  [0.8830221340617413, 0.9053298791767835, 0.8917152271938952, 0.8470153341426755, 0.8829715140478667]
['6-6', '6', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.5218 - acc: 0.7959 - val_loss: 2.7205 - val_acc: 0.4965
Epoch 2/5
 - 36s - loss: 0.2869 - acc: 0.9132 - val_loss: 1.8332 - val_acc: 0.4966
Epoch 3/5
 - 36s - loss: 0.1989 - acc: 0.9544 - val_loss: 1.6670 - val_acc: 0.5203
Epoch 4/5
 - 36s - loss: 0.1495 - acc: 0.9736 - val_loss: 2.4568 - val_acc: 0.4967
Epoch 5/5
 - 36s - loss: 0.1232 - acc: 0.9829 - val_loss: 0.7078 - val_acc: 0.6274
Test accuracy:0.499
current auc_score ------------------> 0.727
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 49s - loss: 0.4975 - acc: 0.8080 - val_loss: 0.3330 - val_acc: 0.8951
Epoch 2/5
 - 40s - loss: 0.2608 - acc: 0.9284 - val_loss: 0.2036 - val_acc: 0.9573
Epoch 3/5
 - 40s - loss: 0.1835 - acc: 0.9600 - val_loss: 0.1473 - val_acc: 0.9795
Epoch 4/5
 - 40s - loss: 0.1426 - acc: 0.9770 - val_loss: 0.1088 - val_acc: 0.9868
Epoch 5/5
 - 40s - loss: 0.1210 - acc: 0.9837 - val_loss: 0.0998 - val_acc: 0.9907
Test accuracy:0.715
current auc_score ------------------> 0.854
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.5236 - acc: 0.7973 - val_loss: 0.3125 - val_acc: 0.9050
Epoch 2/5
 - 39s - loss: 0.2613 - acc: 0.9260 - val_loss: 0.1798 - val_acc: 0.9681
Epoch 3/5
 - 39s - loss: 0.1792 - acc: 0.9635 - val_loss: 0.1242 - val_acc: 0.9834
Epoch 4/5
 - 39s - loss: 0.1384 - acc: 0.9784 - val_loss: 0.1099 - val_acc: 0.9897
Epoch 5/5
 - 39s - loss: 0.1179 - acc: 0.9844 - val_loss: 0.0878 - val_acc: 0.9946
Test accuracy:0.657
current auc_score ------------------> 0.909
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.5414 - acc: 0.7893 - val_loss: 0.3407 - val_acc: 0.8913
Epoch 2/5
 - 39s - loss: 0.2840 - acc: 0.9155 - val_loss: 0.2157 - val_acc: 0.9490
Epoch 3/5
 - 39s - loss: 0.1948 - acc: 0.9557 - val_loss: 0.1492 - val_acc: 0.9792
Epoch 4/5
 - 39s - loss: 0.1478 - acc: 0.9736 - val_loss: 0.1214 - val_acc: 0.9846
Epoch 5/5
 - 38s - loss: 0.1224 - acc: 0.9823 - val_loss: 0.1039 - val_acc: 0.9900
Test accuracy:0.643
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         31456       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 9,176,801
Trainable params: 9,174,077
Non-trainable params: 2,724
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.4894 - acc: 0.8164 - val_loss: 0.2743 - val_acc: 0.9196
Epoch 2/5
 - 40s - loss: 0.2492 - acc: 0.9306 - val_loss: 0.1908 - val_acc: 0.9622
Epoch 3/5
 - 40s - loss: 0.1765 - acc: 0.9641 - val_loss: 0.1405 - val_acc: 0.9800
Epoch 4/5
 - 39s - loss: 0.1410 - acc: 0.9764 - val_loss: 0.1144 - val_acc: 0.9863
Epoch 5/5
 - 38s - loss: 0.1173 - acc: 0.9837 - val_loss: 0.0984 - val_acc: 0.9922
Test accuracy:0.629
current auc_score ------------------> 0.869
accuracies:  [0.49946236559139784, 0.7153225806451613, 0.6568548387096774, 0.6431451612903226, 0.6286290322580645]
aucs:  [0.7274110446294368, 0.8541939819632327, 0.9088804341542375, 0.8801723465140479, 0.8694445167071337]
['6-6', '12', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.5719 - acc: 0.8007 - val_loss: 1.2422 - val_acc: 0.5458
Epoch 2/5
 - 36s - loss: 0.3273 - acc: 0.9246 - val_loss: 2.0870 - val_acc: 0.5036
Epoch 3/5
 - 36s - loss: 0.2401 - acc: 0.9618 - val_loss: 0.9208 - val_acc: 0.6163
Epoch 4/5
 - 36s - loss: 0.1933 - acc: 0.9793 - val_loss: 1.5161 - val_acc: 0.5110
Epoch 5/5
 - 36s - loss: 0.1665 - acc: 0.9867 - val_loss: 0.7747 - val_acc: 0.6480
Test accuracy:0.518
current auc_score ------------------> 0.576
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6098 - acc: 0.7850 - val_loss: 0.3958 - val_acc: 0.9019
Epoch 2/5
 - 37s - loss: 0.3592 - acc: 0.9093 - val_loss: 0.2858 - val_acc: 0.9489
Epoch 3/5
 - 37s - loss: 0.2651 - acc: 0.9540 - val_loss: 0.2165 - val_acc: 0.9753
Epoch 4/5
 - 36s - loss: 0.2137 - acc: 0.9719 - val_loss: 0.1705 - val_acc: 0.9901
Epoch 5/5
 - 37s - loss: 0.1800 - acc: 0.9831 - val_loss: 0.1555 - val_acc: 0.9922
Test accuracy:0.683
current auc_score ------------------> 0.855
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6385 - acc: 0.7679 - val_loss: 1.1103 - val_acc: 0.5325
Epoch 2/5
 - 36s - loss: 0.3657 - acc: 0.9057 - val_loss: 0.7426 - val_acc: 0.6343
Epoch 3/5
 - 36s - loss: 0.2598 - acc: 0.9555 - val_loss: 2.1028 - val_acc: 0.5102
Epoch 4/5
 - 36s - loss: 0.2118 - acc: 0.9734 - val_loss: 1.1131 - val_acc: 0.6057

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 36s - loss: 0.1749 - acc: 0.9858 - val_loss: 0.6908 - val_acc: 0.7302
Test accuracy:0.718
current auc_score ------------------> 0.748
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.6374 - acc: 0.7668 - val_loss: 0.4763 - val_acc: 0.8519
Epoch 2/5
 - 39s - loss: 0.3910 - acc: 0.8922 - val_loss: 0.3154 - val_acc: 0.9473
Epoch 3/5
 - 40s - loss: 0.2785 - acc: 0.9478 - val_loss: 0.2520 - val_acc: 0.9607
Epoch 4/5
 - 40s - loss: 0.2162 - acc: 0.9717 - val_loss: 0.1723 - val_acc: 0.9881
Epoch 5/5
 - 39s - loss: 0.1891 - acc: 0.9798 - val_loss: 0.1653 - val_acc: 0.9877
Test accuracy:0.528
current auc_score ------------------> 0.870
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16704)        107488      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 33408)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17105408    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 17,215,457
Trainable params: 17,211,401
Non-trainable params: 4,056
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.6095 - acc: 0.7811 - val_loss: 0.8688 - val_acc: 0.6053
Epoch 2/5
 - 37s - loss: 0.3479 - acc: 0.9148 - val_loss: 2.8008 - val_acc: 0.5036
Epoch 3/5
 - 37s - loss: 0.2505 - acc: 0.9602 - val_loss: 1.4758 - val_acc: 0.5097

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 37s - loss: 0.1955 - acc: 0.9806 - val_loss: 2.4108 - val_acc: 0.5038
Epoch 5/5
 - 37s - loss: 0.1766 - acc: 0.9862 - val_loss: 0.1628 - val_acc: 0.9917
Test accuracy:0.681
current auc_score ------------------> 0.909
accuracies:  [0.5176075268817204, 0.6834677419354839, 0.717741935483871, 0.5283602150537634, 0.6814516129032258]
aucs:  [0.576161369811539, 0.8545685917447103, 0.7483130275176321, 0.8698496574748525, 0.9087243467452886]
['6-6', '18', '2', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 49s - loss: 0.6660 - acc: 0.7830 - val_loss: 0.9268 - val_acc: 0.5523
Epoch 2/5
 - 39s - loss: 0.4132 - acc: 0.9116 - val_loss: 0.9604 - val_acc: 0.5540
Epoch 3/5
 - 39s - loss: 0.3195 - acc: 0.9547 - val_loss: 1.0828 - val_acc: 0.5809

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 39s - loss: 0.2599 - acc: 0.9771 - val_loss: 1.0658 - val_acc: 0.5684
Epoch 5/5
 - 39s - loss: 0.2370 - acc: 0.9839 - val_loss: 0.2086 - val_acc: 0.9942
Test accuracy:0.697
current auc_score ------------------> 0.901
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.6519 - acc: 0.7950 - val_loss: 0.5111 - val_acc: 0.8496
Epoch 2/5
 - 41s - loss: 0.4014 - acc: 0.9193 - val_loss: 0.3103 - val_acc: 0.9677
Epoch 3/5
 - 41s - loss: 0.3060 - acc: 0.9611 - val_loss: 0.2607 - val_acc: 0.9826
Epoch 4/5
 - 40s - loss: 0.2562 - acc: 0.9769 - val_loss: 0.2389 - val_acc: 0.9854
Epoch 5/5
 - 40s - loss: 0.2283 - acc: 0.9837 - val_loss: 0.2082 - val_acc: 0.9895
Test accuracy:0.665
current auc_score ------------------> 0.870
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.6423 - acc: 0.7979 - val_loss: 0.4838 - val_acc: 0.8775
Epoch 2/5
 - 39s - loss: 0.4125 - acc: 0.9108 - val_loss: 0.3521 - val_acc: 0.9460
Epoch 3/5
 - 39s - loss: 0.3086 - acc: 0.9577 - val_loss: 0.3202 - val_acc: 0.9543
Epoch 4/5
 - 38s - loss: 0.2502 - acc: 0.9790 - val_loss: 0.2267 - val_acc: 0.9853
Epoch 5/5
 - 38s - loss: 0.2184 - acc: 0.9870 - val_loss: 0.1912 - val_acc: 0.9947
Test accuracy:0.605
current auc_score ------------------> 0.860
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 51s - loss: 0.6627 - acc: 0.7838 - val_loss: 0.5792 - val_acc: 0.8218
Epoch 2/5
 - 42s - loss: 0.4160 - acc: 0.9098 - val_loss: 0.3684 - val_acc: 0.9472
Epoch 3/5
 - 43s - loss: 0.3181 - acc: 0.9541 - val_loss: 0.2823 - val_acc: 0.9748
Epoch 4/5
 - 42s - loss: 0.2598 - acc: 0.9754 - val_loss: 0.2514 - val_acc: 0.9819
Epoch 5/5
 - 42s - loss: 0.2230 - acc: 0.9861 - val_loss: 0.2004 - val_acc: 0.9913
Test accuracy:0.729
current auc_score ------------------> 0.872
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 24480)        229744      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 48960)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          25068032    merge_features[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_28[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 25,300,337
Trainable params: 25,294,949
Non-trainable params: 5,388
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.6593 - acc: 0.7862 - val_loss: 0.5937 - val_acc: 0.8086
Epoch 2/5
 - 39s - loss: 0.4166 - acc: 0.9105 - val_loss: 0.3744 - val_acc: 0.9327
Epoch 3/5
 - 39s - loss: 0.3187 - acc: 0.9533 - val_loss: 0.3017 - val_acc: 0.9617
Epoch 4/5
 - 39s - loss: 0.2667 - acc: 0.9731 - val_loss: 0.2424 - val_acc: 0.9841
Epoch 5/5
 - 38s - loss: 0.2300 - acc: 0.9834 - val_loss: 0.2080 - val_acc: 0.9908
Test accuracy:0.710
current auc_score ------------------> 0.872
accuracies:  [0.696505376344086, 0.6651881720430107, 0.6053763440860215, 0.7286290322580645, 0.7100806451612903]
aucs:  [0.9005657445947509, 0.8701620129494738, 0.8601610735345128, 0.8723810917447103, 0.8722397820557289]
['2-2-2', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.5926 - acc: 0.7460 - val_loss: 0.3835 - val_acc: 0.8468
Epoch 2/5
 - 28s - loss: 0.3442 - acc: 0.8657 - val_loss: 0.2457 - val_acc: 0.9179
Epoch 3/5
 - 28s - loss: 0.2349 - acc: 0.9209 - val_loss: 0.1850 - val_acc: 0.9478
Epoch 4/5
 - 28s - loss: 0.1753 - acc: 0.9484 - val_loss: 0.1234 - val_acc: 0.9734
Epoch 5/5
 - 28s - loss: 0.1376 - acc: 0.9649 - val_loss: 0.1006 - val_acc: 0.9803
Test accuracy:0.577
current auc_score ------------------> 0.824
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.6115 - acc: 0.7384 - val_loss: 0.4278 - val_acc: 0.8238
Epoch 2/5
 - 28s - loss: 0.3846 - acc: 0.8481 - val_loss: 0.3202 - val_acc: 0.8833
Epoch 3/5
 - 28s - loss: 0.2823 - acc: 0.8998 - val_loss: 0.2502 - val_acc: 0.9203
Epoch 4/5
 - 28s - loss: 0.2219 - acc: 0.9288 - val_loss: 0.1819 - val_acc: 0.9507
Epoch 5/5
 - 28s - loss: 0.1736 - acc: 0.9473 - val_loss: 0.1248 - val_acc: 0.9715
Test accuracy:0.637
current auc_score ------------------> 0.890
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 32s - loss: 0.6314 - acc: 0.7307 - val_loss: 0.4142 - val_acc: 0.8237
Epoch 2/5
 - 28s - loss: 0.3899 - acc: 0.8430 - val_loss: 0.3287 - val_acc: 0.8789
Epoch 3/5
 - 28s - loss: 0.2757 - acc: 0.9018 - val_loss: 0.2088 - val_acc: 0.9384
Epoch 4/5
 - 29s - loss: 0.2045 - acc: 0.9358 - val_loss: 0.1521 - val_acc: 0.9610
Epoch 5/5
 - 28s - loss: 0.1585 - acc: 0.9556 - val_loss: 0.1168 - val_acc: 0.9762
Test accuracy:0.706
current auc_score ------------------> 0.910
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.7302 - acc: 0.6717 - val_loss: 0.4807 - val_acc: 0.7775
Epoch 2/5
 - 28s - loss: 0.4585 - acc: 0.8021 - val_loss: 0.3194 - val_acc: 0.8793
Epoch 3/5
 - 29s - loss: 0.3201 - acc: 0.8792 - val_loss: 0.2323 - val_acc: 0.9231
Epoch 4/5
 - 29s - loss: 0.2371 - acc: 0.9197 - val_loss: 0.1674 - val_acc: 0.9524
Epoch 5/5
 - 28s - loss: 0.1797 - acc: 0.9458 - val_loss: 0.1355 - val_acc: 0.9652
Test accuracy:0.687
current auc_score ------------------> 0.847
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 900)          13158       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1800)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          922112      merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 937,831
Trainable params: 936,121
Non-trainable params: 1,710
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 35s - loss: 0.6376 - acc: 0.7234 - val_loss: 0.3969 - val_acc: 0.8436
Epoch 2/5
 - 30s - loss: 0.3926 - acc: 0.8413 - val_loss: 0.2805 - val_acc: 0.9024
Epoch 3/5
 - 30s - loss: 0.2808 - acc: 0.8990 - val_loss: 0.2251 - val_acc: 0.9277
Epoch 4/5
 - 30s - loss: 0.2109 - acc: 0.9344 - val_loss: 0.1602 - val_acc: 0.9571
Epoch 5/5
 - 29s - loss: 0.1609 - acc: 0.9553 - val_loss: 0.1142 - val_acc: 0.9790
Test accuracy:0.630
current auc_score ------------------> 0.870
accuracies:  [0.5768817204301075, 0.6366935483870968, 0.7059139784946237, 0.687231182795699, 0.630241935483871]
aucs:  [0.8244240663660538, 0.8896207654064052, 0.9103600849809226, 0.8471454069834663, 0.8703487036073535]
['2-2-2', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.6511 - acc: 0.7346 - val_loss: 0.4372 - val_acc: 0.8284
Epoch 2/5
 - 28s - loss: 0.3992 - acc: 0.8546 - val_loss: 0.3366 - val_acc: 0.8904
Epoch 3/5
 - 28s - loss: 0.2747 - acc: 0.9165 - val_loss: 0.2328 - val_acc: 0.9416
Epoch 4/5
 - 28s - loss: 0.2041 - acc: 0.9503 - val_loss: 0.1451 - val_acc: 0.9733
Epoch 5/5
 - 28s - loss: 0.1598 - acc: 0.9689 - val_loss: 0.1253 - val_acc: 0.9838
Test accuracy:0.565
current auc_score ------------------> 0.855
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.6205 - acc: 0.7509 - val_loss: 0.4792 - val_acc: 0.8018
Epoch 2/5
 - 29s - loss: 0.3649 - acc: 0.8707 - val_loss: 0.2833 - val_acc: 0.9160
Epoch 3/5
 - 29s - loss: 0.2520 - acc: 0.9278 - val_loss: 0.1833 - val_acc: 0.9625
Epoch 4/5
 - 29s - loss: 0.1858 - acc: 0.9579 - val_loss: 0.1297 - val_acc: 0.9798
Epoch 5/5
 - 29s - loss: 0.1497 - acc: 0.9713 - val_loss: 0.1073 - val_acc: 0.9887
Test accuracy:0.734
current auc_score ------------------> 0.928
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.6373 - acc: 0.7408 - val_loss: 0.3856 - val_acc: 0.8616
Epoch 2/5
 - 30s - loss: 0.3725 - acc: 0.8692 - val_loss: 0.2736 - val_acc: 0.9234
Epoch 3/5
 - 30s - loss: 0.2655 - acc: 0.9246 - val_loss: 0.1971 - val_acc: 0.9588
Epoch 4/5
 - 30s - loss: 0.1971 - acc: 0.9532 - val_loss: 0.1497 - val_acc: 0.9764
Epoch 5/5
 - 30s - loss: 0.1613 - acc: 0.9702 - val_loss: 0.1187 - val_acc: 0.9851
Test accuracy:0.701
current auc_score ------------------> 0.879
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.6409 - acc: 0.7423 - val_loss: 0.4095 - val_acc: 0.8470
Epoch 2/5
 - 28s - loss: 0.3742 - acc: 0.8681 - val_loss: 0.2908 - val_acc: 0.9109
Epoch 3/5
 - 29s - loss: 0.2685 - acc: 0.9218 - val_loss: 0.2089 - val_acc: 0.9474
Epoch 4/5
 - 29s - loss: 0.2005 - acc: 0.9523 - val_loss: 0.1651 - val_acc: 0.9696
Epoch 5/5
 - 29s - loss: 0.1590 - acc: 0.9694 - val_loss: 0.1194 - val_acc: 0.9837
Test accuracy:0.743
current auc_score ------------------> 0.921
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         43296       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 1,742,113
Trainable params: 1,739,917
Non-trainable params: 2,196
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.5809 - acc: 0.7684 - val_loss: 0.4326 - val_acc: 0.8338
Epoch 2/5
 - 28s - loss: 0.3417 - acc: 0.8822 - val_loss: 0.2711 - val_acc: 0.9209
Epoch 3/5
 - 28s - loss: 0.2317 - acc: 0.9362 - val_loss: 0.1761 - val_acc: 0.9662
Epoch 4/5
 - 28s - loss: 0.1714 - acc: 0.9641 - val_loss: 0.1343 - val_acc: 0.9782
Epoch 5/5
 - 28s - loss: 0.1387 - acc: 0.9773 - val_loss: 0.1124 - val_acc: 0.9861
Test accuracy:0.665
current auc_score ------------------> 0.814
accuracies:  [0.5650537634408602, 0.7338709677419355, 0.7005376344086022, 0.7434139784946237, 0.6646505376344086]
aucs:  [0.8548523673257025, 0.9284833868077235, 0.8790791565498901, 0.9205104636374147, 0.814497196207654]
['2-2-2', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 35s - loss: 0.6862 - acc: 0.7341 - val_loss: 0.5285 - val_acc: 0.7840
Epoch 2/5
 - 30s - loss: 0.4101 - acc: 0.8657 - val_loss: 0.3538 - val_acc: 0.8983
Epoch 3/5
 - 31s - loss: 0.2969 - acc: 0.9225 - val_loss: 0.2309 - val_acc: 0.9618
Epoch 4/5
 - 31s - loss: 0.2240 - acc: 0.9563 - val_loss: 0.1619 - val_acc: 0.9813
Epoch 5/5
 - 30s - loss: 0.1784 - acc: 0.9747 - val_loss: 0.1459 - val_acc: 0.9853
Test accuracy:0.713
current auc_score ------------------> 0.828
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 34s - loss: 0.6316 - acc: 0.7606 - val_loss: 0.4665 - val_acc: 0.8330
Epoch 2/5
 - 29s - loss: 0.3790 - acc: 0.8825 - val_loss: 0.2951 - val_acc: 0.9336
Epoch 3/5
 - 29s - loss: 0.2653 - acc: 0.9351 - val_loss: 0.2189 - val_acc: 0.9625
Epoch 4/5
 - 29s - loss: 0.2035 - acc: 0.9640 - val_loss: 0.1628 - val_acc: 0.9814
Epoch 5/5
 - 29s - loss: 0.1655 - acc: 0.9781 - val_loss: 0.1338 - val_acc: 0.9920
Test accuracy:0.651
current auc_score ------------------> 0.873
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.6834 - acc: 0.7368 - val_loss: 0.4668 - val_acc: 0.8425
Epoch 2/5
 - 28s - loss: 0.4067 - acc: 0.8678 - val_loss: 0.3056 - val_acc: 0.9285
Epoch 3/5
 - 28s - loss: 0.2836 - acc: 0.9288 - val_loss: 0.2114 - val_acc: 0.9630
Epoch 4/5
 - 28s - loss: 0.2155 - acc: 0.9574 - val_loss: 0.1618 - val_acc: 0.9777
Epoch 5/5
 - 29s - loss: 0.1731 - acc: 0.9755 - val_loss: 0.1360 - val_acc: 0.9890
Test accuracy:0.569
current auc_score ------------------> 0.892
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.6145 - acc: 0.7759 - val_loss: 2.5728 - val_acc: 0.4965
Epoch 2/5
 - 28s - loss: 0.3626 - acc: 0.8917 - val_loss: 0.9178 - val_acc: 0.5676
Epoch 3/5
 - 29s - loss: 0.2596 - acc: 0.9397 - val_loss: 1.2625 - val_acc: 0.5094
Epoch 4/5
 - 28s - loss: 0.2010 - acc: 0.9656 - val_loss: 0.9383 - val_acc: 0.5730

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 28s - loss: 0.1641 - acc: 0.9785 - val_loss: 0.1675 - val_acc: 0.9863
Test accuracy:0.554
current auc_score ------------------> 0.893
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         91758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_17[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_7[0][0]                  
==================================================================================================
Total params: 2,564,719
Trainable params: 2,562,037
Non-trainable params: 2,682
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 33s - loss: 0.6450 - acc: 0.7556 - val_loss: 1.3569 - val_acc: 0.5774
Epoch 2/5
 - 29s - loss: 0.3780 - acc: 0.8817 - val_loss: 0.9466 - val_acc: 0.5944
Epoch 3/5
 - 29s - loss: 0.2689 - acc: 0.9362 - val_loss: 0.2150 - val_acc: 0.9652
Epoch 4/5
 - 28s - loss: 0.2038 - acc: 0.9638 - val_loss: 0.1709 - val_acc: 0.9804
Epoch 5/5
 - 28s - loss: 0.1626 - acc: 0.9802 - val_loss: 0.1540 - val_acc: 0.9851
Test accuracy:0.620
current auc_score ------------------> 0.866
accuracies:  [0.7129032258064516, 0.6514784946236559, 0.5693548387096774, 0.5541666666666667, 0.6202956989247311]
aucs:  [0.8277705515088449, 0.8732857844837554, 0.8915962105445717, 0.8931081627933866, 0.8657181827378887]
['3-3-3', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.6773 - acc: 0.7082 - val_loss: 1.6834 - val_acc: 0.4758
Epoch 2/5
 - 33s - loss: 0.4303 - acc: 0.8285 - val_loss: 2.4332 - val_acc: 0.4967
Epoch 3/5
 - 33s - loss: 0.3102 - acc: 0.8927 - val_loss: 0.8032 - val_acc: 0.6084
Epoch 4/5
 - 33s - loss: 0.2357 - acc: 0.9297 - val_loss: 0.7296 - val_acc: 0.6397
Epoch 5/5
 - 34s - loss: 0.1807 - acc: 0.9536 - val_loss: 0.8227 - val_acc: 0.6281
Test accuracy:0.560
current auc_score ------------------> 0.661
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.6495 - acc: 0.7269 - val_loss: 0.4933 - val_acc: 0.7947
Epoch 2/5
 - 36s - loss: 0.4131 - acc: 0.8394 - val_loss: 0.3220 - val_acc: 0.8884
Epoch 3/5
 - 36s - loss: 0.3040 - acc: 0.8944 - val_loss: 0.2963 - val_acc: 0.9069
Epoch 4/5
 - 36s - loss: 0.2277 - acc: 0.9340 - val_loss: 0.1734 - val_acc: 0.9602
Epoch 5/5
 - 36s - loss: 0.1772 - acc: 0.9549 - val_loss: 0.1278 - val_acc: 0.9772
Test accuracy:0.595
current auc_score ------------------> 0.854
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6515 - acc: 0.7247 - val_loss: 2.5927 - val_acc: 0.5036
Epoch 2/5
 - 33s - loss: 0.4174 - acc: 0.8369 - val_loss: 1.5723 - val_acc: 0.5186
Epoch 3/5
 - 33s - loss: 0.3042 - acc: 0.8953 - val_loss: 1.9902 - val_acc: 0.5099
Epoch 4/5
 - 33s - loss: 0.2354 - acc: 0.9297 - val_loss: 1.0850 - val_acc: 0.5705
Epoch 5/5
 - 33s - loss: 0.1918 - acc: 0.9475 - val_loss: 0.8712 - val_acc: 0.6007
Test accuracy:0.641
current auc_score ------------------> 0.732
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.7353 - acc: 0.6856 - val_loss: 0.4990 - val_acc: 0.7864
Epoch 2/5
 - 37s - loss: 0.4734 - acc: 0.8106 - val_loss: 0.3529 - val_acc: 0.8745
Epoch 3/5
 - 36s - loss: 0.3427 - acc: 0.8771 - val_loss: 0.2753 - val_acc: 0.9137
Epoch 4/5
 - 36s - loss: 0.2681 - acc: 0.9153 - val_loss: 0.2146 - val_acc: 0.9435
Epoch 5/5
 - 37s - loss: 0.2142 - acc: 0.9387 - val_loss: 0.1665 - val_acc: 0.9645
Test accuracy:0.690
current auc_score ------------------> 0.877
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1260)         20677       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2520)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1290752     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 1,313,990
Trainable params: 1,311,886
Non-trainable params: 2,104
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.7022 - acc: 0.7007 - val_loss: 0.4571 - val_acc: 0.8169
Epoch 2/5
 - 34s - loss: 0.4489 - acc: 0.8240 - val_loss: 0.3646 - val_acc: 0.8741
Epoch 3/5
 - 32s - loss: 0.3291 - acc: 0.8866 - val_loss: 0.2570 - val_acc: 0.9233
Epoch 4/5
 - 33s - loss: 0.2524 - acc: 0.9217 - val_loss: 0.1853 - val_acc: 0.9559
Epoch 5/5
 - 33s - loss: 0.2023 - acc: 0.9436 - val_loss: 0.1469 - val_acc: 0.9734
Test accuracy:0.713
current auc_score ------------------> 0.889
accuracies:  [0.5602150537634408, 0.5951612903225807, 0.6407258064516129, 0.6895161290322581, 0.7127688172043011]
aucs:  [0.6608764380275176, 0.8535426060816279, 0.7320261374147301, 0.877043661116892, 0.8894911261417506]
['3-3-3', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6494 - acc: 0.7530 - val_loss: 0.4613 - val_acc: 0.8385
Epoch 2/5
 - 33s - loss: 0.4216 - acc: 0.8589 - val_loss: 0.3469 - val_acc: 0.9016
Epoch 3/5
 - 33s - loss: 0.3042 - acc: 0.9185 - val_loss: 0.2361 - val_acc: 0.9504
Epoch 4/5
 - 33s - loss: 0.2316 - acc: 0.9532 - val_loss: 0.1756 - val_acc: 0.9802
Epoch 5/5
 - 33s - loss: 0.1868 - acc: 0.9701 - val_loss: 0.1429 - val_acc: 0.9888
Test accuracy:0.656
current auc_score ------------------> 0.882
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.6675 - acc: 0.7419 - val_loss: 0.7858 - val_acc: 0.6133
Epoch 2/5
 - 33s - loss: 0.4062 - acc: 0.8689 - val_loss: 0.3621 - val_acc: 0.8952
Epoch 3/5
 - 34s - loss: 0.2927 - acc: 0.9259 - val_loss: 0.2783 - val_acc: 0.9385
Epoch 4/5
 - 34s - loss: 0.2255 - acc: 0.9565 - val_loss: 0.1894 - val_acc: 0.9686
Epoch 5/5
 - 33s - loss: 0.1825 - acc: 0.9724 - val_loss: 0.1613 - val_acc: 0.9782
Test accuracy:0.676
current auc_score ------------------> 0.856
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.6269 - acc: 0.7636 - val_loss: 0.4853 - val_acc: 0.8225
Epoch 2/5
 - 37s - loss: 0.3816 - acc: 0.8816 - val_loss: 0.3308 - val_acc: 0.9109
Epoch 3/5
 - 36s - loss: 0.2773 - acc: 0.9330 - val_loss: 0.2314 - val_acc: 0.9586
Epoch 4/5
 - 37s - loss: 0.2139 - acc: 0.9605 - val_loss: 0.1700 - val_acc: 0.9804
Epoch 5/5
 - 37s - loss: 0.1770 - acc: 0.9744 - val_loss: 0.1446 - val_acc: 0.9859
Test accuracy:0.629
current auc_score ------------------> 0.869
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6934 - acc: 0.7278 - val_loss: 0.5463 - val_acc: 0.7809
Epoch 2/5
 - 33s - loss: 0.4343 - acc: 0.8517 - val_loss: 0.4833 - val_acc: 0.8278
Epoch 3/5
 - 33s - loss: 0.3201 - acc: 0.9127 - val_loss: 0.2921 - val_acc: 0.9319
Epoch 4/5
 - 33s - loss: 0.2445 - acc: 0.9472 - val_loss: 0.2326 - val_acc: 0.9539
Epoch 5/5
 - 33s - loss: 0.1937 - acc: 0.9690 - val_loss: 0.2088 - val_acc: 0.9664
Test accuracy:0.686
current auc_score ------------------> 0.871
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         70234       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 2,543,195
Trainable params: 2,540,259
Non-trainable params: 2,936
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.6816 - acc: 0.7363 - val_loss: 0.6253 - val_acc: 0.7422
Epoch 2/5
 - 36s - loss: 0.4296 - acc: 0.8558 - val_loss: 0.3887 - val_acc: 0.8827
Epoch 3/5
 - 37s - loss: 0.3182 - acc: 0.9127 - val_loss: 0.3625 - val_acc: 0.9031
Epoch 4/5
 - 36s - loss: 0.2388 - acc: 0.9499 - val_loss: 0.2319 - val_acc: 0.9585
Epoch 5/5
 - 36s - loss: 0.1935 - acc: 0.9677 - val_loss: 0.1740 - val_acc: 0.9800
Test accuracy:0.670
current auc_score ------------------> 0.873
accuracies:  [0.6561827956989247, 0.6758064516129032, 0.6288978494623656, 0.6858870967741936, 0.6697580645161291]
aucs:  [0.8822716499017227, 0.8556984188923575, 0.8685464360041624, 0.8713733524106833, 0.8728140897791652]
['3-3-3', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6998 - acc: 0.7462 - val_loss: 1.0712 - val_acc: 0.5262
Epoch 2/5
 - 33s - loss: 0.4383 - acc: 0.8744 - val_loss: 1.0006 - val_acc: 0.5005
Epoch 3/5
 - 34s - loss: 0.3293 - acc: 0.9295 - val_loss: 0.3318 - val_acc: 0.9522
Epoch 4/5
 - 34s - loss: 0.2599 - acc: 0.9606 - val_loss: 0.2274 - val_acc: 0.9754
Epoch 5/5
 - 33s - loss: 0.2225 - acc: 0.9743 - val_loss: 0.1786 - val_acc: 0.9896
Test accuracy:0.683
current auc_score ------------------> 0.865
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.6654 - acc: 0.7675 - val_loss: 0.4775 - val_acc: 0.8597
Epoch 2/5
 - 34s - loss: 0.4120 - acc: 0.8920 - val_loss: 0.3344 - val_acc: 0.9331
Epoch 3/5
 - 34s - loss: 0.2987 - acc: 0.9437 - val_loss: 0.2575 - val_acc: 0.9640
Epoch 4/5
 - 34s - loss: 0.2388 - acc: 0.9693 - val_loss: 0.1975 - val_acc: 0.9847
Epoch 5/5
 - 34s - loss: 0.2039 - acc: 0.9814 - val_loss: 0.1752 - val_acc: 0.9893
Test accuracy:0.694
current auc_score ------------------> 0.847
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.7120 - acc: 0.7440 - val_loss: 4.9009 - val_acc: 0.4965
Epoch 2/5
 - 34s - loss: 0.4313 - acc: 0.8815 - val_loss: 0.9248 - val_acc: 0.5934
Epoch 3/5
 - 33s - loss: 0.3135 - acc: 0.9386 - val_loss: 0.2660 - val_acc: 0.9607
Epoch 4/5
 - 33s - loss: 0.2494 - acc: 0.9655 - val_loss: 0.2374 - val_acc: 0.9698
Epoch 5/5
 - 33s - loss: 0.2115 - acc: 0.9805 - val_loss: 0.1934 - val_acc: 0.9874
Test accuracy:0.528
current auc_score ------------------> 0.876
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.6710 - acc: 0.7685 - val_loss: 0.4983 - val_acc: 0.8454
Epoch 2/5
 - 34s - loss: 0.4078 - acc: 0.8883 - val_loss: 0.3664 - val_acc: 0.9216
Epoch 3/5
 - 33s - loss: 0.3055 - acc: 0.9398 - val_loss: 0.2485 - val_acc: 0.9686
Epoch 4/5
 - 34s - loss: 0.2410 - acc: 0.9689 - val_loss: 0.2048 - val_acc: 0.9828
Epoch 5/5
 - 34s - loss: 0.2070 - acc: 0.9804 - val_loss: 0.1893 - val_acc: 0.9867
Test accuracy:0.641
current auc_score ------------------> 0.837
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3528)         149782      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 7056)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3613184     merge_features[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_23[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_10[0][0]                 
==================================================================================================
Total params: 3,765,527
Trainable params: 3,761,767
Non-trainable params: 3,760
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 44s - loss: 0.6629 - acc: 0.7682 - val_loss: 0.5323 - val_acc: 0.8286
Epoch 2/5
 - 36s - loss: 0.4125 - acc: 0.8909 - val_loss: 0.3844 - val_acc: 0.9113
Epoch 3/5
 - 37s - loss: 0.3111 - acc: 0.9383 - val_loss: 0.2964 - val_acc: 0.9463
Epoch 4/5
 - 37s - loss: 0.2491 - acc: 0.9660 - val_loss: 0.2255 - val_acc: 0.9745
Epoch 5/5
 - 37s - loss: 0.2093 - acc: 0.9803 - val_loss: 0.1758 - val_acc: 0.9917
Test accuracy:0.625
current auc_score ------------------> 0.912
accuracies:  [0.6831989247311828, 0.6939516129032258, 0.5280913978494624, 0.6408602150537634, 0.6254032258064516]
aucs:  [0.8646586310556132, 0.8470691698462249, 0.8757634553127529, 0.8366536593825875, 0.9118444328824141]
['4-4-4', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.6608 - acc: 0.7251 - val_loss: 1.6640 - val_acc: 0.4872
Epoch 2/5
 - 36s - loss: 0.4102 - acc: 0.8488 - val_loss: 1.2546 - val_acc: 0.5548
Epoch 3/5
 - 36s - loss: 0.3036 - acc: 0.9030 - val_loss: 1.2265 - val_acc: 0.5446
Epoch 4/5
 - 37s - loss: 0.2304 - acc: 0.9388 - val_loss: 0.6864 - val_acc: 0.6550
Epoch 5/5
 - 37s - loss: 0.1820 - acc: 0.9595 - val_loss: 0.7389 - val_acc: 0.6505
Test accuracy:0.692
current auc_score ------------------> 0.716
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.6647 - acc: 0.7293 - val_loss: 0.9307 - val_acc: 0.5673
Epoch 2/5
 - 36s - loss: 0.4140 - acc: 0.8470 - val_loss: 0.8046 - val_acc: 0.5876
Epoch 3/5
 - 36s - loss: 0.3055 - acc: 0.9027 - val_loss: 0.9736 - val_acc: 0.5897
Epoch 4/5
 - 36s - loss: 0.2303 - acc: 0.9380 - val_loss: 0.7795 - val_acc: 0.6363
Epoch 5/5
 - 35s - loss: 0.1863 - acc: 0.9573 - val_loss: 0.6461 - val_acc: 0.6760
Test accuracy:0.551
current auc_score ------------------> 0.587
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6485 - acc: 0.7397 - val_loss: 5.1914 - val_acc: 0.4965
Epoch 2/5
 - 36s - loss: 0.4076 - acc: 0.8503 - val_loss: 2.4213 - val_acc: 0.4981
Epoch 3/5
 - 36s - loss: 0.3043 - acc: 0.9051 - val_loss: 1.4053 - val_acc: 0.5105
Epoch 4/5
 - 36s - loss: 0.2394 - acc: 0.9334 - val_loss: 0.2204 - val_acc: 0.9501
Epoch 5/5
 - 37s - loss: 0.1889 - acc: 0.9563 - val_loss: 0.1687 - val_acc: 0.9699
Test accuracy:0.600
current auc_score ------------------> 0.839
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.6821 - acc: 0.7207 - val_loss: 0.4548 - val_acc: 0.8235
Epoch 2/5
 - 41s - loss: 0.4316 - acc: 0.8423 - val_loss: 0.3316 - val_acc: 0.8914
Epoch 3/5
 - 42s - loss: 0.3190 - acc: 0.8979 - val_loss: 0.2547 - val_acc: 0.9290
Epoch 4/5
 - 42s - loss: 0.2515 - acc: 0.9293 - val_loss: 0.1897 - val_acc: 0.9565
Epoch 5/5
 - 41s - loss: 0.2049 - acc: 0.9502 - val_loss: 0.1588 - val_acc: 0.9675
Test accuracy:0.685
current auc_score ------------------> 0.883
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1656)         29360       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3312)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1696256     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,728,177
Trainable params: 1,725,605
Non-trainable params: 2,572
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.6283 - acc: 0.7483 - val_loss: 1.7982 - val_acc: 0.5260
Epoch 2/5
 - 37s - loss: 0.3891 - acc: 0.8620 - val_loss: 1.3170 - val_acc: 0.5346
Epoch 3/5
 - 37s - loss: 0.2840 - acc: 0.9147 - val_loss: 0.7426 - val_acc: 0.6270
Epoch 4/5
 - 37s - loss: 0.2142 - acc: 0.9460 - val_loss: 0.7365 - val_acc: 0.6609
Epoch 5/5
 - 37s - loss: 0.1698 - acc: 0.9650 - val_loss: 0.7416 - val_acc: 0.6458
Test accuracy:0.631
current auc_score ------------------> 0.731
accuracies:  [0.6919354838709677, 0.5506720430107527, 0.5995967741935484, 0.6846774193548387, 0.6306451612903226]
aucs:  [0.7159686090877558, 0.5873398658804486, 0.8392146490923806, 0.8825752254595908, 0.7311546132500867]
['4-4-4', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.7129 - acc: 0.7390 - val_loss: 4.4676 - val_acc: 0.4965
Epoch 2/5
 - 37s - loss: 0.4501 - acc: 0.8630 - val_loss: 1.0945 - val_acc: 0.5184
Epoch 3/5
 - 37s - loss: 0.3281 - acc: 0.9231 - val_loss: 0.2811 - val_acc: 0.9487
Epoch 4/5
 - 36s - loss: 0.2581 - acc: 0.9549 - val_loss: 0.2094 - val_acc: 0.9774
Epoch 5/5
 - 36s - loss: 0.2129 - acc: 0.9729 - val_loss: 0.1995 - val_acc: 0.9797
Test accuracy:0.660
current auc_score ------------------> 0.907
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.7026 - acc: 0.7379 - val_loss: 0.5360 - val_acc: 0.8174
Epoch 2/5
 - 41s - loss: 0.4505 - acc: 0.8624 - val_loss: 0.4034 - val_acc: 0.8859
Epoch 3/5
 - 41s - loss: 0.3398 - acc: 0.9168 - val_loss: 0.3198 - val_acc: 0.9243
Epoch 4/5
 - 41s - loss: 0.2691 - acc: 0.9491 - val_loss: 0.2328 - val_acc: 0.9664
Epoch 5/5
 - 41s - loss: 0.2233 - acc: 0.9692 - val_loss: 0.2037 - val_acc: 0.9785
Test accuracy:0.656
current auc_score ------------------> 0.874
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.7111 - acc: 0.7355 - val_loss: 0.6998 - val_acc: 0.7111
Epoch 2/5
 - 41s - loss: 0.4525 - acc: 0.8592 - val_loss: 0.4171 - val_acc: 0.8770
Epoch 3/5
 - 41s - loss: 0.3396 - acc: 0.9182 - val_loss: 0.3280 - val_acc: 0.9276
Epoch 4/5
 - 41s - loss: 0.2668 - acc: 0.9511 - val_loss: 0.2596 - val_acc: 0.9558
Epoch 5/5
 - 42s - loss: 0.2212 - acc: 0.9694 - val_loss: 0.1968 - val_acc: 0.9800
Test accuracy:0.615
current auc_score ------------------> 0.905
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.6967 - acc: 0.7480 - val_loss: 4.8323 - val_acc: 0.4965
Epoch 2/5
 - 37s - loss: 0.4390 - acc: 0.8691 - val_loss: 0.9368 - val_acc: 0.5749
Epoch 3/5
 - 36s - loss: 0.3350 - acc: 0.9193 - val_loss: 0.8880 - val_acc: 0.5852
Epoch 4/5
 - 36s - loss: 0.2703 - acc: 0.9497 - val_loss: 1.1865 - val_acc: 0.5292
Epoch 5/5
 - 36s - loss: 0.2237 - acc: 0.9675 - val_loss: 0.9600 - val_acc: 0.5909

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.534
current auc_score ------------------> 0.707
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 3168)         101072      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 6336)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          3244544     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 3,348,177
Trainable params: 3,344,369
Non-trainable params: 3,808
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.6606 - acc: 0.7641 - val_loss: 0.6256 - val_acc: 0.7810
Epoch 2/5
 - 39s - loss: 0.4144 - acc: 0.8799 - val_loss: 0.4001 - val_acc: 0.8940
Epoch 3/5
 - 39s - loss: 0.3001 - acc: 0.9377 - val_loss: 0.2501 - val_acc: 0.9602
Epoch 4/5
 - 39s - loss: 0.2385 - acc: 0.9634 - val_loss: 0.2043 - val_acc: 0.9749
Epoch 5/5
 - 39s - loss: 0.2033 - acc: 0.9757 - val_loss: 0.1685 - val_acc: 0.9876
Test accuracy:0.647
current auc_score ------------------> 0.888
accuracies:  [0.6595430107526882, 0.6557795698924731, 0.614516129032258, 0.5337365591397849, 0.646774193548387]
aucs:  [0.9065946930280957, 0.8744095415654989, 0.9045047115273442, 0.7066571641230199, 0.8884411492658111]
['4-4-4', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.7435 - acc: 0.7555 - val_loss: 1.6600 - val_acc: 0.5448
Epoch 2/5
 - 38s - loss: 0.4842 - acc: 0.8763 - val_loss: 0.9980 - val_acc: 0.5198
Epoch 3/5
 - 37s - loss: 0.3718 - acc: 0.9331 - val_loss: 0.9343 - val_acc: 0.5656
Epoch 4/5
 - 37s - loss: 0.3060 - acc: 0.9616 - val_loss: 1.3620 - val_acc: 0.5221
Epoch 5/5
 - 38s - loss: 0.2657 - acc: 0.9756 - val_loss: 1.2006 - val_acc: 0.5663

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.537
current auc_score ------------------> 0.572
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.7783 - acc: 0.7322 - val_loss: 0.6120 - val_acc: 0.8055
Epoch 2/5
 - 38s - loss: 0.5039 - acc: 0.8685 - val_loss: 0.4619 - val_acc: 0.8869
Epoch 3/5
 - 38s - loss: 0.3889 - acc: 0.9252 - val_loss: 0.3800 - val_acc: 0.9331
Epoch 4/5
 - 38s - loss: 0.3183 - acc: 0.9565 - val_loss: 0.2742 - val_acc: 0.9735
Epoch 5/5
 - 38s - loss: 0.2725 - acc: 0.9730 - val_loss: 0.2345 - val_acc: 0.9892
Test accuracy:0.639
current auc_score ------------------> 0.886
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.6971 - acc: 0.7765 - val_loss: 1.4732 - val_acc: 0.5117
Epoch 2/5
 - 38s - loss: 0.4471 - acc: 0.8951 - val_loss: 1.1469 - val_acc: 0.4941
Epoch 3/5
 - 38s - loss: 0.3344 - acc: 0.9497 - val_loss: 0.9344 - val_acc: 0.5483
Epoch 4/5
 - 38s - loss: 0.2780 - acc: 0.9724 - val_loss: 1.2535 - val_acc: 0.5413
Epoch 5/5
 - 37s - loss: 0.2429 - acc: 0.9833 - val_loss: 1.3872 - val_acc: 0.5383

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.514
current auc_score ------------------> 0.590
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.7055 - acc: 0.7689 - val_loss: 3.0145 - val_acc: 0.4966
Epoch 2/5
 - 38s - loss: 0.4667 - acc: 0.8848 - val_loss: 1.6039 - val_acc: 0.5184
Epoch 3/5
 - 38s - loss: 0.3533 - acc: 0.9398 - val_loss: 0.8609 - val_acc: 0.6042
Epoch 4/5
 - 38s - loss: 0.2862 - acc: 0.9698 - val_loss: 1.5945 - val_acc: 0.5473
Epoch 5/5
 - 37s - loss: 0.2504 - acc: 0.9817 - val_loss: 0.8000 - val_acc: 0.6826
Test accuracy:0.755
current auc_score ------------------> 0.774
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         216704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_29[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 5,012,097
Trainable params: 5,007,053
Non-trainable params: 5,044
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 51s - loss: 0.7083 - acc: 0.7722 - val_loss: 0.6613 - val_acc: 0.7983
Epoch 2/5
 - 42s - loss: 0.4653 - acc: 0.8878 - val_loss: 0.4197 - val_acc: 0.9129
Epoch 3/5
 - 42s - loss: 0.3534 - acc: 0.9423 - val_loss: 0.2932 - val_acc: 0.9705
Epoch 4/5
 - 41s - loss: 0.2883 - acc: 0.9683 - val_loss: 0.2408 - val_acc: 0.9868
Epoch 5/5
 - 42s - loss: 0.2531 - acc: 0.9811 - val_loss: 0.2284 - val_acc: 0.9851
Test accuracy:0.724
current auc_score ------------------> 0.893
accuracies:  [0.5375, 0.6391129032258065, 0.513978494623656, 0.7551075268817204, 0.7235215053763441]
aucs:  [0.5716379061163139, 0.8860603827032028, 0.5903277112961036, 0.7742761807723436, 0.8933995620881027]
['6-6-6', '6', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.6533 - acc: 0.7481 - val_loss: 0.5369 - val_acc: 0.7812
Epoch 2/5
 - 47s - loss: 0.4137 - acc: 0.8637 - val_loss: 0.4008 - val_acc: 0.8735
Epoch 3/5
 - 46s - loss: 0.3149 - acc: 0.9140 - val_loss: 0.2936 - val_acc: 0.9307
Epoch 4/5
 - 46s - loss: 0.2440 - acc: 0.9475 - val_loss: 0.2023 - val_acc: 0.9710
Epoch 5/5
 - 46s - loss: 0.2032 - acc: 0.9651 - val_loss: 0.1657 - val_acc: 0.9822
Test accuracy:0.707
current auc_score ------------------> 0.909
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.7433 - acc: 0.7125 - val_loss: 2.9680 - val_acc: 0.4974
Epoch 2/5
 - 44s - loss: 0.4569 - acc: 0.8424 - val_loss: 4.0342 - val_acc: 0.4965
Epoch 3/5
 - 45s - loss: 0.3413 - acc: 0.9020 - val_loss: 0.5013 - val_acc: 0.7845
Epoch 4/5
 - 44s - loss: 0.2660 - acc: 0.9378 - val_loss: 0.2245 - val_acc: 0.9562
Epoch 5/5
 - 44s - loss: 0.2159 - acc: 0.9592 - val_loss: 0.1704 - val_acc: 0.9792
Test accuracy:0.591
current auc_score ------------------> 0.854
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.6863 - acc: 0.7331 - val_loss: 3.1640 - val_acc: 0.4970
Epoch 2/5
 - 45s - loss: 0.4298 - acc: 0.8576 - val_loss: 3.0442 - val_acc: 0.4965
Epoch 3/5
 - 45s - loss: 0.3255 - acc: 0.9091 - val_loss: 2.8251 - val_acc: 0.4971
Epoch 4/5
 - 44s - loss: 0.2565 - acc: 0.9403 - val_loss: 2.7573 - val_acc: 0.4969
Epoch 5/5
 - 44s - loss: 0.2091 - acc: 0.9627 - val_loss: 2.8011 - val_acc: 0.4965
Test accuracy:0.500
current auc_score ------------------> 0.565
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.6857 - acc: 0.7328 - val_loss: 1.7771 - val_acc: 0.5094
Epoch 2/5
 - 44s - loss: 0.4428 - acc: 0.8478 - val_loss: 0.8974 - val_acc: 0.5725
Epoch 3/5
 - 43s - loss: 0.3299 - acc: 0.9065 - val_loss: 1.2851 - val_acc: 0.5370
Epoch 4/5
 - 43s - loss: 0.2587 - acc: 0.9409 - val_loss: 0.8838 - val_acc: 0.5936
Epoch 5/5
 - 43s - loss: 0.2121 - acc: 0.9602 - val_loss: 0.8431 - val_acc: 0.5375
Test accuracy:0.520
current auc_score ------------------> 0.531
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 2412)         49726       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 4824)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          2470400     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 2,522,687
Trainable params: 2,518,989
Non-trainable params: 3,698
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.6406 - acc: 0.7545 - val_loss: 1.9021 - val_acc: 0.5167
Epoch 2/5
 - 45s - loss: 0.4206 - acc: 0.8597 - val_loss: 1.2670 - val_acc: 0.5457
Epoch 3/5
 - 44s - loss: 0.3207 - acc: 0.9112 - val_loss: 0.8837 - val_acc: 0.5892
Epoch 4/5
 - 44s - loss: 0.2552 - acc: 0.9423 - val_loss: 0.7569 - val_acc: 0.6462
Epoch 5/5
 - 45s - loss: 0.2102 - acc: 0.9603 - val_loss: 0.8963 - val_acc: 0.6978
Test accuracy:0.746
current auc_score ------------------> 0.729
accuracies:  [0.7071236559139785, 0.5913978494623656, 0.5, 0.519758064516129, 0.7463709677419355]
aucs:  [0.908676292056885, 0.8543825875823794, 0.5648766114579721, 0.5312274540409296, 0.7285344403977339]
['6-6-6', '12', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.7787 - acc: 0.7252 - val_loss: 2.7851 - val_acc: 0.5038
Epoch 2/5
 - 46s - loss: 0.5148 - acc: 0.8617 - val_loss: 0.8805 - val_acc: 0.5946
Epoch 3/5
 - 46s - loss: 0.4001 - acc: 0.9212 - val_loss: 1.4460 - val_acc: 0.5112
Epoch 4/5
 - 46s - loss: 0.3325 - acc: 0.9499 - val_loss: 1.4192 - val_acc: 0.5235

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 46s - loss: 0.2846 - acc: 0.9688 - val_loss: 1.2176 - val_acc: 0.5373
Test accuracy:0.556
current auc_score ------------------> 0.718
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.7391 - acc: 0.7520 - val_loss: 3.6452 - val_acc: 0.4986
Epoch 2/5
 - 45s - loss: 0.5026 - acc: 0.8687 - val_loss: 2.2439 - val_acc: 0.4966
Epoch 3/5
 - 46s - loss: 0.3884 - acc: 0.9232 - val_loss: 1.3769 - val_acc: 0.5187
Epoch 4/5
 - 45s - loss: 0.3155 - acc: 0.9591 - val_loss: 1.4682 - val_acc: 0.5212
Epoch 5/5
 - 45s - loss: 0.2691 - acc: 0.9754 - val_loss: 0.8261 - val_acc: 0.6660
Test accuracy:0.518
current auc_score ------------------> 0.683
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 61s - loss: 0.7708 - acc: 0.7341 - val_loss: 2.6863 - val_acc: 0.4965
Epoch 2/5
 - 46s - loss: 0.5224 - acc: 0.8558 - val_loss: 1.2568 - val_acc: 0.5260
Epoch 3/5
 - 46s - loss: 0.4131 - acc: 0.9119 - val_loss: 1.6808 - val_acc: 0.5131
Epoch 4/5
 - 46s - loss: 0.3326 - acc: 0.9510 - val_loss: 0.8711 - val_acc: 0.6212
Epoch 5/5
 - 46s - loss: 0.2857 - acc: 0.9677 - val_loss: 1.4837 - val_acc: 0.5221
Test accuracy:0.516
current auc_score ------------------> 0.598
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.7255 - acc: 0.7586 - val_loss: 1.1836 - val_acc: 0.5292
Epoch 2/5
 - 47s - loss: 0.4975 - acc: 0.8703 - val_loss: 1.0798 - val_acc: 0.5403
Epoch 3/5
 - 46s - loss: 0.3899 - acc: 0.9247 - val_loss: 3.4679 - val_acc: 0.5035
Epoch 4/5
 - 46s - loss: 0.3170 - acc: 0.9571 - val_loss: 1.2058 - val_acc: 0.6140

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 45s - loss: 0.2726 - acc: 0.9737 - val_loss: 1.7775 - val_acc: 0.5118
Test accuracy:0.499
current auc_score ------------------> 0.684
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 4680)         174448      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 9360)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          4792832     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 4,969,841
Trainable params: 4,963,893
Non-trainable params: 5,948
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 61s - loss: 0.7545 - acc: 0.7445 - val_loss: 0.7992 - val_acc: 0.7083
Epoch 2/5
 - 48s - loss: 0.5072 - acc: 0.8663 - val_loss: 0.5096 - val_acc: 0.8651
Epoch 3/5
 - 48s - loss: 0.3923 - acc: 0.9258 - val_loss: 0.4247 - val_acc: 0.9125
Epoch 4/5
 - 48s - loss: 0.3182 - acc: 0.9570 - val_loss: 0.3136 - val_acc: 0.9621
Epoch 5/5
 - 49s - loss: 0.2721 - acc: 0.9737 - val_loss: 0.2455 - val_acc: 0.9836
Test accuracy:0.626
current auc_score ------------------> 0.873
accuracies:  [0.5561827956989247, 0.5177419354838709, 0.516263440860215, 0.49946236559139784, 0.6262096774193548]
aucs:  [0.7181424875708174, 0.6832953954214359, 0.5983835559024165, 0.6840936452191004, 0.8728325167649439]
['6-6-6', '18', '3', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 65s - loss: 0.8205 - acc: 0.7557 - val_loss: 0.7587 - val_acc: 0.7893
Epoch 2/5
 - 52s - loss: 0.5600 - acc: 0.8887 - val_loss: 0.4887 - val_acc: 0.9246
Epoch 3/5
 - 52s - loss: 0.4408 - acc: 0.9449 - val_loss: 0.4014 - val_acc: 0.9627
Epoch 4/5
 - 52s - loss: 0.3750 - acc: 0.9692 - val_loss: 0.3543 - val_acc: 0.9752
Epoch 5/5
 - 52s - loss: 0.3332 - acc: 0.9832 - val_loss: 0.3149 - val_acc: 0.9883
Test accuracy:0.601
current auc_score ------------------> 0.878
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 63s - loss: 0.8109 - acc: 0.7681 - val_loss: 2.5863 - val_acc: 0.4971
Epoch 2/5
 - 49s - loss: 0.5699 - acc: 0.8813 - val_loss: 1.1040 - val_acc: 0.5237
Epoch 3/5
 - 49s - loss: 0.4621 - acc: 0.9341 - val_loss: 1.3738 - val_acc: 0.5271
Epoch 4/5
 - 49s - loss: 0.3855 - acc: 0.9645 - val_loss: 0.9618 - val_acc: 0.6088
Epoch 5/5
 - 50s - loss: 0.3472 - acc: 0.9773 - val_loss: 2.0251 - val_acc: 0.5045
Test accuracy:0.505
current auc_score ------------------> 0.551
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 64s - loss: 0.8193 - acc: 0.7581 - val_loss: 1.1238 - val_acc: 0.5422
Epoch 2/5
 - 50s - loss: 0.5787 - acc: 0.8787 - val_loss: 1.3295 - val_acc: 0.5561
Epoch 3/5
 - 50s - loss: 0.4586 - acc: 0.9364 - val_loss: 1.8519 - val_acc: 0.5143

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 51s - loss: 0.3921 - acc: 0.9640 - val_loss: 2.2244 - val_acc: 0.5070
Epoch 5/5
 - 50s - loss: 0.3624 - acc: 0.9750 - val_loss: 0.3519 - val_acc: 0.9813
Test accuracy:0.688
current auc_score ------------------> 0.878
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 64s - loss: 0.7878 - acc: 0.7798 - val_loss: 0.7771 - val_acc: 0.7663
Epoch 2/5
 - 51s - loss: 0.5530 - acc: 0.8896 - val_loss: 0.5074 - val_acc: 0.9169
Epoch 3/5
 - 51s - loss: 0.4370 - acc: 0.9463 - val_loss: 0.3879 - val_acc: 0.9674
Epoch 4/5
 - 52s - loss: 0.3713 - acc: 0.9715 - val_loss: 0.3528 - val_acc: 0.9808
Epoch 5/5
 - 52s - loss: 0.3353 - acc: 0.9814 - val_loss: 0.3092 - val_acc: 0.9902
Test accuracy:0.540
current auc_score ------------------> 0.894
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  3  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 6948)         375958      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 13896)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          7115264     merge_features[0][0]             
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_41[0][0]              
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_19[0][0]                 
==================================================================================================
Total params: 7,493,783
Trainable params: 7,485,585
Non-trainable params: 8,198
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 65s - loss: 0.8134 - acc: 0.7627 - val_loss: 3.7779 - val_acc: 0.4965
Epoch 2/5
 - 51s - loss: 0.5721 - acc: 0.8790 - val_loss: 1.0307 - val_acc: 0.5516
Epoch 3/5
 - 51s - loss: 0.4538 - acc: 0.9379 - val_loss: 0.9036 - val_acc: 0.6591
Epoch 4/5
 - 50s - loss: 0.3828 - acc: 0.9652 - val_loss: 1.4373 - val_acc: 0.5167
Epoch 5/5
 - 50s - loss: 0.3391 - acc: 0.9812 - val_loss: 0.8815 - val_acc: 0.6944
Test accuracy:0.616
current auc_score ------------------> 0.661
accuracies:  [0.6008064516129032, 0.5053763440860215, 0.6876344086021505, 0.5395161290322581, 0.6158602150537634]
aucs:  [0.8777658544340387, 0.5506217120476355, 0.8778244594750838, 0.8937244912706672, 0.6610306104751995]
['2-2-2-2', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.7901 - acc: 0.6427 - val_loss: 1.0406 - val_acc: 0.5432
Epoch 2/5
 - 32s - loss: 0.6409 - acc: 0.7061 - val_loss: 0.7680 - val_acc: 0.5959
Epoch 3/5
 - 33s - loss: 0.5417 - acc: 0.7628 - val_loss: 0.7935 - val_acc: 0.6069
Epoch 4/5
 - 33s - loss: 0.4688 - acc: 0.8069 - val_loss: 0.7245 - val_acc: 0.6190
Epoch 5/5
 - 32s - loss: 0.4188 - acc: 0.8352 - val_loss: 0.3667 - val_acc: 0.8667
Test accuracy:0.727
current auc_score ------------------> 0.821
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.7702 - acc: 0.6525 - val_loss: 1.3258 - val_acc: 0.4725
Epoch 2/5
 - 32s - loss: 0.5961 - acc: 0.7353 - val_loss: 1.3115 - val_acc: 0.5082
Epoch 3/5
 - 32s - loss: 0.4991 - acc: 0.7871 - val_loss: 1.6561 - val_acc: 0.5094
Epoch 4/5
 - 32s - loss: 0.4389 - acc: 0.8215 - val_loss: 0.9792 - val_acc: 0.4814
Epoch 5/5
 - 32s - loss: 0.3828 - acc: 0.8543 - val_loss: 0.9504 - val_acc: 0.5070
Test accuracy:0.512
current auc_score ------------------> 0.555
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8068 - acc: 0.6331 - val_loss: 0.6996 - val_acc: 0.6128
Epoch 2/5
 - 34s - loss: 0.6462 - acc: 0.7014 - val_loss: 0.5635 - val_acc: 0.7295
Epoch 3/5
 - 35s - loss: 0.5463 - acc: 0.7521 - val_loss: 0.5029 - val_acc: 0.7750
Epoch 4/5
 - 35s - loss: 0.4627 - acc: 0.8024 - val_loss: 0.3930 - val_acc: 0.8446
Epoch 5/5
 - 34s - loss: 0.3920 - acc: 0.8437 - val_loss: 0.3427 - val_acc: 0.8725
Test accuracy:0.612
current auc_score ------------------> 0.812
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8428 - acc: 0.6084 - val_loss: 0.6833 - val_acc: 0.6450
Epoch 2/5
 - 34s - loss: 0.7082 - acc: 0.6640 - val_loss: 0.6283 - val_acc: 0.6885
Epoch 3/5
 - 34s - loss: 0.6327 - acc: 0.7016 - val_loss: 0.5603 - val_acc: 0.7346
Epoch 4/5
 - 34s - loss: 0.5612 - acc: 0.7387 - val_loss: 0.5346 - val_acc: 0.7663
Epoch 5/5
 - 34s - loss: 0.4853 - acc: 0.7877 - val_loss: 0.4446 - val_acc: 0.8222
Test accuracy:0.733
current auc_score ------------------> 0.857
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 216)          17178       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 432)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          221696      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 241,435
Trainable params: 239,521
Non-trainable params: 1,914
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.8324 - acc: 0.6219 - val_loss: 2.8807 - val_acc: 0.5035
Epoch 2/5
 - 33s - loss: 0.6725 - acc: 0.6872 - val_loss: 2.0486 - val_acc: 0.5035
Epoch 3/5
 - 33s - loss: 0.5710 - acc: 0.7421 - val_loss: 1.9081 - val_acc: 0.5041
Epoch 4/5
 - 32s - loss: 0.4767 - acc: 0.7990 - val_loss: 1.5768 - val_acc: 0.5040
Epoch 5/5
 - 32s - loss: 0.4087 - acc: 0.8390 - val_loss: 0.3701 - val_acc: 0.8588
Test accuracy:0.626
current auc_score ------------------> 0.766
accuracies:  [0.7272849462365591, 0.5122311827956989, 0.6115591397849462, 0.7334677419354839, 0.6262096774193548]
aucs:  [0.8213944169846225, 0.5554520031217483, 0.8117442767950052, 0.8573879205688519, 0.7655384654295294]
['2-2-2-2', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.8004 - acc: 0.6606 - val_loss: 0.6821 - val_acc: 0.6616
Epoch 2/5
 - 32s - loss: 0.6156 - acc: 0.7476 - val_loss: 0.6139 - val_acc: 0.7516
Epoch 3/5
 - 32s - loss: 0.5032 - acc: 0.8060 - val_loss: 0.4536 - val_acc: 0.8469
Epoch 4/5
 - 32s - loss: 0.4252 - acc: 0.8510 - val_loss: 0.3842 - val_acc: 0.8764
Epoch 5/5
 - 32s - loss: 0.3638 - acc: 0.8830 - val_loss: 0.3064 - val_acc: 0.9101
Test accuracy:0.683
current auc_score ------------------> 0.832
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.8074 - acc: 0.6601 - val_loss: 0.8413 - val_acc: 0.6323
Epoch 2/5
 - 35s - loss: 0.6000 - acc: 0.7547 - val_loss: 0.5857 - val_acc: 0.7702
Epoch 3/5
 - 35s - loss: 0.4811 - acc: 0.8205 - val_loss: 0.5622 - val_acc: 0.7961
Epoch 4/5
 - 36s - loss: 0.4040 - acc: 0.8646 - val_loss: 0.4637 - val_acc: 0.8366
Epoch 5/5
 - 35s - loss: 0.3460 - acc: 0.8938 - val_loss: 0.2984 - val_acc: 0.9185
Test accuracy:0.757
current auc_score ------------------> 0.880
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 40s - loss: 0.8277 - acc: 0.6498 - val_loss: 0.6956 - val_acc: 0.6782
Epoch 2/5
 - 33s - loss: 0.6428 - acc: 0.7331 - val_loss: 0.6427 - val_acc: 0.7396
Epoch 3/5
 - 32s - loss: 0.5247 - acc: 0.7989 - val_loss: 0.5115 - val_acc: 0.8223
Epoch 4/5
 - 32s - loss: 0.4330 - acc: 0.8472 - val_loss: 0.3903 - val_acc: 0.8747
Epoch 5/5
 - 32s - loss: 0.3572 - acc: 0.8851 - val_loss: 0.3000 - val_acc: 0.9132
Test accuracy:0.653
current auc_score ------------------> 0.826
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 41s - loss: 0.8204 - acc: 0.6514 - val_loss: 0.7144 - val_acc: 0.6650
Epoch 2/5
 - 34s - loss: 0.6310 - acc: 0.7428 - val_loss: 0.5728 - val_acc: 0.7696
Epoch 3/5
 - 35s - loss: 0.5107 - acc: 0.8080 - val_loss: 0.5351 - val_acc: 0.7958
Epoch 4/5
 - 35s - loss: 0.4229 - acc: 0.8560 - val_loss: 0.3665 - val_acc: 0.8775
Epoch 5/5
 - 35s - loss: 0.3459 - acc: 0.8950 - val_loss: 0.3536 - val_acc: 0.8891
Test accuracy:0.624
current auc_score ------------------> 0.770
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          58310       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 494,535
Trainable params: 491,937
Non-trainable params: 2,598
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.7909 - acc: 0.6711 - val_loss: 0.9234 - val_acc: 0.6211
Epoch 2/5
 - 31s - loss: 0.5999 - acc: 0.7561 - val_loss: 0.6341 - val_acc: 0.7364
Epoch 3/5
 - 33s - loss: 0.4918 - acc: 0.8151 - val_loss: 0.6414 - val_acc: 0.7584
Epoch 4/5
 - 32s - loss: 0.4213 - acc: 0.8548 - val_loss: 0.4486 - val_acc: 0.8405
Epoch 5/5
 - 32s - loss: 0.3590 - acc: 0.8880 - val_loss: 0.3459 - val_acc: 0.8980
Test accuracy:0.706
current auc_score ------------------> 0.825
accuracies:  [0.6830645161290323, 0.7567204301075269, 0.6533602150537634, 0.6237903225806452, 0.7064516129032258]
aucs:  [0.8319625101167765, 0.8799079734651405, 0.8256811842409526, 0.7695040250317956, 0.8254652271938951]
['2-2-2-2', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 38s - loss: 0.8328 - acc: 0.6687 - val_loss: 1.0045 - val_acc: 0.4971
Epoch 2/5
 - 32s - loss: 0.6339 - acc: 0.7586 - val_loss: 2.0132 - val_acc: 0.4964
Epoch 3/5
 - 32s - loss: 0.5006 - acc: 0.8325 - val_loss: 1.0416 - val_acc: 0.5457

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 31s - loss: 0.4321 - acc: 0.8724 - val_loss: 0.6988 - val_acc: 0.7439
Epoch 5/5
 - 31s - loss: 0.4019 - acc: 0.8855 - val_loss: 0.3917 - val_acc: 0.8966
Test accuracy:0.587
current auc_score ------------------> 0.808
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 43s - loss: 0.8307 - acc: 0.6740 - val_loss: 0.8271 - val_acc: 0.6345
Epoch 2/5
 - 36s - loss: 0.6226 - acc: 0.7661 - val_loss: 0.6755 - val_acc: 0.7441
Epoch 3/5
 - 36s - loss: 0.4893 - acc: 0.8392 - val_loss: 0.5111 - val_acc: 0.8373
Epoch 4/5
 - 36s - loss: 0.3996 - acc: 0.8880 - val_loss: 0.3459 - val_acc: 0.9154
Epoch 5/5
 - 36s - loss: 0.3406 - acc: 0.9160 - val_loss: 0.3322 - val_acc: 0.9212
Test accuracy:0.650
current auc_score ------------------> 0.815
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.7919 - acc: 0.6934 - val_loss: 0.9126 - val_acc: 0.6399
Epoch 2/5
 - 32s - loss: 0.5880 - acc: 0.7934 - val_loss: 0.5235 - val_acc: 0.8223
Epoch 3/5
 - 32s - loss: 0.4779 - acc: 0.8484 - val_loss: 0.4954 - val_acc: 0.8375
Epoch 4/5
 - 32s - loss: 0.4003 - acc: 0.8869 - val_loss: 0.3494 - val_acc: 0.9155
Epoch 5/5
 - 32s - loss: 0.3384 - acc: 0.9180 - val_loss: 0.2820 - val_acc: 0.9454
Test accuracy:0.644
current auc_score ------------------> 0.827
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 42s - loss: 0.8738 - acc: 0.6576 - val_loss: 0.7223 - val_acc: 0.6879
Epoch 2/5
 - 35s - loss: 0.6523 - acc: 0.7567 - val_loss: 0.5579 - val_acc: 0.8104
Epoch 3/5
 - 36s - loss: 0.5164 - acc: 0.8258 - val_loss: 0.5363 - val_acc: 0.8312
Epoch 4/5
 - 36s - loss: 0.4202 - acc: 0.8782 - val_loss: 0.3603 - val_acc: 0.9145
Epoch 5/5
 - 36s - loss: 0.3500 - acc: 0.9143 - val_loss: 0.3103 - val_acc: 0.9370
Test accuracy:0.662
current auc_score ------------------> 0.838
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          124533      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_22[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_9[0][0]                  
==================================================================================================
Total params: 763,510
Trainable params: 760,234
Non-trainable params: 3,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 39s - loss: 0.8296 - acc: 0.6765 - val_loss: 0.7563 - val_acc: 0.6645
Epoch 2/5
 - 32s - loss: 0.6153 - acc: 0.7733 - val_loss: 0.6431 - val_acc: 0.7638
Epoch 3/5
 - 33s - loss: 0.4906 - acc: 0.8421 - val_loss: 0.5263 - val_acc: 0.8237
Epoch 4/5
 - 33s - loss: 0.4097 - acc: 0.8838 - val_loss: 0.3992 - val_acc: 0.8985
Epoch 5/5
 - 33s - loss: 0.3493 - acc: 0.9119 - val_loss: 0.3275 - val_acc: 0.9272
Test accuracy:0.637
current auc_score ------------------> 0.824
accuracies:  [0.587231182795699, 0.6498655913978495, 0.644489247311828, 0.6619623655913979, 0.6370967741935484]
aucs:  [0.8075336744132271, 0.8152132833275523, 0.8273731789802289, 0.8381294802867385, 0.8237536131344664]
['3-3-3-3', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.8368 - acc: 0.6355 - val_loss: 0.9711 - val_acc: 0.5694
Epoch 2/5
 - 36s - loss: 0.6902 - acc: 0.6957 - val_loss: 0.5909 - val_acc: 0.7321
Epoch 3/5
 - 37s - loss: 0.5952 - acc: 0.7413 - val_loss: 0.5362 - val_acc: 0.7769
Epoch 4/5
 - 36s - loss: 0.5207 - acc: 0.7848 - val_loss: 0.4969 - val_acc: 0.8158
Epoch 5/5
 - 36s - loss: 0.4564 - acc: 0.8267 - val_loss: 0.4630 - val_acc: 0.8326
Test accuracy:0.743
current auc_score ------------------> 0.826
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 45s - loss: 0.8365 - acc: 0.6240 - val_loss: 1.5194 - val_acc: 0.5070
Epoch 2/5
 - 35s - loss: 0.6818 - acc: 0.6912 - val_loss: 1.5090 - val_acc: 0.5048
Epoch 3/5
 - 35s - loss: 0.5935 - acc: 0.7348 - val_loss: 1.1478 - val_acc: 0.5054
Epoch 4/5
 - 34s - loss: 0.5266 - acc: 0.7729 - val_loss: 1.8822 - val_acc: 0.5035
Epoch 5/5
 - 35s - loss: 0.4642 - acc: 0.8152 - val_loss: 2.4563 - val_acc: 0.5035

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 00005: early stopping
Test accuracy:0.500
current auc_score ------------------> 0.528
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.8093 - acc: 0.6428 - val_loss: 1.9988 - val_acc: 0.5051
Epoch 2/5
 - 37s - loss: 0.6373 - acc: 0.7247 - val_loss: 0.5924 - val_acc: 0.7515
Epoch 3/5
 - 37s - loss: 0.5421 - acc: 0.7746 - val_loss: 0.5218 - val_acc: 0.7999
Epoch 4/5
 - 36s - loss: 0.4604 - acc: 0.8220 - val_loss: 0.4962 - val_acc: 0.8194
Epoch 5/5
 - 36s - loss: 0.4003 - acc: 0.8561 - val_loss: 0.3820 - val_acc: 0.8727
Test accuracy:0.714
current auc_score ------------------> 0.852
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.8337 - acc: 0.6306 - val_loss: 0.6971 - val_acc: 0.6463
Epoch 2/5
 - 41s - loss: 0.6556 - acc: 0.7110 - val_loss: 0.6486 - val_acc: 0.6972
Epoch 3/5
 - 41s - loss: 0.5429 - acc: 0.7727 - val_loss: 0.5387 - val_acc: 0.7836
Epoch 4/5
 - 41s - loss: 0.4608 - acc: 0.8199 - val_loss: 0.4700 - val_acc: 0.8232
Epoch 5/5
 - 41s - loss: 0.3937 - acc: 0.8593 - val_loss: 0.3710 - val_acc: 0.8689
Test accuracy:0.603
current auc_score ------------------> 0.777
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 315)          27520       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 630)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          323072      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 353,153
Trainable params: 350,697
Non-trainable params: 2,456
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.7975 - acc: 0.6482 - val_loss: 0.9489 - val_acc: 0.5537
Epoch 2/5
 - 37s - loss: 0.6315 - acc: 0.7254 - val_loss: 0.7061 - val_acc: 0.6423
Epoch 3/5
 - 37s - loss: 0.5338 - acc: 0.7832 - val_loss: 0.4809 - val_acc: 0.8189
Epoch 4/5
 - 37s - loss: 0.4613 - acc: 0.8257 - val_loss: 0.4132 - val_acc: 0.8495
Epoch 5/5
 - 37s - loss: 0.4148 - acc: 0.8485 - val_loss: 0.4283 - val_acc: 0.8509
Test accuracy:0.653
current auc_score ------------------> 0.788
accuracies:  [0.7428763440860215, 0.5, 0.7139784946236559, 0.6033602150537635, 0.6533602150537634]
aucs:  [0.8262497109492426, 0.528096709157128, 0.8516011966701353, 0.7773080702971442, 0.7882974187767372]
['3-3-3-3', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8502 - acc: 0.6598 - val_loss: 0.7077 - val_acc: 0.7022
Epoch 2/5
 - 37s - loss: 0.6490 - acc: 0.7552 - val_loss: 0.6256 - val_acc: 0.7679
Epoch 3/5
 - 37s - loss: 0.5262 - acc: 0.8223 - val_loss: 0.4553 - val_acc: 0.8566
Epoch 4/5
 - 38s - loss: 0.4348 - acc: 0.8689 - val_loss: 0.3501 - val_acc: 0.9109
Epoch 5/5
 - 37s - loss: 0.3691 - acc: 0.9028 - val_loss: 0.2974 - val_acc: 0.9362
Test accuracy:0.701
current auc_score ------------------> 0.870
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8474 - acc: 0.6730 - val_loss: 1.3442 - val_acc: 0.4990
Epoch 2/5
 - 37s - loss: 0.6657 - acc: 0.7469 - val_loss: 0.9101 - val_acc: 0.5905
Epoch 3/5
 - 37s - loss: 0.5539 - acc: 0.8051 - val_loss: 0.5259 - val_acc: 0.8252
Epoch 4/5
 - 36s - loss: 0.4665 - acc: 0.8511 - val_loss: 0.5395 - val_acc: 0.8261
Epoch 5/5
 - 37s - loss: 0.3996 - acc: 0.8867 - val_loss: 0.3946 - val_acc: 0.8940
Test accuracy:0.728
current auc_score ------------------> 0.854
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.8687 - acc: 0.6576 - val_loss: 1.3677 - val_acc: 0.4880
Epoch 2/5
 - 37s - loss: 0.6647 - acc: 0.7459 - val_loss: 1.1651 - val_acc: 0.4748
Epoch 3/5
 - 37s - loss: 0.5400 - acc: 0.8125 - val_loss: 0.9965 - val_acc: 0.5311
Epoch 4/5
 - 37s - loss: 0.4599 - acc: 0.8545 - val_loss: 1.3907 - val_acc: 0.5255
Epoch 5/5
 - 37s - loss: 0.3973 - acc: 0.8896 - val_loss: 0.8506 - val_acc: 0.5998
Test accuracy:0.568
current auc_score ------------------> 0.629
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 46s - loss: 0.8803 - acc: 0.6426 - val_loss: 0.7683 - val_acc: 0.6500
Epoch 2/5
 - 37s - loss: 0.7035 - acc: 0.7246 - val_loss: 0.6706 - val_acc: 0.7529
Epoch 3/5
 - 38s - loss: 0.5772 - acc: 0.7921 - val_loss: 0.5455 - val_acc: 0.8217
Epoch 4/5
 - 38s - loss: 0.4832 - acc: 0.8445 - val_loss: 0.4561 - val_acc: 0.8699
Epoch 5/5
 - 37s - loss: 0.4044 - acc: 0.8850 - val_loss: 0.3939 - val_acc: 0.8996
Test accuracy:0.731
current auc_score ------------------> 0.866
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          95869       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 734,846
Trainable params: 731,214
Non-trainable params: 3,632
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.8883 - acc: 0.6446 - val_loss: 0.9225 - val_acc: 0.5904
Epoch 2/5
 - 40s - loss: 0.6854 - acc: 0.7327 - val_loss: 0.7273 - val_acc: 0.7203
Epoch 3/5
 - 41s - loss: 0.5714 - acc: 0.7950 - val_loss: 0.6961 - val_acc: 0.7590
Epoch 4/5
 - 40s - loss: 0.4733 - acc: 0.8490 - val_loss: 0.6241 - val_acc: 0.7923
Epoch 5/5
 - 41s - loss: 0.4051 - acc: 0.8854 - val_loss: 0.4447 - val_acc: 0.8673
Test accuracy:0.675
current auc_score ------------------> 0.791
accuracies:  [0.7010752688172043, 0.728225806451613, 0.5678763440860215, 0.7314516129032258, 0.6754032258064516]
aucs:  [0.8703427419354839, 0.853731825933634, 0.629160271418661, 0.8655000578101514, 0.7907812319343277]
['3-3-3-3', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 50s - loss: 0.9016 - acc: 0.6672 - val_loss: 1.3175 - val_acc: 0.5371
Epoch 2/5
 - 40s - loss: 0.7002 - acc: 0.7624 - val_loss: 0.8197 - val_acc: 0.7111
Epoch 3/5
 - 40s - loss: 0.5750 - acc: 0.8293 - val_loss: 0.6125 - val_acc: 0.8066
Epoch 4/5
 - 40s - loss: 0.4861 - acc: 0.8776 - val_loss: 0.5030 - val_acc: 0.8630
Epoch 5/5
 - 41s - loss: 0.4145 - acc: 0.9129 - val_loss: 0.4024 - val_acc: 0.9155
Test accuracy:0.660
current auc_score ------------------> 0.824
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.8854 - acc: 0.6778 - val_loss: 0.9423 - val_acc: 0.6222
Epoch 2/5
 - 38s - loss: 0.6675 - acc: 0.7801 - val_loss: 1.1548 - val_acc: 0.5812
Epoch 3/5
 - 38s - loss: 0.5470 - acc: 0.8445 - val_loss: 0.9316 - val_acc: 0.6274
Epoch 4/5
 - 37s - loss: 0.4667 - acc: 0.8869 - val_loss: 0.8007 - val_acc: 0.6844
Epoch 5/5
 - 37s - loss: 0.4032 - acc: 0.9182 - val_loss: 0.7397 - val_acc: 0.7436
Test accuracy:0.740
current auc_score ------------------> 0.797
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 48s - loss: 0.9295 - acc: 0.6519 - val_loss: 1.3818 - val_acc: 0.5513
Epoch 2/5
 - 38s - loss: 0.7005 - acc: 0.7615 - val_loss: 1.8018 - val_acc: 0.4713
Epoch 3/5
 - 38s - loss: 0.5591 - acc: 0.8406 - val_loss: 1.5828 - val_acc: 0.5153

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 39s - loss: 0.4860 - acc: 0.8782 - val_loss: 1.1216 - val_acc: 0.5036
Epoch 5/5
 - 39s - loss: 0.4497 - acc: 0.8943 - val_loss: 1.0041 - val_acc: 0.5323
Epoch 00005: early stopping
Test accuracy:0.570
current auc_score ------------------> 0.580
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.8928 - acc: 0.6815 - val_loss: 4.4206 - val_acc: 0.4965
Epoch 2/5
 - 37s - loss: 0.6892 - acc: 0.7718 - val_loss: 1.0104 - val_acc: 0.5880
Epoch 3/5
 - 37s - loss: 0.5644 - acc: 0.8396 - val_loss: 1.8060 - val_acc: 0.5009
Epoch 4/5
 - 37s - loss: 0.4850 - acc: 0.8791 - val_loss: 0.9132 - val_acc: 0.6253
Epoch 5/5
 - 37s - loss: 0.4141 - acc: 0.9129 - val_loss: 0.8771 - val_acc: 0.6145
Test accuracy:0.499
current auc_score ------------------> 0.597
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [3, 3, 3, 3]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 927)          206128      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1854)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          949760      merge_features[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_30[0][0]              
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_13[0][0]                 
==================================================================================================
Total params: 1,158,449
Trainable params: 1,153,649
Non-trainable params: 4,800
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 47s - loss: 0.9531 - acc: 0.6428 - val_loss: 4.2674 - val_acc: 0.4965
Epoch 2/5
 - 38s - loss: 0.7526 - acc: 0.7380 - val_loss: 1.8168 - val_acc: 0.4990
Epoch 3/5
 - 37s - loss: 0.6173 - acc: 0.8087 - val_loss: 1.7766 - val_acc: 0.4964
Epoch 4/5
 - 37s - loss: 0.5149 - acc: 0.8654 - val_loss: 0.8911 - val_acc: 0.5828
Epoch 5/5
 - 37s - loss: 0.4262 - acc: 0.9070 - val_loss: 0.9599 - val_acc: 0.5936
Test accuracy:0.600
current auc_score ------------------> 0.703
accuracies:  [0.660483870967742, 0.7401881720430108, 0.5698924731182796, 0.4985215053763441, 0.6004032258064517]
aucs:  [0.8244909454850271, 0.7973113943808533, 0.5798550771765522, 0.5967035929009133, 0.7033623106717538]
['4-4-4-4', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.8142 - acc: 0.6630 - val_loss: 0.7622 - val_acc: 0.6441
Epoch 2/5
 - 45s - loss: 0.6516 - acc: 0.7321 - val_loss: 0.6517 - val_acc: 0.7216
Epoch 3/5
 - 46s - loss: 0.5483 - acc: 0.7866 - val_loss: 0.5764 - val_acc: 0.7873
Epoch 4/5
 - 46s - loss: 0.4733 - acc: 0.8249 - val_loss: 0.4686 - val_acc: 0.8387
Epoch 5/5
 - 45s - loss: 0.4110 - acc: 0.8595 - val_loss: 0.4621 - val_acc: 0.8539
Test accuracy:0.672
current auc_score ------------------> 0.841
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 54s - loss: 0.8157 - acc: 0.6618 - val_loss: 1.9077 - val_acc: 0.5011
Epoch 2/5
 - 42s - loss: 0.6289 - acc: 0.7415 - val_loss: 1.0385 - val_acc: 0.5197
Epoch 3/5
 - 41s - loss: 0.5318 - acc: 0.7956 - val_loss: 1.0344 - val_acc: 0.4911
Epoch 4/5
 - 41s - loss: 0.4584 - acc: 0.8350 - val_loss: 0.8353 - val_acc: 0.5360
Epoch 5/5
 - 40s - loss: 0.4045 - acc: 0.8651 - val_loss: 1.0870 - val_acc: 0.5143
Test accuracy:0.510
current auc_score ------------------> 0.561
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 55s - loss: 0.8550 - acc: 0.6424 - val_loss: 1.0073 - val_acc: 0.5279
Epoch 2/5
 - 43s - loss: 0.6648 - acc: 0.7207 - val_loss: 2.1816 - val_acc: 0.4980
Epoch 3/5
 - 43s - loss: 0.5518 - acc: 0.7823 - val_loss: 2.1802 - val_acc: 0.4967

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 43s - loss: 0.4922 - acc: 0.8168 - val_loss: 1.9086 - val_acc: 0.4969
Epoch 5/5
 - 43s - loss: 0.4650 - acc: 0.8313 - val_loss: 1.2605 - val_acc: 0.5080

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 00005: early stopping
Test accuracy:0.499
current auc_score ------------------> 0.580
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 55s - loss: 0.8582 - acc: 0.6269 - val_loss: 1.3125 - val_acc: 0.5064
Epoch 2/5
 - 43s - loss: 0.6975 - acc: 0.6966 - val_loss: 0.8498 - val_acc: 0.5502
Epoch 3/5
 - 43s - loss: 0.5947 - acc: 0.7575 - val_loss: 0.7970 - val_acc: 0.5860
Epoch 4/5
 - 43s - loss: 0.5197 - acc: 0.8010 - val_loss: 0.8036 - val_acc: 0.5120
Epoch 5/5
 - 43s - loss: 0.4606 - acc: 0.8326 - val_loss: 0.8498 - val_acc: 0.5339

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.478
current auc_score ------------------> 0.469
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 423)          39758       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 846)          0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          433664      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 475,983
Trainable params: 472,869
Non-trainable params: 3,114
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 54s - loss: 0.8348 - acc: 0.6488 - val_loss: 1.2752 - val_acc: 0.5429
Epoch 2/5
 - 42s - loss: 0.6584 - acc: 0.7224 - val_loss: 1.0118 - val_acc: 0.5395
Epoch 3/5
 - 42s - loss: 0.5523 - acc: 0.7798 - val_loss: 1.2427 - val_acc: 0.4730
Epoch 4/5
 - 42s - loss: 0.4682 - acc: 0.8290 - val_loss: 1.2887 - val_acc: 0.4866

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 42s - loss: 0.4132 - acc: 0.8576 - val_loss: 0.9209 - val_acc: 0.5029
Epoch 00005: early stopping
Test accuracy:0.481
current auc_score ------------------> 0.461
accuracies:  [0.671505376344086, 0.5099462365591397, 0.49879032258064515, 0.4783602150537634, 0.4814516129032258]
aucs:  [0.841267632096196, 0.5611304775118511, 0.579899952306625, 0.4693078318302694, 0.46058579749103945]
['4-4-4-4', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 60s - loss: 0.8864 - acc: 0.6704 - val_loss: 0.8092 - val_acc: 0.6678
Epoch 2/5
 - 47s - loss: 0.6750 - acc: 0.7665 - val_loss: 0.8262 - val_acc: 0.7136
Epoch 3/5
 - 47s - loss: 0.5530 - acc: 0.8319 - val_loss: 0.5544 - val_acc: 0.8429
Epoch 4/5
 - 47s - loss: 0.4672 - acc: 0.8766 - val_loss: 0.4333 - val_acc: 0.8934
Epoch 5/5
 - 46s - loss: 0.4045 - acc: 0.9069 - val_loss: 0.4082 - val_acc: 0.9054
Test accuracy:0.652
current auc_score ------------------> 0.802
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 57s - loss: 0.8694 - acc: 0.6817 - val_loss: 1.1097 - val_acc: 0.5359
Epoch 2/5
 - 44s - loss: 0.6595 - acc: 0.7769 - val_loss: 0.7588 - val_acc: 0.7303
Epoch 3/5
 - 44s - loss: 0.5477 - acc: 0.8344 - val_loss: 0.5500 - val_acc: 0.8435
Epoch 4/5
 - 44s - loss: 0.4675 - acc: 0.8752 - val_loss: 0.4889 - val_acc: 0.8712
Epoch 5/5
 - 44s - loss: 0.4036 - acc: 0.9056 - val_loss: 0.4609 - val_acc: 0.8837
Test accuracy:0.685
current auc_score ------------------> 0.810
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.8735 - acc: 0.6785 - val_loss: 0.9817 - val_acc: 0.5841
Epoch 2/5
 - 45s - loss: 0.6832 - acc: 0.7651 - val_loss: 0.8280 - val_acc: 0.7068
Epoch 3/5
 - 45s - loss: 0.5640 - acc: 0.8254 - val_loss: 0.6280 - val_acc: 0.8117
Epoch 4/5
 - 46s - loss: 0.4852 - acc: 0.8663 - val_loss: 0.6189 - val_acc: 0.8205
Epoch 5/5
 - 45s - loss: 0.4203 - acc: 0.8991 - val_loss: 0.3886 - val_acc: 0.9130
Test accuracy:0.688
current auc_score ------------------> 0.849
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.8944 - acc: 0.6653 - val_loss: 0.8152 - val_acc: 0.6588
Epoch 2/5
 - 45s - loss: 0.7021 - acc: 0.7540 - val_loss: 0.6383 - val_acc: 0.7903
Epoch 3/5
 - 45s - loss: 0.5645 - acc: 0.8267 - val_loss: 0.5420 - val_acc: 0.8466
Epoch 4/5
 - 45s - loss: 0.4692 - acc: 0.8739 - val_loss: 0.4988 - val_acc: 0.8690
Epoch 5/5
 - 45s - loss: 0.3988 - acc: 0.9094 - val_loss: 0.3803 - val_acc: 0.9198
Test accuracy:0.645
current auc_score ------------------> 0.813
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 828)          139712      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1656)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          848384      merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 990,657
Trainable params: 985,785
Non-trainable params: 4,872
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 57s - loss: 0.8997 - acc: 0.6634 - val_loss: 0.9591 - val_acc: 0.5705
Epoch 2/5
 - 44s - loss: 0.7012 - acc: 0.7509 - val_loss: 0.7028 - val_acc: 0.7613
Epoch 3/5
 - 43s - loss: 0.5773 - acc: 0.8184 - val_loss: 0.6018 - val_acc: 0.8203
Epoch 4/5
 - 43s - loss: 0.4944 - acc: 0.8634 - val_loss: 0.5074 - val_acc: 0.8622
Epoch 5/5
 - 42s - loss: 0.4246 - acc: 0.8968 - val_loss: 0.4107 - val_acc: 0.9086
Test accuracy:0.674
current auc_score ------------------> 0.812
accuracies:  [0.652016129032258, 0.6853494623655914, 0.6881720430107527, 0.644758064516129, 0.6744623655913978]
aucs:  [0.8017387486992715, 0.8103888455312753, 0.8489663183605041, 0.8134037171927391, 0.8121084807492196]
['4-4-4-4', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.9861 - acc: 0.6685 - val_loss: 2.3001 - val_acc: 0.5355
Epoch 2/5
 - 45s - loss: 0.7593 - acc: 0.7687 - val_loss: 0.7477 - val_acc: 0.7540
Epoch 3/5
 - 46s - loss: 0.6330 - acc: 0.8354 - val_loss: 0.6934 - val_acc: 0.8249
Epoch 4/5
 - 45s - loss: 0.5486 - acc: 0.8776 - val_loss: 0.5628 - val_acc: 0.8820
Epoch 5/5
 - 45s - loss: 0.4776 - acc: 0.9137 - val_loss: 0.4510 - val_acc: 0.9239
Test accuracy:0.696
current auc_score ------------------> 0.845
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 57s - loss: 0.9670 - acc: 0.6719 - val_loss: 3.6907 - val_acc: 0.4989
Epoch 2/5
 - 46s - loss: 0.7524 - acc: 0.7674 - val_loss: 0.8228 - val_acc: 0.7459
Epoch 3/5
 - 46s - loss: 0.6237 - acc: 0.8392 - val_loss: 0.7716 - val_acc: 0.7815
Epoch 4/5
 - 46s - loss: 0.5441 - acc: 0.8798 - val_loss: 0.5291 - val_acc: 0.8902
Epoch 5/5
 - 45s - loss: 0.4655 - acc: 0.9186 - val_loss: 0.5055 - val_acc: 0.8982
Test accuracy:0.687
current auc_score ------------------> 0.827
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.9397 - acc: 0.6851 - val_loss: 1.1589 - val_acc: 0.5818
Epoch 2/5
 - 46s - loss: 0.7191 - acc: 0.7909 - val_loss: 0.8768 - val_acc: 0.7265
Epoch 3/5
 - 46s - loss: 0.5815 - acc: 0.8618 - val_loss: 0.5600 - val_acc: 0.8746
Epoch 4/5
 - 46s - loss: 0.4954 - acc: 0.9056 - val_loss: 0.5378 - val_acc: 0.8873
Epoch 5/5
 - 46s - loss: 0.4248 - acc: 0.9379 - val_loss: 0.4385 - val_acc: 0.9321
Test accuracy:0.663
current auc_score ------------------> 0.840
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 59s - loss: 0.9459 - acc: 0.6842 - val_loss: 1.3474 - val_acc: 0.6253
Epoch 2/5
 - 46s - loss: 0.7403 - acc: 0.7806 - val_loss: 1.0016 - val_acc: 0.5537
Epoch 3/5
 - 46s - loss: 0.6000 - acc: 0.8543 - val_loss: 1.4528 - val_acc: 0.5156
Epoch 4/5
 - 46s - loss: 0.5020 - acc: 0.9023 - val_loss: 0.5027 - val_acc: 0.9104
Epoch 5/5
 - 46s - loss: 0.4304 - acc: 0.9348 - val_loss: 0.4551 - val_acc: 0.9317
Test accuracy:0.772
current auc_score ------------------> 0.919
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [4, 4, 4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         301478      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_38[0][0]              
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_17[0][0]                 
==================================================================================================
Total params: 1,567,143
Trainable params: 1,560,513
Non-trainable params: 6,630
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 58s - loss: 0.9454 - acc: 0.6790 - val_loss: 1.5552 - val_acc: 0.5206
Epoch 2/5
 - 45s - loss: 0.7418 - acc: 0.7759 - val_loss: 1.0344 - val_acc: 0.5753
Epoch 3/5
 - 45s - loss: 0.6146 - acc: 0.8441 - val_loss: 1.3779 - val_acc: 0.5146
Epoch 4/5
 - 45s - loss: 0.5208 - acc: 0.8926 - val_loss: 1.2363 - val_acc: 0.5210

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 44s - loss: 0.4610 - acc: 0.9215 - val_loss: 1.2786 - val_acc: 0.5250
Test accuracy:0.542
current auc_score ------------------> 0.653
accuracies:  [0.6959677419354838, 0.6870967741935484, 0.6633064516129032, 0.7716397849462365, 0.5423387096774194]
aucs:  [0.8452451150422015, 0.8270138888888889, 0.8395938114232859, 0.9186839519019541, 0.65257692363279]
['6-6-6-6', '6', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 74s - loss: 0.8535 - acc: 0.6694 - val_loss: 1.9435 - val_acc: 0.5328
Epoch 2/5
 - 57s - loss: 0.6500 - acc: 0.7573 - val_loss: 1.1853 - val_acc: 0.5247
Epoch 3/5
 - 57s - loss: 0.5472 - acc: 0.8114 - val_loss: 1.5444 - val_acc: 0.5157
Epoch 4/5
 - 57s - loss: 0.4681 - acc: 0.8523 - val_loss: 0.7984 - val_acc: 0.6491
Epoch 5/5
 - 56s - loss: 0.4172 - acc: 0.8789 - val_loss: 1.0919 - val_acc: 0.5336
Test accuracy:0.539
current auc_score ------------------> 0.693
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 72s - loss: 0.8725 - acc: 0.6549 - val_loss: 0.9897 - val_acc: 0.5476
Epoch 2/5
 - 53s - loss: 0.7158 - acc: 0.7234 - val_loss: 1.0137 - val_acc: 0.5301
Epoch 3/5
 - 54s - loss: 0.6129 - acc: 0.7722 - val_loss: 1.1918 - val_acc: 0.5252

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 4/5
 - 53s - loss: 0.5412 - acc: 0.8147 - val_loss: 1.2624 - val_acc: 0.5060
Epoch 5/5
 - 55s - loss: 0.5184 - acc: 0.8267 - val_loss: 1.1829 - val_acc: 0.5064

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 00005: early stopping
Test accuracy:0.501
current auc_score ------------------> 0.594
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 74s - loss: 0.8779 - acc: 0.6560 - val_loss: 2.6467 - val_acc: 0.4971
Epoch 2/5
 - 56s - loss: 0.6952 - acc: 0.7322 - val_loss: 0.9899 - val_acc: 0.5753
Epoch 3/5
 - 55s - loss: 0.5819 - acc: 0.7932 - val_loss: 1.1079 - val_acc: 0.5786
Epoch 4/5
 - 56s - loss: 0.5037 - acc: 0.8364 - val_loss: 1.1560 - val_acc: 0.5536

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 56s - loss: 0.4611 - acc: 0.8603 - val_loss: 1.7566 - val_acc: 0.5174
Test accuracy:0.510
current auc_score ------------------> 0.691
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 75s - loss: 0.8854 - acc: 0.6473 - val_loss: 1.4140 - val_acc: 0.4977
Epoch 2/5
 - 56s - loss: 0.7264 - acc: 0.7099 - val_loss: 1.3836 - val_acc: 0.4995
Epoch 3/5
 - 56s - loss: 0.6221 - acc: 0.7635 - val_loss: 2.1655 - val_acc: 0.4960
Epoch 4/5
 - 56s - loss: 0.5355 - acc: 0.8133 - val_loss: 0.9331 - val_acc: 0.5275
Epoch 5/5
 - 56s - loss: 0.4690 - acc: 0.8495 - val_loss: 1.0332 - val_acc: 0.4966
Test accuracy:0.526
current auc_score ------------------> 0.478
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  6  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 621)          68629       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 1242)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          636416      merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 707,606
Trainable params: 702,906
Non-trainable params: 4,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 74s - loss: 0.8486 - acc: 0.6646 - val_loss: 2.4897 - val_acc: 0.4991
Epoch 2/5
 - 54s - loss: 0.6665 - acc: 0.7413 - val_loss: 1.4869 - val_acc: 0.5069
Epoch 3/5
 - 54s - loss: 0.5619 - acc: 0.8024 - val_loss: 0.9971 - val_acc: 0.5082
Epoch 4/5
 - 55s - loss: 0.4880 - acc: 0.8408 - val_loss: 1.1397 - val_acc: 0.5444
Epoch 5/5
 - 56s - loss: 0.4305 - acc: 0.8700 - val_loss: 0.9268 - val_acc: 0.5749
Test accuracy:0.532
current auc_score ------------------> 0.631
accuracies:  [0.5387096774193548, 0.5013440860215054, 0.5099462365591397, 0.5263440860215054, 0.5318548387096774]
aucs:  [0.6934136894438664, 0.5936971037114117, 0.6911831208810267, 0.477708369464678, 0.6309354405133543]
['6-6-6-6', '12', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 78s - loss: 0.9458 - acc: 0.6875 - val_loss: 2.9563 - val_acc: 0.4984
Epoch 2/5
 - 60s - loss: 0.7528 - acc: 0.7699 - val_loss: 1.2489 - val_acc: 0.5555
Epoch 3/5
 - 60s - loss: 0.6307 - acc: 0.8333 - val_loss: 2.9116 - val_acc: 0.5045
Epoch 4/5
 - 59s - loss: 0.5481 - acc: 0.8764 - val_loss: 2.3857 - val_acc: 0.5054

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 58s - loss: 0.4911 - acc: 0.9056 - val_loss: 2.1376 - val_acc: 0.5064
Test accuracy:0.500
current auc_score ------------------> 0.729
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 78s - loss: 0.9532 - acc: 0.6779 - val_loss: 4.9134 - val_acc: 0.4965
Epoch 2/5
 - 59s - loss: 0.7630 - acc: 0.7666 - val_loss: 0.8375 - val_acc: 0.7287
Epoch 3/5
 - 60s - loss: 0.6367 - acc: 0.8321 - val_loss: 0.6536 - val_acc: 0.8340
Epoch 4/5
 - 59s - loss: 0.5521 - acc: 0.8759 - val_loss: 0.5452 - val_acc: 0.8838
Epoch 5/5
 - 59s - loss: 0.4805 - acc: 0.9119 - val_loss: 0.4594 - val_acc: 0.9242
Test accuracy:0.708
current auc_score ------------------> 0.843
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 75s - loss: 0.9454 - acc: 0.6867 - val_loss: 1.3940 - val_acc: 0.5164
Epoch 2/5
 - 57s - loss: 0.7375 - acc: 0.7849 - val_loss: 1.6409 - val_acc: 0.4962
Epoch 3/5
 - 56s - loss: 0.6259 - acc: 0.8393 - val_loss: 1.0863 - val_acc: 0.5193
Epoch 4/5
 - 56s - loss: 0.5444 - acc: 0.8803 - val_loss: 1.9362 - val_acc: 0.4965
Epoch 5/5
 - 57s - loss: 0.4781 - acc: 0.9125 - val_loss: 1.0730 - val_acc: 0.5518
Test accuracy:0.530
current auc_score ------------------> 0.608
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 77s - loss: 0.9370 - acc: 0.6910 - val_loss: 3.0286 - val_acc: 0.5035
Epoch 2/5
 - 58s - loss: 0.7264 - acc: 0.7873 - val_loss: 2.3869 - val_acc: 0.5034
Epoch 3/5
 - 56s - loss: 0.6101 - acc: 0.8454 - val_loss: 1.0984 - val_acc: 0.5567
Epoch 4/5
 - 57s - loss: 0.5200 - acc: 0.8896 - val_loss: 2.5786 - val_acc: 0.5035
Epoch 5/5
 - 58s - loss: 0.4480 - acc: 0.9256 - val_loss: 1.6765 - val_acc: 0.5080

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Test accuracy:0.502
current auc_score ------------------> 0.770
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1233)         245342      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 2466)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1263104     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 1,511,007
Trainable params: 1,503,069
Non-trainable params: 7,938
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 77s - loss: 0.9875 - acc: 0.6667 - val_loss: 1.8797 - val_acc: 0.4847
Epoch 2/5
 - 59s - loss: 0.7790 - acc: 0.7580 - val_loss: 0.8309 - val_acc: 0.7332
Epoch 3/5
 - 59s - loss: 0.6500 - acc: 0.8239 - val_loss: 0.7038 - val_acc: 0.8094
Epoch 4/5
 - 58s - loss: 0.5556 - acc: 0.8739 - val_loss: 0.6449 - val_acc: 0.8268
Epoch 5/5
 - 57s - loss: 0.4808 - acc: 0.9110 - val_loss: 0.5014 - val_acc: 0.8973
Test accuracy:0.609
current auc_score ------------------> 0.821
accuracies:  [0.5001344086021505, 0.7083333333333334, 0.5297043010752688, 0.5024193548387097, 0.6094086021505376]
aucs:  [0.7294329908081859, 0.843159975141635, 0.6076948563417736, 0.7696238004393571, 0.8208231804254827]
['6-6-6-6', '18', '4', '16', '0.2', '0.0002', '5']
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 79s - loss: 1.0724 - acc: 0.6877 - val_loss: 5.5127 - val_acc: 0.4964
Epoch 2/5
 - 60s - loss: 0.8620 - acc: 0.7843 - val_loss: 1.4124 - val_acc: 0.4706
Epoch 3/5
 - 60s - loss: 0.7403 - acc: 0.8468 - val_loss: 1.0957 - val_acc: 0.5695
Epoch 4/5
 - 60s - loss: 0.6527 - acc: 0.8905 - val_loss: 1.4926 - val_acc: 0.5196
Epoch 5/5
 - 60s - loss: 0.5731 - acc: 0.9270 - val_loss: 0.6194 - val_acc: 0.9071
Test accuracy:0.717
current auc_score ------------------> 0.816
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 81s - loss: 1.0608 - acc: 0.6917 - val_loss: 1.5510 - val_acc: 0.4977
Epoch 2/5
 - 60s - loss: 0.8792 - acc: 0.7742 - val_loss: 1.3589 - val_acc: 0.5307
Epoch 3/5
 - 61s - loss: 0.7598 - acc: 0.8333 - val_loss: 1.7962 - val_acc: 0.5065
Epoch 4/5
 - 60s - loss: 0.6329 - acc: 0.9010 - val_loss: 2.8630 - val_acc: 0.5035

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 5/5
 - 60s - loss: 0.5562 - acc: 0.9352 - val_loss: 1.8354 - val_acc: 0.5132
Test accuracy:0.507
current auc_score ------------------> 0.629
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 80s - loss: 1.0542 - acc: 0.7008 - val_loss: 1.9076 - val_acc: 0.5207
Epoch 2/5
 - 61s - loss: 0.8438 - acc: 0.7927 - val_loss: 1.0981 - val_acc: 0.6170
Epoch 3/5
 - 62s - loss: 0.7357 - acc: 0.8468 - val_loss: 1.0921 - val_acc: 0.5538
Epoch 4/5
 - 61s - loss: 0.6490 - acc: 0.8913 - val_loss: 1.1110 - val_acc: 0.6136
Epoch 5/5
 - 61s - loss: 0.5659 - acc: 0.9298 - val_loss: 0.9714 - val_acc: 0.6980
Test accuracy:0.703
current auc_score ------------------> 0.801
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 79s - loss: 1.0633 - acc: 0.6892 - val_loss: 2.8818 - val_acc: 0.5158
Epoch 2/5
 - 59s - loss: 0.8590 - acc: 0.7798 - val_loss: 1.2408 - val_acc: 0.5418
Epoch 3/5
 - 59s - loss: 0.7368 - acc: 0.8483 - val_loss: 2.1700 - val_acc: 0.5033
Epoch 4/5
 - 59s - loss: 0.6418 - acc: 0.8945 - val_loss: 1.2108 - val_acc: 0.5388
Epoch 5/5
 - 59s - loss: 0.5599 - acc: 0.9325 - val_loss: 1.3033 - val_acc: 0.5410
Test accuracy:0.478
current auc_score ------------------> 0.563
Epochs  5  batch_size:  64  lr:  0.0002  es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [6, 6, 6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  4  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 1836)         531310      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 3672)         0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          1880576     merge_features[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_54[0][0]              
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_25[0][0]                 
==================================================================================================
Total params: 2,414,447
Trainable params: 2,403,285
Non-trainable params: 11,162
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/5
 - 79s - loss: 1.0510 - acc: 0.6950 - val_loss: 2.0130 - val_acc: 0.5050
Epoch 2/5
 - 63s - loss: 0.8361 - acc: 0.7973 - val_loss: 1.4143 - val_acc: 0.4951
Epoch 3/5
 - 63s - loss: 0.7206 - acc: 0.8585 - val_loss: 2.3444 - val_acc: 0.4965
Epoch 4/5
 - 61s - loss: 0.6379 - acc: 0.8978 - val_loss: 1.3931 - val_acc: 0.4842
Epoch 5/5
 - 61s - loss: 0.5650 - acc: 0.9311 - val_loss: 1.1688 - val_acc: 0.5424
Test accuracy:0.518
current auc_score ------------------> 0.576
accuracies:  [0.7168010752688172, 0.5067204301075269, 0.7028225806451613, 0.47809139784946236, 0.5182795698924731]
aucs:  [0.8159200124291826, 0.6289103509076194, 0.801145869464678, 0.5634722222222223, 0.5762570817435542]
['0.879+/-0.007', '0.874+/-0.01', '0.887+/-0.012', '0.879+/-0.021', '0.88+/-0.019', '0.891+/-0.017', '0.879+/-0.021', '0.892+/-0.017', '0.886+/-0.019', '0.88+/-0.017', '0.887+/-0.014', '0.861+/-0.074', '0.897+/-0.014', '0.891+/-0.022', '0.889+/-0.018', '0.864+/-0.037', '0.882+/-0.007', '0.879+/-0.02', '0.889+/-0.019', '0.861+/-0.072', '0.882+/-0.019', '0.848+/-0.063', '0.792+/-0.12', '0.875+/-0.014', '0.868+/-0.03', '0.879+/-0.042', '0.87+/-0.024', '0.803+/-0.09', '0.87+/-0.009', '0.867+/-0.026', '0.751+/-0.103', '0.856+/-0.076', '0.743+/-0.139', '0.718+/-0.151', '0.711+/-0.09', '0.772+/-0.14', '0.762+/-0.107', '0.827+/-0.035', '0.822+/-0.01', '0.754+/-0.116', '0.802+/-0.091', '0.7+/-0.1', '0.582+/-0.138', '0.817+/-0.016', '0.817+/-0.088', '0.617+/-0.079', '0.754+/-0.083', '0.677+/-0.11']
(['2', '6', '1', '16', '0.2', '0.0002', '5'], '0.879+/-0.007')
(['2', '12', '1', '16', '0.2', '0.0002', '5'], '0.874+/-0.01')
(['2', '18', '1', '16', '0.2', '0.0002', '5'], '0.887+/-0.012')
(['3', '6', '1', '16', '0.2', '0.0002', '5'], '0.879+/-0.021')
(['3', '12', '1', '16', '0.2', '0.0002', '5'], '0.88+/-0.019')
(['3', '18', '1', '16', '0.2', '0.0002', '5'], '0.891+/-0.017')
(['4', '6', '1', '16', '0.2', '0.0002', '5'], '0.879+/-0.021')
(['4', '12', '1', '16', '0.2', '0.0002', '5'], '0.892+/-0.017')
(['4', '18', '1', '16', '0.2', '0.0002', '5'], '0.886+/-0.019')
(['6', '6', '1', '16', '0.2', '0.0002', '5'], '0.88+/-0.017')
(['6', '12', '1', '16', '0.2', '0.0002', '5'], '0.887+/-0.014')
(['6', '18', '1', '16', '0.2', '0.0002', '5'], '0.861+/-0.074')
(['2-2', '6', '2', '16', '0.2', '0.0002', '5'], '0.897+/-0.014')
(['2-2', '12', '2', '16', '0.2', '0.0002', '5'], '0.891+/-0.022')
(['2-2', '18', '2', '16', '0.2', '0.0002', '5'], '0.889+/-0.018')
(['3-3', '6', '2', '16', '0.2', '0.0002', '5'], '0.864+/-0.037')
(['3-3', '12', '2', '16', '0.2', '0.0002', '5'], '0.882+/-0.007')
(['3-3', '18', '2', '16', '0.2', '0.0002', '5'], '0.879+/-0.02')
(['4-4', '6', '2', '16', '0.2', '0.0002', '5'], '0.889+/-0.019')
(['4-4', '12', '2', '16', '0.2', '0.0002', '5'], '0.861+/-0.072')
(['4-4', '18', '2', '16', '0.2', '0.0002', '5'], '0.882+/-0.019')
(['6-6', '6', '2', '16', '0.2', '0.0002', '5'], '0.848+/-0.063')
(['6-6', '12', '2', '16', '0.2', '0.0002', '5'], '0.792+/-0.12')
(['6-6', '18', '2', '16', '0.2', '0.0002', '5'], '0.875+/-0.014')
(['2-2-2', '6', '3', '16', '0.2', '0.0002', '5'], '0.868+/-0.03')
(['2-2-2', '12', '3', '16', '0.2', '0.0002', '5'], '0.879+/-0.042')
(['2-2-2', '18', '3', '16', '0.2', '0.0002', '5'], '0.87+/-0.024')
(['3-3-3', '6', '3', '16', '0.2', '0.0002', '5'], '0.803+/-0.09')
(['3-3-3', '12', '3', '16', '0.2', '0.0002', '5'], '0.87+/-0.009')
(['3-3-3', '18', '3', '16', '0.2', '0.0002', '5'], '0.867+/-0.026')
(['4-4-4', '6', '3', '16', '0.2', '0.0002', '5'], '0.751+/-0.103')
(['4-4-4', '12', '3', '16', '0.2', '0.0002', '5'], '0.856+/-0.076')
(['4-4-4', '18', '3', '16', '0.2', '0.0002', '5'], '0.743+/-0.139')
(['6-6-6', '6', '3', '16', '0.2', '0.0002', '5'], '0.718+/-0.151')
(['6-6-6', '12', '3', '16', '0.2', '0.0002', '5'], '0.711+/-0.09')
(['6-6-6', '18', '3', '16', '0.2', '0.0002', '5'], '0.772+/-0.14')
(['2-2-2-2', '6', '4', '16', '0.2', '0.0002', '5'], '0.762+/-0.107')
(['2-2-2-2', '12', '4', '16', '0.2', '0.0002', '5'], '0.827+/-0.035')
(['2-2-2-2', '18', '4', '16', '0.2', '0.0002', '5'], '0.822+/-0.01')
(['3-3-3-3', '6', '4', '16', '0.2', '0.0002', '5'], '0.754+/-0.116')
(['3-3-3-3', '12', '4', '16', '0.2', '0.0002', '5'], '0.802+/-0.091')
(['3-3-3-3', '18', '4', '16', '0.2', '0.0002', '5'], '0.7+/-0.1')
(['4-4-4-4', '6', '4', '16', '0.2', '0.0002', '5'], '0.582+/-0.138')
(['4-4-4-4', '12', '4', '16', '0.2', '0.0002', '5'], '0.817+/-0.016')
(['4-4-4-4', '18', '4', '16', '0.2', '0.0002', '5'], '0.817+/-0.088')
(['6-6-6-6', '6', '4', '16', '0.2', '0.0002', '5'], '0.617+/-0.079')
(['6-6-6-6', '12', '4', '16', '0.2', '0.0002', '5'], '0.754+/-0.083')
(['6-6-6-6', '18', '4', '16', '0.2', '0.0002', '5'], '0.677+/-0.11')
