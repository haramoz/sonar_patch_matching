python hello-world.py
python hyperas_simple.py
python hyperas_contrastive_loss.py
python densenet_siamese_best_run.py
python hyperas_densenet.py
python hyperas_densenet_siamese.py
python densenet_simple.py
python keras_densenet_siamese.py
python keras_densenet_simple.py
>>> Imports:
#coding=utf-8

try:
    import numpy as np
except:
    pass

try:
    import random
except:
    pass

try:
    import h5py
except:
    pass

try:
    import tensorflow as tf
except:
    pass

try:
    import matplotlib.pyplot as plt
except:
    pass

try:
    import keras.backend as K
except:
    pass

try:
    from keras.initializers import RandomNormal
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D
except:
    pass

try:
    from keras.layers import Input, concatenate, Concatenate
except:
    pass

try:
    from keras.layers import normalization, BatchNormalization, Lambda
except:
    pass

try:
    from keras.layers import Flatten, Conv2D, MaxPooling2D
except:
    pass

try:
    from keras.regularizers import l2
except:
    pass

try:
    from keras.optimizers import RMSprop, Adam
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.models import Model, Sequential
except:
    pass

try:
    from keras.models import model_from_json
except:
    pass

try:
    from keras.models import load_model
except:
    pass

try:
    import keras.initializers
except:
    pass

try:
    from keras.losses import binary_crossentropy
except:
    pass

try:
    from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
except:
    pass

try:
    from sklearn.metrics import accuracy_score
except:
    pass

try:
    from sklearn.metrics import roc_auc_score
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from keras_contrib.applications import DenseNet
except:
    pass

try:
    import pickle
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'depth': hp.choice('depth', [7,16,25,34]),
        'nb_dense_block': hp.choice('nb_dense_block', [2,3,4]),
        'growth_rate': hp.choice('growth_rate', [6,10,14,18]),
    }

>>> Functions
  1: def process_data():
  2:     random_seed = 7
  3: 
  4:     f = h5py.File('matchedImagesSplitClasses-2017-02-24-17-39-44-96-96-split-val0.15-tr0.7-tst0.15.hdf5','r')
  5:     X_train = f['X_train'].value
  6:     y_train = f['y_train'].value
  7:     X_test = f['X_val'].value
  8:     y_test = f['y_val'].value
  9:     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_seed)
 10:  
 11:     return X_train,y_train,X_val,y_val,X_test,y_test
 12: 
 13: 
>>> Data
 1: 
 2: X_train,y_train,X_val,y_val,X_test,y_test = process_data()
 3: 
 4: 
 5: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     epochs = 50
   4:     es_patience = 7
   5:     lr_patience = 4
   6:     dropout = None
   7:     depth = space['depth']
   8:     nb_dense_block = space['nb_dense_block']
   9:     nb_filter = 16
  10:     growth_rate = space['growth_rate']
  11:     bn = True
  12:     reduction_ = 0.5
  13:     bs = 32
  14:     lr = 2E-4 #########################################################CHange file name##########################################
  15:     weight_file = 'keras_densenet_simple_wt_30Sept_0900.h5'
  16:     nb_classes = 1
  17:     img_dim = (2,96,96) 
  18:     n_channels = 2 
  19: 
  20:     
  21:     model  = DenseNet(depth=depth, nb_dense_block=nb_dense_block,
  22:                  growth_rate=growth_rate, nb_filter=nb_filter,
  23:                  dropout_rate=dropout,activation='sigmoid',
  24:                  input_shape=img_dim,include_top=True,
  25:                  bottleneck=bn,reduction=reduction_,
  26:                  classes=nb_classes,pooling='avg',
  27:                  weights=None)
  28:     
  29: 
  30:     model.summary()
  31:     opt = Adam(lr=lr)
  32:     model.compile(loss=binary_crossentropy, optimizer=opt, metrics=['accuracy'])
  33: 
  34:     es = EarlyStopping(monitor='val_loss', patience=es_patience,verbose=1)
  35:     #es = EarlyStopping(monitor='val_acc', patience=es_patience,verbose=1,restore_best_weights=True)
  36:     checkpointer = ModelCheckpoint(filepath=weight_file,verbose=1, save_best_only=True)
  37: 
  38:     lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), cooldown=0, patience=lr_patience, min_lr=0.5e-6,verbose=1)
  39: 
  40:     model.fit(X_train,y_train,
  41:           batch_size=bs,
  42:           epochs=epochs,
  43:           callbacks=[es,lr_reducer],
  44:           validation_data=(X_val,y_val),
  45:           verbose=2)
  46:     
  47:     score, acc = model.evaluate(X_test, y_test)
  48:     print('current Test accuracy:', acc)
  49:     pred = model.predict(X_test)
  50:     auc_score = roc_auc_score(y_test,pred)
  51:     print("current auc_score ------------------> ",auc_score)
  52: 
  53:     #model = load_model(weight_file) #This is the best model
  54:     #score, acc = model.evaluate(X_test, y_test)
  55:     #print('Best saved model Test accuracy:', acc)
  56:     #pred = model.predict(X_test)
  57:     #auc_score = roc_auc_score(y_test,pred)
  58:     #print("best saved model auc_score ------------------> ",auc_score)
  59: 
  60:     
  61:     return {'loss': -auc_score, 'status': STATUS_OK, 'model': model}  
  62: 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_1 (Activation)    (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_1 (Average (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_2 (Activation)    (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_2 (Average (None, 4, 24, 24)         0         
_________________________________________________________________
tr_2_bn (BatchNormalization) (None, 4, 24, 24)         16        
_________________________________________________________________
activation_3 (Activation)    (None, 4, 24, 24)         0         
_________________________________________________________________
tr_2_conv2D (Conv2D)         (None, 2, 24, 24)         8         
_________________________________________________________________
average_pooling2d_3 (Average (None, 2, 12, 12)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 2, 12, 12)         8         
_________________________________________________________________
activation_4 (Activation)    (None, 2, 12, 12)         0         
_________________________________________________________________
global_average_pooling2d_1 ( (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 3         
=================================================================
Total params: 579
Trainable params: 519
Non-trainable params: 60
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 11s - loss: 0.7080 - acc: 0.5086 - val_loss: 0.6772 - val_acc: 0.5705
Epoch 2/50
 - 8s - loss: 0.6684 - acc: 0.6223 - val_loss: 0.6611 - val_acc: 0.6693
Epoch 3/50
 - 8s - loss: 0.6566 - acc: 0.6708 - val_loss: 0.6502 - val_acc: 0.6827
Epoch 4/50
 - 8s - loss: 0.6482 - acc: 0.6803 - val_loss: 0.6425 - val_acc: 0.6857
Epoch 5/50
 - 8s - loss: 0.6404 - acc: 0.6898 - val_loss: 0.6351 - val_acc: 0.6940
Epoch 6/50
 - 8s - loss: 0.6330 - acc: 0.6934 - val_loss: 0.6284 - val_acc: 0.7065
Epoch 7/50
 - 8s - loss: 0.6262 - acc: 0.7015 - val_loss: 0.6207 - val_acc: 0.7111
Epoch 8/50
 - 8s - loss: 0.6179 - acc: 0.7102 - val_loss: 0.6135 - val_acc: 0.7185
Epoch 9/50
 - 8s - loss: 0.6102 - acc: 0.7157 - val_loss: 0.6054 - val_acc: 0.7260
Epoch 10/50
 - 8s - loss: 0.6022 - acc: 0.7229 - val_loss: 0.6080 - val_acc: 0.7027
Epoch 11/50
 - 8s - loss: 0.5945 - acc: 0.7321 - val_loss: 0.5895 - val_acc: 0.7411
Epoch 12/50
 - 8s - loss: 0.5881 - acc: 0.7309 - val_loss: 0.5839 - val_acc: 0.7344
Epoch 13/50
 - 8s - loss: 0.5824 - acc: 0.7362 - val_loss: 0.5798 - val_acc: 0.7415
Epoch 14/50
 - 8s - loss: 0.5761 - acc: 0.7384 - val_loss: 0.5745 - val_acc: 0.7332
Epoch 15/50
 - 8s - loss: 0.5711 - acc: 0.7407 - val_loss: 0.5753 - val_acc: 0.7257
Epoch 16/50
 - 8s - loss: 0.5664 - acc: 0.7405 - val_loss: 0.5661 - val_acc: 0.7364
Epoch 17/50
 - 8s - loss: 0.5612 - acc: 0.7454 - val_loss: 0.5722 - val_acc: 0.7196
Epoch 18/50
 - 8s - loss: 0.5571 - acc: 0.7466 - val_loss: 0.5544 - val_acc: 0.7469
Epoch 19/50
 - 8s - loss: 0.5537 - acc: 0.7488 - val_loss: 0.5700 - val_acc: 0.7194
Epoch 20/50
 - 8s - loss: 0.5492 - acc: 0.7498 - val_loss: 0.5483 - val_acc: 0.7489
Epoch 21/50
 - 8s - loss: 0.5463 - acc: 0.7490 - val_loss: 0.5569 - val_acc: 0.7223
Epoch 22/50
 - 8s - loss: 0.5439 - acc: 0.7514 - val_loss: 0.5460 - val_acc: 0.7395
Epoch 23/50
 - 8s - loss: 0.5399 - acc: 0.7541 - val_loss: 0.5395 - val_acc: 0.7504
Epoch 24/50
 - 8s - loss: 0.5362 - acc: 0.7551 - val_loss: 0.5597 - val_acc: 0.7238
Epoch 25/50
 - 8s - loss: 0.5345 - acc: 0.7551 - val_loss: 0.5353 - val_acc: 0.7482
Epoch 26/50
 - 8s - loss: 0.5328 - acc: 0.7542 - val_loss: 0.5439 - val_acc: 0.7339
Epoch 27/50
 - 8s - loss: 0.5309 - acc: 0.7550 - val_loss: 0.5620 - val_acc: 0.7196
Epoch 28/50
 - 8s - loss: 0.5279 - acc: 0.7574 - val_loss: 0.5325 - val_acc: 0.7554
Epoch 29/50
 - 8s - loss: 0.5253 - acc: 0.7561 - val_loss: 0.5413 - val_acc: 0.7396
Epoch 30/50
 - 8s - loss: 0.5238 - acc: 0.7601 - val_loss: 0.5275 - val_acc: 0.7553
Epoch 31/50
 - 8s - loss: 0.5217 - acc: 0.7579 - val_loss: 0.5273 - val_acc: 0.7556
Epoch 32/50
 - 8s - loss: 0.5209 - acc: 0.7608 - val_loss: 0.5326 - val_acc: 0.7446
Epoch 33/50
 - 8s - loss: 0.5191 - acc: 0.7593 - val_loss: 0.5484 - val_acc: 0.7390
Epoch 34/50
 - 8s - loss: 0.5173 - acc: 0.7614 - val_loss: 0.5165 - val_acc: 0.7604
Epoch 35/50
 - 8s - loss: 0.5160 - acc: 0.7608 - val_loss: 0.5284 - val_acc: 0.7430
Epoch 36/50
 - 8s - loss: 0.5140 - acc: 0.7611 - val_loss: 0.5228 - val_acc: 0.7535
Epoch 37/50
 - 8s - loss: 0.5137 - acc: 0.7626 - val_loss: 0.5180 - val_acc: 0.7570
Epoch 38/50
 - 8s - loss: 0.5125 - acc: 0.7625 - val_loss: 0.5250 - val_acc: 0.7459

Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 39/50
 - 7s - loss: 0.5092 - acc: 0.7660 - val_loss: 0.5068 - val_acc: 0.7678
Epoch 40/50
 - 7s - loss: 0.5071 - acc: 0.7656 - val_loss: 0.5106 - val_acc: 0.7643
Epoch 41/50
 - 7s - loss: 0.5086 - acc: 0.7644 - val_loss: 0.5065 - val_acc: 0.7673
Epoch 42/50
 - 7s - loss: 0.5078 - acc: 0.7644 - val_loss: 0.5133 - val_acc: 0.7584
Epoch 43/50
 - 7s - loss: 0.5082 - acc: 0.7659 - val_loss: 0.5060 - val_acc: 0.7677
Epoch 44/50
 - 8s - loss: 0.5070 - acc: 0.7660 - val_loss: 0.5133 - val_acc: 0.7587
Epoch 45/50
 - 7s - loss: 0.5053 - acc: 0.7664 - val_loss: 0.5058 - val_acc: 0.7693
Epoch 46/50
 - 7s - loss: 0.5063 - acc: 0.7666 - val_loss: 0.5158 - val_acc: 0.7575
Epoch 47/50
 - 7s - loss: 0.5044 - acc: 0.7681 - val_loss: 0.5048 - val_acc: 0.7661
Epoch 48/50
 - 7s - loss: 0.5042 - acc: 0.7668 - val_loss: 0.5063 - val_acc: 0.7711
Epoch 49/50
 - 7s - loss: 0.5037 - acc: 0.7679 - val_loss: 0.5055 - val_acc: 0.7682
Epoch 50/50
 - 7s - loss: 0.5050 - acc: 0.7671 - val_loss: 0.5164 - val_acc: 0.7534

  32/7440 [..............................] - ETA: 0s
 608/7440 [=>............................] - ETA: 0s
1152/7440 [===>..........................] - ETA: 0s
1728/7440 [=====>........................] - ETA: 0s
2304/7440 [========>.....................] - ETA: 0s
2880/7440 [==========>...................] - ETA: 0s
3456/7440 [============>.................] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5728/7440 [======================>.......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 92us/step
current Test accuracy: 0.7788978494623656
current auc_score ------------------>  0.8662155306971904
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_2[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_5[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_7[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 96, 96)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 96, 96)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 96, 96)   968         activation_9[0][0]               
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 22, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 48, 48)   88          average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 22, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   1232        activation_10[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 36, 48, 48)   0           average_pooling2d_4[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 36, 48, 48)   144         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 36, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   2016        activation_12[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 50, 48, 48)   0           concatenate_3[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 50, 48, 48)   200         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 50, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 50)           0           activation_14[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            51          global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 37,043
Trainable params: 36,199
Non-trainable params: 844
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 27s - loss: 0.5690 - acc: 0.7531 - val_loss: 0.5387 - val_acc: 0.7644
Epoch 2/50
 - 25s - loss: 0.5075 - acc: 0.7773 - val_loss: 0.5148 - val_acc: 0.7613
Epoch 3/50
 - 25s - loss: 0.4822 - acc: 0.7860 - val_loss: 0.4931 - val_acc: 0.7923
Epoch 4/50
 - 25s - loss: 0.4658 - acc: 0.7974 - val_loss: 0.5340 - val_acc: 0.7348
Epoch 5/50
 - 25s - loss: 0.4526 - acc: 0.8018 - val_loss: 0.4462 - val_acc: 0.8036
Epoch 6/50
 - 25s - loss: 0.4418 - acc: 0.8079 - val_loss: 0.5187 - val_acc: 0.7973
Epoch 7/50
 - 25s - loss: 0.4347 - acc: 0.8129 - val_loss: 0.4810 - val_acc: 0.7923
Epoch 8/50
 - 25s - loss: 0.4233 - acc: 0.8197 - val_loss: 0.4331 - val_acc: 0.8199
Epoch 9/50
 - 25s - loss: 0.4155 - acc: 0.8248 - val_loss: 0.4232 - val_acc: 0.8121
Epoch 10/50
 - 25s - loss: 0.4096 - acc: 0.8281 - val_loss: 0.4468 - val_acc: 0.8107
Epoch 11/50
 - 25s - loss: 0.4043 - acc: 0.8316 - val_loss: 0.3921 - val_acc: 0.8416
Epoch 12/50
 - 25s - loss: 0.3964 - acc: 0.8356 - val_loss: 0.4288 - val_acc: 0.8209
Epoch 13/50
 - 25s - loss: 0.3884 - acc: 0.8414 - val_loss: 0.3897 - val_acc: 0.8399
Epoch 14/50
 - 25s - loss: 0.3830 - acc: 0.8437 - val_loss: 0.3856 - val_acc: 0.8441
Epoch 15/50
 - 25s - loss: 0.3779 - acc: 0.8459 - val_loss: 0.3687 - val_acc: 0.8498
Epoch 16/50
 - 25s - loss: 0.3705 - acc: 0.8490 - val_loss: 0.4091 - val_acc: 0.8332
Epoch 17/50
 - 25s - loss: 0.3665 - acc: 0.8518 - val_loss: 0.3797 - val_acc: 0.8453
Epoch 18/50
 - 25s - loss: 0.3595 - acc: 0.8561 - val_loss: 0.3947 - val_acc: 0.8317
Epoch 19/50
 - 25s - loss: 0.3566 - acc: 0.8575 - val_loss: 0.3540 - val_acc: 0.8594
Epoch 20/50
 - 25s - loss: 0.3496 - acc: 0.8605 - val_loss: 0.4853 - val_acc: 0.8064
Epoch 21/50
 - 25s - loss: 0.3450 - acc: 0.8615 - val_loss: 0.4364 - val_acc: 0.8062
Epoch 22/50
 - 25s - loss: 0.3413 - acc: 0.8638 - val_loss: 0.3865 - val_acc: 0.8495
Epoch 23/50
 - 25s - loss: 0.3378 - acc: 0.8674 - val_loss: 0.4048 - val_acc: 0.8372

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 24/50
 - 25s - loss: 0.3198 - acc: 0.8775 - val_loss: 0.3298 - val_acc: 0.8754
Epoch 25/50
 - 25s - loss: 0.3158 - acc: 0.8795 - val_loss: 0.3351 - val_acc: 0.8691
Epoch 26/50
 - 25s - loss: 0.3136 - acc: 0.8815 - val_loss: 0.3404 - val_acc: 0.8671
Epoch 27/50
 - 25s - loss: 0.3113 - acc: 0.8821 - val_loss: 0.3251 - val_acc: 0.8790
Epoch 28/50
 - 25s - loss: 0.3100 - acc: 0.8827 - val_loss: 0.3198 - val_acc: 0.8780
Epoch 29/50
 - 25s - loss: 0.3056 - acc: 0.8855 - val_loss: 0.3206 - val_acc: 0.8785
Epoch 30/50
 - 25s - loss: 0.3058 - acc: 0.8849 - val_loss: 0.3170 - val_acc: 0.8799
Epoch 31/50
 - 25s - loss: 0.3005 - acc: 0.8890 - val_loss: 0.3231 - val_acc: 0.8756
Epoch 32/50
 - 25s - loss: 0.3017 - acc: 0.8866 - val_loss: 0.3175 - val_acc: 0.8823
Epoch 33/50
 - 25s - loss: 0.2975 - acc: 0.8902 - val_loss: 0.3336 - val_acc: 0.8650
Epoch 34/50
 - 25s - loss: 0.2986 - acc: 0.8873 - val_loss: 0.3242 - val_acc: 0.8727

Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 35/50
 - 25s - loss: 0.2923 - acc: 0.8919 - val_loss: 0.3121 - val_acc: 0.8813
Epoch 36/50
 - 25s - loss: 0.2880 - acc: 0.8956 - val_loss: 0.3137 - val_acc: 0.8809
Epoch 37/50
 - 25s - loss: 0.2903 - acc: 0.8926 - val_loss: 0.3091 - val_acc: 0.8823
Epoch 38/50
 - 25s - loss: 0.2901 - acc: 0.8945 - val_loss: 0.3081 - val_acc: 0.8857
Epoch 39/50
 - 25s - loss: 0.2889 - acc: 0.8941 - val_loss: 0.3062 - val_acc: 0.8839
Epoch 40/50
 - 25s - loss: 0.2887 - acc: 0.8945 - val_loss: 0.3084 - val_acc: 0.8850
Epoch 41/50
 - 25s - loss: 0.2894 - acc: 0.8939 - val_loss: 0.3067 - val_acc: 0.8864
Epoch 42/50
 - 25s - loss: 0.2857 - acc: 0.8948 - val_loss: 0.3076 - val_acc: 0.8834
Epoch 43/50
 - 25s - loss: 0.2856 - acc: 0.8946 - val_loss: 0.3045 - val_acc: 0.8865
Epoch 44/50
 - 25s - loss: 0.2834 - acc: 0.8978 - val_loss: 0.3045 - val_acc: 0.8853
Epoch 45/50
 - 25s - loss: 0.2857 - acc: 0.8959 - val_loss: 0.3032 - val_acc: 0.8869
Epoch 46/50
 - 25s - loss: 0.2842 - acc: 0.8963 - val_loss: 0.3077 - val_acc: 0.8843
Epoch 47/50
 - 25s - loss: 0.2846 - acc: 0.8970 - val_loss: 0.3038 - val_acc: 0.8868
Epoch 48/50
 - 25s - loss: 0.2822 - acc: 0.8958 - val_loss: 0.3036 - val_acc: 0.8849
Epoch 49/50
 - 25s - loss: 0.2805 - acc: 0.8979 - val_loss: 0.3097 - val_acc: 0.8803

Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 50/50
 - 25s - loss: 0.2797 - acc: 0.8997 - val_loss: 0.3016 - val_acc: 0.8857

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 1s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 0s
3872/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5440/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 269us/step
current Test accuracy: 0.8033602150537634
current auc_score ------------------>  0.8917915365938258
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_3[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_15[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_16[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_17[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_18[0][0]              
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 44, 96, 96)   0           concatenate_5[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_19[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_20[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 58, 96, 96)   0           concatenate_6[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 58, 96, 96)   232         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 58, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 29, 96, 96)   1682        activation_21[0][0]              
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 29, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 29, 48, 48)   116         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 29, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   1624        activation_22[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_23[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 43, 48, 48)   0           average_pooling2d_5[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   2408        activation_24[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 57, 48, 48)   0           concatenate_8[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 57, 48, 48)   228         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 57, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3192        activation_26[0][0]              
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_27[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 71, 48, 48)   0           concatenate_9[0][0]              
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 71, 48, 48)   284         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 71, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 48, 48)   2485        activation_28[0][0]              
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 35, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 24, 24)   140         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 35, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 56, 24, 24)   1960        activation_29[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 56, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_30[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 49, 24, 24)   0           average_pooling2d_6[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 24, 24)   196         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 49, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 56, 24, 24)   2744        activation_31[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 56, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_32[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 63, 24, 24)   0           concatenate_11[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 63, 24, 24)   252         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 63, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 56, 24, 24)   3528        activation_33[0][0]              
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 56, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_34[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 77, 24, 24)   0           concatenate_12[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 77, 24, 24)   308         concatenate_13[0][0]             
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 77, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 77)           0           activation_35[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            78          global_average_pooling2d_3[0][0] 
==================================================================================================
Total params: 92,837
Trainable params: 90,685
Non-trainable params: 2,152
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 45s - loss: 0.5811 - acc: 0.7709 - val_loss: 0.5729 - val_acc: 0.7720
Epoch 2/50
 - 41s - loss: 0.4939 - acc: 0.8167 - val_loss: 0.5960 - val_acc: 0.7489
Epoch 3/50
 - 41s - loss: 0.4492 - acc: 0.8434 - val_loss: 0.4683 - val_acc: 0.8390
Epoch 4/50
 - 41s - loss: 0.4158 - acc: 0.8598 - val_loss: 0.5216 - val_acc: 0.8176
Epoch 5/50
 - 41s - loss: 0.3923 - acc: 0.8706 - val_loss: 0.4218 - val_acc: 0.8609
Epoch 6/50
 - 41s - loss: 0.3675 - acc: 0.8840 - val_loss: 0.3564 - val_acc: 0.8865
Epoch 7/50
 - 41s - loss: 0.3457 - acc: 0.8925 - val_loss: 0.5169 - val_acc: 0.8287
Epoch 8/50
 - 41s - loss: 0.3258 - acc: 0.9031 - val_loss: 0.3995 - val_acc: 0.8771
Epoch 9/50
 - 41s - loss: 0.3120 - acc: 0.9069 - val_loss: 0.3702 - val_acc: 0.8842
Epoch 10/50
 - 41s - loss: 0.2946 - acc: 0.9153 - val_loss: 0.3546 - val_acc: 0.8878
Epoch 11/50
 - 41s - loss: 0.2825 - acc: 0.9230 - val_loss: 0.3685 - val_acc: 0.8884
Epoch 12/50
 - 41s - loss: 0.2696 - acc: 0.9251 - val_loss: 0.4366 - val_acc: 0.8663
Epoch 13/50
 - 41s - loss: 0.2528 - acc: 0.9337 - val_loss: 0.3358 - val_acc: 0.9011
Epoch 14/50
 - 41s - loss: 0.2431 - acc: 0.9383 - val_loss: 0.3026 - val_acc: 0.9174
Epoch 15/50
 - 41s - loss: 0.2344 - acc: 0.9413 - val_loss: 0.2779 - val_acc: 0.9233
Epoch 16/50
 - 41s - loss: 0.2238 - acc: 0.9451 - val_loss: 0.3630 - val_acc: 0.8947
Epoch 17/50
 - 41s - loss: 0.2174 - acc: 0.9466 - val_loss: 0.2881 - val_acc: 0.9199
Epoch 18/50
 - 41s - loss: 0.2087 - acc: 0.9521 - val_loss: 0.4619 - val_acc: 0.8293
Epoch 19/50
 - 41s - loss: 0.1989 - acc: 0.9549 - val_loss: 0.3266 - val_acc: 0.9010

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 20/50
 - 41s - loss: 0.1680 - acc: 0.9710 - val_loss: 0.2575 - val_acc: 0.9305
Epoch 21/50
 - 41s - loss: 0.1597 - acc: 0.9736 - val_loss: 0.2385 - val_acc: 0.9379
Epoch 22/50
 - 41s - loss: 0.1568 - acc: 0.9740 - val_loss: 0.2434 - val_acc: 0.9383
Epoch 23/50
 - 41s - loss: 0.1544 - acc: 0.9754 - val_loss: 0.2399 - val_acc: 0.9385
Epoch 24/50
 - 41s - loss: 0.1489 - acc: 0.9769 - val_loss: 0.2340 - val_acc: 0.9424
Epoch 25/50
 - 41s - loss: 0.1457 - acc: 0.9784 - val_loss: 0.2372 - val_acc: 0.9390
Epoch 26/50
 - 41s - loss: 0.1431 - acc: 0.9798 - val_loss: 0.2583 - val_acc: 0.9337
Epoch 27/50
 - 41s - loss: 0.1410 - acc: 0.9803 - val_loss: 0.2270 - val_acc: 0.9433
Epoch 28/50
 - 41s - loss: 0.1380 - acc: 0.9807 - val_loss: 0.2863 - val_acc: 0.9206
Epoch 29/50
 - 41s - loss: 0.1349 - acc: 0.9820 - val_loss: 0.2315 - val_acc: 0.9433
Epoch 30/50
 - 41s - loss: 0.1318 - acc: 0.9832 - val_loss: 0.3507 - val_acc: 0.9060
Epoch 31/50
 - 41s - loss: 0.1312 - acc: 0.9839 - val_loss: 0.2500 - val_acc: 0.9335

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 32/50
 - 41s - loss: 0.1210 - acc: 0.9883 - val_loss: 0.2200 - val_acc: 0.9459
Epoch 33/50
 - 41s - loss: 0.1181 - acc: 0.9892 - val_loss: 0.2209 - val_acc: 0.9444
Epoch 34/50
 - 41s - loss: 0.1200 - acc: 0.9880 - val_loss: 0.2260 - val_acc: 0.9449
Epoch 35/50
 - 41s - loss: 0.1153 - acc: 0.9903 - val_loss: 0.2255 - val_acc: 0.9457
Epoch 36/50
 - 41s - loss: 0.1149 - acc: 0.9908 - val_loss: 0.2222 - val_acc: 0.9445

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 37/50
 - 41s - loss: 0.1138 - acc: 0.9910 - val_loss: 0.2230 - val_acc: 0.9443
Epoch 38/50
 - 41s - loss: 0.1123 - acc: 0.9925 - val_loss: 0.2209 - val_acc: 0.9455
Epoch 39/50
 - 41s - loss: 0.1124 - acc: 0.9916 - val_loss: 0.2206 - val_acc: 0.9440
Epoch 00039: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 2s
 288/7440 [>.............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 544/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2848/7440 [==========>...................] - ETA: 1s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 399us/step
current Test accuracy: 0.8026881720430108
current auc_score ------------------>  0.8881608422939069
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_4[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_36[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_37[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_14[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_38[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_39[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 36, 96, 96)   0           concatenate_14[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 36, 96, 96)   144         concatenate_15[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 36, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 18, 96, 96)   648         activation_40[0][0]              
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 18, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 18, 48, 48)   72          average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 18, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   720         activation_41[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_42[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 28, 48, 48)   0           average_pooling2d_7[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 28, 48, 48)   112         concatenate_16[0][0]             
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 28, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1120        activation_43[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_44[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 38, 48, 48)   0           concatenate_16[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 38, 48, 48)   152         concatenate_17[0][0]             
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 38, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 19, 48, 48)   722         activation_45[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 19, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 19, 24, 24)   76          average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 19, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   760         activation_46[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_47[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 29, 24, 24)   0           average_pooling2d_8[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_18[0][0]             
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 29, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   1160        activation_48[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_49[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 39, 24, 24)   0           concatenate_18[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 39, 24, 24)   156         concatenate_19[0][0]             
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 39, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 39)           0           activation_50[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            40          global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 30,694
Trainable params: 29,716
Non-trainable params: 978
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 28s - loss: 0.5700 - acc: 0.7517 - val_loss: 0.4998 - val_acc: 0.7863
Epoch 2/50
 - 25s - loss: 0.4886 - acc: 0.7914 - val_loss: 0.4667 - val_acc: 0.8027
Epoch 3/50
 - 25s - loss: 0.4591 - acc: 0.8080 - val_loss: 0.5647 - val_acc: 0.7755
Epoch 4/50
 - 25s - loss: 0.4391 - acc: 0.8168 - val_loss: 0.5137 - val_acc: 0.7731
Epoch 5/50
 - 25s - loss: 0.4215 - acc: 0.8279 - val_loss: 0.5753 - val_acc: 0.7745
Epoch 6/50
 - 25s - loss: 0.4089 - acc: 0.8347 - val_loss: 0.4010 - val_acc: 0.8414
Epoch 7/50
 - 25s - loss: 0.3960 - acc: 0.8427 - val_loss: 0.4844 - val_acc: 0.8077
Epoch 8/50
 - 25s - loss: 0.3839 - acc: 0.8498 - val_loss: 0.3758 - val_acc: 0.8569
Epoch 9/50
 - 25s - loss: 0.3726 - acc: 0.8540 - val_loss: 0.4531 - val_acc: 0.8002
Epoch 10/50
 - 24s - loss: 0.3608 - acc: 0.8603 - val_loss: 0.5013 - val_acc: 0.7912
Epoch 11/50
 - 24s - loss: 0.3527 - acc: 0.8647 - val_loss: 0.4162 - val_acc: 0.8427
Epoch 12/50
 - 25s - loss: 0.3454 - acc: 0.8704 - val_loss: 0.3501 - val_acc: 0.8705
Epoch 13/50
 - 25s - loss: 0.3368 - acc: 0.8731 - val_loss: 0.3553 - val_acc: 0.8638
Epoch 14/50
 - 25s - loss: 0.3320 - acc: 0.8759 - val_loss: 0.3284 - val_acc: 0.8765
Epoch 15/50
 - 25s - loss: 0.3251 - acc: 0.8793 - val_loss: 0.3528 - val_acc: 0.8720
Epoch 16/50
 - 25s - loss: 0.3167 - acc: 0.8838 - val_loss: 0.3582 - val_acc: 0.8611
Epoch 17/50
 - 25s - loss: 0.3133 - acc: 0.8863 - val_loss: 0.3491 - val_acc: 0.8778
Epoch 18/50
 - 25s - loss: 0.3046 - acc: 0.8884 - val_loss: 0.3150 - val_acc: 0.8832
Epoch 19/50
 - 25s - loss: 0.2992 - acc: 0.8934 - val_loss: 0.3354 - val_acc: 0.8741
Epoch 20/50
 - 25s - loss: 0.2934 - acc: 0.8934 - val_loss: 0.3407 - val_acc: 0.8672
Epoch 21/50
 - 25s - loss: 0.2867 - acc: 0.8985 - val_loss: 0.3241 - val_acc: 0.8894
Epoch 22/50
 - 25s - loss: 0.2780 - acc: 0.9032 - val_loss: 0.3330 - val_acc: 0.8706

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 23/50
 - 24s - loss: 0.2590 - acc: 0.9120 - val_loss: 0.2783 - val_acc: 0.9011
Epoch 24/50
 - 24s - loss: 0.2539 - acc: 0.9131 - val_loss: 0.2822 - val_acc: 0.8985
Epoch 25/50
 - 24s - loss: 0.2524 - acc: 0.9165 - val_loss: 0.3048 - val_acc: 0.8907
Epoch 26/50
 - 25s - loss: 0.2496 - acc: 0.9185 - val_loss: 0.2877 - val_acc: 0.9002
Epoch 27/50
 - 25s - loss: 0.2445 - acc: 0.9193 - val_loss: 0.2818 - val_acc: 0.8988

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 28/50
 - 25s - loss: 0.2392 - acc: 0.9219 - val_loss: 0.2715 - val_acc: 0.9037
Epoch 29/50
 - 24s - loss: 0.2366 - acc: 0.9236 - val_loss: 0.2696 - val_acc: 0.9057
Epoch 30/50
 - 25s - loss: 0.2357 - acc: 0.9246 - val_loss: 0.2677 - val_acc: 0.9068
Epoch 31/50
 - 25s - loss: 0.2368 - acc: 0.9235 - val_loss: 0.2722 - val_acc: 0.9034
Epoch 32/50
 - 25s - loss: 0.2342 - acc: 0.9254 - val_loss: 0.2690 - val_acc: 0.9049
Epoch 33/50
 - 24s - loss: 0.2356 - acc: 0.9245 - val_loss: 0.2718 - val_acc: 0.9056
Epoch 34/50
 - 25s - loss: 0.2337 - acc: 0.9264 - val_loss: 0.2673 - val_acc: 0.9076
Epoch 35/50
 - 25s - loss: 0.2321 - acc: 0.9257 - val_loss: 0.2815 - val_acc: 0.8982
Epoch 36/50
 - 24s - loss: 0.2311 - acc: 0.9273 - val_loss: 0.2683 - val_acc: 0.9060
Epoch 37/50
 - 25s - loss: 0.2307 - acc: 0.9258 - val_loss: 0.2655 - val_acc: 0.9056
Epoch 38/50
 - 25s - loss: 0.2279 - acc: 0.9284 - val_loss: 0.2648 - val_acc: 0.9074
Epoch 39/50
 - 25s - loss: 0.2286 - acc: 0.9272 - val_loss: 0.2658 - val_acc: 0.9076
Epoch 40/50
 - 24s - loss: 0.2302 - acc: 0.9260 - val_loss: 0.2695 - val_acc: 0.9070
Epoch 41/50
 - 24s - loss: 0.2280 - acc: 0.9271 - val_loss: 0.2633 - val_acc: 0.9105
Epoch 42/50
 - 24s - loss: 0.2284 - acc: 0.9284 - val_loss: 0.2698 - val_acc: 0.9081
Epoch 43/50
 - 24s - loss: 0.2264 - acc: 0.9281 - val_loss: 0.2678 - val_acc: 0.9078
Epoch 44/50
 - 24s - loss: 0.2272 - acc: 0.9269 - val_loss: 0.2635 - val_acc: 0.9074
Epoch 45/50
 - 24s - loss: 0.2254 - acc: 0.9282 - val_loss: 0.2642 - val_acc: 0.9073

Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 46/50
 - 24s - loss: 0.2229 - acc: 0.9292 - val_loss: 0.2608 - val_acc: 0.9094
Epoch 47/50
 - 24s - loss: 0.2201 - acc: 0.9315 - val_loss: 0.2612 - val_acc: 0.9101
Epoch 48/50
 - 24s - loss: 0.2182 - acc: 0.9308 - val_loss: 0.2664 - val_acc: 0.9054
Epoch 49/50
 - 24s - loss: 0.2209 - acc: 0.9311 - val_loss: 0.2610 - val_acc: 0.9095
Epoch 50/50
 - 24s - loss: 0.2203 - acc: 0.9311 - val_loss: 0.2648 - val_acc: 0.9054

Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 246us/step
current Test accuracy: 0.8139784946236559
current auc_score ------------------>  0.9094339663544918
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_5[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 96, 96)   1152        activation_51[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 72, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_52[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 34, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_20[0][0]             
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 34, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 96, 96)   2448        activation_53[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 72, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_54[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 52, 96, 96)   0           concatenate_20[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_21[0][0]             
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 52, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 72, 96, 96)   3744        activation_55[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 72, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_56[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 70, 96, 96)   0           concatenate_21[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 70, 96, 96)   280         concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 70, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 35, 96, 96)   2450        activation_57[0][0]              
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 35, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 35, 48, 48)   140         average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 35, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 48, 48)   2520        activation_58[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 72, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_59[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 53, 48, 48)   0           average_pooling2d_9[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 53, 48, 48)   212         concatenate_23[0][0]             
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 53, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 48, 48)   3816        activation_60[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 72, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_61[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 71, 48, 48)   0           concatenate_23[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_24[0][0]             
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 71, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 72, 48, 48)   5112        activation_62[0][0]              
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 72, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_63[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 89, 48, 48)   0           concatenate_24[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 89, 48, 48)   356         concatenate_25[0][0]             
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 89, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 89)           0           activation_64[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            90          global_average_pooling2d_5[0][0] 
==================================================================================================
Total params: 95,012
Trainable params: 93,308
Non-trainable params: 1,704
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 48s - loss: 0.5907 - acc: 0.7552 - val_loss: 0.5640 - val_acc: 0.7691
Epoch 2/50
 - 45s - loss: 0.5147 - acc: 0.7930 - val_loss: 0.4930 - val_acc: 0.8074
Epoch 3/50
 - 45s - loss: 0.4837 - acc: 0.8080 - val_loss: 0.5529 - val_acc: 0.7491
Epoch 4/50
 - 45s - loss: 0.4593 - acc: 0.8189 - val_loss: 0.4580 - val_acc: 0.8215
Epoch 5/50
 - 45s - loss: 0.4393 - acc: 0.8284 - val_loss: 0.4436 - val_acc: 0.8264
Epoch 6/50
 - 45s - loss: 0.4232 - acc: 0.8398 - val_loss: 0.4359 - val_acc: 0.8325
Epoch 7/50
 - 45s - loss: 0.4115 - acc: 0.8442 - val_loss: 0.4587 - val_acc: 0.8306
Epoch 8/50
 - 45s - loss: 0.3980 - acc: 0.8517 - val_loss: 0.4665 - val_acc: 0.8176
Epoch 9/50
 - 45s - loss: 0.3878 - acc: 0.8594 - val_loss: 0.5471 - val_acc: 0.7766
Epoch 10/50
 - 45s - loss: 0.3764 - acc: 0.8616 - val_loss: 0.4377 - val_acc: 0.8365

Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 11/50
 - 45s - loss: 0.3477 - acc: 0.8794 - val_loss: 0.3483 - val_acc: 0.8783
Epoch 12/50
 - 45s - loss: 0.3387 - acc: 0.8845 - val_loss: 0.3475 - val_acc: 0.8784
Epoch 13/50
 - 45s - loss: 0.3361 - acc: 0.8847 - val_loss: 0.3702 - val_acc: 0.8632
Epoch 14/50
 - 45s - loss: 0.3319 - acc: 0.8872 - val_loss: 0.3343 - val_acc: 0.8839
Epoch 15/50
 - 45s - loss: 0.3235 - acc: 0.8922 - val_loss: 0.3375 - val_acc: 0.8833
Epoch 16/50
 - 45s - loss: 0.3189 - acc: 0.8924 - val_loss: 0.3328 - val_acc: 0.8854
Epoch 17/50
 - 45s - loss: 0.3170 - acc: 0.8950 - val_loss: 0.3559 - val_acc: 0.8805
Epoch 18/50
 - 45s - loss: 0.3113 - acc: 0.8956 - val_loss: 0.3217 - val_acc: 0.8918
Epoch 19/50
 - 45s - loss: 0.3070 - acc: 0.8981 - val_loss: 0.3369 - val_acc: 0.8914
Epoch 20/50
 - 45s - loss: 0.3040 - acc: 0.9003 - val_loss: 0.3154 - val_acc: 0.8938
Epoch 21/50
 - 45s - loss: 0.2992 - acc: 0.9025 - val_loss: 0.4303 - val_acc: 0.8427
Epoch 22/50
 - 45s - loss: 0.2958 - acc: 0.9049 - val_loss: 0.3053 - val_acc: 0.8991
Epoch 23/50
 - 45s - loss: 0.2904 - acc: 0.9081 - val_loss: 0.3396 - val_acc: 0.8778
Epoch 24/50
 - 45s - loss: 0.2862 - acc: 0.9095 - val_loss: 0.3963 - val_acc: 0.8537
Epoch 25/50
 - 45s - loss: 0.2833 - acc: 0.9095 - val_loss: 0.3134 - val_acc: 0.8921
Epoch 26/50
 - 45s - loss: 0.2808 - acc: 0.9095 - val_loss: 0.3048 - val_acc: 0.9000
Epoch 27/50
 - 45s - loss: 0.2772 - acc: 0.9126 - val_loss: 0.3175 - val_acc: 0.8965
Epoch 28/50
 - 45s - loss: 0.2742 - acc: 0.9146 - val_loss: 0.3178 - val_acc: 0.8960
Epoch 29/50
 - 45s - loss: 0.2681 - acc: 0.9188 - val_loss: 0.2987 - val_acc: 0.8981
Epoch 30/50
 - 45s - loss: 0.2669 - acc: 0.9180 - val_loss: 0.3174 - val_acc: 0.8943
Epoch 31/50
 - 45s - loss: 0.2633 - acc: 0.9204 - val_loss: 0.3625 - val_acc: 0.8660
Epoch 32/50
 - 45s - loss: 0.2608 - acc: 0.9199 - val_loss: 0.2976 - val_acc: 0.8997
Epoch 33/50
 - 45s - loss: 0.2577 - acc: 0.9210 - val_loss: 0.2953 - val_acc: 0.9006
Epoch 34/50
 - 45s - loss: 0.2528 - acc: 0.9256 - val_loss: 0.3024 - val_acc: 0.9027
Epoch 35/50
 - 45s - loss: 0.2530 - acc: 0.9233 - val_loss: 0.3238 - val_acc: 0.8948
Epoch 36/50
 - 45s - loss: 0.2470 - acc: 0.9269 - val_loss: 0.3257 - val_acc: 0.8869
Epoch 37/50
 - 45s - loss: 0.2452 - acc: 0.9263 - val_loss: 0.2811 - val_acc: 0.9083
Epoch 38/50
 - 45s - loss: 0.2427 - acc: 0.9274 - val_loss: 0.3047 - val_acc: 0.8965
Epoch 39/50
 - 45s - loss: 0.2400 - acc: 0.9289 - val_loss: 0.3708 - val_acc: 0.8858
Epoch 40/50
 - 45s - loss: 0.2359 - acc: 0.9320 - val_loss: 0.2942 - val_acc: 0.9041
Epoch 41/50
 - 45s - loss: 0.2324 - acc: 0.9323 - val_loss: 0.3082 - val_acc: 0.8945

Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 42/50
 - 45s - loss: 0.2192 - acc: 0.9394 - val_loss: 0.2697 - val_acc: 0.9140
Epoch 43/50
 - 45s - loss: 0.2191 - acc: 0.9415 - val_loss: 0.2744 - val_acc: 0.9091
Epoch 44/50
 - 45s - loss: 0.2165 - acc: 0.9420 - val_loss: 0.2760 - val_acc: 0.9127
Epoch 45/50
 - 45s - loss: 0.2148 - acc: 0.9433 - val_loss: 0.2794 - val_acc: 0.9106
Epoch 46/50
 - 45s - loss: 0.2140 - acc: 0.9440 - val_loss: 0.2657 - val_acc: 0.9160
Epoch 47/50
 - 45s - loss: 0.2124 - acc: 0.9442 - val_loss: 0.2689 - val_acc: 0.9128
Epoch 48/50
 - 45s - loss: 0.2085 - acc: 0.9467 - val_loss: 0.2791 - val_acc: 0.9068
Epoch 49/50
 - 45s - loss: 0.2092 - acc: 0.9450 - val_loss: 0.2676 - val_acc: 0.9160
Epoch 50/50
 - 45s - loss: 0.2084 - acc: 0.9459 - val_loss: 0.2800 - val_acc: 0.9064

Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 452us/step
current Test accuracy: 0.7674731182795699
current auc_score ------------------>  0.882263122904382
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_6[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 96, 96)   1152        activation_65[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 72, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_66[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 34, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 34, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 96, 96)   2448        activation_67[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 72, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_68[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 52, 96, 96)   0           concatenate_26[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_27[0][0]             
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 52, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 72, 96, 96)   3744        activation_69[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 72, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_70[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 70, 96, 96)   0           concatenate_27[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 70, 96, 96)   280         concatenate_28[0][0]             
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 70, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 35, 96, 96)   2450        activation_71[0][0]              
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 35, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 35, 48, 48)   140         average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 35, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 48, 48)   2520        activation_72[0][0]              
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 72, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_73[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 53, 48, 48)   0           average_pooling2d_10[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 53, 48, 48)   212         concatenate_29[0][0]             
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 53, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 48, 48)   3816        activation_74[0][0]              
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 72, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_75[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 71, 48, 48)   0           concatenate_29[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_30[0][0]             
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 71, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 72, 48, 48)   5112        activation_76[0][0]              
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 72, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_77[0][0]              
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 89, 48, 48)   0           concatenate_30[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 89, 48, 48)   356         concatenate_31[0][0]             
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 89, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 44, 48, 48)   3916        activation_78[0][0]              
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 44, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 44, 24, 24)   176         average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 44, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 72, 24, 24)   3168        activation_79[0][0]              
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 72, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_80[0][0]              
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 62, 24, 24)   0           average_pooling2d_11[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_32[0][0]             
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 62, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 72, 24, 24)   4464        activation_81[0][0]              
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 72, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_82[0][0]              
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 80, 24, 24)   0           concatenate_32[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 80, 24, 24)   320         concatenate_33[0][0]             
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 80, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 72, 24, 24)   5760        activation_83[0][0]              
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 72, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_84[0][0]              
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 98, 24, 24)   0           concatenate_33[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 98, 24, 24)   392         concatenate_34[0][0]             
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 98, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 49, 24, 24)   4802        activation_85[0][0]              
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 49, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 49, 12, 12)   196         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 49, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3528        activation_86[0][0]              
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 72, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_87[0][0]              
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 67, 12, 12)   0           average_pooling2d_12[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 67, 12, 12)   268         concatenate_35[0][0]             
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 67, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4824        activation_88[0][0]              
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 72, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_89[0][0]              
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 85, 12, 12)   0           concatenate_35[0][0]             
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 85, 12, 12)   340         concatenate_36[0][0]             
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 85, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 72, 12, 12)   6120        activation_90[0][0]              
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 72, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_91[0][0]              
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 103, 12, 12)  0           concatenate_36[0][0]             
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 103, 12, 12)  412         concatenate_37[0][0]             
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 103, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 103)          0           activation_92[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            104         global_average_pooling2d_6[0][0] 
==================================================================================================
Total params: 205,672
Trainable params: 201,928
Non-trainable params: 3,744
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 61s - loss: 0.6211 - acc: 0.7935 - val_loss: 0.5600 - val_acc: 0.8230
Epoch 2/50
 - 55s - loss: 0.4875 - acc: 0.8660 - val_loss: 0.5598 - val_acc: 0.8422
Epoch 3/50
 - 55s - loss: 0.4227 - acc: 0.8966 - val_loss: 0.3976 - val_acc: 0.9121
Epoch 4/50
 - 55s - loss: 0.3752 - acc: 0.9177 - val_loss: 0.4596 - val_acc: 0.8746
Epoch 5/50
 - 55s - loss: 0.3401 - acc: 0.9325 - val_loss: 0.6056 - val_acc: 0.8228
Epoch 6/50
 - 55s - loss: 0.3115 - acc: 0.9434 - val_loss: 0.4374 - val_acc: 0.8966
Epoch 7/50
 - 55s - loss: 0.2904 - acc: 0.9494 - val_loss: 0.3185 - val_acc: 0.9398
Epoch 8/50
 - 55s - loss: 0.2695 - acc: 0.9573 - val_loss: 0.3183 - val_acc: 0.9355
Epoch 9/50
 - 55s - loss: 0.2518 - acc: 0.9643 - val_loss: 0.5150 - val_acc: 0.8584
Epoch 10/50
 - 55s - loss: 0.2433 - acc: 0.9661 - val_loss: 0.2740 - val_acc: 0.9527
Epoch 11/50
 - 55s - loss: 0.2286 - acc: 0.9713 - val_loss: 0.4865 - val_acc: 0.8853
Epoch 12/50
 - 55s - loss: 0.2191 - acc: 0.9740 - val_loss: 0.2650 - val_acc: 0.9561
Epoch 13/50
 - 55s - loss: 0.2067 - acc: 0.9775 - val_loss: 0.2468 - val_acc: 0.9608
Epoch 14/50
 - 55s - loss: 0.2023 - acc: 0.9767 - val_loss: 0.2843 - val_acc: 0.9431
Epoch 15/50
 - 55s - loss: 0.1921 - acc: 0.9801 - val_loss: 0.2512 - val_acc: 0.9605
Epoch 16/50
 - 55s - loss: 0.1898 - acc: 0.9802 - val_loss: 0.4855 - val_acc: 0.8699
Epoch 17/50
 - 55s - loss: 0.1817 - acc: 0.9838 - val_loss: 0.2606 - val_acc: 0.9563

Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 18/50
 - 55s - loss: 0.1545 - acc: 0.9940 - val_loss: 0.2028 - val_acc: 0.9743
Epoch 19/50
 - 55s - loss: 0.1496 - acc: 0.9953 - val_loss: 0.2023 - val_acc: 0.9739
Epoch 20/50
 - 55s - loss: 0.1461 - acc: 0.9965 - val_loss: 0.2090 - val_acc: 0.9709
Epoch 21/50
 - 55s - loss: 0.1442 - acc: 0.9962 - val_loss: 0.2132 - val_acc: 0.9695
Epoch 22/50
 - 56s - loss: 0.1438 - acc: 0.9959 - val_loss: 0.2021 - val_acc: 0.9726
Epoch 23/50
 - 55s - loss: 0.1408 - acc: 0.9963 - val_loss: 0.2167 - val_acc: 0.9695
Epoch 24/50
 - 55s - loss: 0.1383 - acc: 0.9968 - val_loss: 0.1959 - val_acc: 0.9738
Epoch 25/50
 - 55s - loss: 0.1371 - acc: 0.9970 - val_loss: 0.2103 - val_acc: 0.9724
Epoch 26/50
 - 55s - loss: 0.1355 - acc: 0.9972 - val_loss: 0.1931 - val_acc: 0.9762
Epoch 27/50
 - 55s - loss: 0.1324 - acc: 0.9977 - val_loss: 0.2139 - val_acc: 0.9684
Epoch 28/50
 - 55s - loss: 0.1337 - acc: 0.9967 - val_loss: 0.1963 - val_acc: 0.9743
Epoch 29/50
 - 55s - loss: 0.1306 - acc: 0.9977 - val_loss: 0.2456 - val_acc: 0.9602
Epoch 30/50
 - 55s - loss: 0.1296 - acc: 0.9975 - val_loss: 0.1960 - val_acc: 0.9724

Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 31/50
 - 55s - loss: 0.1250 - acc: 0.9989 - val_loss: 0.1867 - val_acc: 0.9767
Epoch 32/50
 - 55s - loss: 0.1246 - acc: 0.9988 - val_loss: 0.1838 - val_acc: 0.9780
Epoch 33/50
 - 55s - loss: 0.1231 - acc: 0.9993 - val_loss: 0.1839 - val_acc: 0.9782
Epoch 34/50
 - 55s - loss: 0.1231 - acc: 0.9989 - val_loss: 0.1884 - val_acc: 0.9768
Epoch 35/50
 - 55s - loss: 0.1216 - acc: 0.9994 - val_loss: 0.1901 - val_acc: 0.9768
Epoch 36/50
 - 55s - loss: 0.1216 - acc: 0.9991 - val_loss: 0.1824 - val_acc: 0.9777
Epoch 37/50
 - 55s - loss: 0.1210 - acc: 0.9993 - val_loss: 0.1873 - val_acc: 0.9770
Epoch 38/50
 - 55s - loss: 0.1203 - acc: 0.9991 - val_loss: 0.1846 - val_acc: 0.9778
Epoch 39/50
 - 55s - loss: 0.1196 - acc: 0.9994 - val_loss: 0.1843 - val_acc: 0.9778
Epoch 40/50
 - 55s - loss: 0.1192 - acc: 0.9994 - val_loss: 0.1859 - val_acc: 0.9767

Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 41/50
 - 55s - loss: 0.1181 - acc: 0.9994 - val_loss: 0.1894 - val_acc: 0.9755
Epoch 42/50
 - 55s - loss: 0.1176 - acc: 0.9996 - val_loss: 0.1824 - val_acc: 0.9780
Epoch 43/50
 - 55s - loss: 0.1177 - acc: 0.9995 - val_loss: 0.1825 - val_acc: 0.9787
Epoch 00043: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 928/7440 [==>...........................] - ETA: 3s
1056/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1312/7440 [====>.........................] - ETA: 3s
1440/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3232/7440 [============>.................] - ETA: 2s
3360/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 507us/step
current Test accuracy: 0.7705645161290322
current auc_score ------------------>  0.8975165481558561
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_93 (Activation)   (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_13 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 8, 48, 48)         32        
_________________________________________________________________
activation_94 (Activation)   (None, 8, 48, 48)         0         
_________________________________________________________________
global_average_pooling2d_7 ( (None, 8)                 0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 9         
=================================================================
Total params: 521
Trainable params: 473
Non-trainable params: 48
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 8s - loss: 0.6692 - acc: 0.6057 - val_loss: 0.6576 - val_acc: 0.6009
Epoch 2/50
 - 7s - loss: 0.6350 - acc: 0.6773 - val_loss: 0.6235 - val_acc: 0.7024
Epoch 3/50
 - 7s - loss: 0.6195 - acc: 0.6930 - val_loss: 0.6141 - val_acc: 0.6999
Epoch 4/50
 - 7s - loss: 0.6103 - acc: 0.6984 - val_loss: 0.6068 - val_acc: 0.7077
Epoch 5/50
 - 7s - loss: 0.6042 - acc: 0.7010 - val_loss: 0.6019 - val_acc: 0.7091
Epoch 6/50
 - 7s - loss: 0.5991 - acc: 0.7059 - val_loss: 0.6016 - val_acc: 0.7006
Epoch 7/50
 - 7s - loss: 0.5951 - acc: 0.7112 - val_loss: 0.5982 - val_acc: 0.7072
Epoch 8/50
 - 7s - loss: 0.5888 - acc: 0.7126 - val_loss: 0.5867 - val_acc: 0.7175
Epoch 9/50
 - 7s - loss: 0.5824 - acc: 0.7172 - val_loss: 0.5823 - val_acc: 0.7191
Epoch 10/50
 - 7s - loss: 0.5764 - acc: 0.7224 - val_loss: 0.5745 - val_acc: 0.7226
Epoch 11/50
 - 7s - loss: 0.5707 - acc: 0.7241 - val_loss: 0.5697 - val_acc: 0.7285
Epoch 12/50
 - 7s - loss: 0.5638 - acc: 0.7276 - val_loss: 0.5626 - val_acc: 0.7294
Epoch 13/50
 - 7s - loss: 0.5585 - acc: 0.7301 - val_loss: 0.5563 - val_acc: 0.7314
Epoch 14/50
 - 7s - loss: 0.5535 - acc: 0.7314 - val_loss: 0.5722 - val_acc: 0.7215
Epoch 15/50
 - 7s - loss: 0.5489 - acc: 0.7374 - val_loss: 0.5480 - val_acc: 0.7338
Epoch 16/50
 - 7s - loss: 0.5466 - acc: 0.7371 - val_loss: 0.5753 - val_acc: 0.7268
Epoch 17/50
 - 7s - loss: 0.5423 - acc: 0.7415 - val_loss: 0.5421 - val_acc: 0.7454
Epoch 18/50
 - 7s - loss: 0.5397 - acc: 0.7413 - val_loss: 0.5410 - val_acc: 0.7401
Epoch 19/50
 - 7s - loss: 0.5377 - acc: 0.7442 - val_loss: 0.5440 - val_acc: 0.7381
Epoch 20/50
 - 7s - loss: 0.5374 - acc: 0.7452 - val_loss: 0.5482 - val_acc: 0.7228
Epoch 21/50
 - 7s - loss: 0.5345 - acc: 0.7459 - val_loss: 0.5431 - val_acc: 0.7308
Epoch 22/50
 - 7s - loss: 0.5336 - acc: 0.7478 - val_loss: 0.5545 - val_acc: 0.7382

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 23/50
 - 7s - loss: 0.5321 - acc: 0.7464 - val_loss: 0.5358 - val_acc: 0.7413
Epoch 24/50
 - 7s - loss: 0.5308 - acc: 0.7479 - val_loss: 0.5294 - val_acc: 0.7441
Epoch 25/50
 - 7s - loss: 0.5308 - acc: 0.7490 - val_loss: 0.5293 - val_acc: 0.7454
Epoch 26/50
 - 6s - loss: 0.5311 - acc: 0.7472 - val_loss: 0.5291 - val_acc: 0.7464
Epoch 27/50
 - 7s - loss: 0.5308 - acc: 0.7472 - val_loss: 0.5286 - val_acc: 0.7471
Epoch 28/50
 - 6s - loss: 0.5296 - acc: 0.7486 - val_loss: 0.5292 - val_acc: 0.7482
Epoch 29/50
 - 6s - loss: 0.5286 - acc: 0.7491 - val_loss: 0.5278 - val_acc: 0.7481
Epoch 30/50
 - 7s - loss: 0.5282 - acc: 0.7490 - val_loss: 0.5310 - val_acc: 0.7430
Epoch 31/50
 - 7s - loss: 0.5295 - acc: 0.7483 - val_loss: 0.5298 - val_acc: 0.7440
Epoch 32/50
 - 6s - loss: 0.5277 - acc: 0.7487 - val_loss: 0.5274 - val_acc: 0.7486
Epoch 33/50
 - 6s - loss: 0.5255 - acc: 0.7500 - val_loss: 0.5287 - val_acc: 0.7476
Epoch 34/50
 - 6s - loss: 0.5286 - acc: 0.7497 - val_loss: 0.5275 - val_acc: 0.7477
Epoch 35/50
 - 6s - loss: 0.5278 - acc: 0.7496 - val_loss: 0.5257 - val_acc: 0.7510
Epoch 36/50
 - 6s - loss: 0.5277 - acc: 0.7493 - val_loss: 0.5301 - val_acc: 0.7452
Epoch 37/50
 - 7s - loss: 0.5266 - acc: 0.7508 - val_loss: 0.5251 - val_acc: 0.7499
Epoch 38/50
 - 6s - loss: 0.5261 - acc: 0.7494 - val_loss: 0.5338 - val_acc: 0.7447
Epoch 39/50
 - 7s - loss: 0.5260 - acc: 0.7497 - val_loss: 0.5292 - val_acc: 0.7405
Epoch 40/50
 - 7s - loss: 0.5259 - acc: 0.7494 - val_loss: 0.5241 - val_acc: 0.7484
Epoch 41/50
 - 7s - loss: 0.5263 - acc: 0.7481 - val_loss: 0.5277 - val_acc: 0.7418
Epoch 42/50
 - 7s - loss: 0.5244 - acc: 0.7497 - val_loss: 0.5245 - val_acc: 0.7487
Epoch 43/50
 - 7s - loss: 0.5255 - acc: 0.7501 - val_loss: 0.5235 - val_acc: 0.7516
Epoch 44/50
 - 7s - loss: 0.5244 - acc: 0.7530 - val_loss: 0.5232 - val_acc: 0.7521
Epoch 45/50
 - 6s - loss: 0.5254 - acc: 0.7500 - val_loss: 0.5252 - val_acc: 0.7496
Epoch 46/50
 - 6s - loss: 0.5249 - acc: 0.7500 - val_loss: 0.5229 - val_acc: 0.7519
Epoch 47/50
 - 7s - loss: 0.5232 - acc: 0.7532 - val_loss: 0.5269 - val_acc: 0.7480
Epoch 48/50
 - 7s - loss: 0.5243 - acc: 0.7506 - val_loss: 0.5242 - val_acc: 0.7459
Epoch 49/50
 - 7s - loss: 0.5229 - acc: 0.7507 - val_loss: 0.5213 - val_acc: 0.7494
Epoch 50/50
 - 7s - loss: 0.5228 - acc: 0.7524 - val_loss: 0.5218 - val_acc: 0.7490

  32/7440 [..............................] - ETA: 0s
 576/7440 [=>............................] - ETA: 0s
1120/7440 [===>..........................] - ETA: 0s
1632/7440 [=====>........................] - ETA: 0s
2176/7440 [=======>......................] - ETA: 0s
2720/7440 [=========>....................] - ETA: 0s
3232/7440 [============>.................] - ETA: 0s
3744/7440 [==============>...............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4768/7440 [==================>...........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 100us/step
current Test accuracy: 0.8385752688172043
current auc_score ------------------>  0.8644298473812001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_8 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_8[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_95[0][0]              
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_96[0][0]              
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_38[0][0]             
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_97[0][0]              
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_98[0][0]              
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 36, 96, 96)   0           concatenate_38[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 36, 96, 96)   144         concatenate_39[0][0]             
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 36, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 40, 96, 96)   1440        activation_99[0][0]              
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 40, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_100[0][0]             
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 46, 96, 96)   0           concatenate_39[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 46, 96, 96)   184         concatenate_40[0][0]             
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 46, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 40, 96, 96)   1840        activation_101[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 40, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_102[0][0]             
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 56, 96, 96)   0           concatenate_40[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 56, 96, 96)   224         concatenate_41[0][0]             
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 56, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 40, 96, 96)   2240        activation_103[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_104[0][0]             
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 66, 96, 96)   0           concatenate_41[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 66, 96, 96)   264         concatenate_42[0][0]             
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 66, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 33, 96, 96)   2178        activation_105[0][0]             
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 33, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 33, 48, 48)   132         average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 33, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   1320        activation_106[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_107[0][0]             
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 43, 48, 48)   0           average_pooling2d_14[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_43[0][0]             
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1720        activation_108[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_109[0][0]             
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 53, 48, 48)   0           concatenate_43[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 53, 48, 48)   212         concatenate_44[0][0]             
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 53, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 40, 48, 48)   2120        activation_110[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_111[0][0]             
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 63, 48, 48)   0           concatenate_44[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 63, 48, 48)   252         concatenate_45[0][0]             
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 63, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 40, 48, 48)   2520        activation_112[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 40, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_113[0][0]             
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 73, 48, 48)   0           concatenate_45[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 73, 48, 48)   292         concatenate_46[0][0]             
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 73, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 40, 48, 48)   2920        activation_114[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 40, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_115[0][0]             
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 83, 48, 48)   0           concatenate_46[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 83, 48, 48)   332         concatenate_47[0][0]             
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 83, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 41, 48, 48)   3403        activation_116[0][0]             
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 41, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 41, 24, 24)   164         average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 41, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   1640        activation_117[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_118[0][0]             
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 51, 24, 24)   0           average_pooling2d_15[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 51, 24, 24)   204         concatenate_48[0][0]             
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 51, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   2040        activation_119[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_120[0][0]             
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 61, 24, 24)   0           concatenate_48[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 61, 24, 24)   244         concatenate_49[0][0]             
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 61, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 40, 24, 24)   2440        activation_121[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 40, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_122[0][0]             
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 71, 24, 24)   0           concatenate_49[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 71, 24, 24)   284         concatenate_50[0][0]             
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 71, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 40, 24, 24)   2840        activation_123[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 40, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_124[0][0]             
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 81, 24, 24)   0           concatenate_50[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 81, 24, 24)   324         concatenate_51[0][0]             
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 81, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 40, 24, 24)   3240        activation_125[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 40, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_126[0][0]             
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 91, 24, 24)   0           concatenate_51[0][0]             
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 91, 24, 24)   364         concatenate_52[0][0]             
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 91, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 45, 24, 24)   4095        activation_127[0][0]             
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 45, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 45, 12, 12)   180         average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 45, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 40, 12, 12)   1800        activation_128[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 40, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_129[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 55, 12, 12)   0           average_pooling2d_16[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 55, 12, 12)   220         concatenate_53[0][0]             
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 55, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 40, 12, 12)   2200        activation_130[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 40, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_131[0][0]             
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 65, 12, 12)   0           concatenate_53[0][0]             
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 65, 12, 12)   260         concatenate_54[0][0]             
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 65, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 40, 12, 12)   2600        activation_132[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 40, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_133[0][0]             
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 75, 12, 12)   0           concatenate_54[0][0]             
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_3_bn (BatchNormalizatio (None, 75, 12, 12)   300         concatenate_55[0][0]             
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 75, 12, 12)   0           dense_3_3_bn[0][0]               
__________________________________________________________________________________________________
dense_3_3_bottleneck_conv2D (Co (None, 40, 12, 12)   3000        activation_134[0][0]             
__________________________________________________________________________________________________
dense_3_3_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 40, 12, 12)   0           dense_3_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_3_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_135[0][0]             
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 85, 12, 12)   0           concatenate_55[0][0]             
                                                                 dense_3_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_4_bn (BatchNormalizatio (None, 85, 12, 12)   340         concatenate_56[0][0]             
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 85, 12, 12)   0           dense_3_4_bn[0][0]               
__________________________________________________________________________________________________
dense_3_4_bottleneck_conv2D (Co (None, 40, 12, 12)   3400        activation_136[0][0]             
__________________________________________________________________________________________________
dense_3_4_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 40, 12, 12)   0           dense_3_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_4_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_137[0][0]             
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 95, 12, 12)   0           concatenate_56[0][0]             
                                                                 dense_3_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 95, 12, 12)   380         concatenate_57[0][0]             
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 95, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 95)           0           activation_138[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            96          global_average_pooling2d_8[0][0] 
==================================================================================================
Total params: 133,900
Trainable params: 129,480
Non-trainable params: 4,420
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 78s - loss: 0.6127 - acc: 0.7908 - val_loss: 0.5935 - val_acc: 0.7977
Epoch 2/50
 - 68s - loss: 0.4882 - acc: 0.8591 - val_loss: 0.4969 - val_acc: 0.8510
Epoch 3/50
 - 68s - loss: 0.4213 - acc: 0.8921 - val_loss: 0.4044 - val_acc: 0.8986
Epoch 4/50
 - 68s - loss: 0.3721 - acc: 0.9147 - val_loss: 0.3979 - val_acc: 0.9020
Epoch 5/50
 - 67s - loss: 0.3416 - acc: 0.9282 - val_loss: 0.3409 - val_acc: 0.9249
Epoch 6/50
 - 67s - loss: 0.3169 - acc: 0.9372 - val_loss: 0.3467 - val_acc: 0.9232
Epoch 7/50
 - 67s - loss: 0.2977 - acc: 0.9450 - val_loss: 0.4084 - val_acc: 0.8896
Epoch 8/50
 - 67s - loss: 0.2830 - acc: 0.9499 - val_loss: 0.3528 - val_acc: 0.9191
Epoch 9/50
 - 67s - loss: 0.2659 - acc: 0.9547 - val_loss: 0.3086 - val_acc: 0.9370
Epoch 10/50
 - 67s - loss: 0.2541 - acc: 0.9587 - val_loss: 0.3035 - val_acc: 0.9376
Epoch 11/50
 - 67s - loss: 0.2435 - acc: 0.9613 - val_loss: 0.4224 - val_acc: 0.8971
Epoch 12/50
 - 67s - loss: 0.2348 - acc: 0.9656 - val_loss: 0.2936 - val_acc: 0.9396
Epoch 13/50
 - 67s - loss: 0.2284 - acc: 0.9666 - val_loss: 0.2668 - val_acc: 0.9495
Epoch 14/50
 - 67s - loss: 0.2177 - acc: 0.9712 - val_loss: 0.3672 - val_acc: 0.9203
Epoch 15/50
 - 67s - loss: 0.2138 - acc: 0.9720 - val_loss: 0.2756 - val_acc: 0.9473
Epoch 16/50
 - 67s - loss: 0.2065 - acc: 0.9747 - val_loss: 0.2864 - val_acc: 0.9475
Epoch 17/50
 - 67s - loss: 0.2001 - acc: 0.9754 - val_loss: 0.2796 - val_acc: 0.9484

Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 18/50
 - 67s - loss: 0.1705 - acc: 0.9889 - val_loss: 0.2241 - val_acc: 0.9677
Epoch 19/50
 - 67s - loss: 0.1652 - acc: 0.9897 - val_loss: 0.2277 - val_acc: 0.9680
Epoch 20/50
 - 67s - loss: 0.1606 - acc: 0.9917 - val_loss: 0.2282 - val_acc: 0.9677
Epoch 21/50
 - 67s - loss: 0.1574 - acc: 0.9925 - val_loss: 0.2260 - val_acc: 0.9644
Epoch 22/50
 - 67s - loss: 0.1550 - acc: 0.9928 - val_loss: 0.2375 - val_acc: 0.9661

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 23/50
 - 67s - loss: 0.1488 - acc: 0.9950 - val_loss: 0.2149 - val_acc: 0.9719
Epoch 24/50
 - 67s - loss: 0.1485 - acc: 0.9954 - val_loss: 0.2209 - val_acc: 0.9718
Epoch 25/50
 - 67s - loss: 0.1455 - acc: 0.9964 - val_loss: 0.2169 - val_acc: 0.9723
Epoch 26/50
 - 67s - loss: 0.1449 - acc: 0.9961 - val_loss: 0.2149 - val_acc: 0.9711
Epoch 27/50
 - 67s - loss: 0.1449 - acc: 0.9965 - val_loss: 0.2165 - val_acc: 0.9726

Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 28/50
 - 67s - loss: 0.1440 - acc: 0.9964 - val_loss: 0.2127 - val_acc: 0.9731
Epoch 29/50
 - 67s - loss: 0.1433 - acc: 0.9966 - val_loss: 0.2112 - val_acc: 0.9731
Epoch 30/50
 - 67s - loss: 0.1417 - acc: 0.9976 - val_loss: 0.2118 - val_acc: 0.9720
Epoch 31/50
 - 67s - loss: 0.1413 - acc: 0.9973 - val_loss: 0.2115 - val_acc: 0.9738
Epoch 32/50
 - 67s - loss: 0.1408 - acc: 0.9973 - val_loss: 0.2118 - val_acc: 0.9734
Epoch 33/50
 - 67s - loss: 0.1416 - acc: 0.9972 - val_loss: 0.2109 - val_acc: 0.9733
Epoch 34/50
 - 67s - loss: 0.1421 - acc: 0.9970 - val_loss: 0.2109 - val_acc: 0.9731
Epoch 35/50
 - 67s - loss: 0.1413 - acc: 0.9972 - val_loss: 0.2119 - val_acc: 0.9741
Epoch 36/50
 - 67s - loss: 0.1404 - acc: 0.9974 - val_loss: 0.2110 - val_acc: 0.9741
Epoch 37/50
 - 67s - loss: 0.1406 - acc: 0.9974 - val_loss: 0.2105 - val_acc: 0.9735
Epoch 38/50
 - 67s - loss: 0.1395 - acc: 0.9980 - val_loss: 0.2127 - val_acc: 0.9740
Epoch 39/50
 - 67s - loss: 0.1402 - acc: 0.9972 - val_loss: 0.2107 - val_acc: 0.9746
Epoch 40/50
 - 67s - loss: 0.1390 - acc: 0.9979 - val_loss: 0.2113 - val_acc: 0.9739
Epoch 41/50
 - 67s - loss: 0.1390 - acc: 0.9979 - val_loss: 0.2136 - val_acc: 0.9738

Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 42/50
 - 67s - loss: 0.1386 - acc: 0.9980 - val_loss: 0.2119 - val_acc: 0.9736
Epoch 43/50
 - 67s - loss: 0.1383 - acc: 0.9981 - val_loss: 0.2108 - val_acc: 0.9740
Epoch 44/50
 - 67s - loss: 0.1383 - acc: 0.9979 - val_loss: 0.2115 - val_acc: 0.9731
Epoch 00044: early stopping

  32/7440 [..............................] - ETA: 4s
 128/7440 [..............................] - ETA: 4s
 224/7440 [..............................] - ETA: 4s
 320/7440 [>.............................] - ETA: 4s
 416/7440 [>.............................] - ETA: 4s
 512/7440 [=>............................] - ETA: 4s
 608/7440 [=>............................] - ETA: 4s
 704/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
 992/7440 [===>..........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 2s
2528/7440 [=========>....................] - ETA: 2s
2624/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2816/7440 [==========>...................] - ETA: 2s
2912/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 1s
4160/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4448/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 593us/step
current Test accuracy: 0.7926075268817204
current auc_score ------------------>  0.8889524800554977
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_9[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 96, 96)   1152        activation_139[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 72, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_140[0][0]             
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 34, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_58[0][0]             
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 34, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 96, 96)   2448        activation_141[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 72, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_142[0][0]             
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 52, 96, 96)   0           concatenate_58[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_59[0][0]             
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 52, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 72, 96, 96)   3744        activation_143[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 72, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_144[0][0]             
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 70, 96, 96)   0           concatenate_59[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 96, 96)   280         concatenate_60[0][0]             
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 70, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 72, 96, 96)   5040        activation_145[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 72, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_146[0][0]             
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 88, 96, 96)   0           concatenate_60[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 96, 96)   352         concatenate_61[0][0]             
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 88, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 72, 96, 96)   6336        activation_147[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 72, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_148[0][0]             
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 106, 96, 96)  0           concatenate_61[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 106, 96, 96)  424         concatenate_62[0][0]             
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 106, 96, 96)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 96, 96)   5618        activation_149[0][0]             
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 53, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 48, 48)   212         average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 53, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 48, 48)   3816        activation_150[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 72, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_151[0][0]             
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 71, 48, 48)   0           average_pooling2d_17[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_63[0][0]             
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 71, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 48, 48)   5112        activation_152[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 72, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_153[0][0]             
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 89, 48, 48)   0           concatenate_63[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 89, 48, 48)   356         concatenate_64[0][0]             
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 89, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 72, 48, 48)   6408        activation_154[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 72, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_155[0][0]             
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 107, 48, 48)  0           concatenate_64[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 107, 48, 48)  428         concatenate_65[0][0]             
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 107, 48, 48)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 72, 48, 48)   7704        activation_156[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 72, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_157[0][0]             
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 125, 48, 48)  0           concatenate_65[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 125, 48, 48)  500         concatenate_66[0][0]             
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 125, 48, 48)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 72, 48, 48)   9000        activation_158[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 72, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_159[0][0]             
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 143, 48, 48)  0           concatenate_66[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 143, 48, 48)  572         concatenate_67[0][0]             
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 143, 48, 48)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 143)          0           activation_160[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1)            144         global_average_pooling2d_9[0][0] 
==================================================================================================
Total params: 180,146
Trainable params: 176,798
Non-trainable params: 3,348
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 87s - loss: 0.6219 - acc: 0.7681 - val_loss: 0.5657 - val_acc: 0.7833
Epoch 2/50
 - 80s - loss: 0.5371 - acc: 0.8036 - val_loss: 0.5315 - val_acc: 0.7971
Epoch 3/50
 - 80s - loss: 0.4930 - acc: 0.8243 - val_loss: 0.5072 - val_acc: 0.8205
Epoch 4/50
 - 80s - loss: 0.4668 - acc: 0.8348 - val_loss: 0.4580 - val_acc: 0.8327
Epoch 5/50
 - 80s - loss: 0.4391 - acc: 0.8491 - val_loss: 0.4319 - val_acc: 0.8524
Epoch 6/50
 - 80s - loss: 0.4176 - acc: 0.8575 - val_loss: 0.4260 - val_acc: 0.8548
Epoch 7/50
 - 80s - loss: 0.3972 - acc: 0.8681 - val_loss: 0.4599 - val_acc: 0.8475
Epoch 8/50
 - 80s - loss: 0.3814 - acc: 0.8766 - val_loss: 0.3860 - val_acc: 0.8801
Epoch 9/50
 - 80s - loss: 0.3612 - acc: 0.8858 - val_loss: 0.3747 - val_acc: 0.8850
Epoch 10/50
 - 80s - loss: 0.3405 - acc: 0.8966 - val_loss: 0.6319 - val_acc: 0.7605
Epoch 11/50
 - 80s - loss: 0.3288 - acc: 0.9015 - val_loss: 0.3382 - val_acc: 0.8973
Epoch 12/50
 - 80s - loss: 0.3119 - acc: 0.9087 - val_loss: 0.4336 - val_acc: 0.8574
Epoch 13/50
 - 80s - loss: 0.3022 - acc: 0.9121 - val_loss: 0.4016 - val_acc: 0.8618
Epoch 14/50
 - 80s - loss: 0.2861 - acc: 0.9209 - val_loss: 0.3526 - val_acc: 0.8961
Epoch 15/50
 - 80s - loss: 0.2750 - acc: 0.9249 - val_loss: 0.3088 - val_acc: 0.9100
Epoch 16/50
 - 80s - loss: 0.2653 - acc: 0.9292 - val_loss: 0.3390 - val_acc: 0.8971
Epoch 17/50
 - 80s - loss: 0.2552 - acc: 0.9327 - val_loss: 0.5582 - val_acc: 0.8067
Epoch 18/50
 - 80s - loss: 0.2426 - acc: 0.9383 - val_loss: 0.2994 - val_acc: 0.9133
Epoch 19/50
 - 80s - loss: 0.2391 - acc: 0.9395 - val_loss: 0.3999 - val_acc: 0.8783
Epoch 20/50
 - 80s - loss: 0.2275 - acc: 0.9439 - val_loss: 0.4195 - val_acc: 0.8745
Epoch 21/50
 - 80s - loss: 0.2166 - acc: 0.9480 - val_loss: 0.3958 - val_acc: 0.8878
Epoch 22/50
 - 80s - loss: 0.2103 - acc: 0.9515 - val_loss: 0.3362 - val_acc: 0.8863

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 23/50
 - 80s - loss: 0.1723 - acc: 0.9696 - val_loss: 0.2462 - val_acc: 0.9357
Epoch 24/50
 - 80s - loss: 0.1634 - acc: 0.9735 - val_loss: 0.2438 - val_acc: 0.9357
Epoch 25/50
 - 80s - loss: 0.1592 - acc: 0.9739 - val_loss: 0.2626 - val_acc: 0.9286
Epoch 26/50
 - 80s - loss: 0.1509 - acc: 0.9790 - val_loss: 0.2442 - val_acc: 0.9371
Epoch 27/50
 - 80s - loss: 0.1500 - acc: 0.9781 - val_loss: 0.2409 - val_acc: 0.9384
Epoch 28/50
 - 80s - loss: 0.1452 - acc: 0.9793 - val_loss: 0.2614 - val_acc: 0.9306
Epoch 29/50
 - 80s - loss: 0.1407 - acc: 0.9817 - val_loss: 0.4174 - val_acc: 0.8655
Epoch 30/50
 - 80s - loss: 0.1404 - acc: 0.9808 - val_loss: 0.2495 - val_acc: 0.9330
Epoch 31/50
 - 80s - loss: 0.1352 - acc: 0.9831 - val_loss: 0.2396 - val_acc: 0.9378
Epoch 32/50
 - 80s - loss: 0.1312 - acc: 0.9853 - val_loss: 0.2871 - val_acc: 0.9256
Epoch 33/50
 - 80s - loss: 0.1317 - acc: 0.9840 - val_loss: 0.2727 - val_acc: 0.9270
Epoch 34/50
 - 80s - loss: 0.1252 - acc: 0.9875 - val_loss: 0.2747 - val_acc: 0.9270
Epoch 35/50
 - 80s - loss: 0.1224 - acc: 0.9884 - val_loss: 0.2446 - val_acc: 0.9403

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 36/50
 - 80s - loss: 0.1140 - acc: 0.9927 - val_loss: 0.2316 - val_acc: 0.9421
Epoch 37/50
 - 80s - loss: 0.1112 - acc: 0.9935 - val_loss: 0.2353 - val_acc: 0.9414
Epoch 38/50
 - 80s - loss: 0.1115 - acc: 0.9926 - val_loss: 0.2341 - val_acc: 0.9424
Epoch 39/50
 - 80s - loss: 0.1083 - acc: 0.9936 - val_loss: 0.2414 - val_acc: 0.9379
Epoch 40/50
 - 80s - loss: 0.1094 - acc: 0.9936 - val_loss: 0.2364 - val_acc: 0.9426

Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 41/50
 - 80s - loss: 0.1046 - acc: 0.9952 - val_loss: 0.2348 - val_acc: 0.9419
Epoch 42/50
 - 80s - loss: 0.1045 - acc: 0.9957 - val_loss: 0.2327 - val_acc: 0.9431
Epoch 43/50
 - 80s - loss: 0.1048 - acc: 0.9954 - val_loss: 0.2334 - val_acc: 0.9430
Epoch 00043: early stopping

  32/7440 [..............................] - ETA: 5s
  96/7440 [..............................] - ETA: 5s
 160/7440 [..............................] - ETA: 5s
 224/7440 [..............................] - ETA: 5s
 288/7440 [>.............................] - ETA: 5s
 352/7440 [>.............................] - ETA: 5s
 416/7440 [>.............................] - ETA: 5s
 480/7440 [>.............................] - ETA: 5s
 544/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 5s
 704/7440 [=>............................] - ETA: 5s
 768/7440 [==>...........................] - ETA: 5s
 832/7440 [==>...........................] - ETA: 5s
 896/7440 [==>...........................] - ETA: 5s
 960/7440 [==>...........................] - ETA: 5s
1024/7440 [===>..........................] - ETA: 5s
1088/7440 [===>..........................] - ETA: 5s
1152/7440 [===>..........................] - ETA: 4s
1216/7440 [===>..........................] - ETA: 4s
1280/7440 [====>.........................] - ETA: 4s
1344/7440 [====>.........................] - ETA: 4s
1408/7440 [====>.........................] - ETA: 4s
1472/7440 [====>.........................] - ETA: 4s
1536/7440 [=====>........................] - ETA: 4s
1600/7440 [=====>........................] - ETA: 4s
1664/7440 [=====>........................] - ETA: 4s
1728/7440 [=====>........................] - ETA: 4s
1792/7440 [======>.......................] - ETA: 4s
1856/7440 [======>.......................] - ETA: 4s
1920/7440 [======>.......................] - ETA: 4s
1984/7440 [=======>......................] - ETA: 4s
2048/7440 [=======>......................] - ETA: 4s
2112/7440 [=======>......................] - ETA: 4s
2176/7440 [=======>......................] - ETA: 4s
2240/7440 [========>.....................] - ETA: 4s
2304/7440 [========>.....................] - ETA: 4s
2368/7440 [========>.....................] - ETA: 4s
2432/7440 [========>.....................] - ETA: 3s
2496/7440 [=========>....................] - ETA: 3s
2560/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 3s
2688/7440 [=========>....................] - ETA: 3s
2752/7440 [==========>...................] - ETA: 3s
2816/7440 [==========>...................] - ETA: 3s
2880/7440 [==========>...................] - ETA: 3s
2944/7440 [==========>...................] - ETA: 3s
3008/7440 [===========>..................] - ETA: 3s
3072/7440 [===========>..................] - ETA: 3s
3136/7440 [===========>..................] - ETA: 3s
3200/7440 [===========>..................] - ETA: 3s
3264/7440 [============>.................] - ETA: 3s
3328/7440 [============>.................] - ETA: 3s
3392/7440 [============>.................] - ETA: 3s
3456/7440 [============>.................] - ETA: 3s
3520/7440 [=============>................] - ETA: 3s
3584/7440 [=============>................] - ETA: 3s
3648/7440 [=============>................] - ETA: 2s
3712/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3840/7440 [==============>...............] - ETA: 2s
3904/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4032/7440 [===============>..............] - ETA: 2s
4096/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 2s
4224/7440 [================>.............] - ETA: 2s
4288/7440 [================>.............] - ETA: 2s
4352/7440 [================>.............] - ETA: 2s
4416/7440 [================>.............] - ETA: 2s
4480/7440 [=================>............] - ETA: 2s
4544/7440 [=================>............] - ETA: 2s
4608/7440 [=================>............] - ETA: 2s
4672/7440 [=================>............] - ETA: 2s
4736/7440 [==================>...........] - ETA: 2s
4800/7440 [==================>...........] - ETA: 2s
4864/7440 [==================>...........] - ETA: 2s
4928/7440 [==================>...........] - ETA: 1s
4992/7440 [===================>..........] - ETA: 1s
5056/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5184/7440 [===================>..........] - ETA: 1s
5248/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5376/7440 [====================>.........] - ETA: 1s
5440/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5568/7440 [=====================>........] - ETA: 1s
5632/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5760/7440 [======================>.......] - ETA: 1s
5824/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5952/7440 [=======================>......] - ETA: 1s
6016/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 1s
6144/7440 [=======================>......] - ETA: 1s
6208/7440 [========================>.....] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 796us/step
current Test accuracy: 0.7751344086021505
current auc_score ------------------>  0.8632000086715226
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_10[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_161[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_162[0][0]             
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_68[0][0]             
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_163[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_164[0][0]             
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 28, 96, 96)   0           concatenate_68[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_69[0][0]             
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_165[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_166[0][0]             
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 34, 96, 96)   0           concatenate_69[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_70[0][0]             
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_167[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_168[0][0]             
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 40, 96, 96)   0           concatenate_70[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_71[0][0]             
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_169[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_170[0][0]             
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 46, 96, 96)   0           concatenate_71[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_72[0][0]             
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_171[0][0]             
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_172[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_173[0][0]             
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 29, 48, 48)   0           average_pooling2d_18[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_73[0][0]             
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_174[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_175[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 35, 48, 48)   0           concatenate_73[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_74[0][0]             
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_176[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_177[0][0]             
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 41, 48, 48)   0           concatenate_74[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_75[0][0]             
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_178[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_179[0][0]             
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 47, 48, 48)   0           concatenate_75[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_76[0][0]             
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_180[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_181[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 53, 48, 48)   0           concatenate_76[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_77[0][0]             
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_182[0][0]             
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   624         activation_183[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_184[0][0]             
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 32, 24, 24)   0           average_pooling2d_19[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 32, 24, 24)   128         concatenate_78[0][0]             
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   768         activation_185[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_186[0][0]             
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 38, 24, 24)   0           concatenate_78[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_79[0][0]             
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 38, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   912         activation_187[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_188[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 44, 24, 24)   0           concatenate_79[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_80[0][0]             
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 44, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 24, 24, 24)   1056        activation_189[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 24, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_190[0][0]             
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 50, 24, 24)   0           concatenate_80[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_81[0][0]             
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 50, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 24, 24, 24)   1200        activation_191[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 24, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_192[0][0]             
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 56, 24, 24)   0           concatenate_81[0][0]             
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 56, 24, 24)   224         concatenate_82[0][0]             
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 56, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_10 (Gl (None, 56)           0           activation_193[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1)            57          global_average_pooling2d_10[0][0]
==================================================================================================
Total params: 38,421
Trainable params: 36,381
Non-trainable params: 2,040
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 56s - loss: 0.5807 - acc: 0.7591 - val_loss: 0.5102 - val_acc: 0.7971
Epoch 2/50
 - 47s - loss: 0.4920 - acc: 0.8030 - val_loss: 0.4769 - val_acc: 0.8089
Epoch 3/50
 - 47s - loss: 0.4539 - acc: 0.8224 - val_loss: 0.4553 - val_acc: 0.8296
Epoch 4/50
 - 47s - loss: 0.4268 - acc: 0.8390 - val_loss: 0.3942 - val_acc: 0.8581
Epoch 5/50
 - 47s - loss: 0.4006 - acc: 0.8517 - val_loss: 0.3720 - val_acc: 0.8710
Epoch 6/50
 - 47s - loss: 0.3779 - acc: 0.8665 - val_loss: 0.3977 - val_acc: 0.8562
Epoch 7/50
 - 47s - loss: 0.3657 - acc: 0.8725 - val_loss: 0.3494 - val_acc: 0.8852
Epoch 8/50
 - 47s - loss: 0.3487 - acc: 0.8788 - val_loss: 0.3477 - val_acc: 0.8798
Epoch 9/50
 - 47s - loss: 0.3373 - acc: 0.8846 - val_loss: 0.3500 - val_acc: 0.8854
Epoch 10/50
 - 47s - loss: 0.3251 - acc: 0.8929 - val_loss: 0.3310 - val_acc: 0.8896
Epoch 11/50
 - 47s - loss: 0.3154 - acc: 0.8951 - val_loss: 0.3297 - val_acc: 0.8899
Epoch 12/50
 - 47s - loss: 0.3078 - acc: 0.9008 - val_loss: 0.3315 - val_acc: 0.8907
Epoch 13/50
 - 47s - loss: 0.2996 - acc: 0.9033 - val_loss: 0.4563 - val_acc: 0.8417
Epoch 14/50
 - 47s - loss: 0.2840 - acc: 0.9111 - val_loss: 0.2872 - val_acc: 0.9100
Epoch 15/50
 - 47s - loss: 0.2813 - acc: 0.9127 - val_loss: 0.4622 - val_acc: 0.8212
Epoch 16/50
 - 47s - loss: 0.2726 - acc: 0.9144 - val_loss: 0.2846 - val_acc: 0.9110
Epoch 17/50
 - 47s - loss: 0.2681 - acc: 0.9182 - val_loss: 0.2858 - val_acc: 0.9081
Epoch 18/50
 - 47s - loss: 0.2594 - acc: 0.9220 - val_loss: 0.3181 - val_acc: 0.8919
Epoch 19/50
 - 47s - loss: 0.2533 - acc: 0.9225 - val_loss: 0.2855 - val_acc: 0.9061
Epoch 20/50
 - 47s - loss: 0.2429 - acc: 0.9291 - val_loss: 0.4148 - val_acc: 0.8444

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 21/50
 - 47s - loss: 0.2197 - acc: 0.9395 - val_loss: 0.2731 - val_acc: 0.9174
Epoch 22/50
 - 47s - loss: 0.2149 - acc: 0.9417 - val_loss: 0.2494 - val_acc: 0.9236
Epoch 23/50
 - 47s - loss: 0.2141 - acc: 0.9413 - val_loss: 0.2580 - val_acc: 0.9242
Epoch 24/50
 - 47s - loss: 0.2090 - acc: 0.9447 - val_loss: 0.2639 - val_acc: 0.9178
Epoch 25/50
 - 47s - loss: 0.2084 - acc: 0.9446 - val_loss: 0.2398 - val_acc: 0.9295
Epoch 26/50
 - 47s - loss: 0.2020 - acc: 0.9475 - val_loss: 0.2419 - val_acc: 0.9271
Epoch 27/50
 - 47s - loss: 0.2005 - acc: 0.9485 - val_loss: 0.2372 - val_acc: 0.9278
Epoch 28/50
 - 47s - loss: 0.2030 - acc: 0.9459 - val_loss: 0.2864 - val_acc: 0.9109
Epoch 29/50
 - 47s - loss: 0.1977 - acc: 0.9483 - val_loss: 0.2529 - val_acc: 0.9218
Epoch 30/50
 - 47s - loss: 0.1963 - acc: 0.9494 - val_loss: 0.2471 - val_acc: 0.9276
Epoch 31/50
 - 47s - loss: 0.1917 - acc: 0.9509 - val_loss: 0.2386 - val_acc: 0.9257

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 32/50
 - 47s - loss: 0.1848 - acc: 0.9550 - val_loss: 0.2301 - val_acc: 0.9320
Epoch 33/50
 - 47s - loss: 0.1826 - acc: 0.9568 - val_loss: 0.2257 - val_acc: 0.9355
Epoch 34/50
 - 47s - loss: 0.1821 - acc: 0.9562 - val_loss: 0.2245 - val_acc: 0.9360
Epoch 35/50
 - 47s - loss: 0.1817 - acc: 0.9566 - val_loss: 0.2256 - val_acc: 0.9351
Epoch 36/50
 - 47s - loss: 0.1816 - acc: 0.9570 - val_loss: 0.2238 - val_acc: 0.9359
Epoch 37/50
 - 47s - loss: 0.1810 - acc: 0.9557 - val_loss: 0.2226 - val_acc: 0.9370
Epoch 38/50
 - 47s - loss: 0.1779 - acc: 0.9588 - val_loss: 0.2270 - val_acc: 0.9357
Epoch 39/50
 - 47s - loss: 0.1791 - acc: 0.9566 - val_loss: 0.2241 - val_acc: 0.9384
Epoch 40/50
 - 47s - loss: 0.1776 - acc: 0.9583 - val_loss: 0.2256 - val_acc: 0.9352
Epoch 41/50
 - 47s - loss: 0.1757 - acc: 0.9586 - val_loss: 0.2283 - val_acc: 0.9327

Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 42/50
 - 47s - loss: 0.1736 - acc: 0.9593 - val_loss: 0.2226 - val_acc: 0.9379
Epoch 43/50
 - 47s - loss: 0.1744 - acc: 0.9597 - val_loss: 0.2227 - val_acc: 0.9365
Epoch 44/50
 - 47s - loss: 0.1745 - acc: 0.9580 - val_loss: 0.2233 - val_acc: 0.9375
Epoch 00044: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 445us/step
current Test accuracy: 0.823252688172043
current auc_score ------------------>  0.9152903876170655
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_11[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 96, 96)   1152        activation_194[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 72, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_195[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 34, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_83[0][0]             
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 34, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 96, 96)   2448        activation_196[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 72, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_197[0][0]             
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 52, 96, 96)   0           concatenate_83[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_84[0][0]             
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 52, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 72, 96, 96)   3744        activation_198[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 72, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_199[0][0]             
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 70, 96, 96)   0           concatenate_84[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 96, 96)   280         concatenate_85[0][0]             
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 70, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 72, 96, 96)   5040        activation_200[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 72, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_201[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 88, 96, 96)   0           concatenate_85[0][0]             
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 96, 96)   352         concatenate_86[0][0]             
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 88, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 72, 96, 96)   6336        activation_202[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 72, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_203[0][0]             
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 106, 96, 96)  0           concatenate_86[0][0]             
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 106, 96, 96)  424         concatenate_87[0][0]             
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 106, 96, 96)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 96, 96)   5618        activation_204[0][0]             
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 53, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 48, 48)   212         average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 53, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 48, 48)   3816        activation_205[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 72, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_206[0][0]             
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 71, 48, 48)   0           average_pooling2d_20[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_88[0][0]             
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 71, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 48, 48)   5112        activation_207[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 72, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_208[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 89, 48, 48)   0           concatenate_88[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 89, 48, 48)   356         concatenate_89[0][0]             
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 89, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 72, 48, 48)   6408        activation_209[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 72, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_210[0][0]             
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 107, 48, 48)  0           concatenate_89[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 107, 48, 48)  428         concatenate_90[0][0]             
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 107, 48, 48)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 72, 48, 48)   7704        activation_211[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 72, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_212[0][0]             
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 125, 48, 48)  0           concatenate_90[0][0]             
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 125, 48, 48)  500         concatenate_91[0][0]             
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 125, 48, 48)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 72, 48, 48)   9000        activation_213[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 72, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_214[0][0]             
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 143, 48, 48)  0           concatenate_91[0][0]             
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 143, 48, 48)  572         concatenate_92[0][0]             
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 143, 48, 48)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 71, 48, 48)   10153       activation_215[0][0]             
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 71, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 71, 24, 24)   284         average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 71, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 72, 24, 24)   5112        activation_216[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 72, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_217[0][0]             
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 89, 24, 24)   0           average_pooling2d_21[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 89, 24, 24)   356         concatenate_93[0][0]             
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 89, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 72, 24, 24)   6408        activation_218[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 72, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_219[0][0]             
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 107, 24, 24)  0           concatenate_93[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 107, 24, 24)  428         concatenate_94[0][0]             
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 107, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 72, 24, 24)   7704        activation_220[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 72, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_221[0][0]             
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 125, 24, 24)  0           concatenate_94[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 125, 24, 24)  500         concatenate_95[0][0]             
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 125, 24, 24)  0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 72, 24, 24)   9000        activation_222[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 72, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_223[0][0]             
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 143, 24, 24)  0           concatenate_95[0][0]             
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 143, 24, 24)  572         concatenate_96[0][0]             
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 143, 24, 24)  0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 72, 24, 24)   10296       activation_224[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 72, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_225[0][0]             
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 161, 24, 24)  0           concatenate_96[0][0]             
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 161, 24, 24)  644         concatenate_97[0][0]             
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 161, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_11 (Gl (None, 161)          0           activation_226[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1)            162         global_average_pooling2d_11[0][0]
==================================================================================================
Total params: 291,381
Trainable params: 285,921
Non-trainable params: 5,460
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 99s - loss: 0.6728 - acc: 0.7793 - val_loss: 0.6140 - val_acc: 0.8179
Epoch 2/50
 - 90s - loss: 0.5634 - acc: 0.8345 - val_loss: 0.5069 - val_acc: 0.8650
Epoch 3/50
 - 90s - loss: 0.4988 - acc: 0.8661 - val_loss: 0.4797 - val_acc: 0.8827
Epoch 4/50
 - 90s - loss: 0.4507 - acc: 0.8867 - val_loss: 0.5096 - val_acc: 0.8560
Epoch 5/50
 - 90s - loss: 0.4142 - acc: 0.9009 - val_loss: 0.6270 - val_acc: 0.8367
Epoch 6/50
 - 90s - loss: 0.3799 - acc: 0.9149 - val_loss: 0.4083 - val_acc: 0.9054
Epoch 7/50
 - 90s - loss: 0.3515 - acc: 0.9256 - val_loss: 0.4284 - val_acc: 0.8976
Epoch 8/50
 - 90s - loss: 0.3293 - acc: 0.9337 - val_loss: 0.3473 - val_acc: 0.9262
Epoch 9/50
 - 90s - loss: 0.3110 - acc: 0.9425 - val_loss: 0.3460 - val_acc: 0.9251
Epoch 10/50
 - 90s - loss: 0.2921 - acc: 0.9477 - val_loss: 0.3217 - val_acc: 0.9366
Epoch 11/50
 - 90s - loss: 0.2780 - acc: 0.9531 - val_loss: 0.4099 - val_acc: 0.9050
Epoch 12/50
 - 90s - loss: 0.2581 - acc: 0.9598 - val_loss: 0.6386 - val_acc: 0.8529
Epoch 13/50
 - 90s - loss: 0.2497 - acc: 0.9614 - val_loss: 0.3476 - val_acc: 0.9196
Epoch 14/50
 - 90s - loss: 0.2357 - acc: 0.9670 - val_loss: 0.3062 - val_acc: 0.9415
Epoch 15/50
 - 90s - loss: 0.2311 - acc: 0.9673 - val_loss: 0.3110 - val_acc: 0.9342
Epoch 16/50
 - 90s - loss: 0.2172 - acc: 0.9716 - val_loss: 0.5956 - val_acc: 0.8397
Epoch 17/50
 - 90s - loss: 0.2109 - acc: 0.9741 - val_loss: 0.2820 - val_acc: 0.9497
Epoch 18/50
 - 90s - loss: 0.2066 - acc: 0.9755 - val_loss: 0.6959 - val_acc: 0.8331
Epoch 19/50
 - 90s - loss: 0.1963 - acc: 0.9774 - val_loss: 0.3126 - val_acc: 0.9310
Epoch 20/50
 - 90s - loss: 0.1920 - acc: 0.9795 - val_loss: 0.2845 - val_acc: 0.9473
Epoch 21/50
 - 90s - loss: 0.1893 - acc: 0.9793 - val_loss: 1.5304 - val_acc: 0.6898

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 22/50
 - 90s - loss: 0.1560 - acc: 0.9928 - val_loss: 0.3277 - val_acc: 0.9249
Epoch 23/50
 - 90s - loss: 0.1492 - acc: 0.9950 - val_loss: 0.2493 - val_acc: 0.9612
Epoch 24/50
 - 90s - loss: 0.1459 - acc: 0.9960 - val_loss: 0.2128 - val_acc: 0.9711
Epoch 25/50
 - 90s - loss: 0.1431 - acc: 0.9964 - val_loss: 0.2133 - val_acc: 0.9700
Epoch 26/50
 - 90s - loss: 0.1400 - acc: 0.9968 - val_loss: 0.2420 - val_acc: 0.9626
Epoch 27/50
 - 90s - loss: 0.1384 - acc: 0.9969 - val_loss: 0.2125 - val_acc: 0.9708
Epoch 28/50
 - 90s - loss: 0.1397 - acc: 0.9961 - val_loss: 0.2185 - val_acc: 0.9680
Epoch 29/50
 - 90s - loss: 0.1359 - acc: 0.9969 - val_loss: 0.2600 - val_acc: 0.9585
Epoch 30/50
 - 90s - loss: 0.1341 - acc: 0.9970 - val_loss: 0.2201 - val_acc: 0.9682
Epoch 31/50
 - 90s - loss: 0.1318 - acc: 0.9973 - val_loss: 0.2042 - val_acc: 0.9699
Epoch 32/50
 - 90s - loss: 0.1315 - acc: 0.9972 - val_loss: 0.2279 - val_acc: 0.9652
Epoch 33/50
 - 90s - loss: 0.1310 - acc: 0.9971 - val_loss: 0.2062 - val_acc: 0.9714
Epoch 34/50
 - 90s - loss: 0.1272 - acc: 0.9979 - val_loss: 0.2126 - val_acc: 0.9710
Epoch 35/50
 - 90s - loss: 0.1289 - acc: 0.9968 - val_loss: 0.2044 - val_acc: 0.9700

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 36/50
 - 90s - loss: 0.1224 - acc: 0.9989 - val_loss: 0.2002 - val_acc: 0.9734
Epoch 37/50
 - 90s - loss: 0.1200 - acc: 0.9997 - val_loss: 0.1991 - val_acc: 0.9738
Epoch 38/50
 - 90s - loss: 0.1208 - acc: 0.9990 - val_loss: 0.2109 - val_acc: 0.9715
Epoch 39/50
 - 90s - loss: 0.1196 - acc: 0.9993 - val_loss: 0.2101 - val_acc: 0.9721
Epoch 40/50
 - 91s - loss: 0.1187 - acc: 0.9993 - val_loss: 0.1945 - val_acc: 0.9736
Epoch 41/50
 - 90s - loss: 0.1176 - acc: 0.9997 - val_loss: 0.1971 - val_acc: 0.9741
Epoch 42/50
 - 90s - loss: 0.1171 - acc: 0.9997 - val_loss: 0.1980 - val_acc: 0.9720
Epoch 43/50
 - 90s - loss: 0.1171 - acc: 0.9993 - val_loss: 0.2198 - val_acc: 0.9693
Epoch 44/50
 - 90s - loss: 0.1160 - acc: 0.9997 - val_loss: 0.1938 - val_acc: 0.9729
Epoch 45/50
 - 90s - loss: 0.1154 - acc: 0.9995 - val_loss: 0.1974 - val_acc: 0.9728
Epoch 46/50
 - 90s - loss: 0.1151 - acc: 0.9994 - val_loss: 0.2036 - val_acc: 0.9714
Epoch 47/50
 - 90s - loss: 0.1137 - acc: 0.9997 - val_loss: 0.1967 - val_acc: 0.9725
Epoch 48/50
 - 90s - loss: 0.1139 - acc: 0.9995 - val_loss: 0.1954 - val_acc: 0.9735

Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 49/50
 - 90s - loss: 0.1127 - acc: 0.9997 - val_loss: 0.1984 - val_acc: 0.9733
Epoch 50/50
 - 90s - loss: 0.1121 - acc: 0.9998 - val_loss: 0.1942 - val_acc: 0.9741

  32/7440 [..............................] - ETA: 6s
  96/7440 [..............................] - ETA: 6s
 160/7440 [..............................] - ETA: 6s
 224/7440 [..............................] - ETA: 6s
 288/7440 [>.............................] - ETA: 6s
 352/7440 [>.............................] - ETA: 6s
 416/7440 [>.............................] - ETA: 6s
 480/7440 [>.............................] - ETA: 6s
 544/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 5s
 672/7440 [=>............................] - ETA: 5s
 736/7440 [=>............................] - ETA: 5s
 800/7440 [==>...........................] - ETA: 5s
 864/7440 [==>...........................] - ETA: 5s
 928/7440 [==>...........................] - ETA: 5s
 992/7440 [===>..........................] - ETA: 5s
1056/7440 [===>..........................] - ETA: 5s
1120/7440 [===>..........................] - ETA: 5s
1184/7440 [===>..........................] - ETA: 5s
1248/7440 [====>.........................] - ETA: 5s
1312/7440 [====>.........................] - ETA: 5s
1376/7440 [====>.........................] - ETA: 5s
1440/7440 [====>.........................] - ETA: 5s
1504/7440 [=====>........................] - ETA: 5s
1568/7440 [=====>........................] - ETA: 5s
1632/7440 [=====>........................] - ETA: 5s
1696/7440 [=====>........................] - ETA: 4s
1760/7440 [======>.......................] - ETA: 4s
1824/7440 [======>.......................] - ETA: 4s
1888/7440 [======>.......................] - ETA: 4s
1952/7440 [======>.......................] - ETA: 4s
2016/7440 [=======>......................] - ETA: 4s
2080/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 4s
2208/7440 [=======>......................] - ETA: 4s
2272/7440 [========>.....................] - ETA: 4s
2336/7440 [========>.....................] - ETA: 4s
2400/7440 [========>.....................] - ETA: 4s
2464/7440 [========>.....................] - ETA: 4s
2528/7440 [=========>....................] - ETA: 4s
2592/7440 [=========>....................] - ETA: 4s
2656/7440 [=========>....................] - ETA: 4s
2720/7440 [=========>....................] - ETA: 4s
2784/7440 [==========>...................] - ETA: 4s
2848/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 3s
2976/7440 [===========>..................] - ETA: 3s
3040/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3168/7440 [===========>..................] - ETA: 3s
3232/7440 [============>.................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3360/7440 [============>.................] - ETA: 3s
3424/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 3s
3552/7440 [=============>................] - ETA: 3s
3616/7440 [=============>................] - ETA: 3s
3680/7440 [=============>................] - ETA: 3s
3744/7440 [==============>...............] - ETA: 3s
3808/7440 [==============>...............] - ETA: 3s
3872/7440 [==============>...............] - ETA: 3s
3936/7440 [==============>...............] - ETA: 3s
4000/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4128/7440 [===============>..............] - ETA: 2s
4192/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4320/7440 [================>.............] - ETA: 2s
4384/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 2s
4576/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4704/7440 [=================>............] - ETA: 2s
4768/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4896/7440 [==================>...........] - ETA: 2s
4960/7440 [===================>..........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 2s
5088/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5344/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5728/7440 [======================>.......] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5856/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6048/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6240/7440 [========================>.....] - ETA: 1s
6304/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 865us/step
current Test accuracy: 0.7752688172043011
current auc_score ------------------>  0.8909878670944618
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_227 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_22 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_228 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_23 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_229 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_12  (None, 4)                 0         
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 13s - loss: 0.6496 - acc: 0.6821 - val_loss: 0.6330 - val_acc: 0.7023
Epoch 2/50
 - 8s - loss: 0.6289 - acc: 0.7004 - val_loss: 0.6191 - val_acc: 0.7090
Epoch 3/50
 - 8s - loss: 0.6140 - acc: 0.7104 - val_loss: 0.6058 - val_acc: 0.7185
Epoch 4/50
 - 8s - loss: 0.5985 - acc: 0.7205 - val_loss: 0.5941 - val_acc: 0.7248
Epoch 5/50
 - 8s - loss: 0.5870 - acc: 0.7268 - val_loss: 0.5780 - val_acc: 0.7312
Epoch 6/50
 - 8s - loss: 0.5738 - acc: 0.7329 - val_loss: 0.5761 - val_acc: 0.7295
Epoch 7/50
 - 8s - loss: 0.5625 - acc: 0.7386 - val_loss: 0.5771 - val_acc: 0.7169
Epoch 8/50
 - 8s - loss: 0.5543 - acc: 0.7450 - val_loss: 0.6072 - val_acc: 0.7116
Epoch 9/50
 - 8s - loss: 0.5443 - acc: 0.7486 - val_loss: 0.5471 - val_acc: 0.7446
Epoch 10/50
 - 8s - loss: 0.5352 - acc: 0.7539 - val_loss: 0.5299 - val_acc: 0.7515
Epoch 11/50
 - 8s - loss: 0.5281 - acc: 0.7575 - val_loss: 0.5248 - val_acc: 0.7528
Epoch 12/50
 - 8s - loss: 0.5234 - acc: 0.7577 - val_loss: 0.5252 - val_acc: 0.7590
Epoch 13/50
 - 8s - loss: 0.5188 - acc: 0.7566 - val_loss: 0.5549 - val_acc: 0.7487
Epoch 14/50
 - 8s - loss: 0.5152 - acc: 0.7600 - val_loss: 0.5142 - val_acc: 0.7583
Epoch 15/50
 - 8s - loss: 0.5113 - acc: 0.7586 - val_loss: 0.5137 - val_acc: 0.7492
Epoch 16/50
 - 8s - loss: 0.5072 - acc: 0.7611 - val_loss: 0.5035 - val_acc: 0.7607
Epoch 17/50
 - 8s - loss: 0.5037 - acc: 0.7634 - val_loss: 0.5294 - val_acc: 0.7337
Epoch 18/50
 - 8s - loss: 0.5048 - acc: 0.7621 - val_loss: 0.5045 - val_acc: 0.7560
Epoch 19/50
 - 8s - loss: 0.5005 - acc: 0.7635 - val_loss: 0.5039 - val_acc: 0.7508
Epoch 20/50
 - 8s - loss: 0.5015 - acc: 0.7612 - val_loss: 0.5009 - val_acc: 0.7620
Epoch 21/50
 - 8s - loss: 0.4988 - acc: 0.7611 - val_loss: 0.4956 - val_acc: 0.7642
Epoch 22/50
 - 8s - loss: 0.4991 - acc: 0.7620 - val_loss: 0.5005 - val_acc: 0.7564
Epoch 23/50
 - 8s - loss: 0.4958 - acc: 0.7650 - val_loss: 0.4969 - val_acc: 0.7553
Epoch 24/50
 - 8s - loss: 0.4952 - acc: 0.7645 - val_loss: 0.5198 - val_acc: 0.7603
Epoch 25/50
 - 8s - loss: 0.4924 - acc: 0.7651 - val_loss: 0.4879 - val_acc: 0.7658
Epoch 26/50
 - 8s - loss: 0.4933 - acc: 0.7643 - val_loss: 0.4929 - val_acc: 0.7577
Epoch 27/50
 - 8s - loss: 0.4905 - acc: 0.7673 - val_loss: 0.5150 - val_acc: 0.7619
Epoch 28/50
 - 8s - loss: 0.4898 - acc: 0.7662 - val_loss: 0.4871 - val_acc: 0.7702
Epoch 29/50
 - 8s - loss: 0.4866 - acc: 0.7695 - val_loss: 0.4951 - val_acc: 0.7707
Epoch 30/50
 - 8s - loss: 0.4884 - acc: 0.7676 - val_loss: 0.4814 - val_acc: 0.7684
Epoch 31/50
 - 8s - loss: 0.4874 - acc: 0.7670 - val_loss: 0.4915 - val_acc: 0.7642
Epoch 32/50
 - 8s - loss: 0.4848 - acc: 0.7707 - val_loss: 0.4794 - val_acc: 0.7683
Epoch 33/50
 - 8s - loss: 0.4862 - acc: 0.7705 - val_loss: 0.4908 - val_acc: 0.7721
Epoch 34/50
 - 8s - loss: 0.4845 - acc: 0.7694 - val_loss: 0.5027 - val_acc: 0.7480
Epoch 35/50
 - 8s - loss: 0.4836 - acc: 0.7673 - val_loss: 0.4894 - val_acc: 0.7553
Epoch 36/50
 - 8s - loss: 0.4836 - acc: 0.7685 - val_loss: 0.5183 - val_acc: 0.7648

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 37/50
 - 8s - loss: 0.4801 - acc: 0.7717 - val_loss: 0.4781 - val_acc: 0.7691
Epoch 38/50
 - 8s - loss: 0.4799 - acc: 0.7717 - val_loss: 0.4819 - val_acc: 0.7610
Epoch 39/50
 - 8s - loss: 0.4797 - acc: 0.7750 - val_loss: 0.4809 - val_acc: 0.7707
Epoch 40/50
 - 8s - loss: 0.4786 - acc: 0.7724 - val_loss: 0.4782 - val_acc: 0.7657
Epoch 41/50
 - 8s - loss: 0.4783 - acc: 0.7739 - val_loss: 0.4755 - val_acc: 0.7696
Epoch 42/50
 - 8s - loss: 0.4808 - acc: 0.7712 - val_loss: 0.4867 - val_acc: 0.7720
Epoch 43/50
 - 8s - loss: 0.4781 - acc: 0.7743 - val_loss: 0.4831 - val_acc: 0.7633
Epoch 44/50
 - 8s - loss: 0.4786 - acc: 0.7717 - val_loss: 0.4736 - val_acc: 0.7715
Epoch 45/50
 - 9s - loss: 0.4771 - acc: 0.7745 - val_loss: 0.4849 - val_acc: 0.7595
Epoch 46/50
 - 9s - loss: 0.4777 - acc: 0.7759 - val_loss: 0.4820 - val_acc: 0.7746
Epoch 47/50
 - 9s - loss: 0.4773 - acc: 0.7742 - val_loss: 0.4728 - val_acc: 0.7722
Epoch 48/50
 - 9s - loss: 0.4759 - acc: 0.7747 - val_loss: 0.4772 - val_acc: 0.7785
Epoch 49/50
 - 9s - loss: 0.4781 - acc: 0.7753 - val_loss: 0.4783 - val_acc: 0.7638
Epoch 50/50
 - 8s - loss: 0.4769 - acc: 0.7733 - val_loss: 0.4708 - val_acc: 0.7727

  32/7440 [..............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 0s
 864/7440 [==>...........................] - ETA: 0s
1280/7440 [====>.........................] - ETA: 0s
1664/7440 [=====>........................] - ETA: 0s
2080/7440 [=======>......................] - ETA: 0s
2464/7440 [========>.....................] - ETA: 0s
2880/7440 [==========>...................] - ETA: 0s
3296/7440 [============>.................] - ETA: 0s
3712/7440 [=============>................] - ETA: 0s
4128/7440 [===============>..............] - ETA: 0s
4544/7440 [=================>............] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7440/7440 [==============================] - 1s 127us/step
current Test accuracy: 0.8060483870967742
current auc_score ------------------>  0.8701720213319459
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_13[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 96, 96)   1152        activation_230[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 72, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_231[0][0]             
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 34, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_98[0][0]             
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 34, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 96, 96)   2448        activation_232[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 72, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_233[0][0]             
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 52, 96, 96)   0           concatenate_98[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 96, 96)   208         concatenate_99[0][0]             
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 52, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 72, 96, 96)   3744        activation_234[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 72, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_235[0][0]             
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 70, 96, 96)   0           concatenate_99[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 96, 96)   280         concatenate_100[0][0]            
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 70, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 72, 96, 96)   5040        activation_236[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 72, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_237[0][0]             
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 88, 96, 96)   0           concatenate_100[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 96, 96)   352         concatenate_101[0][0]            
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 88, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 72, 96, 96)   6336        activation_238[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 72, 96, 96)   288         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 72, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 96, 96)   11664       activation_239[0][0]             
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 106, 96, 96)  0           concatenate_101[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 106, 96, 96)  424         concatenate_102[0][0]            
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 106, 96, 96)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 96, 96)   5618        activation_240[0][0]             
__________________________________________________________________________________________________
average_pooling2d_24 (AveragePo (None, 53, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 48, 48)   212         average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 53, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 48, 48)   3816        activation_241[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 72, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_242[0][0]             
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 71, 48, 48)   0           average_pooling2d_24[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_103[0][0]            
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 71, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 48, 48)   5112        activation_243[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 72, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_244[0][0]             
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 89, 48, 48)   0           concatenate_103[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 89, 48, 48)   356         concatenate_104[0][0]            
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 89, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 72, 48, 48)   6408        activation_245[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 72, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_246[0][0]             
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 107, 48, 48)  0           concatenate_104[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 107, 48, 48)  428         concatenate_105[0][0]            
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 107, 48, 48)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 72, 48, 48)   7704        activation_247[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 72, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_248[0][0]             
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 125, 48, 48)  0           concatenate_105[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 125, 48, 48)  500         concatenate_106[0][0]            
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 125, 48, 48)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 72, 48, 48)   9000        activation_249[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 72, 48, 48)   288         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 72, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 48, 48)   11664       activation_250[0][0]             
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 143, 48, 48)  0           concatenate_106[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 143, 48, 48)  572         concatenate_107[0][0]            
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 143, 48, 48)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 71, 48, 48)   10153       activation_251[0][0]             
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 71, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 71, 24, 24)   284         average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 71, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 72, 24, 24)   5112        activation_252[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 72, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_253[0][0]             
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 89, 24, 24)   0           average_pooling2d_25[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 89, 24, 24)   356         concatenate_108[0][0]            
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 89, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 72, 24, 24)   6408        activation_254[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 72, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_255[0][0]             
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 107, 24, 24)  0           concatenate_108[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 107, 24, 24)  428         concatenate_109[0][0]            
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 107, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 72, 24, 24)   7704        activation_256[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 72, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_257[0][0]             
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 125, 24, 24)  0           concatenate_109[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 125, 24, 24)  500         concatenate_110[0][0]            
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 125, 24, 24)  0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 72, 24, 24)   9000        activation_258[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 72, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_259[0][0]             
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 143, 24, 24)  0           concatenate_110[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 143, 24, 24)  572         concatenate_111[0][0]            
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 143, 24, 24)  0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 72, 24, 24)   10296       activation_260[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_261 (Activation)     (None, 72, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_261[0][0]             
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 161, 24, 24)  0           concatenate_111[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 161, 24, 24)  644         concatenate_112[0][0]            
__________________________________________________________________________________________________
activation_262 (Activation)     (None, 161, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_13 (Gl (None, 161)          0           activation_262[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1)            162         global_average_pooling2d_13[0][0]
==================================================================================================
Total params: 291,381
Trainable params: 285,921
Non-trainable params: 5,460
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 102s - loss: 0.6721 - acc: 0.7862 - val_loss: 0.6240 - val_acc: 0.8082
Epoch 2/50
 - 90s - loss: 0.5564 - acc: 0.8378 - val_loss: 0.5968 - val_acc: 0.8183
Epoch 3/50
 - 90s - loss: 0.4904 - acc: 0.8671 - val_loss: 0.4793 - val_acc: 0.8763
Epoch 4/50
 - 90s - loss: 0.4413 - acc: 0.8892 - val_loss: 0.4240 - val_acc: 0.8983
Epoch 5/50
 - 90s - loss: 0.4025 - acc: 0.9048 - val_loss: 0.4139 - val_acc: 0.9026
Epoch 6/50
 - 90s - loss: 0.3743 - acc: 0.9166 - val_loss: 0.5111 - val_acc: 0.8668
Epoch 7/50
 - 90s - loss: 0.3390 - acc: 0.9324 - val_loss: 0.3812 - val_acc: 0.9188
Epoch 8/50
 - 90s - loss: 0.3234 - acc: 0.9359 - val_loss: 0.3440 - val_acc: 0.9247
Epoch 9/50
 - 90s - loss: 0.3001 - acc: 0.9432 - val_loss: 0.3234 - val_acc: 0.9335
Epoch 10/50
 - 90s - loss: 0.2854 - acc: 0.9496 - val_loss: 0.4708 - val_acc: 0.8843
Epoch 11/50
 - 90s - loss: 0.2684 - acc: 0.9551 - val_loss: 0.3189 - val_acc: 0.9344
Epoch 12/50
 - 90s - loss: 0.2559 - acc: 0.9606 - val_loss: 0.3149 - val_acc: 0.9340
Epoch 13/50
 - 90s - loss: 0.2467 - acc: 0.9625 - val_loss: 0.3082 - val_acc: 0.9398
Epoch 14/50
 - 90s - loss: 0.2348 - acc: 0.9665 - val_loss: 0.3350 - val_acc: 0.9322
Epoch 15/50
 - 90s - loss: 0.2262 - acc: 0.9694 - val_loss: 0.3514 - val_acc: 0.9209
Epoch 16/50
 - 90s - loss: 0.2157 - acc: 0.9734 - val_loss: 0.2786 - val_acc: 0.9498
Epoch 17/50
 - 90s - loss: 0.2098 - acc: 0.9740 - val_loss: 0.2762 - val_acc: 0.9454
Epoch 18/50
 - 90s - loss: 0.2078 - acc: 0.9736 - val_loss: 0.2925 - val_acc: 0.9435
Epoch 19/50
 - 90s - loss: 0.1998 - acc: 0.9768 - val_loss: 0.2801 - val_acc: 0.9463
Epoch 20/50
 - 90s - loss: 0.1895 - acc: 0.9794 - val_loss: 0.2882 - val_acc: 0.9465
Epoch 21/50
 - 90s - loss: 0.1841 - acc: 0.9811 - val_loss: 0.3093 - val_acc: 0.9332

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 22/50
 - 90s - loss: 0.1546 - acc: 0.9932 - val_loss: 0.2558 - val_acc: 0.9558
Epoch 23/50
 - 90s - loss: 0.1472 - acc: 0.9955 - val_loss: 0.2418 - val_acc: 0.9602
Epoch 24/50
 - 90s - loss: 0.1439 - acc: 0.9964 - val_loss: 0.2374 - val_acc: 0.9640
Epoch 25/50
 - 90s - loss: 0.1437 - acc: 0.9953 - val_loss: 0.2183 - val_acc: 0.9665
Epoch 26/50
 - 90s - loss: 0.1388 - acc: 0.9971 - val_loss: 0.2306 - val_acc: 0.9654
Epoch 27/50
 - 90s - loss: 0.1402 - acc: 0.9961 - val_loss: 0.2158 - val_acc: 0.9691
Epoch 28/50
 - 90s - loss: 0.1362 - acc: 0.9972 - val_loss: 0.2223 - val_acc: 0.9660
Epoch 29/50
 - 90s - loss: 0.1339 - acc: 0.9973 - val_loss: 0.2192 - val_acc: 0.9669
Epoch 30/50
 - 90s - loss: 0.1329 - acc: 0.9971 - val_loss: 0.2369 - val_acc: 0.9625
Epoch 31/50
 - 90s - loss: 0.1295 - acc: 0.9979 - val_loss: 0.2445 - val_acc: 0.9618

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 32/50
 - 90s - loss: 0.1261 - acc: 0.9988 - val_loss: 0.2081 - val_acc: 0.9688
Epoch 33/50
 - 90s - loss: 0.1243 - acc: 0.9993 - val_loss: 0.2107 - val_acc: 0.9695
Epoch 34/50
 - 90s - loss: 0.1239 - acc: 0.9994 - val_loss: 0.2147 - val_acc: 0.9669
Epoch 35/50
 - 90s - loss: 0.1227 - acc: 0.9994 - val_loss: 0.2156 - val_acc: 0.9690
Epoch 36/50
 - 90s - loss: 0.1223 - acc: 0.9992 - val_loss: 0.2098 - val_acc: 0.9704

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 37/50
 - 90s - loss: 0.1209 - acc: 0.9997 - val_loss: 0.2078 - val_acc: 0.9699
Epoch 38/50
 - 90s - loss: 0.1202 - acc: 0.9998 - val_loss: 0.2068 - val_acc: 0.9710
Epoch 39/50
 - 90s - loss: 0.1204 - acc: 0.9996 - val_loss: 0.2074 - val_acc: 0.9703
Epoch 40/50
 - 90s - loss: 0.1202 - acc: 0.9994 - val_loss: 0.2070 - val_acc: 0.9704
Epoch 41/50
 - 90s - loss: 0.1203 - acc: 0.9996 - val_loss: 0.2059 - val_acc: 0.9710
Epoch 42/50
 - 91s - loss: 0.1197 - acc: 0.9996 - val_loss: 0.2054 - val_acc: 0.9711
Epoch 43/50
 - 90s - loss: 0.1199 - acc: 0.9994 - val_loss: 0.2102 - val_acc: 0.9705
Epoch 44/50
 - 90s - loss: 0.1195 - acc: 0.9996 - val_loss: 0.2038 - val_acc: 0.9716
Epoch 45/50
 - 90s - loss: 0.1184 - acc: 0.9998 - val_loss: 0.2052 - val_acc: 0.9710
Epoch 46/50
 - 91s - loss: 0.1180 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9709
Epoch 47/50
 - 90s - loss: 0.1187 - acc: 0.9995 - val_loss: 0.2040 - val_acc: 0.9713
Epoch 48/50
 - 90s - loss: 0.1181 - acc: 0.9997 - val_loss: 0.2025 - val_acc: 0.9715
Epoch 49/50
 - 90s - loss: 0.1177 - acc: 0.9997 - val_loss: 0.2023 - val_acc: 0.9716
Epoch 50/50
 - 90s - loss: 0.1174 - acc: 0.9999 - val_loss: 0.2035 - val_acc: 0.9710

  32/7440 [..............................] - ETA: 6s
  96/7440 [..............................] - ETA: 6s
 160/7440 [..............................] - ETA: 6s
 224/7440 [..............................] - ETA: 6s
 288/7440 [>.............................] - ETA: 6s
 352/7440 [>.............................] - ETA: 6s
 416/7440 [>.............................] - ETA: 6s
 480/7440 [>.............................] - ETA: 6s
 544/7440 [=>............................] - ETA: 6s
 608/7440 [=>............................] - ETA: 6s
 672/7440 [=>............................] - ETA: 5s
 736/7440 [=>............................] - ETA: 5s
 800/7440 [==>...........................] - ETA: 5s
 864/7440 [==>...........................] - ETA: 5s
 928/7440 [==>...........................] - ETA: 5s
 992/7440 [===>..........................] - ETA: 5s
1056/7440 [===>..........................] - ETA: 5s
1120/7440 [===>..........................] - ETA: 5s
1184/7440 [===>..........................] - ETA: 5s
1248/7440 [====>.........................] - ETA: 5s
1312/7440 [====>.........................] - ETA: 5s
1376/7440 [====>.........................] - ETA: 5s
1440/7440 [====>.........................] - ETA: 5s
1504/7440 [=====>........................] - ETA: 5s
1568/7440 [=====>........................] - ETA: 5s
1632/7440 [=====>........................] - ETA: 5s
1696/7440 [=====>........................] - ETA: 5s
1760/7440 [======>.......................] - ETA: 5s
1824/7440 [======>.......................] - ETA: 4s
1888/7440 [======>.......................] - ETA: 4s
1952/7440 [======>.......................] - ETA: 4s
2016/7440 [=======>......................] - ETA: 4s
2080/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 4s
2208/7440 [=======>......................] - ETA: 4s
2272/7440 [========>.....................] - ETA: 4s
2336/7440 [========>.....................] - ETA: 4s
2400/7440 [========>.....................] - ETA: 4s
2464/7440 [========>.....................] - ETA: 4s
2528/7440 [=========>....................] - ETA: 4s
2592/7440 [=========>....................] - ETA: 4s
2656/7440 [=========>....................] - ETA: 4s
2720/7440 [=========>....................] - ETA: 4s
2784/7440 [==========>...................] - ETA: 4s
2848/7440 [==========>...................] - ETA: 4s
2912/7440 [==========>...................] - ETA: 4s
2976/7440 [===========>..................] - ETA: 3s
3040/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3168/7440 [===========>..................] - ETA: 3s
3232/7440 [============>.................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3360/7440 [============>.................] - ETA: 3s
3424/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 3s
3552/7440 [=============>................] - ETA: 3s
3616/7440 [=============>................] - ETA: 3s
3680/7440 [=============>................] - ETA: 3s
3744/7440 [==============>...............] - ETA: 3s
3808/7440 [==============>...............] - ETA: 3s
3872/7440 [==============>...............] - ETA: 3s
3936/7440 [==============>...............] - ETA: 3s
4000/7440 [===============>..............] - ETA: 3s
4064/7440 [===============>..............] - ETA: 2s
4128/7440 [===============>..............] - ETA: 2s
4192/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4320/7440 [================>.............] - ETA: 2s
4384/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 2s
4576/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4704/7440 [=================>............] - ETA: 2s
4768/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4896/7440 [==================>...........] - ETA: 2s
4960/7440 [===================>..........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 2s
5088/7440 [===================>..........] - ETA: 2s
5152/7440 [===================>..........] - ETA: 2s
5216/7440 [====================>.........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5344/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5728/7440 [======================>.......] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5856/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6048/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6240/7440 [========================>.....] - ETA: 1s
6304/7440 [========================>.....] - ETA: 1s
6368/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 7s 885us/step
current Test accuracy: 0.7516129032258064
current auc_score ------------------>  0.8714058344895363
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_263 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_26 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 8, 48, 48)         32        
_________________________________________________________________
activation_264 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
global_average_pooling2d_14  (None, 8)                 0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 9         
=================================================================
Total params: 521
Trainable params: 473
Non-trainable params: 48
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 14s - loss: 0.6522 - acc: 0.6538 - val_loss: 0.6256 - val_acc: 0.7028
Epoch 2/50
 - 8s - loss: 0.6204 - acc: 0.6969 - val_loss: 0.6146 - val_acc: 0.7056
Epoch 3/50
 - 8s - loss: 0.6092 - acc: 0.6994 - val_loss: 0.6039 - val_acc: 0.7092
Epoch 4/50
 - 8s - loss: 0.5989 - acc: 0.7094 - val_loss: 0.5940 - val_acc: 0.7129
Epoch 5/50
 - 8s - loss: 0.5914 - acc: 0.7126 - val_loss: 0.6026 - val_acc: 0.6953
Epoch 6/50
 - 8s - loss: 0.5828 - acc: 0.7211 - val_loss: 0.5830 - val_acc: 0.7218
Epoch 7/50
 - 8s - loss: 0.5754 - acc: 0.7257 - val_loss: 0.5732 - val_acc: 0.7288
Epoch 8/50
 - 8s - loss: 0.5686 - acc: 0.7296 - val_loss: 0.5862 - val_acc: 0.7093
Epoch 9/50
 - 8s - loss: 0.5646 - acc: 0.7313 - val_loss: 0.5732 - val_acc: 0.7176
Epoch 10/50
 - 8s - loss: 0.5585 - acc: 0.7354 - val_loss: 0.5754 - val_acc: 0.7115
Epoch 11/50
 - 8s - loss: 0.5558 - acc: 0.7363 - val_loss: 0.5617 - val_acc: 0.7338
Epoch 12/50
 - 8s - loss: 0.5522 - acc: 0.7380 - val_loss: 0.5516 - val_acc: 0.7416
Epoch 13/50
 - 8s - loss: 0.5483 - acc: 0.7386 - val_loss: 0.5623 - val_acc: 0.7262
Epoch 14/50
 - 8s - loss: 0.5454 - acc: 0.7443 - val_loss: 0.5439 - val_acc: 0.7420
Epoch 15/50
 - 8s - loss: 0.5446 - acc: 0.7424 - val_loss: 0.5461 - val_acc: 0.7395
Epoch 16/50
 - 8s - loss: 0.5424 - acc: 0.7440 - val_loss: 0.5496 - val_acc: 0.7328
Epoch 17/50
 - 8s - loss: 0.5392 - acc: 0.7465 - val_loss: 0.5458 - val_acc: 0.7408
Epoch 18/50
 - 8s - loss: 0.5390 - acc: 0.7456 - val_loss: 0.5404 - val_acc: 0.7417
Epoch 19/50
 - 8s - loss: 0.5362 - acc: 0.7471 - val_loss: 0.5383 - val_acc: 0.7392
Epoch 20/50
 - 8s - loss: 0.5355 - acc: 0.7498 - val_loss: 0.5622 - val_acc: 0.7377
Epoch 21/50
 - 8s - loss: 0.5358 - acc: 0.7468 - val_loss: 0.5412 - val_acc: 0.7382
Epoch 22/50
 - 8s - loss: 0.5333 - acc: 0.7499 - val_loss: 0.5350 - val_acc: 0.7491
Epoch 23/50
 - 8s - loss: 0.5321 - acc: 0.7483 - val_loss: 0.5534 - val_acc: 0.7258
Epoch 24/50
 - 8s - loss: 0.5301 - acc: 0.7503 - val_loss: 0.5742 - val_acc: 0.7303
Epoch 25/50
 - 8s - loss: 0.5310 - acc: 0.7486 - val_loss: 0.5309 - val_acc: 0.7515
Epoch 26/50
 - 8s - loss: 0.5294 - acc: 0.7481 - val_loss: 0.5741 - val_acc: 0.7097
Epoch 27/50
 - 8s - loss: 0.5275 - acc: 0.7513 - val_loss: 0.5281 - val_acc: 0.7509
Epoch 28/50
 - 8s - loss: 0.5287 - acc: 0.7504 - val_loss: 0.5443 - val_acc: 0.7461
Epoch 29/50
 - 8s - loss: 0.5273 - acc: 0.7520 - val_loss: 0.5260 - val_acc: 0.7501
Epoch 30/50
 - 8s - loss: 0.5284 - acc: 0.7493 - val_loss: 0.5285 - val_acc: 0.7500
Epoch 31/50
 - 8s - loss: 0.5261 - acc: 0.7519 - val_loss: 0.5381 - val_acc: 0.7324
Epoch 32/50
 - 8s - loss: 0.5263 - acc: 0.7505 - val_loss: 0.5375 - val_acc: 0.7310
Epoch 33/50
 - 8s - loss: 0.5257 - acc: 0.7506 - val_loss: 0.6058 - val_acc: 0.6904

Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 34/50
 - 8s - loss: 0.5227 - acc: 0.7519 - val_loss: 0.5228 - val_acc: 0.7495
Epoch 35/50
 - 8s - loss: 0.5229 - acc: 0.7541 - val_loss: 0.5248 - val_acc: 0.7460
Epoch 36/50
 - 8s - loss: 0.5247 - acc: 0.7497 - val_loss: 0.5238 - val_acc: 0.7465
Epoch 37/50
 - 8s - loss: 0.5246 - acc: 0.7519 - val_loss: 0.5226 - val_acc: 0.7515
Epoch 38/50
 - 8s - loss: 0.5237 - acc: 0.7524 - val_loss: 0.5458 - val_acc: 0.7284
Epoch 39/50
 - 8s - loss: 0.5228 - acc: 0.7513 - val_loss: 0.5269 - val_acc: 0.7467
Epoch 40/50
 - 8s - loss: 0.5231 - acc: 0.7530 - val_loss: 0.5221 - val_acc: 0.7516
Epoch 41/50
 - 8s - loss: 0.5233 - acc: 0.7510 - val_loss: 0.5267 - val_acc: 0.7433
Epoch 42/50
 - 8s - loss: 0.5228 - acc: 0.7497 - val_loss: 0.5214 - val_acc: 0.7526
Epoch 43/50
 - 8s - loss: 0.5207 - acc: 0.7532 - val_loss: 0.5239 - val_acc: 0.7526
Epoch 44/50
 - 8s - loss: 0.5233 - acc: 0.7514 - val_loss: 0.5380 - val_acc: 0.7500
Epoch 45/50
 - 8s - loss: 0.5223 - acc: 0.7530 - val_loss: 0.5220 - val_acc: 0.7489
Epoch 46/50
 - 8s - loss: 0.5232 - acc: 0.7519 - val_loss: 0.5208 - val_acc: 0.7475
Epoch 47/50
 - 8s - loss: 0.5220 - acc: 0.7537 - val_loss: 0.5222 - val_acc: 0.7462
Epoch 48/50
 - 8s - loss: 0.5210 - acc: 0.7521 - val_loss: 0.5197 - val_acc: 0.7490
Epoch 49/50
 - 8s - loss: 0.5218 - acc: 0.7522 - val_loss: 0.5195 - val_acc: 0.7520
Epoch 50/50
 - 8s - loss: 0.5217 - acc: 0.7522 - val_loss: 0.5218 - val_acc: 0.7530

  32/7440 [..............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 0s
 864/7440 [==>...........................] - ETA: 0s
1280/7440 [====>.........................] - ETA: 0s
1696/7440 [=====>........................] - ETA: 0s
2112/7440 [=======>......................] - ETA: 0s
2528/7440 [=========>....................] - ETA: 0s
2944/7440 [==========>...................] - ETA: 0s
3360/7440 [============>.................] - ETA: 0s
3776/7440 [==============>...............] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5440/7440 [====================>.........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7440/7440 [==============================] - 1s 125us/step
current Test accuracy: 0.8330645161290322
current auc_score ------------------>  0.8592744103364551
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_265 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_27 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_266 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_28 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_267 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_15  (None, 4)                 0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 15s - loss: 0.7013 - acc: 0.5026 - val_loss: 0.6771 - val_acc: 0.5218
Epoch 2/50
 - 9s - loss: 0.6662 - acc: 0.6185 - val_loss: 0.6598 - val_acc: 0.6916
Epoch 3/50
 - 9s - loss: 0.6496 - acc: 0.6991 - val_loss: 0.6414 - val_acc: 0.7042
Epoch 4/50
 - 9s - loss: 0.6363 - acc: 0.7181 - val_loss: 0.6389 - val_acc: 0.7085
Epoch 5/50
 - 9s - loss: 0.6241 - acc: 0.7265 - val_loss: 0.6197 - val_acc: 0.7210
Epoch 6/50
 - 9s - loss: 0.6128 - acc: 0.7275 - val_loss: 0.6139 - val_acc: 0.7146
Epoch 7/50
 - 9s - loss: 0.6042 - acc: 0.7314 - val_loss: 0.5990 - val_acc: 0.7273
Epoch 8/50
 - 9s - loss: 0.5955 - acc: 0.7349 - val_loss: 0.5965 - val_acc: 0.7179
Epoch 9/50
 - 9s - loss: 0.5869 - acc: 0.7348 - val_loss: 0.5810 - val_acc: 0.7294
Epoch 10/50
 - 9s - loss: 0.5807 - acc: 0.7394 - val_loss: 0.5817 - val_acc: 0.7223
Epoch 11/50
 - 9s - loss: 0.5743 - acc: 0.7387 - val_loss: 0.5699 - val_acc: 0.7317
Epoch 12/50
 - 9s - loss: 0.5683 - acc: 0.7382 - val_loss: 0.5916 - val_acc: 0.7198
Epoch 13/50
 - 9s - loss: 0.5639 - acc: 0.7404 - val_loss: 0.5674 - val_acc: 0.7363
Epoch 14/50
 - 9s - loss: 0.5598 - acc: 0.7418 - val_loss: 0.5594 - val_acc: 0.7268
Epoch 15/50
 - 9s - loss: 0.5554 - acc: 0.7405 - val_loss: 0.6007 - val_acc: 0.7294
Epoch 16/50
 - 9s - loss: 0.5524 - acc: 0.7425 - val_loss: 0.5529 - val_acc: 0.7310
Epoch 17/50
 - 9s - loss: 0.5491 - acc: 0.7429 - val_loss: 0.5471 - val_acc: 0.7372
Epoch 18/50
 - 9s - loss: 0.5470 - acc: 0.7433 - val_loss: 0.5432 - val_acc: 0.7364
Epoch 19/50
 - 8s - loss: 0.5447 - acc: 0.7443 - val_loss: 0.5495 - val_acc: 0.7444
Epoch 20/50
 - 9s - loss: 0.5431 - acc: 0.7415 - val_loss: 0.5388 - val_acc: 0.7358
Epoch 21/50
 - 9s - loss: 0.5389 - acc: 0.7448 - val_loss: 0.5371 - val_acc: 0.7412
Epoch 22/50
 - 9s - loss: 0.5380 - acc: 0.7454 - val_loss: 0.5346 - val_acc: 0.7413
Epoch 23/50
 - 8s - loss: 0.5371 - acc: 0.7437 - val_loss: 0.5499 - val_acc: 0.7155
Epoch 24/50
 - 8s - loss: 0.5344 - acc: 0.7450 - val_loss: 0.5383 - val_acc: 0.7265
Epoch 25/50
 - 8s - loss: 0.5321 - acc: 0.7449 - val_loss: 0.5327 - val_acc: 0.7432
Epoch 26/50
 - 9s - loss: 0.5295 - acc: 0.7469 - val_loss: 0.5287 - val_acc: 0.7433
Epoch 27/50
 - 9s - loss: 0.5289 - acc: 0.7462 - val_loss: 0.5262 - val_acc: 0.7400
Epoch 28/50
 - 9s - loss: 0.5275 - acc: 0.7472 - val_loss: 0.5348 - val_acc: 0.7459
Epoch 29/50
 - 8s - loss: 0.5262 - acc: 0.7443 - val_loss: 0.5300 - val_acc: 0.7322
Epoch 30/50
 - 9s - loss: 0.5247 - acc: 0.7480 - val_loss: 0.6035 - val_acc: 0.6532
Epoch 31/50
 - 8s - loss: 0.5242 - acc: 0.7455 - val_loss: 0.5271 - val_acc: 0.7321

Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 32/50
 - 9s - loss: 0.5227 - acc: 0.7492 - val_loss: 0.5202 - val_acc: 0.7480
Epoch 33/50
 - 9s - loss: 0.5211 - acc: 0.7473 - val_loss: 0.5229 - val_acc: 0.7385
Epoch 34/50
 - 9s - loss: 0.5212 - acc: 0.7496 - val_loss: 0.5547 - val_acc: 0.6988
Epoch 35/50
 - 9s - loss: 0.5205 - acc: 0.7476 - val_loss: 0.5255 - val_acc: 0.7459
Epoch 36/50
 - 9s - loss: 0.5201 - acc: 0.7504 - val_loss: 0.5222 - val_acc: 0.7405

Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 37/50
 - 9s - loss: 0.5186 - acc: 0.7502 - val_loss: 0.5168 - val_acc: 0.7449
Epoch 38/50
 - 9s - loss: 0.5196 - acc: 0.7493 - val_loss: 0.5183 - val_acc: 0.7423
Epoch 39/50
 - 9s - loss: 0.5201 - acc: 0.7503 - val_loss: 0.5162 - val_acc: 0.7480
Epoch 40/50
 - 9s - loss: 0.5188 - acc: 0.7483 - val_loss: 0.5163 - val_acc: 0.7464
Epoch 41/50
 - 9s - loss: 0.5189 - acc: 0.7489 - val_loss: 0.5166 - val_acc: 0.7439
Epoch 42/50
 - 9s - loss: 0.5192 - acc: 0.7477 - val_loss: 0.5162 - val_acc: 0.7450
Epoch 43/50
 - 9s - loss: 0.5193 - acc: 0.7474 - val_loss: 0.5173 - val_acc: 0.7422

Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 44/50
 - 9s - loss: 0.5185 - acc: 0.7495 - val_loss: 0.5159 - val_acc: 0.7459
Epoch 45/50
 - 9s - loss: 0.5186 - acc: 0.7500 - val_loss: 0.5159 - val_acc: 0.7445
Epoch 46/50
 - 9s - loss: 0.5182 - acc: 0.7528 - val_loss: 0.5163 - val_acc: 0.7431
Epoch 47/50
 - 9s - loss: 0.5199 - acc: 0.7477 - val_loss: 0.5157 - val_acc: 0.7466
Epoch 48/50
 - 9s - loss: 0.5191 - acc: 0.7504 - val_loss: 0.5157 - val_acc: 0.7470
Epoch 49/50
 - 9s - loss: 0.5181 - acc: 0.7506 - val_loss: 0.5157 - val_acc: 0.7454
Epoch 50/50
 - 9s - loss: 0.5189 - acc: 0.7506 - val_loss: 0.5158 - val_acc: 0.7475

  32/7440 [..............................] - ETA: 0s
 448/7440 [>.............................] - ETA: 0s
 864/7440 [==>...........................] - ETA: 0s
1280/7440 [====>.........................] - ETA: 0s
1696/7440 [=====>........................] - ETA: 0s
2112/7440 [=======>......................] - ETA: 0s
2528/7440 [=========>....................] - ETA: 0s
2944/7440 [==========>...................] - ETA: 0s
3360/7440 [============>.................] - ETA: 0s
3776/7440 [==============>...............] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 127us/step
current Test accuracy: 0.8030913978494624
current auc_score ------------------>  0.8487753280726095
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_16 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_268 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_29 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_269 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_30 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_270 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_16  (None, 4)                 0         
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 15s - loss: 0.6768 - acc: 0.5996 - val_loss: 0.6530 - val_acc: 0.6381
Epoch 2/50
 - 9s - loss: 0.6405 - acc: 0.6585 - val_loss: 0.6270 - val_acc: 0.6881
Epoch 3/50
 - 9s - loss: 0.6187 - acc: 0.6987 - val_loss: 0.6136 - val_acc: 0.7062
Epoch 4/50
 - 9s - loss: 0.6040 - acc: 0.7112 - val_loss: 0.6033 - val_acc: 0.7144
Epoch 5/50
 - 8s - loss: 0.5931 - acc: 0.7189 - val_loss: 0.5960 - val_acc: 0.7131
Epoch 6/50
 - 9s - loss: 0.5819 - acc: 0.7268 - val_loss: 0.5795 - val_acc: 0.7279
Epoch 7/50
 - 8s - loss: 0.5736 - acc: 0.7328 - val_loss: 0.5679 - val_acc: 0.7359
Epoch 8/50
 - 9s - loss: 0.5650 - acc: 0.7401 - val_loss: 0.5665 - val_acc: 0.7348
Epoch 9/50
 - 9s - loss: 0.5588 - acc: 0.7412 - val_loss: 0.5560 - val_acc: 0.7432
Epoch 10/50
 - 8s - loss: 0.5519 - acc: 0.7431 - val_loss: 0.5538 - val_acc: 0.7326
Epoch 11/50
 - 8s - loss: 0.5455 - acc: 0.7474 - val_loss: 0.5626 - val_acc: 0.7254
Epoch 12/50
 - 8s - loss: 0.5402 - acc: 0.7492 - val_loss: 0.5365 - val_acc: 0.7519
Epoch 13/50
 - 9s - loss: 0.5359 - acc: 0.7513 - val_loss: 0.5361 - val_acc: 0.7533
Epoch 14/50
 - 9s - loss: 0.5314 - acc: 0.7531 - val_loss: 0.5295 - val_acc: 0.7484
Epoch 15/50
 - 9s - loss: 0.5274 - acc: 0.7514 - val_loss: 0.5390 - val_acc: 0.7490
Epoch 16/50
 - 8s - loss: 0.5226 - acc: 0.7567 - val_loss: 0.5277 - val_acc: 0.7579
Epoch 17/50
 - 8s - loss: 0.5197 - acc: 0.7568 - val_loss: 0.5146 - val_acc: 0.7541
Epoch 18/50
 - 8s - loss: 0.5150 - acc: 0.7600 - val_loss: 0.5093 - val_acc: 0.7583
Epoch 19/50
 - 8s - loss: 0.5137 - acc: 0.7591 - val_loss: 0.5239 - val_acc: 0.7363
Epoch 20/50
 - 9s - loss: 0.5097 - acc: 0.7607 - val_loss: 0.5272 - val_acc: 0.7563
Epoch 21/50
 - 9s - loss: 0.5072 - acc: 0.7618 - val_loss: 0.5075 - val_acc: 0.7476
Epoch 22/50
 - 9s - loss: 0.5056 - acc: 0.7600 - val_loss: 0.5153 - val_acc: 0.7539
Epoch 23/50
 - 9s - loss: 0.5040 - acc: 0.7614 - val_loss: 0.5805 - val_acc: 0.7321
Epoch 24/50
 - 9s - loss: 0.5016 - acc: 0.7625 - val_loss: 0.5024 - val_acc: 0.7558
Epoch 25/50
 - 9s - loss: 0.5002 - acc: 0.7638 - val_loss: 0.4936 - val_acc: 0.7663
Epoch 26/50
 - 9s - loss: 0.4996 - acc: 0.7629 - val_loss: 0.5054 - val_acc: 0.7534
Epoch 27/50
 - 9s - loss: 0.4976 - acc: 0.7638 - val_loss: 0.5040 - val_acc: 0.7653
Epoch 28/50
 - 9s - loss: 0.4956 - acc: 0.7641 - val_loss: 0.5243 - val_acc: 0.7369
Epoch 29/50
 - 9s - loss: 0.4967 - acc: 0.7647 - val_loss: 0.5035 - val_acc: 0.7472

Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 30/50
 - 8s - loss: 0.4933 - acc: 0.7654 - val_loss: 0.4866 - val_acc: 0.7700
Epoch 31/50
 - 9s - loss: 0.4935 - acc: 0.7648 - val_loss: 0.4869 - val_acc: 0.7696
Epoch 32/50
 - 9s - loss: 0.4913 - acc: 0.7663 - val_loss: 0.4923 - val_acc: 0.7588
Epoch 33/50
 - 9s - loss: 0.4928 - acc: 0.7655 - val_loss: 0.4906 - val_acc: 0.7730
Epoch 34/50
 - 9s - loss: 0.4929 - acc: 0.7651 - val_loss: 0.4869 - val_acc: 0.7720

Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 35/50
 - 9s - loss: 0.4906 - acc: 0.7683 - val_loss: 0.4855 - val_acc: 0.7686
Epoch 36/50
 - 9s - loss: 0.4904 - acc: 0.7656 - val_loss: 0.4882 - val_acc: 0.7614
Epoch 37/50
 - 8s - loss: 0.4912 - acc: 0.7670 - val_loss: 0.4858 - val_acc: 0.7710
Epoch 38/50
 - 9s - loss: 0.4913 - acc: 0.7654 - val_loss: 0.4853 - val_acc: 0.7731
Epoch 39/50
 - 8s - loss: 0.4904 - acc: 0.7673 - val_loss: 0.4847 - val_acc: 0.7718
Epoch 40/50
 - 8s - loss: 0.4911 - acc: 0.7674 - val_loss: 0.4852 - val_acc: 0.7730
Epoch 41/50
 - 8s - loss: 0.4899 - acc: 0.7652 - val_loss: 0.4850 - val_acc: 0.7684
Epoch 42/50
 - 8s - loss: 0.4903 - acc: 0.7670 - val_loss: 0.4852 - val_acc: 0.7745
Epoch 43/50
 - 8s - loss: 0.4900 - acc: 0.7675 - val_loss: 0.4861 - val_acc: 0.7661

Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 44/50
 - 8s - loss: 0.4908 - acc: 0.7675 - val_loss: 0.4846 - val_acc: 0.7705
Epoch 45/50
 - 9s - loss: 0.4893 - acc: 0.7672 - val_loss: 0.4852 - val_acc: 0.7752
Epoch 46/50
 - 8s - loss: 0.4890 - acc: 0.7683 - val_loss: 0.4851 - val_acc: 0.7683
Epoch 47/50
 - 8s - loss: 0.4915 - acc: 0.7642 - val_loss: 0.4855 - val_acc: 0.7687
Epoch 48/50
 - 9s - loss: 0.4882 - acc: 0.7682 - val_loss: 0.4845 - val_acc: 0.7681
Epoch 49/50
 - 8s - loss: 0.4888 - acc: 0.7688 - val_loss: 0.4844 - val_acc: 0.7693
Epoch 50/50
 - 8s - loss: 0.4895 - acc: 0.7674 - val_loss: 0.4849 - val_acc: 0.7687

  32/7440 [..............................] - ETA: 0s
 480/7440 [>.............................] - ETA: 0s
 928/7440 [==>...........................] - ETA: 0s
1344/7440 [====>.........................] - ETA: 0s
1760/7440 [======>.......................] - ETA: 0s
2176/7440 [=======>......................] - ETA: 0s
2624/7440 [=========>....................] - ETA: 0s
3040/7440 [===========>..................] - ETA: 0s
3488/7440 [=============>................] - ETA: 0s
3904/7440 [==============>...............] - ETA: 0s
4320/7440 [================>.............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 120us/step
current Test accuracy: 0.7967741935483871
current auc_score ------------------>  0.8558654179673951
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_17[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_271 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_271[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_272 (Activation)     (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_272[0][0]             
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_113[0][0]            
__________________________________________________________________________________________________
activation_273 (Activation)     (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_273[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_274 (Activation)     (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_274[0][0]             
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 36, 96, 96)   0           concatenate_113[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 36, 96, 96)   144         concatenate_114[0][0]            
__________________________________________________________________________________________________
activation_275 (Activation)     (None, 36, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 18, 96, 96)   648         activation_275[0][0]             
__________________________________________________________________________________________________
average_pooling2d_31 (AveragePo (None, 18, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 18, 48, 48)   72          average_pooling2d_31[0][0]       
__________________________________________________________________________________________________
activation_276 (Activation)     (None, 18, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   720         activation_276[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_277 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_277[0][0]             
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 28, 48, 48)   0           average_pooling2d_31[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 28, 48, 48)   112         concatenate_115[0][0]            
__________________________________________________________________________________________________
activation_278 (Activation)     (None, 28, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1120        activation_278[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_279 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_279[0][0]             
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 38, 48, 48)   0           concatenate_115[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 38, 48, 48)   152         concatenate_116[0][0]            
__________________________________________________________________________________________________
activation_280 (Activation)     (None, 38, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 19, 48, 48)   722         activation_280[0][0]             
__________________________________________________________________________________________________
average_pooling2d_32 (AveragePo (None, 19, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 19, 24, 24)   76          average_pooling2d_32[0][0]       
__________________________________________________________________________________________________
activation_281 (Activation)     (None, 19, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   760         activation_281[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_282 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_282[0][0]             
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 29, 24, 24)   0           average_pooling2d_32[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_117[0][0]            
__________________________________________________________________________________________________
activation_283 (Activation)     (None, 29, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   1160        activation_283[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_284 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_284[0][0]             
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 39, 24, 24)   0           concatenate_117[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 39, 24, 24)   156         concatenate_118[0][0]            
__________________________________________________________________________________________________
activation_285 (Activation)     (None, 39, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_17 (Gl (None, 39)           0           activation_285[0][0]             
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 1)            40          global_average_pooling2d_17[0][0]
==================================================================================================
Total params: 30,694
Trainable params: 29,716
Non-trainable params: 978
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 34s - loss: 0.5668 - acc: 0.7510 - val_loss: 0.5220 - val_acc: 0.7781
Epoch 2/50
 - 27s - loss: 0.4927 - acc: 0.7887 - val_loss: 0.5514 - val_acc: 0.7700
Epoch 3/50
 - 26s - loss: 0.4615 - acc: 0.8061 - val_loss: 0.5219 - val_acc: 0.7664
Epoch 4/50
 - 27s - loss: 0.4356 - acc: 0.8194 - val_loss: 0.4497 - val_acc: 0.8150
Epoch 5/50
 - 27s - loss: 0.4201 - acc: 0.8289 - val_loss: 0.4164 - val_acc: 0.8304
Epoch 6/50
 - 27s - loss: 0.4023 - acc: 0.8408 - val_loss: 0.5309 - val_acc: 0.7877
Epoch 7/50
 - 26s - loss: 0.3906 - acc: 0.8457 - val_loss: 0.4091 - val_acc: 0.8263
Epoch 8/50
 - 27s - loss: 0.3768 - acc: 0.8527 - val_loss: 0.4027 - val_acc: 0.8351
Epoch 9/50
 - 27s - loss: 0.3649 - acc: 0.8589 - val_loss: 0.3595 - val_acc: 0.8636
Epoch 10/50
 - 27s - loss: 0.3550 - acc: 0.8656 - val_loss: 0.3693 - val_acc: 0.8612
Epoch 11/50
 - 27s - loss: 0.3470 - acc: 0.8678 - val_loss: 0.3348 - val_acc: 0.8721
Epoch 12/50
 - 27s - loss: 0.3400 - acc: 0.8735 - val_loss: 0.3990 - val_acc: 0.8372
Epoch 13/50
 - 26s - loss: 0.3298 - acc: 0.8781 - val_loss: 0.4132 - val_acc: 0.8399
Epoch 14/50
 - 27s - loss: 0.3254 - acc: 0.8792 - val_loss: 0.4016 - val_acc: 0.8582
Epoch 15/50
 - 26s - loss: 0.3170 - acc: 0.8846 - val_loss: 0.3610 - val_acc: 0.8623

Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 16/50
 - 27s - loss: 0.2952 - acc: 0.8950 - val_loss: 0.3049 - val_acc: 0.8932
Epoch 17/50
 - 26s - loss: 0.2908 - acc: 0.8985 - val_loss: 0.2956 - val_acc: 0.8961
Epoch 18/50
 - 26s - loss: 0.2874 - acc: 0.9002 - val_loss: 0.2907 - val_acc: 0.8987
Epoch 19/50
 - 27s - loss: 0.2842 - acc: 0.9011 - val_loss: 0.2948 - val_acc: 0.8950
Epoch 20/50
 - 27s - loss: 0.2826 - acc: 0.9034 - val_loss: 0.2870 - val_acc: 0.9011
Epoch 21/50
 - 26s - loss: 0.2792 - acc: 0.9045 - val_loss: 0.2808 - val_acc: 0.9062
Epoch 22/50
 - 26s - loss: 0.2773 - acc: 0.9048 - val_loss: 0.2759 - val_acc: 0.9050
Epoch 23/50
 - 26s - loss: 0.2732 - acc: 0.9071 - val_loss: 0.3157 - val_acc: 0.8876
Epoch 24/50
 - 26s - loss: 0.2724 - acc: 0.9074 - val_loss: 0.2815 - val_acc: 0.9025
Epoch 25/50
 - 26s - loss: 0.2680 - acc: 0.9091 - val_loss: 0.3020 - val_acc: 0.8892
Epoch 26/50
 - 27s - loss: 0.2677 - acc: 0.9089 - val_loss: 0.2840 - val_acc: 0.9031

Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 27/50
 - 26s - loss: 0.2560 - acc: 0.9158 - val_loss: 0.2698 - val_acc: 0.9091
Epoch 28/50
 - 26s - loss: 0.2566 - acc: 0.9149 - val_loss: 0.2672 - val_acc: 0.9118
Epoch 29/50
 - 26s - loss: 0.2580 - acc: 0.9141 - val_loss: 0.2654 - val_acc: 0.9088
Epoch 30/50
 - 26s - loss: 0.2554 - acc: 0.9156 - val_loss: 0.2646 - val_acc: 0.9127
Epoch 31/50
 - 26s - loss: 0.2532 - acc: 0.9171 - val_loss: 0.2635 - val_acc: 0.9134
Epoch 32/50
 - 27s - loss: 0.2528 - acc: 0.9182 - val_loss: 0.2652 - val_acc: 0.9104
Epoch 33/50
 - 26s - loss: 0.2550 - acc: 0.9153 - val_loss: 0.2644 - val_acc: 0.9123
Epoch 34/50
 - 26s - loss: 0.2499 - acc: 0.9185 - val_loss: 0.2631 - val_acc: 0.9125
Epoch 35/50
 - 26s - loss: 0.2537 - acc: 0.9164 - val_loss: 0.2670 - val_acc: 0.9105
Epoch 36/50
 - 27s - loss: 0.2504 - acc: 0.9169 - val_loss: 0.2641 - val_acc: 0.9100
Epoch 37/50
 - 26s - loss: 0.2477 - acc: 0.9202 - val_loss: 0.2619 - val_acc: 0.9142
Epoch 38/50
 - 26s - loss: 0.2458 - acc: 0.9201 - val_loss: 0.2779 - val_acc: 0.9037
Epoch 39/50
 - 26s - loss: 0.2485 - acc: 0.9186 - val_loss: 0.2602 - val_acc: 0.9125
Epoch 40/50
 - 26s - loss: 0.2467 - acc: 0.9189 - val_loss: 0.2590 - val_acc: 0.9162
Epoch 41/50
 - 26s - loss: 0.2472 - acc: 0.9193 - val_loss: 0.2623 - val_acc: 0.9134
Epoch 42/50
 - 26s - loss: 0.2470 - acc: 0.9183 - val_loss: 0.2652 - val_acc: 0.9098
Epoch 43/50
 - 26s - loss: 0.2449 - acc: 0.9211 - val_loss: 0.2597 - val_acc: 0.9140
Epoch 44/50
 - 27s - loss: 0.2426 - acc: 0.9201 - val_loss: 0.2869 - val_acc: 0.8976

Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 45/50
 - 26s - loss: 0.2408 - acc: 0.9232 - val_loss: 0.2572 - val_acc: 0.9143
Epoch 46/50
 - 26s - loss: 0.2417 - acc: 0.9224 - val_loss: 0.2573 - val_acc: 0.9147
Epoch 47/50
 - 26s - loss: 0.2403 - acc: 0.9230 - val_loss: 0.2571 - val_acc: 0.9163
Epoch 48/50
 - 27s - loss: 0.2405 - acc: 0.9234 - val_loss: 0.2557 - val_acc: 0.9149
Epoch 49/50
 - 27s - loss: 0.2405 - acc: 0.9225 - val_loss: 0.2566 - val_acc: 0.9160
Epoch 50/50
 - 26s - loss: 0.2396 - acc: 0.9222 - val_loss: 0.2567 - val_acc: 0.9170

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 1s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 277us/step
current Test accuracy: 0.8065860215053764
current auc_score ------------------>  0.902499783211932
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_286 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_33 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 8, 48, 48)         32        
_________________________________________________________________
activation_287 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
global_average_pooling2d_18  (None, 8)                 0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 9         
=================================================================
Total params: 521
Trainable params: 473
Non-trainable params: 48
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 14s - loss: 0.6798 - acc: 0.5749 - val_loss: 0.6437 - val_acc: 0.6600
Epoch 2/50
 - 8s - loss: 0.6314 - acc: 0.6846 - val_loss: 0.6226 - val_acc: 0.6958
Epoch 3/50
 - 8s - loss: 0.6171 - acc: 0.6949 - val_loss: 0.6118 - val_acc: 0.7036
Epoch 4/50
 - 8s - loss: 0.6093 - acc: 0.6991 - val_loss: 0.6059 - val_acc: 0.7081
Epoch 5/50
 - 8s - loss: 0.6046 - acc: 0.7030 - val_loss: 0.6023 - val_acc: 0.7105
Epoch 6/50
 - 8s - loss: 0.5995 - acc: 0.7080 - val_loss: 0.5967 - val_acc: 0.7106
Epoch 7/50
 - 8s - loss: 0.5946 - acc: 0.7122 - val_loss: 0.5973 - val_acc: 0.7052
Epoch 8/50
 - 8s - loss: 0.5912 - acc: 0.7131 - val_loss: 0.5936 - val_acc: 0.7137
Epoch 9/50
 - 8s - loss: 0.5868 - acc: 0.7170 - val_loss: 0.5874 - val_acc: 0.7214
Epoch 10/50
 - 8s - loss: 0.5840 - acc: 0.7193 - val_loss: 0.5821 - val_acc: 0.7223
Epoch 11/50
 - 8s - loss: 0.5780 - acc: 0.7214 - val_loss: 0.5769 - val_acc: 0.7229
Epoch 12/50
 - 8s - loss: 0.5739 - acc: 0.7226 - val_loss: 0.5685 - val_acc: 0.7304
Epoch 13/50
 - 8s - loss: 0.5666 - acc: 0.7291 - val_loss: 0.5633 - val_acc: 0.7323
Epoch 14/50
 - 8s - loss: 0.5611 - acc: 0.7318 - val_loss: 0.5610 - val_acc: 0.7292
Epoch 15/50
 - 8s - loss: 0.5548 - acc: 0.7358 - val_loss: 0.5506 - val_acc: 0.7391
Epoch 16/50
 - 8s - loss: 0.5508 - acc: 0.7369 - val_loss: 0.5462 - val_acc: 0.7411
Epoch 17/50
 - 8s - loss: 0.5474 - acc: 0.7377 - val_loss: 0.5444 - val_acc: 0.7426
Epoch 18/50
 - 8s - loss: 0.5436 - acc: 0.7417 - val_loss: 0.5558 - val_acc: 0.7252
Epoch 19/50
 - 8s - loss: 0.5407 - acc: 0.7441 - val_loss: 0.5404 - val_acc: 0.7411
Epoch 20/50
 - 8s - loss: 0.5388 - acc: 0.7452 - val_loss: 0.5842 - val_acc: 0.6990
Epoch 21/50
 - 8s - loss: 0.5368 - acc: 0.7456 - val_loss: 0.5334 - val_acc: 0.7456
Epoch 22/50
 - 8s - loss: 0.5334 - acc: 0.7479 - val_loss: 0.5324 - val_acc: 0.7475
Epoch 23/50
 - 8s - loss: 0.5315 - acc: 0.7472 - val_loss: 0.5291 - val_acc: 0.7476
Epoch 24/50
 - 8s - loss: 0.5306 - acc: 0.7489 - val_loss: 0.5305 - val_acc: 0.7447
Epoch 25/50
 - 8s - loss: 0.5302 - acc: 0.7493 - val_loss: 0.5304 - val_acc: 0.7439
Epoch 26/50
 - 8s - loss: 0.5295 - acc: 0.7471 - val_loss: 0.5262 - val_acc: 0.7487
Epoch 27/50
 - 8s - loss: 0.5275 - acc: 0.7477 - val_loss: 0.5301 - val_acc: 0.7431
Epoch 28/50
 - 8s - loss: 0.5268 - acc: 0.7482 - val_loss: 0.5231 - val_acc: 0.7480
Epoch 29/50
 - 8s - loss: 0.5246 - acc: 0.7518 - val_loss: 0.5216 - val_acc: 0.7514
Epoch 30/50
 - 8s - loss: 0.5255 - acc: 0.7486 - val_loss: 0.5204 - val_acc: 0.7530
Epoch 31/50
 - 8s - loss: 0.5228 - acc: 0.7520 - val_loss: 0.5332 - val_acc: 0.7338
Epoch 32/50
 - 8s - loss: 0.5233 - acc: 0.7502 - val_loss: 0.5275 - val_acc: 0.7390
Epoch 33/50
 - 8s - loss: 0.5212 - acc: 0.7497 - val_loss: 0.5201 - val_acc: 0.7506
Epoch 34/50
 - 8s - loss: 0.5220 - acc: 0.7491 - val_loss: 0.5299 - val_acc: 0.7377
Epoch 35/50
 - 8s - loss: 0.5212 - acc: 0.7486 - val_loss: 0.5281 - val_acc: 0.7386
Epoch 36/50
 - 8s - loss: 0.5197 - acc: 0.7513 - val_loss: 0.5252 - val_acc: 0.7408
Epoch 37/50
 - 8s - loss: 0.5200 - acc: 0.7515 - val_loss: 0.5158 - val_acc: 0.7480
Epoch 38/50
 - 8s - loss: 0.5176 - acc: 0.7508 - val_loss: 0.5651 - val_acc: 0.7427
Epoch 39/50
 - 8s - loss: 0.5182 - acc: 0.7524 - val_loss: 0.5182 - val_acc: 0.7450
Epoch 40/50
 - 8s - loss: 0.5155 - acc: 0.7533 - val_loss: 0.5199 - val_acc: 0.7441
Epoch 41/50
 - 8s - loss: 0.5176 - acc: 0.7510 - val_loss: 0.5166 - val_acc: 0.7541

Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 42/50
 - 8s - loss: 0.5172 - acc: 0.7524 - val_loss: 0.5123 - val_acc: 0.7531
Epoch 43/50
 - 8s - loss: 0.5149 - acc: 0.7538 - val_loss: 0.5134 - val_acc: 0.7535
Epoch 44/50
 - 8s - loss: 0.5159 - acc: 0.7524 - val_loss: 0.5133 - val_acc: 0.7479
Epoch 45/50
 - 8s - loss: 0.5162 - acc: 0.7517 - val_loss: 0.5162 - val_acc: 0.7548
Epoch 46/50
 - 8s - loss: 0.5160 - acc: 0.7524 - val_loss: 0.5190 - val_acc: 0.7411

Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 47/50
 - 8s - loss: 0.5144 - acc: 0.7527 - val_loss: 0.5117 - val_acc: 0.7495
Epoch 48/50
 - 8s - loss: 0.5156 - acc: 0.7535 - val_loss: 0.5117 - val_acc: 0.7513
Epoch 49/50
 - 8s - loss: 0.5151 - acc: 0.7531 - val_loss: 0.5117 - val_acc: 0.7521
Epoch 50/50
 - 8s - loss: 0.5162 - acc: 0.7527 - val_loss: 0.5119 - val_acc: 0.7482

  32/7440 [..............................] - ETA: 0s
 448/7440 [>.............................] - ETA: 0s
 864/7440 [==>...........................] - ETA: 0s
1280/7440 [====>.........................] - ETA: 0s
1664/7440 [=====>........................] - ETA: 0s
2048/7440 [=======>......................] - ETA: 0s
2432/7440 [========>.....................] - ETA: 0s
2816/7440 [==========>...................] - ETA: 0s
3200/7440 [===========>..................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
4032/7440 [===============>..............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7440/7440 [==============================] - 1s 132us/step
current Test accuracy: 0.8258064516129032
current auc_score ------------------>  0.8621280278066829
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_288 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_34 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 8, 48, 48)         32        
_________________________________________________________________
activation_289 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
global_average_pooling2d_19  (None, 8)                 0         
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 9         
=================================================================
Total params: 521
Trainable params: 473
Non-trainable params: 48
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 14s - loss: 0.6652 - acc: 0.5975 - val_loss: 0.6322 - val_acc: 0.6709
Epoch 2/50
 - 8s - loss: 0.6249 - acc: 0.6870 - val_loss: 0.6165 - val_acc: 0.7016
Epoch 3/50
 - 8s - loss: 0.6135 - acc: 0.6949 - val_loss: 0.6086 - val_acc: 0.7061
Epoch 4/50
 - 8s - loss: 0.6059 - acc: 0.7042 - val_loss: 0.6033 - val_acc: 0.7118
Epoch 5/50
 - 8s - loss: 0.5997 - acc: 0.7122 - val_loss: 0.6034 - val_acc: 0.7012
Epoch 6/50
 - 8s - loss: 0.5950 - acc: 0.7116 - val_loss: 0.5928 - val_acc: 0.7189
Epoch 7/50
 - 8s - loss: 0.5907 - acc: 0.7168 - val_loss: 0.5893 - val_acc: 0.7213
Epoch 8/50
 - 8s - loss: 0.5867 - acc: 0.7177 - val_loss: 0.5824 - val_acc: 0.7259
Epoch 9/50
 - 8s - loss: 0.5790 - acc: 0.7220 - val_loss: 0.5775 - val_acc: 0.7292
Epoch 10/50
 - 8s - loss: 0.5745 - acc: 0.7244 - val_loss: 0.5714 - val_acc: 0.7312
Epoch 11/50
 - 8s - loss: 0.5691 - acc: 0.7256 - val_loss: 0.5732 - val_acc: 0.7240
Epoch 12/50
 - 8s - loss: 0.5630 - acc: 0.7279 - val_loss: 0.5614 - val_acc: 0.7307
Epoch 13/50
 - 8s - loss: 0.5580 - acc: 0.7329 - val_loss: 0.5552 - val_acc: 0.7331
Epoch 14/50
 - 8s - loss: 0.5538 - acc: 0.7342 - val_loss: 0.5510 - val_acc: 0.7323
Epoch 15/50
 - 8s - loss: 0.5488 - acc: 0.7358 - val_loss: 0.5511 - val_acc: 0.7300
Epoch 16/50
 - 8s - loss: 0.5462 - acc: 0.7368 - val_loss: 0.5562 - val_acc: 0.7287
Epoch 17/50
 - 8s - loss: 0.5432 - acc: 0.7404 - val_loss: 0.5478 - val_acc: 0.7336
Epoch 18/50
 - 8s - loss: 0.5404 - acc: 0.7433 - val_loss: 0.5371 - val_acc: 0.7446
Epoch 19/50
 - 8s - loss: 0.5361 - acc: 0.7421 - val_loss: 0.5381 - val_acc: 0.7397
Epoch 20/50
 - 8s - loss: 0.5335 - acc: 0.7437 - val_loss: 0.5461 - val_acc: 0.7366
Epoch 21/50
 - 8s - loss: 0.5346 - acc: 0.7461 - val_loss: 0.5372 - val_acc: 0.7407
Epoch 22/50
 - 8s - loss: 0.5321 - acc: 0.7458 - val_loss: 0.5302 - val_acc: 0.7467
Epoch 23/50
 - 8s - loss: 0.5306 - acc: 0.7452 - val_loss: 0.5481 - val_acc: 0.7439
Epoch 24/50
 - 8s - loss: 0.5292 - acc: 0.7483 - val_loss: 0.5265 - val_acc: 0.7485
Epoch 25/50
 - 8s - loss: 0.5288 - acc: 0.7476 - val_loss: 0.5342 - val_acc: 0.7470
Epoch 26/50
 - 8s - loss: 0.5274 - acc: 0.7500 - val_loss: 0.5659 - val_acc: 0.7428
Epoch 27/50
 - 8s - loss: 0.5261 - acc: 0.7478 - val_loss: 0.5330 - val_acc: 0.7369
Epoch 28/50
 - 8s - loss: 0.5253 - acc: 0.7487 - val_loss: 0.5214 - val_acc: 0.7508
Epoch 29/50
 - 8s - loss: 0.5227 - acc: 0.7497 - val_loss: 0.5313 - val_acc: 0.7447
Epoch 30/50
 - 8s - loss: 0.5227 - acc: 0.7500 - val_loss: 0.5378 - val_acc: 0.7514
Epoch 31/50
 - 8s - loss: 0.5224 - acc: 0.7501 - val_loss: 0.5247 - val_acc: 0.7479
Epoch 32/50
 - 8s - loss: 0.5182 - acc: 0.7508 - val_loss: 0.5426 - val_acc: 0.7264

Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 33/50
 - 8s - loss: 0.5208 - acc: 0.7510 - val_loss: 0.5168 - val_acc: 0.7485
Epoch 34/50
 - 8s - loss: 0.5202 - acc: 0.7516 - val_loss: 0.5185 - val_acc: 0.7509
Epoch 35/50
 - 8s - loss: 0.5212 - acc: 0.7499 - val_loss: 0.5419 - val_acc: 0.7482
Epoch 36/50
 - 8s - loss: 0.5184 - acc: 0.7534 - val_loss: 0.5227 - val_acc: 0.7396
Epoch 37/50
 - 8s - loss: 0.5187 - acc: 0.7511 - val_loss: 0.5195 - val_acc: 0.7449

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 38/50
 - 8s - loss: 0.5179 - acc: 0.7510 - val_loss: 0.5155 - val_acc: 0.7494
Epoch 39/50
 - 8s - loss: 0.5195 - acc: 0.7507 - val_loss: 0.5167 - val_acc: 0.7455
Epoch 40/50
 - 8s - loss: 0.5176 - acc: 0.7518 - val_loss: 0.5199 - val_acc: 0.7518
Epoch 41/50
 - 8s - loss: 0.5186 - acc: 0.7514 - val_loss: 0.5158 - val_acc: 0.7501
Epoch 42/50
 - 8s - loss: 0.5172 - acc: 0.7497 - val_loss: 0.5154 - val_acc: 0.7481
Epoch 43/50
 - 8s - loss: 0.5192 - acc: 0.7516 - val_loss: 0.5153 - val_acc: 0.7475
Epoch 44/50
 - 8s - loss: 0.5171 - acc: 0.7503 - val_loss: 0.5164 - val_acc: 0.7466
Epoch 45/50
 - 8s - loss: 0.5167 - acc: 0.7525 - val_loss: 0.5154 - val_acc: 0.7466
Epoch 46/50
 - 8s - loss: 0.5158 - acc: 0.7519 - val_loss: 0.5146 - val_acc: 0.7482
Epoch 47/50
 - 8s - loss: 0.5172 - acc: 0.7525 - val_loss: 0.5170 - val_acc: 0.7501
Epoch 48/50
 - 8s - loss: 0.5167 - acc: 0.7503 - val_loss: 0.5150 - val_acc: 0.7485
Epoch 49/50
 - 8s - loss: 0.5176 - acc: 0.7526 - val_loss: 0.5148 - val_acc: 0.7485
Epoch 50/50
 - 8s - loss: 0.5176 - acc: 0.7509 - val_loss: 0.5163 - val_acc: 0.7500

Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.

  32/7440 [..............................] - ETA: 0s
 480/7440 [>.............................] - ETA: 0s
 928/7440 [==>...........................] - ETA: 0s
1344/7440 [====>.........................] - ETA: 0s
1760/7440 [======>.......................] - ETA: 0s
2176/7440 [=======>......................] - ETA: 0s
2624/7440 [=========>....................] - ETA: 0s
3040/7440 [===========>..................] - ETA: 0s
3456/7440 [============>.................] - ETA: 0s
3904/7440 [==============>...............] - ETA: 0s
4320/7440 [================>.............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 122us/step
current Test accuracy: 0.8346774193548387
current auc_score ------------------>  0.8613269597641346
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        (None, 2, 96, 96)         0         
_________________________________________________________________
initial_conv2D (Conv2D)      (None, 16, 96, 96)        288       
_________________________________________________________________
tr_0_bn (BatchNormalization) (None, 16, 96, 96)        64        
_________________________________________________________________
activation_290 (Activation)  (None, 16, 96, 96)        0         
_________________________________________________________________
tr_0_conv2D (Conv2D)         (None, 8, 96, 96)         128       
_________________________________________________________________
average_pooling2d_35 (Averag (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_bn (BatchNormalization) (None, 8, 48, 48)         32        
_________________________________________________________________
activation_291 (Activation)  (None, 8, 48, 48)         0         
_________________________________________________________________
tr_1_conv2D (Conv2D)         (None, 4, 48, 48)         32        
_________________________________________________________________
average_pooling2d_36 (Averag (None, 4, 24, 24)         0         
_________________________________________________________________
final_bn (BatchNormalization (None, 4, 24, 24)         16        
_________________________________________________________________
activation_292 (Activation)  (None, 4, 24, 24)         0         
_________________________________________________________________
global_average_pooling2d_20  (None, 4)                 0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 5         
=================================================================
Total params: 565
Trainable params: 509
Non-trainable params: 56
_________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 16s - loss: 0.6592 - acc: 0.6245 - val_loss: 0.6292 - val_acc: 0.6903
Epoch 2/50
 - 9s - loss: 0.6218 - acc: 0.6887 - val_loss: 0.6140 - val_acc: 0.7007
Epoch 3/50
 - 9s - loss: 0.6113 - acc: 0.6976 - val_loss: 0.6131 - val_acc: 0.6950
Epoch 4/50
 - 9s - loss: 0.5968 - acc: 0.7097 - val_loss: 0.5896 - val_acc: 0.7156
Epoch 5/50
 - 9s - loss: 0.5850 - acc: 0.7207 - val_loss: 0.5928 - val_acc: 0.7179
Epoch 6/50
 - 9s - loss: 0.5733 - acc: 0.7288 - val_loss: 0.5775 - val_acc: 0.7216
Epoch 7/50
 - 9s - loss: 0.5629 - acc: 0.7392 - val_loss: 0.5574 - val_acc: 0.7426
Epoch 8/50
 - 9s - loss: 0.5557 - acc: 0.7446 - val_loss: 0.5486 - val_acc: 0.7462
Epoch 9/50
 - 9s - loss: 0.5483 - acc: 0.7480 - val_loss: 0.5442 - val_acc: 0.7506
Epoch 10/50
 - 9s - loss: 0.5433 - acc: 0.7498 - val_loss: 0.5427 - val_acc: 0.7505
Epoch 11/50
 - 9s - loss: 0.5374 - acc: 0.7513 - val_loss: 0.5361 - val_acc: 0.7506
Epoch 12/50
 - 9s - loss: 0.5342 - acc: 0.7526 - val_loss: 0.5475 - val_acc: 0.7354
Epoch 13/50
 - 9s - loss: 0.5286 - acc: 0.7515 - val_loss: 0.5289 - val_acc: 0.7497
Epoch 14/50
 - 9s - loss: 0.5245 - acc: 0.7558 - val_loss: 0.5628 - val_acc: 0.7460
Epoch 15/50
 - 9s - loss: 0.5225 - acc: 0.7552 - val_loss: 0.5879 - val_acc: 0.7288
Epoch 16/50
 - 9s - loss: 0.5210 - acc: 0.7552 - val_loss: 0.5219 - val_acc: 0.7501
Epoch 17/50
 - 9s - loss: 0.5189 - acc: 0.7557 - val_loss: 0.5164 - val_acc: 0.7531
Epoch 18/50
 - 9s - loss: 0.5156 - acc: 0.7568 - val_loss: 0.5133 - val_acc: 0.7521
Epoch 19/50
 - 9s - loss: 0.5136 - acc: 0.7543 - val_loss: 0.5146 - val_acc: 0.7588
Epoch 20/50
 - 9s - loss: 0.5128 - acc: 0.7541 - val_loss: 0.5067 - val_acc: 0.7549
Epoch 21/50
 - 9s - loss: 0.5108 - acc: 0.7566 - val_loss: 0.5115 - val_acc: 0.7518
Epoch 22/50
 - 9s - loss: 0.5091 - acc: 0.7557 - val_loss: 0.5121 - val_acc: 0.7460
Epoch 23/50
 - 9s - loss: 0.5078 - acc: 0.7560 - val_loss: 0.5087 - val_acc: 0.7520
Epoch 24/50
 - 9s - loss: 0.5044 - acc: 0.7564 - val_loss: 0.5119 - val_acc: 0.7609

Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 25/50
 - 9s - loss: 0.5029 - acc: 0.7573 - val_loss: 0.5066 - val_acc: 0.7524
Epoch 26/50
 - 9s - loss: 0.5027 - acc: 0.7586 - val_loss: 0.5023 - val_acc: 0.7538
Epoch 27/50
 - 9s - loss: 0.5031 - acc: 0.7586 - val_loss: 0.5175 - val_acc: 0.7359
Epoch 28/50
 - 8s - loss: 0.5026 - acc: 0.7566 - val_loss: 0.4986 - val_acc: 0.7563
Epoch 29/50
 - 9s - loss: 0.4999 - acc: 0.7592 - val_loss: 0.5079 - val_acc: 0.7490
Epoch 30/50
 - 9s - loss: 0.5012 - acc: 0.7569 - val_loss: 0.4977 - val_acc: 0.7569
Epoch 31/50
 - 9s - loss: 0.5022 - acc: 0.7565 - val_loss: 0.4973 - val_acc: 0.7560
Epoch 32/50
 - 9s - loss: 0.5002 - acc: 0.7583 - val_loss: 0.4962 - val_acc: 0.7573
Epoch 33/50
 - 9s - loss: 0.5006 - acc: 0.7578 - val_loss: 0.4955 - val_acc: 0.7579
Epoch 34/50
 - 9s - loss: 0.4982 - acc: 0.7603 - val_loss: 0.5011 - val_acc: 0.7595
Epoch 35/50
 - 9s - loss: 0.4983 - acc: 0.7610 - val_loss: 0.4960 - val_acc: 0.7578
Epoch 36/50
 - 9s - loss: 0.4987 - acc: 0.7588 - val_loss: 0.4959 - val_acc: 0.7577
Epoch 37/50
 - 9s - loss: 0.4973 - acc: 0.7595 - val_loss: 0.4966 - val_acc: 0.7602

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 38/50
 - 9s - loss: 0.4980 - acc: 0.7594 - val_loss: 0.4938 - val_acc: 0.7608
Epoch 39/50
 - 8s - loss: 0.4980 - acc: 0.7580 - val_loss: 0.4952 - val_acc: 0.7555
Epoch 40/50
 - 8s - loss: 0.4975 - acc: 0.7609 - val_loss: 0.4938 - val_acc: 0.7592
Epoch 41/50
 - 9s - loss: 0.4987 - acc: 0.7599 - val_loss: 0.4943 - val_acc: 0.7610
Epoch 42/50
 - 9s - loss: 0.4963 - acc: 0.7599 - val_loss: 0.4927 - val_acc: 0.7585
Epoch 43/50
 - 9s - loss: 0.4962 - acc: 0.7599 - val_loss: 0.4929 - val_acc: 0.7593
Epoch 44/50
 - 9s - loss: 0.4970 - acc: 0.7607 - val_loss: 0.4928 - val_acc: 0.7589
Epoch 45/50
 - 9s - loss: 0.4970 - acc: 0.7599 - val_loss: 0.4936 - val_acc: 0.7574
Epoch 46/50
 - 8s - loss: 0.4975 - acc: 0.7597 - val_loss: 0.4924 - val_acc: 0.7584
Epoch 47/50
 - 8s - loss: 0.4975 - acc: 0.7572 - val_loss: 0.4925 - val_acc: 0.7584
Epoch 48/50
 - 8s - loss: 0.4967 - acc: 0.7587 - val_loss: 0.4928 - val_acc: 0.7579
Epoch 49/50
 - 8s - loss: 0.4959 - acc: 0.7618 - val_loss: 0.4936 - val_acc: 0.7578
Epoch 50/50
 - 8s - loss: 0.4984 - acc: 0.7613 - val_loss: 0.4913 - val_acc: 0.7610

  32/7440 [..............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 0s
 864/7440 [==>...........................] - ETA: 0s
1280/7440 [====>.........................] - ETA: 0s
1696/7440 [=====>........................] - ETA: 0s
2112/7440 [=======>......................] - ETA: 0s
2528/7440 [=========>....................] - ETA: 0s
2944/7440 [==========>...................] - ETA: 0s
3360/7440 [============>.................] - ETA: 0s
3776/7440 [==============>...............] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5440/7440 [====================>.........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7440/7440 [==============================] - 1s 126us/step
current Test accuracy: 0.8157258064516129
current auc_score ------------------>  0.8524503555324314
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_21[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_293 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_293[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_294 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_294[0][0]             
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_119[0][0]            
__________________________________________________________________________________________________
activation_295 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_295[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_296 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_296[0][0]             
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 28, 96, 96)   0           concatenate_119[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 28, 96, 96)   112         concatenate_120[0][0]            
__________________________________________________________________________________________________
activation_297 (Activation)     (None, 28, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 14, 96, 96)   392         activation_297[0][0]             
__________________________________________________________________________________________________
average_pooling2d_37 (AveragePo (None, 14, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 14, 48, 48)   56          average_pooling2d_37[0][0]       
__________________________________________________________________________________________________
activation_298 (Activation)     (None, 14, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   336         activation_298[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_299 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_299[0][0]             
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_37[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 20, 48, 48)   80          concatenate_121[0][0]            
__________________________________________________________________________________________________
activation_300 (Activation)     (None, 20, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   480         activation_300[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_301 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_301[0][0]             
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 26, 48, 48)   0           concatenate_121[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 26, 48, 48)   104         concatenate_122[0][0]            
__________________________________________________________________________________________________
activation_302 (Activation)     (None, 26, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 13, 48, 48)   338         activation_302[0][0]             
__________________________________________________________________________________________________
average_pooling2d_38 (AveragePo (None, 13, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 13, 24, 24)   52          average_pooling2d_38[0][0]       
__________________________________________________________________________________________________
activation_303 (Activation)     (None, 13, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   312         activation_303[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_304 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_304[0][0]             
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 19, 24, 24)   0           average_pooling2d_38[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 19, 24, 24)   76          concatenate_123[0][0]            
__________________________________________________________________________________________________
activation_305 (Activation)     (None, 19, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   456         activation_305[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_306 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_306[0][0]             
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 25, 24, 24)   0           concatenate_123[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 25, 24, 24)   100         concatenate_124[0][0]            
__________________________________________________________________________________________________
activation_307 (Activation)     (None, 25, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_21 (Gl (None, 25)           0           activation_307[0][0]             
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 1)            26          global_average_pooling2d_21[0][0]
==================================================================================================
Total params: 12,624
Trainable params: 11,970
Non-trainable params: 654
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 32s - loss: 0.5747 - acc: 0.7491 - val_loss: 0.5227 - val_acc: 0.7681
Epoch 2/50
 - 23s - loss: 0.4997 - acc: 0.7809 - val_loss: 0.4819 - val_acc: 0.7814
Epoch 3/50
 - 23s - loss: 0.4675 - acc: 0.7942 - val_loss: 0.5107 - val_acc: 0.7583
Epoch 4/50
 - 23s - loss: 0.4467 - acc: 0.8051 - val_loss: 0.4917 - val_acc: 0.7589
Epoch 5/50
 - 23s - loss: 0.4313 - acc: 0.8116 - val_loss: 0.4368 - val_acc: 0.8168
Epoch 6/50
 - 23s - loss: 0.4164 - acc: 0.8205 - val_loss: 0.4218 - val_acc: 0.8276
Epoch 7/50
 - 23s - loss: 0.4067 - acc: 0.8271 - val_loss: 0.3914 - val_acc: 0.8341
Epoch 8/50
 - 23s - loss: 0.3964 - acc: 0.8297 - val_loss: 0.3821 - val_acc: 0.8381
Epoch 9/50
 - 23s - loss: 0.3873 - acc: 0.8358 - val_loss: 0.4028 - val_acc: 0.8307
Epoch 10/50
 - 23s - loss: 0.3809 - acc: 0.8401 - val_loss: 0.4736 - val_acc: 0.8080
Epoch 11/50
 - 23s - loss: 0.3737 - acc: 0.8452 - val_loss: 0.3822 - val_acc: 0.8460
Epoch 12/50
 - 23s - loss: 0.3688 - acc: 0.8479 - val_loss: 0.4155 - val_acc: 0.8174

Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 13/50
 - 23s - loss: 0.3522 - acc: 0.8551 - val_loss: 0.3528 - val_acc: 0.8577
Epoch 14/50
 - 23s - loss: 0.3522 - acc: 0.8561 - val_loss: 0.3645 - val_acc: 0.8475
Epoch 15/50
 - 23s - loss: 0.3506 - acc: 0.8574 - val_loss: 0.3497 - val_acc: 0.8578
Epoch 16/50
 - 23s - loss: 0.3480 - acc: 0.8575 - val_loss: 0.3468 - val_acc: 0.8591
Epoch 17/50
 - 23s - loss: 0.3469 - acc: 0.8586 - val_loss: 0.3758 - val_acc: 0.8397
Epoch 18/50
 - 23s - loss: 0.3431 - acc: 0.8600 - val_loss: 0.3657 - val_acc: 0.8479
Epoch 19/50
 - 23s - loss: 0.3443 - acc: 0.8592 - val_loss: 0.3694 - val_acc: 0.8432
Epoch 20/50
 - 23s - loss: 0.3414 - acc: 0.8615 - val_loss: 0.3440 - val_acc: 0.8608
Epoch 21/50
 - 23s - loss: 0.3395 - acc: 0.8628 - val_loss: 0.3438 - val_acc: 0.8652
Epoch 22/50
 - 23s - loss: 0.3371 - acc: 0.8641 - val_loss: 0.3373 - val_acc: 0.8666
Epoch 23/50
 - 23s - loss: 0.3363 - acc: 0.8632 - val_loss: 0.3413 - val_acc: 0.8616
Epoch 24/50
 - 23s - loss: 0.3336 - acc: 0.8641 - val_loss: 0.3471 - val_acc: 0.8632
Epoch 25/50
 - 23s - loss: 0.3327 - acc: 0.8655 - val_loss: 0.3337 - val_acc: 0.8682
Epoch 26/50
 - 23s - loss: 0.3318 - acc: 0.8653 - val_loss: 0.3475 - val_acc: 0.8648
Epoch 27/50
 - 23s - loss: 0.3285 - acc: 0.8695 - val_loss: 0.3349 - val_acc: 0.8662
Epoch 28/50
 - 23s - loss: 0.3290 - acc: 0.8684 - val_loss: 0.3404 - val_acc: 0.8594
Epoch 29/50
 - 23s - loss: 0.3268 - acc: 0.8675 - val_loss: 0.3267 - val_acc: 0.8739
Epoch 30/50
 - 23s - loss: 0.3236 - acc: 0.8710 - val_loss: 0.3349 - val_acc: 0.8642
Epoch 31/50
 - 23s - loss: 0.3221 - acc: 0.8718 - val_loss: 0.3599 - val_acc: 0.8533
Epoch 32/50
 - 23s - loss: 0.3232 - acc: 0.8705 - val_loss: 0.3298 - val_acc: 0.8706
Epoch 33/50
 - 23s - loss: 0.3204 - acc: 0.8716 - val_loss: 0.3323 - val_acc: 0.8685

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 34/50
 - 23s - loss: 0.3135 - acc: 0.8764 - val_loss: 0.3219 - val_acc: 0.8732
Epoch 35/50
 - 23s - loss: 0.3143 - acc: 0.8756 - val_loss: 0.3295 - val_acc: 0.8661
Epoch 36/50
 - 23s - loss: 0.3142 - acc: 0.8764 - val_loss: 0.3237 - val_acc: 0.8722
Epoch 37/50
 - 23s - loss: 0.3153 - acc: 0.8770 - val_loss: 0.3198 - val_acc: 0.8725
Epoch 38/50
 - 23s - loss: 0.3122 - acc: 0.8758 - val_loss: 0.3222 - val_acc: 0.8779
Epoch 39/50
 - 23s - loss: 0.3102 - acc: 0.8781 - val_loss: 0.3196 - val_acc: 0.8763
Epoch 40/50
 - 23s - loss: 0.3125 - acc: 0.8757 - val_loss: 0.3220 - val_acc: 0.8725
Epoch 41/50
 - 23s - loss: 0.3131 - acc: 0.8759 - val_loss: 0.3203 - val_acc: 0.8761
Epoch 42/50
 - 23s - loss: 0.3119 - acc: 0.8786 - val_loss: 0.3184 - val_acc: 0.8747
Epoch 43/50
 - 23s - loss: 0.3100 - acc: 0.8785 - val_loss: 0.3216 - val_acc: 0.8735
Epoch 44/50
 - 23s - loss: 0.3115 - acc: 0.8766 - val_loss: 0.3210 - val_acc: 0.8714
Epoch 45/50
 - 23s - loss: 0.3082 - acc: 0.8802 - val_loss: 0.3201 - val_acc: 0.8726
Epoch 46/50
 - 23s - loss: 0.3088 - acc: 0.8775 - val_loss: 0.3180 - val_acc: 0.8747
Epoch 47/50
 - 23s - loss: 0.3077 - acc: 0.8785 - val_loss: 0.3189 - val_acc: 0.8760
Epoch 48/50
 - 23s - loss: 0.3081 - acc: 0.8803 - val_loss: 0.3214 - val_acc: 0.8717
Epoch 49/50
 - 23s - loss: 0.3101 - acc: 0.8772 - val_loss: 0.3175 - val_acc: 0.8765
Epoch 50/50
 - 23s - loss: 0.3075 - acc: 0.8791 - val_loss: 0.3233 - val_acc: 0.8727

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 0s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 247us/step
current Test accuracy: 0.803763440860215
current auc_score ------------------>  0.8884526390334143
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_22 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_22[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_308 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_308[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_309 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_309[0][0]             
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_125[0][0]            
__________________________________________________________________________________________________
activation_310 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_310[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_311 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_311[0][0]             
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 28, 96, 96)   0           concatenate_125[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 28, 96, 96)   112         concatenate_126[0][0]            
__________________________________________________________________________________________________
activation_312 (Activation)     (None, 28, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 14, 96, 96)   392         activation_312[0][0]             
__________________________________________________________________________________________________
average_pooling2d_39 (AveragePo (None, 14, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 14, 48, 48)   56          average_pooling2d_39[0][0]       
__________________________________________________________________________________________________
activation_313 (Activation)     (None, 14, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   336         activation_313[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_314 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_314[0][0]             
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_39[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 20, 48, 48)   80          concatenate_127[0][0]            
__________________________________________________________________________________________________
activation_315 (Activation)     (None, 20, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   480         activation_315[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_316 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_316[0][0]             
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 26, 48, 48)   0           concatenate_127[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 26, 48, 48)   104         concatenate_128[0][0]            
__________________________________________________________________________________________________
activation_317 (Activation)     (None, 26, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 13, 48, 48)   338         activation_317[0][0]             
__________________________________________________________________________________________________
average_pooling2d_40 (AveragePo (None, 13, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 13, 24, 24)   52          average_pooling2d_40[0][0]       
__________________________________________________________________________________________________
activation_318 (Activation)     (None, 13, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   312         activation_318[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_319 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_319[0][0]             
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 19, 24, 24)   0           average_pooling2d_40[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 19, 24, 24)   76          concatenate_129[0][0]            
__________________________________________________________________________________________________
activation_320 (Activation)     (None, 19, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   456         activation_320[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_321 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_321[0][0]             
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 25, 24, 24)   0           concatenate_129[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 25, 24, 24)   100         concatenate_130[0][0]            
__________________________________________________________________________________________________
activation_322 (Activation)     (None, 25, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_22 (Gl (None, 25)           0           activation_322[0][0]             
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 1)            26          global_average_pooling2d_22[0][0]
==================================================================================================
Total params: 12,624
Trainable params: 11,970
Non-trainable params: 654
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 32s - loss: 0.5898 - acc: 0.7265 - val_loss: 0.5276 - val_acc: 0.7666
Epoch 2/50
 - 23s - loss: 0.5109 - acc: 0.7753 - val_loss: 0.4840 - val_acc: 0.7834
Epoch 3/50
 - 23s - loss: 0.4790 - acc: 0.7861 - val_loss: 0.4740 - val_acc: 0.7889
Epoch 4/50
 - 23s - loss: 0.4621 - acc: 0.7920 - val_loss: 0.4941 - val_acc: 0.7620
Epoch 5/50
 - 23s - loss: 0.4488 - acc: 0.8006 - val_loss: 0.4274 - val_acc: 0.8119
Epoch 6/50
 - 23s - loss: 0.4384 - acc: 0.8073 - val_loss: 0.4705 - val_acc: 0.7899
Epoch 7/50
 - 23s - loss: 0.4285 - acc: 0.8125 - val_loss: 0.4237 - val_acc: 0.8165
Epoch 8/50
 - 23s - loss: 0.4181 - acc: 0.8169 - val_loss: 0.4095 - val_acc: 0.8189
Epoch 9/50
 - 23s - loss: 0.4083 - acc: 0.8218 - val_loss: 0.3964 - val_acc: 0.8271
Epoch 10/50
 - 23s - loss: 0.4030 - acc: 0.8270 - val_loss: 0.3965 - val_acc: 0.8351
Epoch 11/50
 - 23s - loss: 0.3942 - acc: 0.8338 - val_loss: 0.3923 - val_acc: 0.8367
Epoch 12/50
 - 23s - loss: 0.3902 - acc: 0.8347 - val_loss: 0.3861 - val_acc: 0.8436
Epoch 13/50
 - 23s - loss: 0.3845 - acc: 0.8402 - val_loss: 0.3994 - val_acc: 0.8399
Epoch 14/50
 - 23s - loss: 0.3769 - acc: 0.8411 - val_loss: 0.3760 - val_acc: 0.8395
Epoch 15/50
 - 23s - loss: 0.3721 - acc: 0.8461 - val_loss: 0.3806 - val_acc: 0.8463
Epoch 16/50
 - 23s - loss: 0.3684 - acc: 0.8479 - val_loss: 0.4288 - val_acc: 0.8262
Epoch 17/50
 - 23s - loss: 0.3630 - acc: 0.8511 - val_loss: 0.3641 - val_acc: 0.8513
Epoch 18/50
 - 23s - loss: 0.3576 - acc: 0.8533 - val_loss: 0.3598 - val_acc: 0.8540
Epoch 19/50
 - 23s - loss: 0.3543 - acc: 0.8550 - val_loss: 0.3423 - val_acc: 0.8587
Epoch 20/50
 - 23s - loss: 0.3492 - acc: 0.8575 - val_loss: 0.3525 - val_acc: 0.8576
Epoch 21/50
 - 23s - loss: 0.3439 - acc: 0.8598 - val_loss: 0.3555 - val_acc: 0.8534
Epoch 22/50
 - 23s - loss: 0.3395 - acc: 0.8629 - val_loss: 0.3411 - val_acc: 0.8635
Epoch 23/50
 - 23s - loss: 0.3355 - acc: 0.8659 - val_loss: 0.3679 - val_acc: 0.8399
Epoch 24/50
 - 23s - loss: 0.3324 - acc: 0.8676 - val_loss: 0.3346 - val_acc: 0.8638
Epoch 25/50
 - 23s - loss: 0.3327 - acc: 0.8674 - val_loss: 0.3404 - val_acc: 0.8668
Epoch 26/50
 - 23s - loss: 0.3245 - acc: 0.8703 - val_loss: 0.3190 - val_acc: 0.8744
Epoch 27/50
 - 23s - loss: 0.3224 - acc: 0.8727 - val_loss: 0.3500 - val_acc: 0.8545
Epoch 28/50
 - 23s - loss: 0.3220 - acc: 0.8716 - val_loss: 0.3220 - val_acc: 0.8734
Epoch 29/50
 - 23s - loss: 0.3177 - acc: 0.8729 - val_loss: 0.3230 - val_acc: 0.8714
Epoch 30/50
 - 23s - loss: 0.3153 - acc: 0.8769 - val_loss: 0.3405 - val_acc: 0.8599

Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 31/50
 - 23s - loss: 0.2991 - acc: 0.8812 - val_loss: 0.3097 - val_acc: 0.8805
Epoch 32/50
 - 23s - loss: 0.2978 - acc: 0.8860 - val_loss: 0.3090 - val_acc: 0.8800
Epoch 33/50
 - 23s - loss: 0.2988 - acc: 0.8850 - val_loss: 0.3081 - val_acc: 0.8788
Epoch 34/50
 - 23s - loss: 0.2947 - acc: 0.8870 - val_loss: 0.3020 - val_acc: 0.8827
Epoch 35/50
 - 23s - loss: 0.2936 - acc: 0.8876 - val_loss: 0.3120 - val_acc: 0.8753
Epoch 36/50
 - 23s - loss: 0.2920 - acc: 0.8874 - val_loss: 0.3204 - val_acc: 0.8719
Epoch 37/50
 - 23s - loss: 0.2892 - acc: 0.8896 - val_loss: 0.3001 - val_acc: 0.8815
Epoch 38/50
 - 23s - loss: 0.2904 - acc: 0.8893 - val_loss: 0.2975 - val_acc: 0.8884
Epoch 39/50
 - 23s - loss: 0.2895 - acc: 0.8899 - val_loss: 0.3098 - val_acc: 0.8765
Epoch 40/50
 - 23s - loss: 0.2886 - acc: 0.8882 - val_loss: 0.3392 - val_acc: 0.8603
Epoch 41/50
 - 23s - loss: 0.2898 - acc: 0.8892 - val_loss: 0.2991 - val_acc: 0.8853
Epoch 42/50
 - 23s - loss: 0.2872 - acc: 0.8886 - val_loss: 0.2979 - val_acc: 0.8820

Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 43/50
 - 23s - loss: 0.2802 - acc: 0.8929 - val_loss: 0.2947 - val_acc: 0.8863
Epoch 44/50
 - 23s - loss: 0.2794 - acc: 0.8954 - val_loss: 0.2927 - val_acc: 0.8877
Epoch 45/50
 - 23s - loss: 0.2805 - acc: 0.8928 - val_loss: 0.2945 - val_acc: 0.8859
Epoch 46/50
 - 23s - loss: 0.2790 - acc: 0.8950 - val_loss: 0.2938 - val_acc: 0.8879
Epoch 47/50
 - 23s - loss: 0.2806 - acc: 0.8936 - val_loss: 0.2933 - val_acc: 0.8886
Epoch 48/50
 - 23s - loss: 0.2812 - acc: 0.8941 - val_loss: 0.2959 - val_acc: 0.8854

Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 49/50
 - 23s - loss: 0.2775 - acc: 0.8962 - val_loss: 0.2910 - val_acc: 0.8881
Epoch 50/50
 - 23s - loss: 0.2767 - acc: 0.8959 - val_loss: 0.2911 - val_acc: 0.8868

  32/7440 [..............................] - ETA: 1s
 256/7440 [>.............................] - ETA: 1s
 480/7440 [>.............................] - ETA: 1s
 704/7440 [=>............................] - ETA: 1s
 928/7440 [==>...........................] - ETA: 1s
1152/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1824/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2496/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3168/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 0s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4288/7440 [================>.............] - ETA: 0s
4512/7440 [=================>............] - ETA: 0s
4736/7440 [==================>...........] - ETA: 0s
4960/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5856/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 249us/step
current Test accuracy: 0.8022849462365591
current auc_score ------------------>  0.8836743409642733
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_23[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_323 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_323[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_324 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_324[0][0]             
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_131[0][0]            
__________________________________________________________________________________________________
activation_325 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_325[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_326 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_326[0][0]             
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 28, 96, 96)   0           concatenate_131[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_132[0][0]            
__________________________________________________________________________________________________
activation_327 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_327[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_328 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_328[0][0]             
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 34, 96, 96)   0           concatenate_132[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_133[0][0]            
__________________________________________________________________________________________________
activation_329 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_329[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_330 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_330[0][0]             
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 40, 96, 96)   0           concatenate_133[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_134[0][0]            
__________________________________________________________________________________________________
activation_331 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_331[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_332 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_332[0][0]             
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 46, 96, 96)   0           concatenate_134[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_135[0][0]            
__________________________________________________________________________________________________
activation_333 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_333[0][0]             
__________________________________________________________________________________________________
average_pooling2d_41 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_41[0][0]       
__________________________________________________________________________________________________
activation_334 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_334[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_335 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_335[0][0]             
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 29, 48, 48)   0           average_pooling2d_41[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_136[0][0]            
__________________________________________________________________________________________________
activation_336 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_336[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_337 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_337[0][0]             
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 35, 48, 48)   0           concatenate_136[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_137[0][0]            
__________________________________________________________________________________________________
activation_338 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_338[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_339 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_339[0][0]             
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 41, 48, 48)   0           concatenate_137[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_138[0][0]            
__________________________________________________________________________________________________
activation_340 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_340[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_341 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_341[0][0]             
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 47, 48, 48)   0           concatenate_138[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_139[0][0]            
__________________________________________________________________________________________________
activation_342 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_342[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_343 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_343[0][0]             
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 53, 48, 48)   0           concatenate_139[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_140[0][0]            
__________________________________________________________________________________________________
activation_344 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_344[0][0]             
__________________________________________________________________________________________________
average_pooling2d_42 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_42[0][0]       
__________________________________________________________________________________________________
activation_345 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   624         activation_345[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_346 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_346[0][0]             
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 32, 24, 24)   0           average_pooling2d_42[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 32, 24, 24)   128         concatenate_141[0][0]            
__________________________________________________________________________________________________
activation_347 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   768         activation_347[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_348 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_348[0][0]             
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 38, 24, 24)   0           concatenate_141[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_142[0][0]            
__________________________________________________________________________________________________
activation_349 (Activation)     (None, 38, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   912         activation_349[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_350 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_350[0][0]             
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 44, 24, 24)   0           concatenate_142[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_143[0][0]            
__________________________________________________________________________________________________
activation_351 (Activation)     (None, 44, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 24, 24, 24)   1056        activation_351[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_352 (Activation)     (None, 24, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_352[0][0]             
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 50, 24, 24)   0           concatenate_143[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_144[0][0]            
__________________________________________________________________________________________________
activation_353 (Activation)     (None, 50, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 24, 24, 24)   1200        activation_353[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_354 (Activation)     (None, 24, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_354[0][0]             
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 56, 24, 24)   0           concatenate_144[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 56, 24, 24)   224         concatenate_145[0][0]            
__________________________________________________________________________________________________
activation_355 (Activation)     (None, 56, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_23 (Gl (None, 56)           0           activation_355[0][0]             
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 1)            57          global_average_pooling2d_23[0][0]
==================================================================================================
Total params: 38,421
Trainable params: 36,381
Non-trainable params: 2,040
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 61s - loss: 0.5969 - acc: 0.7417 - val_loss: 0.5207 - val_acc: 0.7828
Epoch 2/50
 - 48s - loss: 0.5029 - acc: 0.7919 - val_loss: 0.5297 - val_acc: 0.7952
Epoch 3/50
 - 48s - loss: 0.4631 - acc: 0.8132 - val_loss: 0.4339 - val_acc: 0.8268
Epoch 4/50
 - 48s - loss: 0.4299 - acc: 0.8353 - val_loss: 0.4362 - val_acc: 0.8362
Epoch 5/50
 - 48s - loss: 0.4038 - acc: 0.8495 - val_loss: 0.4961 - val_acc: 0.7795
Epoch 6/50
 - 48s - loss: 0.3795 - acc: 0.8618 - val_loss: 0.3610 - val_acc: 0.8692
Epoch 7/50
 - 48s - loss: 0.3580 - acc: 0.8745 - val_loss: 0.3468 - val_acc: 0.8770
Epoch 8/50
 - 48s - loss: 0.3443 - acc: 0.8811 - val_loss: 0.4027 - val_acc: 0.8485
Epoch 9/50
 - 48s - loss: 0.3275 - acc: 0.8893 - val_loss: 0.3396 - val_acc: 0.8864
Epoch 10/50
 - 48s - loss: 0.3106 - acc: 0.8991 - val_loss: 0.3842 - val_acc: 0.8596
Epoch 11/50
 - 48s - loss: 0.3016 - acc: 0.9026 - val_loss: 0.3032 - val_acc: 0.9034
Epoch 12/50
 - 48s - loss: 0.2895 - acc: 0.9078 - val_loss: 0.3196 - val_acc: 0.8934
Epoch 13/50
 - 48s - loss: 0.2806 - acc: 0.9113 - val_loss: 0.3204 - val_acc: 0.8942
Epoch 14/50
 - 48s - loss: 0.2698 - acc: 0.9167 - val_loss: 0.3808 - val_acc: 0.8633
Epoch 15/50
 - 48s - loss: 0.2672 - acc: 0.9178 - val_loss: 0.3275 - val_acc: 0.8889

Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 16/50
 - 48s - loss: 0.2382 - acc: 0.9324 - val_loss: 0.2990 - val_acc: 0.9085
Epoch 17/50
 - 48s - loss: 0.2335 - acc: 0.9355 - val_loss: 0.2594 - val_acc: 0.9211
Epoch 18/50
 - 48s - loss: 0.2301 - acc: 0.9365 - val_loss: 0.2723 - val_acc: 0.9118
Epoch 19/50
 - 48s - loss: 0.2237 - acc: 0.9396 - val_loss: 0.2640 - val_acc: 0.9157
Epoch 20/50
 - 48s - loss: 0.2241 - acc: 0.9385 - val_loss: 0.2681 - val_acc: 0.9206
Epoch 21/50
 - 48s - loss: 0.2221 - acc: 0.9393 - val_loss: 0.2572 - val_acc: 0.9223
Epoch 22/50
 - 48s - loss: 0.2157 - acc: 0.9425 - val_loss: 0.2962 - val_acc: 0.9066
Epoch 23/50
 - 48s - loss: 0.2133 - acc: 0.9431 - val_loss: 0.2970 - val_acc: 0.9025
Epoch 24/50
 - 48s - loss: 0.2110 - acc: 0.9440 - val_loss: 0.2745 - val_acc: 0.9105
Epoch 25/50
 - 48s - loss: 0.2058 - acc: 0.9452 - val_loss: 0.2582 - val_acc: 0.9201

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 26/50
 - 48s - loss: 0.2005 - acc: 0.9487 - val_loss: 0.2478 - val_acc: 0.9265
Epoch 27/50
 - 48s - loss: 0.1954 - acc: 0.9522 - val_loss: 0.2509 - val_acc: 0.9256
Epoch 28/50
 - 48s - loss: 0.1987 - acc: 0.9511 - val_loss: 0.2557 - val_acc: 0.9213
Epoch 29/50
 - 48s - loss: 0.1959 - acc: 0.9504 - val_loss: 0.2473 - val_acc: 0.9266
Epoch 30/50
 - 48s - loss: 0.1961 - acc: 0.9504 - val_loss: 0.2502 - val_acc: 0.9234
Epoch 31/50
 - 48s - loss: 0.1956 - acc: 0.9518 - val_loss: 0.2467 - val_acc: 0.9258
Epoch 32/50
 - 48s - loss: 0.1911 - acc: 0.9527 - val_loss: 0.2466 - val_acc: 0.9248
Epoch 33/50
 - 48s - loss: 0.1917 - acc: 0.9524 - val_loss: 0.2483 - val_acc: 0.9242
Epoch 34/50
 - 48s - loss: 0.1888 - acc: 0.9537 - val_loss: 0.2577 - val_acc: 0.9214
Epoch 35/50
 - 48s - loss: 0.1892 - acc: 0.9523 - val_loss: 0.2513 - val_acc: 0.9243

Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 36/50
 - 48s - loss: 0.1878 - acc: 0.9543 - val_loss: 0.2464 - val_acc: 0.9246
Epoch 37/50
 - 48s - loss: 0.1892 - acc: 0.9537 - val_loss: 0.2462 - val_acc: 0.9276
Epoch 38/50
 - 48s - loss: 0.1859 - acc: 0.9551 - val_loss: 0.2453 - val_acc: 0.9256
Epoch 39/50
 - 48s - loss: 0.1868 - acc: 0.9550 - val_loss: 0.2455 - val_acc: 0.9272
Epoch 40/50
 - 48s - loss: 0.1848 - acc: 0.9558 - val_loss: 0.2461 - val_acc: 0.9267
Epoch 41/50
 - 48s - loss: 0.1856 - acc: 0.9553 - val_loss: 0.2458 - val_acc: 0.9271
Epoch 42/50
 - 48s - loss: 0.1847 - acc: 0.9550 - val_loss: 0.2454 - val_acc: 0.9276

Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 43/50
 - 48s - loss: 0.1833 - acc: 0.9559 - val_loss: 0.2448 - val_acc: 0.9267
Epoch 44/50
 - 48s - loss: 0.1846 - acc: 0.9555 - val_loss: 0.2458 - val_acc: 0.9262
Epoch 45/50
 - 48s - loss: 0.1847 - acc: 0.9562 - val_loss: 0.2450 - val_acc: 0.9262
Epoch 46/50
 - 48s - loss: 0.1825 - acc: 0.9567 - val_loss: 0.2451 - val_acc: 0.9276
Epoch 47/50
 - 48s - loss: 0.1832 - acc: 0.9573 - val_loss: 0.2447 - val_acc: 0.9265

Epoch 00047: ReduceLROnPlateau reducing learning rate to 6.324554585350097e-07.
Epoch 48/50
 - 48s - loss: 0.1848 - acc: 0.9554 - val_loss: 0.2454 - val_acc: 0.9263
Epoch 49/50
 - 48s - loss: 0.1849 - acc: 0.9541 - val_loss: 0.2454 - val_acc: 0.9267
Epoch 50/50
 - 48s - loss: 0.1823 - acc: 0.9568 - val_loss: 0.2450 - val_acc: 0.9270

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 928/7440 [==>...........................] - ETA: 3s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 465us/step
current Test accuracy: 0.7971774193548387
current auc_score ------------------>  0.8912682824603999
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_24 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_24[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_356 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_356[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_357 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_357[0][0]             
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_146[0][0]            
__________________________________________________________________________________________________
activation_358 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_358[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_359 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_359[0][0]             
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 28, 96, 96)   0           concatenate_146[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 28, 96, 96)   112         concatenate_147[0][0]            
__________________________________________________________________________________________________
activation_360 (Activation)     (None, 28, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 14, 96, 96)   392         activation_360[0][0]             
__________________________________________________________________________________________________
average_pooling2d_43 (AveragePo (None, 14, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 14, 48, 48)   56          average_pooling2d_43[0][0]       
__________________________________________________________________________________________________
activation_361 (Activation)     (None, 14, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   336         activation_361[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_362 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_362[0][0]             
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_43[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 20, 48, 48)   80          concatenate_148[0][0]            
__________________________________________________________________________________________________
activation_363 (Activation)     (None, 20, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   480         activation_363[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_364 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_364[0][0]             
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 26, 48, 48)   0           concatenate_148[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 26, 48, 48)   104         concatenate_149[0][0]            
__________________________________________________________________________________________________
activation_365 (Activation)     (None, 26, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 13, 48, 48)   338         activation_365[0][0]             
__________________________________________________________________________________________________
average_pooling2d_44 (AveragePo (None, 13, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 13, 24, 24)   52          average_pooling2d_44[0][0]       
__________________________________________________________________________________________________
activation_366 (Activation)     (None, 13, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   312         activation_366[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_367 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_367[0][0]             
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 19, 24, 24)   0           average_pooling2d_44[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 19, 24, 24)   76          concatenate_150[0][0]            
__________________________________________________________________________________________________
activation_368 (Activation)     (None, 19, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   456         activation_368[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_369 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_369[0][0]             
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 25, 24, 24)   0           concatenate_150[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 25, 24, 24)   100         concatenate_151[0][0]            
__________________________________________________________________________________________________
activation_370 (Activation)     (None, 25, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 12, 24, 24)   300         activation_370[0][0]             
__________________________________________________________________________________________________
average_pooling2d_45 (AveragePo (None, 12, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 12, 12, 12)   48          average_pooling2d_45[0][0]       
__________________________________________________________________________________________________
activation_371 (Activation)     (None, 12, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   288         activation_371[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_372 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_372[0][0]             
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 18, 12, 12)   0           average_pooling2d_45[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 18, 12, 12)   72          concatenate_152[0][0]            
__________________________________________________________________________________________________
activation_373 (Activation)     (None, 18, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   432         activation_373[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_374 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_374[0][0]             
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 24, 12, 12)   0           concatenate_152[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 24, 12, 12)   96          concatenate_153[0][0]            
__________________________________________________________________________________________________
activation_375 (Activation)     (None, 24, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_24 (Gl (None, 24)           0           activation_375[0][0]             
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 1)            25          global_average_pooling2d_24[0][0]
==================================================================================================
Total params: 16,643
Trainable params: 15,785
Non-trainable params: 858
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 39s - loss: 0.5477 - acc: 0.7551 - val_loss: 0.4967 - val_acc: 0.7754
Epoch 2/50
 - 27s - loss: 0.4673 - acc: 0.7958 - val_loss: 0.4479 - val_acc: 0.8076
Epoch 3/50
 - 27s - loss: 0.4388 - acc: 0.8116 - val_loss: 0.4248 - val_acc: 0.8205
Epoch 4/50
 - 27s - loss: 0.4132 - acc: 0.8309 - val_loss: 0.3930 - val_acc: 0.8363
Epoch 5/50
 - 27s - loss: 0.3928 - acc: 0.8420 - val_loss: 0.3837 - val_acc: 0.8448
Epoch 6/50
 - 28s - loss: 0.3765 - acc: 0.8515 - val_loss: 0.3548 - val_acc: 0.8601
Epoch 7/50
 - 27s - loss: 0.3678 - acc: 0.8566 - val_loss: 0.3510 - val_acc: 0.8642
Epoch 8/50
 - 27s - loss: 0.3517 - acc: 0.8652 - val_loss: 0.3403 - val_acc: 0.8711
Epoch 9/50
 - 27s - loss: 0.3400 - acc: 0.8700 - val_loss: 0.3403 - val_acc: 0.8721
Epoch 10/50
 - 27s - loss: 0.3320 - acc: 0.8739 - val_loss: 0.3895 - val_acc: 0.8478
Epoch 11/50
 - 27s - loss: 0.3216 - acc: 0.8789 - val_loss: 0.3245 - val_acc: 0.8771
Epoch 12/50
 - 27s - loss: 0.3136 - acc: 0.8827 - val_loss: 0.3066 - val_acc: 0.8835
Epoch 13/50
 - 28s - loss: 0.3054 - acc: 0.8870 - val_loss: 0.3158 - val_acc: 0.8849
Epoch 14/50
 - 27s - loss: 0.2998 - acc: 0.8892 - val_loss: 0.2908 - val_acc: 0.8917
Epoch 15/50
 - 27s - loss: 0.2920 - acc: 0.8941 - val_loss: 0.3087 - val_acc: 0.8883
Epoch 16/50
 - 27s - loss: 0.2861 - acc: 0.8965 - val_loss: 0.2914 - val_acc: 0.8934
Epoch 17/50
 - 27s - loss: 0.2785 - acc: 0.8992 - val_loss: 0.2902 - val_acc: 0.8960
Epoch 18/50
 - 28s - loss: 0.2728 - acc: 0.9037 - val_loss: 0.2818 - val_acc: 0.8981
Epoch 19/50
 - 28s - loss: 0.2674 - acc: 0.9053 - val_loss: 0.2806 - val_acc: 0.8985
Epoch 20/50
 - 27s - loss: 0.2621 - acc: 0.9080 - val_loss: 0.2711 - val_acc: 0.9052
Epoch 21/50
 - 27s - loss: 0.2604 - acc: 0.9088 - val_loss: 0.2957 - val_acc: 0.8894
Epoch 22/50
 - 27s - loss: 0.2560 - acc: 0.9113 - val_loss: 0.2602 - val_acc: 0.9101
Epoch 23/50
 - 28s - loss: 0.2521 - acc: 0.9130 - val_loss: 0.2665 - val_acc: 0.9057
Epoch 24/50
 - 27s - loss: 0.2479 - acc: 0.9143 - val_loss: 0.2715 - val_acc: 0.9081
Epoch 25/50
 - 28s - loss: 0.2450 - acc: 0.9149 - val_loss: 0.2831 - val_acc: 0.8934
Epoch 26/50
 - 28s - loss: 0.2395 - acc: 0.9191 - val_loss: 0.2518 - val_acc: 0.9150
Epoch 27/50
 - 28s - loss: 0.2344 - acc: 0.9205 - val_loss: 0.3023 - val_acc: 0.8864
Epoch 28/50
 - 28s - loss: 0.2332 - acc: 0.9215 - val_loss: 0.2494 - val_acc: 0.9118
Epoch 29/50
 - 27s - loss: 0.2274 - acc: 0.9226 - val_loss: 0.2405 - val_acc: 0.9175
Epoch 30/50
 - 28s - loss: 0.2289 - acc: 0.9240 - val_loss: 0.2893 - val_acc: 0.8967
Epoch 31/50
 - 28s - loss: 0.2262 - acc: 0.9239 - val_loss: 0.3023 - val_acc: 0.8941
Epoch 32/50
 - 28s - loss: 0.2190 - acc: 0.9266 - val_loss: 0.2567 - val_acc: 0.9137
Epoch 33/50
 - 28s - loss: 0.2147 - acc: 0.9287 - val_loss: 0.2621 - val_acc: 0.9049

Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 34/50
 - 27s - loss: 0.2002 - acc: 0.9366 - val_loss: 0.2354 - val_acc: 0.9179
Epoch 35/50
 - 27s - loss: 0.1990 - acc: 0.9363 - val_loss: 0.2277 - val_acc: 0.9218
Epoch 36/50
 - 27s - loss: 0.1945 - acc: 0.9396 - val_loss: 0.2265 - val_acc: 0.9252
Epoch 37/50
 - 27s - loss: 0.1959 - acc: 0.9371 - val_loss: 0.2222 - val_acc: 0.9260
Epoch 38/50
 - 27s - loss: 0.1912 - acc: 0.9409 - val_loss: 0.2273 - val_acc: 0.9244
Epoch 39/50
 - 27s - loss: 0.1908 - acc: 0.9397 - val_loss: 0.2249 - val_acc: 0.9255
Epoch 40/50
 - 27s - loss: 0.1920 - acc: 0.9378 - val_loss: 0.2277 - val_acc: 0.9262
Epoch 41/50
 - 27s - loss: 0.1908 - acc: 0.9401 - val_loss: 0.2251 - val_acc: 0.9276

Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 42/50
 - 27s - loss: 0.1821 - acc: 0.9432 - val_loss: 0.2174 - val_acc: 0.9276
Epoch 43/50
 - 27s - loss: 0.1828 - acc: 0.9436 - val_loss: 0.2165 - val_acc: 0.9301
Epoch 44/50
 - 27s - loss: 0.1806 - acc: 0.9448 - val_loss: 0.2149 - val_acc: 0.9295
Epoch 45/50
 - 27s - loss: 0.1825 - acc: 0.9449 - val_loss: 0.2183 - val_acc: 0.9278
Epoch 46/50
 - 27s - loss: 0.1810 - acc: 0.9440 - val_loss: 0.2148 - val_acc: 0.9293
Epoch 47/50
 - 27s - loss: 0.1812 - acc: 0.9439 - val_loss: 0.2168 - val_acc: 0.9282
Epoch 48/50
 - 27s - loss: 0.1821 - acc: 0.9442 - val_loss: 0.2138 - val_acc: 0.9298
Epoch 49/50
 - 27s - loss: 0.1814 - acc: 0.9448 - val_loss: 0.2160 - val_acc: 0.9296
Epoch 50/50
 - 27s - loss: 0.1778 - acc: 0.9457 - val_loss: 0.2141 - val_acc: 0.9302

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1792/7440 [======>.......................] - ETA: 1s
1984/7440 [=======>......................] - ETA: 1s
2208/7440 [=======>......................] - ETA: 1s
2432/7440 [========>.....................] - ETA: 1s
2624/7440 [=========>....................] - ETA: 1s
2816/7440 [==========>...................] - ETA: 1s
3008/7440 [===========>..................] - ETA: 1s
3200/7440 [===========>..................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3840/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4480/7440 [=================>............] - ETA: 0s
4672/7440 [=================>............] - ETA: 0s
4864/7440 [==================>...........] - ETA: 0s
5056/7440 [===================>..........] - ETA: 0s
5248/7440 [====================>.........] - ETA: 0s
5440/7440 [====================>.........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6976/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 267us/step
current Test accuracy: 0.8217741935483871
current auc_score ------------------>  0.9133045727829806
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_25[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_376 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_376[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_377 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_377[0][0]             
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_154[0][0]            
__________________________________________________________________________________________________
activation_378 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_378[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_379 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_379[0][0]             
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 28, 96, 96)   0           concatenate_154[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_155[0][0]            
__________________________________________________________________________________________________
activation_380 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_380[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_381 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_381[0][0]             
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 34, 96, 96)   0           concatenate_155[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_156[0][0]            
__________________________________________________________________________________________________
activation_382 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_382[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_383 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_383[0][0]             
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 40, 96, 96)   0           concatenate_156[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_157[0][0]            
__________________________________________________________________________________________________
activation_384 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_384[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_385 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_385[0][0]             
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 46, 96, 96)   0           concatenate_157[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_158[0][0]            
__________________________________________________________________________________________________
activation_386 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_386[0][0]             
__________________________________________________________________________________________________
average_pooling2d_46 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_46[0][0]       
__________________________________________________________________________________________________
activation_387 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_387[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_388 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_388[0][0]             
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 29, 48, 48)   0           average_pooling2d_46[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_159[0][0]            
__________________________________________________________________________________________________
activation_389 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_389[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_390 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_390[0][0]             
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 35, 48, 48)   0           concatenate_159[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_160[0][0]            
__________________________________________________________________________________________________
activation_391 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_391[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_392 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_392[0][0]             
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 41, 48, 48)   0           concatenate_160[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_161[0][0]            
__________________________________________________________________________________________________
activation_393 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_393[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_394 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_394[0][0]             
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 47, 48, 48)   0           concatenate_161[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_162[0][0]            
__________________________________________________________________________________________________
activation_395 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_395[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_396 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_396[0][0]             
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 53, 48, 48)   0           concatenate_162[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_163[0][0]            
__________________________________________________________________________________________________
activation_397 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_397[0][0]             
__________________________________________________________________________________________________
average_pooling2d_47 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_47[0][0]       
__________________________________________________________________________________________________
activation_398 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   624         activation_398[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_399 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_399[0][0]             
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 32, 24, 24)   0           average_pooling2d_47[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 32, 24, 24)   128         concatenate_164[0][0]            
__________________________________________________________________________________________________
activation_400 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   768         activation_400[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_401 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_401[0][0]             
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 38, 24, 24)   0           concatenate_164[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_165[0][0]            
__________________________________________________________________________________________________
activation_402 (Activation)     (None, 38, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   912         activation_402[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_403 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_403[0][0]             
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 44, 24, 24)   0           concatenate_165[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_166[0][0]            
__________________________________________________________________________________________________
activation_404 (Activation)     (None, 44, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 24, 24, 24)   1056        activation_404[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_405 (Activation)     (None, 24, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_405[0][0]             
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 50, 24, 24)   0           concatenate_166[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_167[0][0]            
__________________________________________________________________________________________________
activation_406 (Activation)     (None, 50, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 24, 24, 24)   1200        activation_406[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_407 (Activation)     (None, 24, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_407[0][0]             
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 56, 24, 24)   0           concatenate_167[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 56, 24, 24)   224         concatenate_168[0][0]            
__________________________________________________________________________________________________
activation_408 (Activation)     (None, 56, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 28, 24, 24)   1568        activation_408[0][0]             
__________________________________________________________________________________________________
average_pooling2d_48 (AveragePo (None, 28, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         average_pooling2d_48[0][0]       
__________________________________________________________________________________________________
activation_409 (Activation)     (None, 28, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   672         activation_409[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_410 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_410[0][0]             
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 34, 12, 12)   0           average_pooling2d_48[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 34, 12, 12)   136         concatenate_169[0][0]            
__________________________________________________________________________________________________
activation_411 (Activation)     (None, 34, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   816         activation_411[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_412 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_412[0][0]             
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 40, 12, 12)   0           concatenate_169[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_170[0][0]            
__________________________________________________________________________________________________
activation_413 (Activation)     (None, 40, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 24, 12, 12)   960         activation_413[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_414 (Activation)     (None, 24, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_414[0][0]             
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 46, 12, 12)   0           concatenate_170[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_3_bn (BatchNormalizatio (None, 46, 12, 12)   184         concatenate_171[0][0]            
__________________________________________________________________________________________________
activation_415 (Activation)     (None, 46, 12, 12)   0           dense_3_3_bn[0][0]               
__________________________________________________________________________________________________
dense_3_3_bottleneck_conv2D (Co (None, 24, 12, 12)   1104        activation_415[0][0]             
__________________________________________________________________________________________________
dense_3_3_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_416 (Activation)     (None, 24, 12, 12)   0           dense_3_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_3_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_416[0][0]             
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 52, 12, 12)   0           concatenate_171[0][0]            
                                                                 dense_3_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_4_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_172[0][0]            
__________________________________________________________________________________________________
activation_417 (Activation)     (None, 52, 12, 12)   0           dense_3_4_bn[0][0]               
__________________________________________________________________________________________________
dense_3_4_bottleneck_conv2D (Co (None, 24, 12, 12)   1248        activation_417[0][0]             
__________________________________________________________________________________________________
dense_3_4_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_418 (Activation)     (None, 24, 12, 12)   0           dense_3_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_4_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_418[0][0]             
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 58, 12, 12)   0           concatenate_172[0][0]            
                                                                 dense_3_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_173[0][0]            
__________________________________________________________________________________________________
activation_419 (Activation)     (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_25 (Gl (None, 58)           0           activation_419[0][0]             
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 1)            59          global_average_pooling2d_25[0][0]
==================================================================================================
Total params: 52,783
Trainable params: 49,987
Non-trainable params: 2,796
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 74s - loss: 0.5780 - acc: 0.7722 - val_loss: 0.7216 - val_acc: 0.7200
Epoch 2/50
 - 57s - loss: 0.4663 - acc: 0.8311 - val_loss: 0.4308 - val_acc: 0.8528
Epoch 3/50
 - 57s - loss: 0.4161 - acc: 0.8607 - val_loss: 0.4313 - val_acc: 0.8543
Epoch 4/50
 - 57s - loss: 0.3777 - acc: 0.8802 - val_loss: 0.3869 - val_acc: 0.8702
Epoch 5/50
 - 57s - loss: 0.3500 - acc: 0.8929 - val_loss: 0.3435 - val_acc: 0.8960
Epoch 6/50
 - 57s - loss: 0.3278 - acc: 0.9019 - val_loss: 0.3437 - val_acc: 0.9004
Epoch 7/50
 - 57s - loss: 0.3125 - acc: 0.9095 - val_loss: 0.3989 - val_acc: 0.8756
Epoch 8/50
 - 57s - loss: 0.2925 - acc: 0.9217 - val_loss: 0.3064 - val_acc: 0.9143
Epoch 9/50
 - 57s - loss: 0.2795 - acc: 0.9253 - val_loss: 0.3017 - val_acc: 0.9108
Epoch 10/50
 - 57s - loss: 0.2657 - acc: 0.9318 - val_loss: 0.3212 - val_acc: 0.9095
Epoch 11/50
 - 57s - loss: 0.2578 - acc: 0.9346 - val_loss: 0.3031 - val_acc: 0.9207
Epoch 12/50
 - 56s - loss: 0.2473 - acc: 0.9374 - val_loss: 0.2781 - val_acc: 0.9247
Epoch 13/50
 - 57s - loss: 0.2350 - acc: 0.9432 - val_loss: 0.2749 - val_acc: 0.9272
Epoch 14/50
 - 56s - loss: 0.2292 - acc: 0.9457 - val_loss: 0.2826 - val_acc: 0.9256
Epoch 15/50
 - 57s - loss: 0.2216 - acc: 0.9488 - val_loss: 0.2693 - val_acc: 0.9266
Epoch 16/50
 - 57s - loss: 0.2108 - acc: 0.9537 - val_loss: 0.3136 - val_acc: 0.9211
Epoch 17/50
 - 56s - loss: 0.2097 - acc: 0.9538 - val_loss: 0.2825 - val_acc: 0.9177
Epoch 18/50
 - 57s - loss: 0.2004 - acc: 0.9570 - val_loss: 0.2760 - val_acc: 0.9308
Epoch 19/50
 - 57s - loss: 0.1979 - acc: 0.9578 - val_loss: 0.2626 - val_acc: 0.9300
Epoch 20/50
 - 57s - loss: 0.1906 - acc: 0.9615 - val_loss: 0.2836 - val_acc: 0.9199
Epoch 21/50
 - 57s - loss: 0.1828 - acc: 0.9629 - val_loss: 0.2525 - val_acc: 0.9396
Epoch 22/50
 - 57s - loss: 0.1768 - acc: 0.9660 - val_loss: 0.3818 - val_acc: 0.8865
Epoch 23/50
 - 57s - loss: 0.1797 - acc: 0.9641 - val_loss: 0.3085 - val_acc: 0.9154
Epoch 24/50
 - 57s - loss: 0.1737 - acc: 0.9672 - val_loss: 0.2428 - val_acc: 0.9431
Epoch 25/50
 - 57s - loss: 0.1693 - acc: 0.9683 - val_loss: 0.2579 - val_acc: 0.9425
Epoch 26/50
 - 57s - loss: 0.1679 - acc: 0.9682 - val_loss: 0.2422 - val_acc: 0.9419
Epoch 27/50
 - 57s - loss: 0.1649 - acc: 0.9693 - val_loss: 0.2805 - val_acc: 0.9251
Epoch 28/50
 - 57s - loss: 0.1579 - acc: 0.9729 - val_loss: 0.2434 - val_acc: 0.9434
Epoch 29/50
 - 57s - loss: 0.1555 - acc: 0.9733 - val_loss: 0.3092 - val_acc: 0.9346
Epoch 30/50
 - 56s - loss: 0.1558 - acc: 0.9737 - val_loss: 0.2705 - val_acc: 0.9332

Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 31/50
 - 57s - loss: 0.1312 - acc: 0.9838 - val_loss: 0.2171 - val_acc: 0.9498
Epoch 32/50
 - 57s - loss: 0.1268 - acc: 0.9857 - val_loss: 0.2262 - val_acc: 0.9468
Epoch 33/50
 - 57s - loss: 0.1240 - acc: 0.9861 - val_loss: 0.2406 - val_acc: 0.9497
Epoch 34/50
 - 57s - loss: 0.1206 - acc: 0.9879 - val_loss: 0.2404 - val_acc: 0.9492
Epoch 35/50
 - 57s - loss: 0.1215 - acc: 0.9867 - val_loss: 0.2258 - val_acc: 0.9517

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 36/50
 - 56s - loss: 0.1129 - acc: 0.9903 - val_loss: 0.2184 - val_acc: 0.9544
Epoch 37/50
 - 57s - loss: 0.1144 - acc: 0.9902 - val_loss: 0.2159 - val_acc: 0.9529
Epoch 38/50
 - 57s - loss: 0.1136 - acc: 0.9903 - val_loss: 0.2192 - val_acc: 0.9532
Epoch 39/50
 - 57s - loss: 0.1122 - acc: 0.9910 - val_loss: 0.2239 - val_acc: 0.9543
Epoch 40/50
 - 57s - loss: 0.1110 - acc: 0.9909 - val_loss: 0.2234 - val_acc: 0.9548
Epoch 41/50
 - 57s - loss: 0.1098 - acc: 0.9926 - val_loss: 0.2180 - val_acc: 0.9537

Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 42/50
 - 57s - loss: 0.1094 - acc: 0.9922 - val_loss: 0.2169 - val_acc: 0.9548
Epoch 43/50
 - 57s - loss: 0.1094 - acc: 0.9920 - val_loss: 0.2162 - val_acc: 0.9543
Epoch 44/50
 - 57s - loss: 0.1068 - acc: 0.9926 - val_loss: 0.2194 - val_acc: 0.9544
Epoch 00044: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 928/7440 [==>...........................] - ETA: 3s
1056/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1312/7440 [====>.........................] - ETA: 3s
1440/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3232/7440 [============>.................] - ETA: 2s
3360/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 505us/step
current Test accuracy: 0.7471774193548387
current auc_score ------------------>  0.8570217655220256
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_26 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_26[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_420 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_420[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_421 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_421[0][0]             
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_174[0][0]            
__________________________________________________________________________________________________
activation_422 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_422[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_423 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_423[0][0]             
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 28, 96, 96)   0           concatenate_174[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 28, 96, 96)   112         concatenate_175[0][0]            
__________________________________________________________________________________________________
activation_424 (Activation)     (None, 28, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 14, 96, 96)   392         activation_424[0][0]             
__________________________________________________________________________________________________
average_pooling2d_49 (AveragePo (None, 14, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 14, 48, 48)   56          average_pooling2d_49[0][0]       
__________________________________________________________________________________________________
activation_425 (Activation)     (None, 14, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   336         activation_425[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_426 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_426[0][0]             
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_49[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 20, 48, 48)   80          concatenate_176[0][0]            
__________________________________________________________________________________________________
activation_427 (Activation)     (None, 20, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   480         activation_427[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_428 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_428[0][0]             
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 26, 48, 48)   0           concatenate_176[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 26, 48, 48)   104         concatenate_177[0][0]            
__________________________________________________________________________________________________
activation_429 (Activation)     (None, 26, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 13, 48, 48)   338         activation_429[0][0]             
__________________________________________________________________________________________________
average_pooling2d_50 (AveragePo (None, 13, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 13, 24, 24)   52          average_pooling2d_50[0][0]       
__________________________________________________________________________________________________
activation_430 (Activation)     (None, 13, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   312         activation_430[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_431 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_431[0][0]             
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 19, 24, 24)   0           average_pooling2d_50[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 19, 24, 24)   76          concatenate_178[0][0]            
__________________________________________________________________________________________________
activation_432 (Activation)     (None, 19, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   456         activation_432[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_433 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_433[0][0]             
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 25, 24, 24)   0           concatenate_178[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 25, 24, 24)   100         concatenate_179[0][0]            
__________________________________________________________________________________________________
activation_434 (Activation)     (None, 25, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 12, 24, 24)   300         activation_434[0][0]             
__________________________________________________________________________________________________
average_pooling2d_51 (AveragePo (None, 12, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 12, 12, 12)   48          average_pooling2d_51[0][0]       
__________________________________________________________________________________________________
activation_435 (Activation)     (None, 12, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   288         activation_435[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_436 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_436[0][0]             
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 18, 12, 12)   0           average_pooling2d_51[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 18, 12, 12)   72          concatenate_180[0][0]            
__________________________________________________________________________________________________
activation_437 (Activation)     (None, 18, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   432         activation_437[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_438 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_438[0][0]             
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 24, 12, 12)   0           concatenate_180[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 24, 12, 12)   96          concatenate_181[0][0]            
__________________________________________________________________________________________________
activation_439 (Activation)     (None, 24, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_26 (Gl (None, 24)           0           activation_439[0][0]             
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 1)            25          global_average_pooling2d_26[0][0]
==================================================================================================
Total params: 16,643
Trainable params: 15,785
Non-trainable params: 858
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 41s - loss: 0.5936 - acc: 0.7302 - val_loss: 0.5010 - val_acc: 0.7864
Epoch 2/50
 - 28s - loss: 0.4886 - acc: 0.7900 - val_loss: 0.4585 - val_acc: 0.7927
Epoch 3/50
 - 28s - loss: 0.4502 - acc: 0.8066 - val_loss: 0.4456 - val_acc: 0.8151
Epoch 4/50
 - 28s - loss: 0.4232 - acc: 0.8221 - val_loss: 0.4231 - val_acc: 0.8262
Epoch 5/50
 - 28s - loss: 0.4027 - acc: 0.8331 - val_loss: 0.4314 - val_acc: 0.8301
Epoch 6/50
 - 28s - loss: 0.3810 - acc: 0.8458 - val_loss: 0.3908 - val_acc: 0.8505
Epoch 7/50
 - 28s - loss: 0.3661 - acc: 0.8548 - val_loss: 0.3645 - val_acc: 0.8611
Epoch 8/50
 - 28s - loss: 0.3531 - acc: 0.8620 - val_loss: 0.4074 - val_acc: 0.8475
Epoch 9/50
 - 28s - loss: 0.3406 - acc: 0.8679 - val_loss: 0.3221 - val_acc: 0.8798
Epoch 10/50
 - 28s - loss: 0.3313 - acc: 0.8729 - val_loss: 0.3637 - val_acc: 0.8518
Epoch 11/50
 - 28s - loss: 0.3165 - acc: 0.8804 - val_loss: 0.3390 - val_acc: 0.8709
Epoch 12/50
 - 28s - loss: 0.3072 - acc: 0.8830 - val_loss: 0.3832 - val_acc: 0.8540
Epoch 13/50
 - 28s - loss: 0.3031 - acc: 0.8873 - val_loss: 0.3471 - val_acc: 0.8587

Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 14/50
 - 28s - loss: 0.2846 - acc: 0.8985 - val_loss: 0.2907 - val_acc: 0.8931
Epoch 15/50
 - 28s - loss: 0.2806 - acc: 0.8982 - val_loss: 0.2803 - val_acc: 0.9015
Epoch 16/50
 - 28s - loss: 0.2788 - acc: 0.9010 - val_loss: 0.2860 - val_acc: 0.8993
Epoch 17/50
 - 28s - loss: 0.2729 - acc: 0.9032 - val_loss: 0.2888 - val_acc: 0.8928
Epoch 18/50
 - 28s - loss: 0.2717 - acc: 0.9034 - val_loss: 0.2805 - val_acc: 0.8967
Epoch 19/50
 - 28s - loss: 0.2704 - acc: 0.9042 - val_loss: 0.2835 - val_acc: 0.8992

Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 20/50
 - 28s - loss: 0.2653 - acc: 0.9073 - val_loss: 0.2800 - val_acc: 0.9017
Epoch 21/50
 - 28s - loss: 0.2643 - acc: 0.9064 - val_loss: 0.2708 - val_acc: 0.9064
Epoch 22/50
 - 28s - loss: 0.2620 - acc: 0.9090 - val_loss: 0.2698 - val_acc: 0.9047
Epoch 23/50
 - 28s - loss: 0.2593 - acc: 0.9086 - val_loss: 0.2695 - val_acc: 0.9066
Epoch 24/50
 - 28s - loss: 0.2582 - acc: 0.9102 - val_loss: 0.2690 - val_acc: 0.9066
Epoch 25/50
 - 28s - loss: 0.2574 - acc: 0.9107 - val_loss: 0.2678 - val_acc: 0.9064
Epoch 26/50
 - 28s - loss: 0.2573 - acc: 0.9106 - val_loss: 0.2705 - val_acc: 0.9040
Epoch 27/50
 - 28s - loss: 0.2572 - acc: 0.9107 - val_loss: 0.2689 - val_acc: 0.9054
Epoch 28/50
 - 28s - loss: 0.2555 - acc: 0.9119 - val_loss: 0.2719 - val_acc: 0.9031
Epoch 29/50
 - 28s - loss: 0.2563 - acc: 0.9109 - val_loss: 0.2672 - val_acc: 0.9079
Epoch 30/50
 - 28s - loss: 0.2537 - acc: 0.9123 - val_loss: 0.2658 - val_acc: 0.9074
Epoch 31/50
 - 28s - loss: 0.2505 - acc: 0.9162 - val_loss: 0.2664 - val_acc: 0.9073
Epoch 32/50
 - 28s - loss: 0.2519 - acc: 0.9149 - val_loss: 0.2657 - val_acc: 0.9079
Epoch 33/50
 - 28s - loss: 0.2512 - acc: 0.9147 - val_loss: 0.2649 - val_acc: 0.9089
Epoch 34/50
 - 28s - loss: 0.2525 - acc: 0.9130 - val_loss: 0.2653 - val_acc: 0.9068
Epoch 35/50
 - 28s - loss: 0.2497 - acc: 0.9139 - val_loss: 0.2645 - val_acc: 0.9089
Epoch 36/50
 - 28s - loss: 0.2518 - acc: 0.9137 - val_loss: 0.2632 - val_acc: 0.9105
Epoch 37/50
 - 28s - loss: 0.2475 - acc: 0.9153 - val_loss: 0.2660 - val_acc: 0.9084
Epoch 38/50
 - 28s - loss: 0.2516 - acc: 0.9154 - val_loss: 0.2673 - val_acc: 0.9062
Epoch 39/50
 - 30s - loss: 0.2485 - acc: 0.9145 - val_loss: 0.2628 - val_acc: 0.9109
Epoch 40/50
 - 30s - loss: 0.2452 - acc: 0.9174 - val_loss: 0.2643 - val_acc: 0.9081
Epoch 41/50
 - 29s - loss: 0.2477 - acc: 0.9151 - val_loss: 0.2623 - val_acc: 0.9085
Epoch 42/50
 - 29s - loss: 0.2438 - acc: 0.9177 - val_loss: 0.2655 - val_acc: 0.9055
Epoch 43/50
 - 28s - loss: 0.2427 - acc: 0.9177 - val_loss: 0.2632 - val_acc: 0.9101
Epoch 44/50
 - 28s - loss: 0.2451 - acc: 0.9182 - val_loss: 0.2617 - val_acc: 0.9098
Epoch 45/50
 - 28s - loss: 0.2442 - acc: 0.9171 - val_loss: 0.2612 - val_acc: 0.9094
Epoch 46/50
 - 28s - loss: 0.2423 - acc: 0.9192 - val_loss: 0.2591 - val_acc: 0.9110
Epoch 47/50
 - 28s - loss: 0.2436 - acc: 0.9168 - val_loss: 0.2593 - val_acc: 0.9125
Epoch 48/50
 - 28s - loss: 0.2407 - acc: 0.9184 - val_loss: 0.2588 - val_acc: 0.9110
Epoch 49/50
 - 28s - loss: 0.2382 - acc: 0.9208 - val_loss: 0.2583 - val_acc: 0.9116
Epoch 50/50
 - 28s - loss: 0.2397 - acc: 0.9188 - val_loss: 0.2589 - val_acc: 0.9110

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 292us/step
current Test accuracy: 0.817741935483871
current auc_score ------------------>  0.8891979925424907
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_27[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_440 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_440[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_441 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_441[0][0]             
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_182[0][0]            
__________________________________________________________________________________________________
activation_442 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_442[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_443 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_443[0][0]             
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 28, 96, 96)   0           concatenate_182[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 28, 96, 96)   112         concatenate_183[0][0]            
__________________________________________________________________________________________________
activation_444 (Activation)     (None, 28, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 14, 96, 96)   392         activation_444[0][0]             
__________________________________________________________________________________________________
average_pooling2d_52 (AveragePo (None, 14, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 14, 48, 48)   56          average_pooling2d_52[0][0]       
__________________________________________________________________________________________________
activation_445 (Activation)     (None, 14, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   336         activation_445[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_446 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_446[0][0]             
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 20, 48, 48)   0           average_pooling2d_52[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 20, 48, 48)   80          concatenate_184[0][0]            
__________________________________________________________________________________________________
activation_447 (Activation)     (None, 20, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   480         activation_447[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_448 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_448[0][0]             
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 26, 48, 48)   0           concatenate_184[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 26, 48, 48)   104         concatenate_185[0][0]            
__________________________________________________________________________________________________
activation_449 (Activation)     (None, 26, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 13, 48, 48)   338         activation_449[0][0]             
__________________________________________________________________________________________________
average_pooling2d_53 (AveragePo (None, 13, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 13, 24, 24)   52          average_pooling2d_53[0][0]       
__________________________________________________________________________________________________
activation_450 (Activation)     (None, 13, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   312         activation_450[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_451 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_451[0][0]             
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 19, 24, 24)   0           average_pooling2d_53[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 19, 24, 24)   76          concatenate_186[0][0]            
__________________________________________________________________________________________________
activation_452 (Activation)     (None, 19, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   456         activation_452[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_453 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_453[0][0]             
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 25, 24, 24)   0           concatenate_186[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 25, 24, 24)   100         concatenate_187[0][0]            
__________________________________________________________________________________________________
activation_454 (Activation)     (None, 25, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 12, 24, 24)   300         activation_454[0][0]             
__________________________________________________________________________________________________
average_pooling2d_54 (AveragePo (None, 12, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 12, 12, 12)   48          average_pooling2d_54[0][0]       
__________________________________________________________________________________________________
activation_455 (Activation)     (None, 12, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   288         activation_455[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_456 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_456[0][0]             
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 18, 12, 12)   0           average_pooling2d_54[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 18, 12, 12)   72          concatenate_188[0][0]            
__________________________________________________________________________________________________
activation_457 (Activation)     (None, 18, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   432         activation_457[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_458 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_458[0][0]             
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 24, 12, 12)   0           concatenate_188[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 24, 12, 12)   96          concatenate_189[0][0]            
__________________________________________________________________________________________________
activation_459 (Activation)     (None, 24, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_27 (Gl (None, 24)           0           activation_459[0][0]             
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 1)            25          global_average_pooling2d_27[0][0]
==================================================================================================
Total params: 16,643
Trainable params: 15,785
Non-trainable params: 858
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 44s - loss: 0.5372 - acc: 0.7599 - val_loss: 0.4928 - val_acc: 0.7816
Epoch 2/50
 - 28s - loss: 0.4601 - acc: 0.8007 - val_loss: 0.4235 - val_acc: 0.8158
Epoch 3/50
 - 28s - loss: 0.4285 - acc: 0.8186 - val_loss: 0.4165 - val_acc: 0.8199
Epoch 4/50
 - 28s - loss: 0.4062 - acc: 0.8288 - val_loss: 0.4115 - val_acc: 0.8238
Epoch 5/50
 - 28s - loss: 0.3869 - acc: 0.8434 - val_loss: 0.3753 - val_acc: 0.8461
Epoch 6/50
 - 27s - loss: 0.3726 - acc: 0.8503 - val_loss: 0.3598 - val_acc: 0.8592
Epoch 7/50
 - 28s - loss: 0.3589 - acc: 0.8586 - val_loss: 0.3490 - val_acc: 0.8586
Epoch 8/50
 - 28s - loss: 0.3447 - acc: 0.8656 - val_loss: 0.3386 - val_acc: 0.8680
Epoch 9/50
 - 28s - loss: 0.3354 - acc: 0.8713 - val_loss: 0.3725 - val_acc: 0.8525
Epoch 10/50
 - 28s - loss: 0.3260 - acc: 0.8778 - val_loss: 0.3367 - val_acc: 0.8736
Epoch 11/50
 - 28s - loss: 0.3206 - acc: 0.8795 - val_loss: 0.3306 - val_acc: 0.8692
Epoch 12/50
 - 28s - loss: 0.3083 - acc: 0.8847 - val_loss: 0.3604 - val_acc: 0.8613
Epoch 13/50
 - 28s - loss: 0.3027 - acc: 0.8884 - val_loss: 0.3193 - val_acc: 0.8771
Epoch 14/50
 - 28s - loss: 0.2957 - acc: 0.8920 - val_loss: 0.3467 - val_acc: 0.8668
Epoch 15/50
 - 28s - loss: 0.2873 - acc: 0.8969 - val_loss: 0.3213 - val_acc: 0.8761
Epoch 16/50
 - 28s - loss: 0.2836 - acc: 0.8975 - val_loss: 0.3391 - val_acc: 0.8734
Epoch 17/50
 - 28s - loss: 0.2764 - acc: 0.9002 - val_loss: 0.2944 - val_acc: 0.8919
Epoch 18/50
 - 28s - loss: 0.2739 - acc: 0.9016 - val_loss: 0.2872 - val_acc: 0.8962
Epoch 19/50
 - 28s - loss: 0.2667 - acc: 0.9062 - val_loss: 0.2921 - val_acc: 0.8967
Epoch 20/50
 - 28s - loss: 0.2631 - acc: 0.9066 - val_loss: 0.3407 - val_acc: 0.8754
Epoch 21/50
 - 28s - loss: 0.2575 - acc: 0.9093 - val_loss: 0.2854 - val_acc: 0.8983
Epoch 22/50
 - 28s - loss: 0.2546 - acc: 0.9110 - val_loss: 0.2617 - val_acc: 0.9090
Epoch 23/50
 - 28s - loss: 0.2461 - acc: 0.9160 - val_loss: 0.2730 - val_acc: 0.9055
Epoch 24/50
 - 28s - loss: 0.2418 - acc: 0.9179 - val_loss: 0.2652 - val_acc: 0.9064
Epoch 25/50
 - 28s - loss: 0.2384 - acc: 0.9188 - val_loss: 0.2786 - val_acc: 0.9049
Epoch 26/50
 - 28s - loss: 0.2393 - acc: 0.9192 - val_loss: 0.2786 - val_acc: 0.9000

Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 27/50
 - 28s - loss: 0.2192 - acc: 0.9291 - val_loss: 0.2516 - val_acc: 0.9121
Epoch 28/50
 - 28s - loss: 0.2182 - acc: 0.9304 - val_loss: 0.2671 - val_acc: 0.9085
Epoch 29/50
 - 28s - loss: 0.2145 - acc: 0.9296 - val_loss: 0.2536 - val_acc: 0.9123
Epoch 30/50
 - 28s - loss: 0.2126 - acc: 0.9308 - val_loss: 0.2484 - val_acc: 0.9133
Epoch 31/50
 - 28s - loss: 0.2139 - acc: 0.9323 - val_loss: 0.2466 - val_acc: 0.9149
Epoch 32/50
 - 28s - loss: 0.2088 - acc: 0.9329 - val_loss: 0.2487 - val_acc: 0.9114
Epoch 33/50
 - 28s - loss: 0.2072 - acc: 0.9343 - val_loss: 0.2422 - val_acc: 0.9158
Epoch 34/50
 - 28s - loss: 0.2062 - acc: 0.9350 - val_loss: 0.2474 - val_acc: 0.9137
Epoch 35/50
 - 28s - loss: 0.2086 - acc: 0.9330 - val_loss: 0.2553 - val_acc: 0.9129
Epoch 36/50
 - 28s - loss: 0.2080 - acc: 0.9342 - val_loss: 0.2439 - val_acc: 0.9162
Epoch 37/50
 - 28s - loss: 0.2009 - acc: 0.9378 - val_loss: 0.2541 - val_acc: 0.9147

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 38/50
 - 28s - loss: 0.1975 - acc: 0.9389 - val_loss: 0.2405 - val_acc: 0.9173
Epoch 39/50
 - 28s - loss: 0.1938 - acc: 0.9410 - val_loss: 0.2421 - val_acc: 0.9180
Epoch 40/50
 - 28s - loss: 0.1940 - acc: 0.9409 - val_loss: 0.2383 - val_acc: 0.9184
Epoch 41/50
 - 28s - loss: 0.1980 - acc: 0.9386 - val_loss: 0.2425 - val_acc: 0.9174
Epoch 42/50
 - 28s - loss: 0.1939 - acc: 0.9422 - val_loss: 0.2400 - val_acc: 0.9177
Epoch 43/50
 - 28s - loss: 0.1966 - acc: 0.9378 - val_loss: 0.2388 - val_acc: 0.9187
Epoch 44/50
 - 28s - loss: 0.1948 - acc: 0.9397 - val_loss: 0.2378 - val_acc: 0.9182
Epoch 45/50
 - 28s - loss: 0.1942 - acc: 0.9405 - val_loss: 0.2406 - val_acc: 0.9160
Epoch 46/50
 - 28s - loss: 0.1941 - acc: 0.9417 - val_loss: 0.2376 - val_acc: 0.9192
Epoch 47/50
 - 28s - loss: 0.1957 - acc: 0.9400 - val_loss: 0.2374 - val_acc: 0.9177
Epoch 48/50
 - 28s - loss: 0.1926 - acc: 0.9404 - val_loss: 0.2380 - val_acc: 0.9177
Epoch 49/50
 - 28s - loss: 0.1914 - acc: 0.9412 - val_loss: 0.2384 - val_acc: 0.9183
Epoch 50/50
 - 28s - loss: 0.1902 - acc: 0.9408 - val_loss: 0.2386 - val_acc: 0.9189

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3264/7440 [============>.................] - ETA: 1s
3456/7440 [============>.................] - ETA: 1s
3648/7440 [=============>................] - ETA: 1s
3840/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4224/7440 [================>.............] - ETA: 0s
4416/7440 [================>.............] - ETA: 0s
4608/7440 [=================>............] - ETA: 0s
4800/7440 [==================>...........] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5184/7440 [===================>..........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5568/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 306us/step
current Test accuracy: 0.8239247311827957
current auc_score ------------------>  0.902193533934559
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_28 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_28[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_460 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_460[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_461 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_461[0][0]             
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_190[0][0]            
__________________________________________________________________________________________________
activation_462 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_462[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_463 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_463[0][0]             
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 28, 96, 96)   0           concatenate_190[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_191[0][0]            
__________________________________________________________________________________________________
activation_464 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_464[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_465 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_465[0][0]             
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 34, 96, 96)   0           concatenate_191[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_192[0][0]            
__________________________________________________________________________________________________
activation_466 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_466[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_467 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_467[0][0]             
__________________________________________________________________________________________________
concatenate_193 (Concatenate)   (None, 40, 96, 96)   0           concatenate_192[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_193[0][0]            
__________________________________________________________________________________________________
activation_468 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_468[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_469 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_469[0][0]             
__________________________________________________________________________________________________
concatenate_194 (Concatenate)   (None, 46, 96, 96)   0           concatenate_193[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_194[0][0]            
__________________________________________________________________________________________________
activation_470 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_470[0][0]             
__________________________________________________________________________________________________
average_pooling2d_55 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_55[0][0]       
__________________________________________________________________________________________________
activation_471 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_471[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_472 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_472[0][0]             
__________________________________________________________________________________________________
concatenate_195 (Concatenate)   (None, 29, 48, 48)   0           average_pooling2d_55[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_195[0][0]            
__________________________________________________________________________________________________
activation_473 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_473[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_474 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_474[0][0]             
__________________________________________________________________________________________________
concatenate_196 (Concatenate)   (None, 35, 48, 48)   0           concatenate_195[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_196[0][0]            
__________________________________________________________________________________________________
activation_475 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_475[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_476 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_476[0][0]             
__________________________________________________________________________________________________
concatenate_197 (Concatenate)   (None, 41, 48, 48)   0           concatenate_196[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_197[0][0]            
__________________________________________________________________________________________________
activation_477 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_477[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_478 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_478[0][0]             
__________________________________________________________________________________________________
concatenate_198 (Concatenate)   (None, 47, 48, 48)   0           concatenate_197[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_198[0][0]            
__________________________________________________________________________________________________
activation_479 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_479[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_480 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_480[0][0]             
__________________________________________________________________________________________________
concatenate_199 (Concatenate)   (None, 53, 48, 48)   0           concatenate_198[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_199[0][0]            
__________________________________________________________________________________________________
activation_481 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_481[0][0]             
__________________________________________________________________________________________________
average_pooling2d_56 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_56[0][0]       
__________________________________________________________________________________________________
activation_482 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   624         activation_482[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_483 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_483[0][0]             
__________________________________________________________________________________________________
concatenate_200 (Concatenate)   (None, 32, 24, 24)   0           average_pooling2d_56[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 32, 24, 24)   128         concatenate_200[0][0]            
__________________________________________________________________________________________________
activation_484 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   768         activation_484[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_485 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_485[0][0]             
__________________________________________________________________________________________________
concatenate_201 (Concatenate)   (None, 38, 24, 24)   0           concatenate_200[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_201[0][0]            
__________________________________________________________________________________________________
activation_486 (Activation)     (None, 38, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   912         activation_486[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_487 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_487[0][0]             
__________________________________________________________________________________________________
concatenate_202 (Concatenate)   (None, 44, 24, 24)   0           concatenate_201[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_202[0][0]            
__________________________________________________________________________________________________
activation_488 (Activation)     (None, 44, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 24, 24, 24)   1056        activation_488[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_489 (Activation)     (None, 24, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_489[0][0]             
__________________________________________________________________________________________________
concatenate_203 (Concatenate)   (None, 50, 24, 24)   0           concatenate_202[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_203[0][0]            
__________________________________________________________________________________________________
activation_490 (Activation)     (None, 50, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 24, 24, 24)   1200        activation_490[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_491 (Activation)     (None, 24, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_491[0][0]             
__________________________________________________________________________________________________
concatenate_204 (Concatenate)   (None, 56, 24, 24)   0           concatenate_203[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 56, 24, 24)   224         concatenate_204[0][0]            
__________________________________________________________________________________________________
activation_492 (Activation)     (None, 56, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 28, 24, 24)   1568        activation_492[0][0]             
__________________________________________________________________________________________________
average_pooling2d_57 (AveragePo (None, 28, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         average_pooling2d_57[0][0]       
__________________________________________________________________________________________________
activation_493 (Activation)     (None, 28, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   672         activation_493[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_494 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_494[0][0]             
__________________________________________________________________________________________________
concatenate_205 (Concatenate)   (None, 34, 12, 12)   0           average_pooling2d_57[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 34, 12, 12)   136         concatenate_205[0][0]            
__________________________________________________________________________________________________
activation_495 (Activation)     (None, 34, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   816         activation_495[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_496 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_496[0][0]             
__________________________________________________________________________________________________
concatenate_206 (Concatenate)   (None, 40, 12, 12)   0           concatenate_205[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_206[0][0]            
__________________________________________________________________________________________________
activation_497 (Activation)     (None, 40, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 24, 12, 12)   960         activation_497[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_498 (Activation)     (None, 24, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_498[0][0]             
__________________________________________________________________________________________________
concatenate_207 (Concatenate)   (None, 46, 12, 12)   0           concatenate_206[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_3_bn (BatchNormalizatio (None, 46, 12, 12)   184         concatenate_207[0][0]            
__________________________________________________________________________________________________
activation_499 (Activation)     (None, 46, 12, 12)   0           dense_3_3_bn[0][0]               
__________________________________________________________________________________________________
dense_3_3_bottleneck_conv2D (Co (None, 24, 12, 12)   1104        activation_499[0][0]             
__________________________________________________________________________________________________
dense_3_3_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_500 (Activation)     (None, 24, 12, 12)   0           dense_3_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_3_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_500[0][0]             
__________________________________________________________________________________________________
concatenate_208 (Concatenate)   (None, 52, 12, 12)   0           concatenate_207[0][0]            
                                                                 dense_3_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_4_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_208[0][0]            
__________________________________________________________________________________________________
activation_501 (Activation)     (None, 52, 12, 12)   0           dense_3_4_bn[0][0]               
__________________________________________________________________________________________________
dense_3_4_bottleneck_conv2D (Co (None, 24, 12, 12)   1248        activation_501[0][0]             
__________________________________________________________________________________________________
dense_3_4_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_502 (Activation)     (None, 24, 12, 12)   0           dense_3_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_4_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_502[0][0]             
__________________________________________________________________________________________________
concatenate_209 (Concatenate)   (None, 58, 12, 12)   0           concatenate_208[0][0]            
                                                                 dense_3_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_209[0][0]            
__________________________________________________________________________________________________
activation_503 (Activation)     (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_28 (Gl (None, 58)           0           activation_503[0][0]             
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 1)            59          global_average_pooling2d_28[0][0]
==================================================================================================
Total params: 52,783
Trainable params: 49,987
Non-trainable params: 2,796
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 76s - loss: 0.5833 - acc: 0.7694 - val_loss: 0.5353 - val_acc: 0.7838
Epoch 2/50
 - 57s - loss: 0.4737 - acc: 0.8302 - val_loss: 0.4623 - val_acc: 0.8405
Epoch 3/50
 - 57s - loss: 0.4206 - acc: 0.8589 - val_loss: 0.3805 - val_acc: 0.8776
Epoch 4/50
 - 56s - loss: 0.3846 - acc: 0.8771 - val_loss: 0.4024 - val_acc: 0.8616
Epoch 5/50
 - 57s - loss: 0.3574 - acc: 0.8894 - val_loss: 0.3437 - val_acc: 0.8976
Epoch 6/50
 - 57s - loss: 0.3375 - acc: 0.9014 - val_loss: 0.3353 - val_acc: 0.8998
Epoch 7/50
 - 57s - loss: 0.3210 - acc: 0.9071 - val_loss: 0.3196 - val_acc: 0.9116
Epoch 8/50
 - 57s - loss: 0.2994 - acc: 0.9175 - val_loss: 0.3354 - val_acc: 0.9021
Epoch 9/50
 - 56s - loss: 0.2900 - acc: 0.9223 - val_loss: 0.2933 - val_acc: 0.9196
Epoch 10/50
 - 56s - loss: 0.2765 - acc: 0.9283 - val_loss: 0.3145 - val_acc: 0.9118
Epoch 11/50
 - 56s - loss: 0.2663 - acc: 0.9339 - val_loss: 0.2832 - val_acc: 0.9246
Epoch 12/50
 - 56s - loss: 0.2563 - acc: 0.9368 - val_loss: 0.2968 - val_acc: 0.9201
Epoch 13/50
 - 57s - loss: 0.2516 - acc: 0.9386 - val_loss: 0.2599 - val_acc: 0.9357
Epoch 14/50
 - 57s - loss: 0.2397 - acc: 0.9423 - val_loss: 0.2656 - val_acc: 0.9360
Epoch 15/50
 - 56s - loss: 0.2322 - acc: 0.9458 - val_loss: 0.4936 - val_acc: 0.8439
Epoch 16/50
 - 57s - loss: 0.2290 - acc: 0.9478 - val_loss: 0.2611 - val_acc: 0.9321
Epoch 17/50
 - 56s - loss: 0.2195 - acc: 0.9516 - val_loss: 0.3390 - val_acc: 0.9056

Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 18/50
 - 56s - loss: 0.1939 - acc: 0.9624 - val_loss: 0.2299 - val_acc: 0.9477
Epoch 19/50
 - 56s - loss: 0.1856 - acc: 0.9653 - val_loss: 0.2293 - val_acc: 0.9478
Epoch 20/50
 - 56s - loss: 0.1821 - acc: 0.9670 - val_loss: 0.2263 - val_acc: 0.9499
Epoch 21/50
 - 56s - loss: 0.1808 - acc: 0.9675 - val_loss: 0.2180 - val_acc: 0.9521
Epoch 22/50
 - 56s - loss: 0.1746 - acc: 0.9701 - val_loss: 0.2214 - val_acc: 0.9514
Epoch 23/50
 - 56s - loss: 0.1745 - acc: 0.9696 - val_loss: 0.2269 - val_acc: 0.9482
Epoch 24/50
 - 56s - loss: 0.1713 - acc: 0.9705 - val_loss: 0.2236 - val_acc: 0.9513
Epoch 25/50
 - 56s - loss: 0.1706 - acc: 0.9708 - val_loss: 0.2221 - val_acc: 0.9517

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 26/50
 - 56s - loss: 0.1642 - acc: 0.9747 - val_loss: 0.2106 - val_acc: 0.9554
Epoch 27/50
 - 56s - loss: 0.1576 - acc: 0.9766 - val_loss: 0.2123 - val_acc: 0.9557
Epoch 28/50
 - 56s - loss: 0.1583 - acc: 0.9763 - val_loss: 0.2126 - val_acc: 0.9552
Epoch 29/50
 - 57s - loss: 0.1551 - acc: 0.9778 - val_loss: 0.2118 - val_acc: 0.9553
Epoch 30/50
 - 56s - loss: 0.1578 - acc: 0.9764 - val_loss: 0.2121 - val_acc: 0.9568

Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 31/50
 - 57s - loss: 0.1541 - acc: 0.9787 - val_loss: 0.2100 - val_acc: 0.9567
Epoch 32/50
 - 56s - loss: 0.1536 - acc: 0.9780 - val_loss: 0.2113 - val_acc: 0.9562
Epoch 33/50
 - 56s - loss: 0.1522 - acc: 0.9789 - val_loss: 0.2098 - val_acc: 0.9570
Epoch 34/50
 - 56s - loss: 0.1524 - acc: 0.9786 - val_loss: 0.2100 - val_acc: 0.9562
Epoch 35/50
 - 57s - loss: 0.1513 - acc: 0.9789 - val_loss: 0.2108 - val_acc: 0.9577
Epoch 36/50
 - 56s - loss: 0.1526 - acc: 0.9780 - val_loss: 0.2105 - val_acc: 0.9571
Epoch 37/50
 - 56s - loss: 0.1494 - acc: 0.9800 - val_loss: 0.2100 - val_acc: 0.9559

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 38/50
 - 56s - loss: 0.1486 - acc: 0.9805 - val_loss: 0.2102 - val_acc: 0.9557
Epoch 39/50
 - 56s - loss: 0.1489 - acc: 0.9796 - val_loss: 0.2102 - val_acc: 0.9575
Epoch 40/50
 - 56s - loss: 0.1494 - acc: 0.9793 - val_loss: 0.2099 - val_acc: 0.9575
Epoch 00040: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 384/7440 [>.............................] - ETA: 3s
 512/7440 [=>............................] - ETA: 3s
 640/7440 [=>............................] - ETA: 3s
 768/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
1024/7440 [===>..........................] - ETA: 3s
1120/7440 [===>..........................] - ETA: 3s
1248/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1504/7440 [=====>........................] - ETA: 3s
1632/7440 [=====>........................] - ETA: 3s
1728/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3232/7440 [============>.................] - ETA: 2s
3360/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3840/7440 [==============>...............] - ETA: 1s
3968/7440 [===============>..............] - ETA: 1s
4096/7440 [===============>..............] - ETA: 1s
4224/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4480/7440 [=================>............] - ETA: 1s
4608/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4864/7440 [==================>...........] - ETA: 1s
4960/7440 [===================>..........] - ETA: 1s
5088/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5344/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5568/7440 [=====================>........] - ETA: 0s
5696/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6208/7440 [========================>.....] - ETA: 0s
6336/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 517us/step
current Test accuracy: 0.810752688172043
current auc_score ------------------>  0.907361978263383
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_29[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_504 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_504[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_505 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_505[0][0]             
__________________________________________________________________________________________________
concatenate_210 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_210[0][0]            
__________________________________________________________________________________________________
activation_506 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_506[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_507 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_507[0][0]             
__________________________________________________________________________________________________
concatenate_211 (Concatenate)   (None, 28, 96, 96)   0           concatenate_210[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_211[0][0]            
__________________________________________________________________________________________________
activation_508 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_508[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_509 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_509[0][0]             
__________________________________________________________________________________________________
concatenate_212 (Concatenate)   (None, 34, 96, 96)   0           concatenate_211[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_212[0][0]            
__________________________________________________________________________________________________
activation_510 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_510[0][0]             
__________________________________________________________________________________________________
average_pooling2d_58 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_58[0][0]       
__________________________________________________________________________________________________
activation_511 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_511[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_512 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_512[0][0]             
__________________________________________________________________________________________________
concatenate_213 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_58[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_213[0][0]            
__________________________________________________________________________________________________
activation_513 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_513[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_514 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_514[0][0]             
__________________________________________________________________________________________________
concatenate_214 (Concatenate)   (None, 29, 48, 48)   0           concatenate_213[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_214[0][0]            
__________________________________________________________________________________________________
activation_515 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_515[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_516 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_516[0][0]             
__________________________________________________________________________________________________
concatenate_215 (Concatenate)   (None, 35, 48, 48)   0           concatenate_214[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_215[0][0]            
__________________________________________________________________________________________________
activation_517 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_517[0][0]             
__________________________________________________________________________________________________
average_pooling2d_59 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_59[0][0]       
__________________________________________________________________________________________________
activation_518 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_518[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_519 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_519[0][0]             
__________________________________________________________________________________________________
concatenate_216 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_59[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_216[0][0]            
__________________________________________________________________________________________________
activation_520 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_520[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_521 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_521[0][0]             
__________________________________________________________________________________________________
concatenate_217 (Concatenate)   (None, 29, 24, 24)   0           concatenate_216[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_217[0][0]            
__________________________________________________________________________________________________
activation_522 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_522[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_523 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_523[0][0]             
__________________________________________________________________________________________________
concatenate_218 (Concatenate)   (None, 35, 24, 24)   0           concatenate_217[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 35, 24, 24)   140         concatenate_218[0][0]            
__________________________________________________________________________________________________
activation_524 (Activation)     (None, 35, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 17, 24, 24)   595         activation_524[0][0]             
__________________________________________________________________________________________________
average_pooling2d_60 (AveragePo (None, 17, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 17, 12, 12)   68          average_pooling2d_60[0][0]       
__________________________________________________________________________________________________
activation_525 (Activation)     (None, 17, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   408         activation_525[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_526 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_526[0][0]             
__________________________________________________________________________________________________
concatenate_219 (Concatenate)   (None, 23, 12, 12)   0           average_pooling2d_60[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 23, 12, 12)   92          concatenate_219[0][0]            
__________________________________________________________________________________________________
activation_527 (Activation)     (None, 23, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   552         activation_527[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_528 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_528[0][0]             
__________________________________________________________________________________________________
concatenate_220 (Concatenate)   (None, 29, 12, 12)   0           concatenate_219[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 29, 12, 12)   116         concatenate_220[0][0]            
__________________________________________________________________________________________________
activation_529 (Activation)     (None, 29, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 24, 12, 12)   696         activation_529[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_530 (Activation)     (None, 24, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_530[0][0]             
__________________________________________________________________________________________________
concatenate_221 (Concatenate)   (None, 35, 12, 12)   0           concatenate_220[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 12, 12)   140         concatenate_221[0][0]            
__________________________________________________________________________________________________
activation_531 (Activation)     (None, 35, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_29 (Gl (None, 35)           0           activation_531[0][0]             
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 1)            36          global_average_pooling2d_29[0][0]
==================================================================================================
Total params: 26,996
Trainable params: 25,596
Non-trainable params: 1,400
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 56s - loss: 0.5645 - acc: 0.7570 - val_loss: 0.5121 - val_acc: 0.7821
Epoch 2/50
 - 38s - loss: 0.4693 - acc: 0.8035 - val_loss: 0.6212 - val_acc: 0.7469
Epoch 3/50
 - 38s - loss: 0.4330 - acc: 0.8239 - val_loss: 0.4140 - val_acc: 0.8325
Epoch 4/50
 - 38s - loss: 0.4020 - acc: 0.8445 - val_loss: 0.3938 - val_acc: 0.8453
Epoch 5/50
 - 38s - loss: 0.3732 - acc: 0.8619 - val_loss: 0.3783 - val_acc: 0.8651
Epoch 6/50
 - 38s - loss: 0.3522 - acc: 0.8739 - val_loss: 0.3369 - val_acc: 0.8820
Epoch 7/50
 - 38s - loss: 0.3317 - acc: 0.8834 - val_loss: 0.3211 - val_acc: 0.8929
Epoch 8/50
 - 38s - loss: 0.3170 - acc: 0.8920 - val_loss: 0.3164 - val_acc: 0.8899
Epoch 9/50
 - 38s - loss: 0.3028 - acc: 0.8987 - val_loss: 0.3347 - val_acc: 0.8877
Epoch 10/50
 - 37s - loss: 0.2912 - acc: 0.9055 - val_loss: 0.3213 - val_acc: 0.8891
Epoch 11/50
 - 37s - loss: 0.2815 - acc: 0.9085 - val_loss: 0.2902 - val_acc: 0.9025
Epoch 12/50
 - 37s - loss: 0.2703 - acc: 0.9136 - val_loss: 0.2789 - val_acc: 0.9095
Epoch 13/50
 - 38s - loss: 0.2620 - acc: 0.9174 - val_loss: 0.2668 - val_acc: 0.9162
Epoch 14/50
 - 38s - loss: 0.2538 - acc: 0.9213 - val_loss: 0.2957 - val_acc: 0.9015
Epoch 15/50
 - 38s - loss: 0.2433 - acc: 0.9253 - val_loss: 0.2670 - val_acc: 0.9128
Epoch 16/50
 - 38s - loss: 0.2393 - acc: 0.9278 - val_loss: 0.2994 - val_acc: 0.9014
Epoch 17/50
 - 38s - loss: 0.2374 - acc: 0.9275 - val_loss: 0.2735 - val_acc: 0.9113

Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 18/50
 - 37s - loss: 0.2159 - acc: 0.9378 - val_loss: 0.2374 - val_acc: 0.9260
Epoch 19/50
 - 38s - loss: 0.2100 - acc: 0.9415 - val_loss: 0.2403 - val_acc: 0.9276
Epoch 20/50
 - 37s - loss: 0.2040 - acc: 0.9434 - val_loss: 0.2396 - val_acc: 0.9253
Epoch 21/50
 - 37s - loss: 0.2073 - acc: 0.9416 - val_loss: 0.2367 - val_acc: 0.9282
Epoch 22/50
 - 37s - loss: 0.2025 - acc: 0.9438 - val_loss: 0.2375 - val_acc: 0.9283
Epoch 23/50
 - 37s - loss: 0.2022 - acc: 0.9433 - val_loss: 0.2282 - val_acc: 0.9308
Epoch 24/50
 - 37s - loss: 0.1972 - acc: 0.9463 - val_loss: 0.2261 - val_acc: 0.9335
Epoch 25/50
 - 37s - loss: 0.1974 - acc: 0.9466 - val_loss: 0.2266 - val_acc: 0.9332
Epoch 26/50
 - 37s - loss: 0.1912 - acc: 0.9474 - val_loss: 0.2566 - val_acc: 0.9244
Epoch 27/50
 - 37s - loss: 0.1913 - acc: 0.9482 - val_loss: 0.2383 - val_acc: 0.9281
Epoch 28/50
 - 37s - loss: 0.1890 - acc: 0.9494 - val_loss: 0.2256 - val_acc: 0.9307
Epoch 29/50
 - 38s - loss: 0.1860 - acc: 0.9505 - val_loss: 0.2373 - val_acc: 0.9257
Epoch 30/50
 - 38s - loss: 0.1865 - acc: 0.9518 - val_loss: 0.2353 - val_acc: 0.9291
Epoch 31/50
 - 38s - loss: 0.1810 - acc: 0.9517 - val_loss: 0.2277 - val_acc: 0.9317
Epoch 32/50
 - 38s - loss: 0.1847 - acc: 0.9497 - val_loss: 0.2218 - val_acc: 0.9340
Epoch 33/50
 - 38s - loss: 0.1792 - acc: 0.9532 - val_loss: 0.2276 - val_acc: 0.9322
Epoch 34/50
 - 37s - loss: 0.1798 - acc: 0.9524 - val_loss: 0.2254 - val_acc: 0.9352
Epoch 35/50
 - 37s - loss: 0.1765 - acc: 0.9534 - val_loss: 0.2189 - val_acc: 0.9366
Epoch 36/50
 - 37s - loss: 0.1766 - acc: 0.9538 - val_loss: 0.2262 - val_acc: 0.9344
Epoch 37/50
 - 38s - loss: 0.1751 - acc: 0.9542 - val_loss: 0.2550 - val_acc: 0.9188
Epoch 38/50
 - 37s - loss: 0.1735 - acc: 0.9551 - val_loss: 0.2198 - val_acc: 0.9365
Epoch 39/50
 - 37s - loss: 0.1731 - acc: 0.9543 - val_loss: 0.2351 - val_acc: 0.9334

Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 40/50
 - 38s - loss: 0.1642 - acc: 0.9606 - val_loss: 0.2126 - val_acc: 0.9370
Epoch 41/50
 - 38s - loss: 0.1659 - acc: 0.9595 - val_loss: 0.2126 - val_acc: 0.9404
Epoch 42/50
 - 37s - loss: 0.1597 - acc: 0.9605 - val_loss: 0.2165 - val_acc: 0.9391
Epoch 43/50
 - 38s - loss: 0.1637 - acc: 0.9601 - val_loss: 0.2122 - val_acc: 0.9399
Epoch 44/50
 - 37s - loss: 0.1617 - acc: 0.9602 - val_loss: 0.2117 - val_acc: 0.9396
Epoch 45/50
 - 37s - loss: 0.1603 - acc: 0.9607 - val_loss: 0.2209 - val_acc: 0.9375
Epoch 46/50
 - 37s - loss: 0.1609 - acc: 0.9596 - val_loss: 0.2150 - val_acc: 0.9393
Epoch 47/50
 - 37s - loss: 0.1562 - acc: 0.9630 - val_loss: 0.2151 - val_acc: 0.9390
Epoch 48/50
 - 37s - loss: 0.1557 - acc: 0.9632 - val_loss: 0.2118 - val_acc: 0.9400

Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 49/50
 - 37s - loss: 0.1546 - acc: 0.9636 - val_loss: 0.2116 - val_acc: 0.9396
Epoch 50/50
 - 37s - loss: 0.1578 - acc: 0.9623 - val_loss: 0.2122 - val_acc: 0.9395

  32/7440 [..............................] - ETA: 2s
 192/7440 [..............................] - ETA: 2s
 352/7440 [>.............................] - ETA: 2s
 512/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 832/7440 [==>...........................] - ETA: 2s
 992/7440 [===>..........................] - ETA: 2s
1152/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1472/7440 [====>.........................] - ETA: 2s
1632/7440 [=====>........................] - ETA: 2s
1792/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2112/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2432/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2752/7440 [==========>...................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3552/7440 [=============>................] - ETA: 1s
3712/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4832/7440 [==================>...........] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5312/7440 [====================>.........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6112/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 370us/step
current Test accuracy: 0.8315860215053763
current auc_score ------------------>  0.915516461440629
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_30 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_30[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_532 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_532[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_533 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_533[0][0]             
__________________________________________________________________________________________________
concatenate_222 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_222[0][0]            
__________________________________________________________________________________________________
activation_534 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_534[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_535 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_535[0][0]             
__________________________________________________________________________________________________
concatenate_223 (Concatenate)   (None, 28, 96, 96)   0           concatenate_222[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_223[0][0]            
__________________________________________________________________________________________________
activation_536 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_536[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_537 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_537[0][0]             
__________________________________________________________________________________________________
concatenate_224 (Concatenate)   (None, 34, 96, 96)   0           concatenate_223[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_224[0][0]            
__________________________________________________________________________________________________
activation_538 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_538[0][0]             
__________________________________________________________________________________________________
average_pooling2d_61 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_61[0][0]       
__________________________________________________________________________________________________
activation_539 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_539[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_540 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_540[0][0]             
__________________________________________________________________________________________________
concatenate_225 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_61[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_225[0][0]            
__________________________________________________________________________________________________
activation_541 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_541[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_542 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_542[0][0]             
__________________________________________________________________________________________________
concatenate_226 (Concatenate)   (None, 29, 48, 48)   0           concatenate_225[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_226[0][0]            
__________________________________________________________________________________________________
activation_543 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_543[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_544 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_544[0][0]             
__________________________________________________________________________________________________
concatenate_227 (Concatenate)   (None, 35, 48, 48)   0           concatenate_226[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_227[0][0]            
__________________________________________________________________________________________________
activation_545 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_545[0][0]             
__________________________________________________________________________________________________
average_pooling2d_62 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_62[0][0]       
__________________________________________________________________________________________________
activation_546 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_546[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_547 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_547[0][0]             
__________________________________________________________________________________________________
concatenate_228 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_62[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_228[0][0]            
__________________________________________________________________________________________________
activation_548 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_548[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_549 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_549[0][0]             
__________________________________________________________________________________________________
concatenate_229 (Concatenate)   (None, 29, 24, 24)   0           concatenate_228[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_229[0][0]            
__________________________________________________________________________________________________
activation_550 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_550[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_551 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_551[0][0]             
__________________________________________________________________________________________________
concatenate_230 (Concatenate)   (None, 35, 24, 24)   0           concatenate_229[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 35, 24, 24)   140         concatenate_230[0][0]            
__________________________________________________________________________________________________
activation_552 (Activation)     (None, 35, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 17, 24, 24)   595         activation_552[0][0]             
__________________________________________________________________________________________________
average_pooling2d_63 (AveragePo (None, 17, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 17, 12, 12)   68          average_pooling2d_63[0][0]       
__________________________________________________________________________________________________
activation_553 (Activation)     (None, 17, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   408         activation_553[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_554 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_554[0][0]             
__________________________________________________________________________________________________
concatenate_231 (Concatenate)   (None, 23, 12, 12)   0           average_pooling2d_63[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 23, 12, 12)   92          concatenate_231[0][0]            
__________________________________________________________________________________________________
activation_555 (Activation)     (None, 23, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   552         activation_555[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_556 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_556[0][0]             
__________________________________________________________________________________________________
concatenate_232 (Concatenate)   (None, 29, 12, 12)   0           concatenate_231[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 29, 12, 12)   116         concatenate_232[0][0]            
__________________________________________________________________________________________________
activation_557 (Activation)     (None, 29, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 24, 12, 12)   696         activation_557[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_558 (Activation)     (None, 24, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_558[0][0]             
__________________________________________________________________________________________________
concatenate_233 (Concatenate)   (None, 35, 12, 12)   0           concatenate_232[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 12, 12)   140         concatenate_233[0][0]            
__________________________________________________________________________________________________
activation_559 (Activation)     (None, 35, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_30 (Gl (None, 35)           0           activation_559[0][0]             
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 1)            36          global_average_pooling2d_30[0][0]
==================================================================================================
Total params: 26,996
Trainable params: 25,596
Non-trainable params: 1,400
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 56s - loss: 0.5643 - acc: 0.7602 - val_loss: 0.4837 - val_acc: 0.8002
Epoch 2/50
 - 38s - loss: 0.4592 - acc: 0.8178 - val_loss: 0.4248 - val_acc: 0.8318
Epoch 3/50
 - 38s - loss: 0.4129 - acc: 0.8434 - val_loss: 0.4197 - val_acc: 0.8346
Epoch 4/50
 - 38s - loss: 0.3818 - acc: 0.8596 - val_loss: 0.3727 - val_acc: 0.8601
Epoch 5/50
 - 38s - loss: 0.3561 - acc: 0.8739 - val_loss: 0.3730 - val_acc: 0.8645
Epoch 6/50
 - 38s - loss: 0.3383 - acc: 0.8843 - val_loss: 0.3549 - val_acc: 0.8732
Epoch 7/50
 - 38s - loss: 0.3212 - acc: 0.8926 - val_loss: 0.3524 - val_acc: 0.8791
Epoch 8/50
 - 38s - loss: 0.3065 - acc: 0.8979 - val_loss: 0.3336 - val_acc: 0.8892
Epoch 9/50
 - 38s - loss: 0.2943 - acc: 0.9044 - val_loss: 0.3653 - val_acc: 0.8589
Epoch 10/50
 - 38s - loss: 0.2828 - acc: 0.9091 - val_loss: 0.2850 - val_acc: 0.9074
Epoch 11/50
 - 38s - loss: 0.2739 - acc: 0.9113 - val_loss: 0.2970 - val_acc: 0.9027
Epoch 12/50
 - 38s - loss: 0.2657 - acc: 0.9171 - val_loss: 0.2733 - val_acc: 0.9109
Epoch 13/50
 - 38s - loss: 0.2578 - acc: 0.9209 - val_loss: 0.2920 - val_acc: 0.9069
Epoch 14/50
 - 38s - loss: 0.2551 - acc: 0.9223 - val_loss: 0.2804 - val_acc: 0.9083
Epoch 15/50
 - 38s - loss: 0.2453 - acc: 0.9256 - val_loss: 0.3143 - val_acc: 0.8978
Epoch 16/50
 - 38s - loss: 0.2383 - acc: 0.9282 - val_loss: 0.2689 - val_acc: 0.9135
Epoch 17/50
 - 38s - loss: 0.2294 - acc: 0.9323 - val_loss: 0.4522 - val_acc: 0.8658
Epoch 18/50
 - 38s - loss: 0.2271 - acc: 0.9337 - val_loss: 0.3516 - val_acc: 0.8898
Epoch 19/50
 - 38s - loss: 0.2208 - acc: 0.9346 - val_loss: 0.3178 - val_acc: 0.9025
Epoch 20/50
 - 38s - loss: 0.2126 - acc: 0.9381 - val_loss: 0.2768 - val_acc: 0.9089

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 21/50
 - 37s - loss: 0.1925 - acc: 0.9487 - val_loss: 0.2338 - val_acc: 0.9281
Epoch 22/50
 - 38s - loss: 0.1875 - acc: 0.9508 - val_loss: 0.2576 - val_acc: 0.9169
Epoch 23/50
 - 38s - loss: 0.1890 - acc: 0.9514 - val_loss: 0.2279 - val_acc: 0.9315
Epoch 24/50
 - 37s - loss: 0.1836 - acc: 0.9523 - val_loss: 0.2220 - val_acc: 0.9330
Epoch 25/50
 - 38s - loss: 0.1800 - acc: 0.9537 - val_loss: 0.2247 - val_acc: 0.9316
Epoch 26/50
 - 38s - loss: 0.1820 - acc: 0.9534 - val_loss: 0.2266 - val_acc: 0.9301
Epoch 27/50
 - 37s - loss: 0.1811 - acc: 0.9535 - val_loss: 0.2307 - val_acc: 0.9319
Epoch 28/50
 - 37s - loss: 0.1775 - acc: 0.9546 - val_loss: 0.2327 - val_acc: 0.9293

Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 29/50
 - 37s - loss: 0.1737 - acc: 0.9556 - val_loss: 0.2180 - val_acc: 0.9370
Epoch 30/50
 - 38s - loss: 0.1692 - acc: 0.9584 - val_loss: 0.2176 - val_acc: 0.9374
Epoch 31/50
 - 38s - loss: 0.1666 - acc: 0.9600 - val_loss: 0.2201 - val_acc: 0.9352
Epoch 32/50
 - 37s - loss: 0.1696 - acc: 0.9588 - val_loss: 0.2199 - val_acc: 0.9342
Epoch 33/50
 - 37s - loss: 0.1684 - acc: 0.9587 - val_loss: 0.2182 - val_acc: 0.9365
Epoch 34/50
 - 37s - loss: 0.1659 - acc: 0.9594 - val_loss: 0.2195 - val_acc: 0.9357

Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 35/50
 - 37s - loss: 0.1659 - acc: 0.9602 - val_loss: 0.2161 - val_acc: 0.9376
Epoch 36/50
 - 37s - loss: 0.1640 - acc: 0.9598 - val_loss: 0.2165 - val_acc: 0.9375
Epoch 37/50
 - 37s - loss: 0.1613 - acc: 0.9613 - val_loss: 0.2173 - val_acc: 0.9383
Epoch 38/50
 - 38s - loss: 0.1606 - acc: 0.9615 - val_loss: 0.2162 - val_acc: 0.9380
Epoch 39/50
 - 37s - loss: 0.1586 - acc: 0.9625 - val_loss: 0.2162 - val_acc: 0.9370

Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 40/50
 - 38s - loss: 0.1589 - acc: 0.9634 - val_loss: 0.2161 - val_acc: 0.9386
Epoch 41/50
 - 37s - loss: 0.1622 - acc: 0.9625 - val_loss: 0.2160 - val_acc: 0.9383
Epoch 42/50
 - 38s - loss: 0.1590 - acc: 0.9629 - val_loss: 0.2172 - val_acc: 0.9381
Epoch 43/50
 - 38s - loss: 0.1614 - acc: 0.9617 - val_loss: 0.2166 - val_acc: 0.9367

Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.324554585350097e-07.
Epoch 44/50
 - 38s - loss: 0.1618 - acc: 0.9613 - val_loss: 0.2162 - val_acc: 0.9378
Epoch 45/50
 - 38s - loss: 0.1615 - acc: 0.9601 - val_loss: 0.2160 - val_acc: 0.9381
Epoch 46/50
 - 38s - loss: 0.1601 - acc: 0.9623 - val_loss: 0.2165 - val_acc: 0.9378
Epoch 47/50
 - 38s - loss: 0.1610 - acc: 0.9613 - val_loss: 0.2163 - val_acc: 0.9380

Epoch 00047: ReduceLROnPlateau reducing learning rate to 5e-07.
Epoch 48/50
 - 38s - loss: 0.1613 - acc: 0.9626 - val_loss: 0.2163 - val_acc: 0.9379
Epoch 00048: early stopping

  32/7440 [..............................] - ETA: 2s
 192/7440 [..............................] - ETA: 2s
 352/7440 [>.............................] - ETA: 2s
 512/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 832/7440 [==>...........................] - ETA: 2s
 992/7440 [===>..........................] - ETA: 2s
1152/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1472/7440 [====>.........................] - ETA: 2s
1632/7440 [=====>........................] - ETA: 2s
1792/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2112/7440 [=======>......................] - ETA: 1s
2272/7440 [========>.....................] - ETA: 1s
2432/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2752/7440 [==========>...................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3552/7440 [=============>................] - ETA: 1s
3712/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4832/7440 [==================>...........] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5312/7440 [====================>.........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6112/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 371us/step
current Test accuracy: 0.7771505376344086
current auc_score ------------------>  0.8685445571742398
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_31[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_560 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_560[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_561 (Activation)     (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_561[0][0]             
__________________________________________________________________________________________________
concatenate_234 (Concatenate)   (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_234[0][0]            
__________________________________________________________________________________________________
activation_562 (Activation)     (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_562[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_563 (Activation)     (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_563[0][0]             
__________________________________________________________________________________________________
concatenate_235 (Concatenate)   (None, 44, 96, 96)   0           concatenate_234[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_235[0][0]            
__________________________________________________________________________________________________
activation_564 (Activation)     (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_564[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_565 (Activation)     (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_565[0][0]             
__________________________________________________________________________________________________
concatenate_236 (Concatenate)   (None, 58, 96, 96)   0           concatenate_235[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 58, 96, 96)   232         concatenate_236[0][0]            
__________________________________________________________________________________________________
activation_566 (Activation)     (None, 58, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 29, 96, 96)   1682        activation_566[0][0]             
__________________________________________________________________________________________________
average_pooling2d_64 (AveragePo (None, 29, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 29, 48, 48)   116         average_pooling2d_64[0][0]       
__________________________________________________________________________________________________
activation_567 (Activation)     (None, 29, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   1624        activation_567[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_568 (Activation)     (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_568[0][0]             
__________________________________________________________________________________________________
concatenate_237 (Concatenate)   (None, 43, 48, 48)   0           average_pooling2d_64[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_237[0][0]            
__________________________________________________________________________________________________
activation_569 (Activation)     (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   2408        activation_569[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_570 (Activation)     (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_570[0][0]             
__________________________________________________________________________________________________
concatenate_238 (Concatenate)   (None, 57, 48, 48)   0           concatenate_237[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 57, 48, 48)   228         concatenate_238[0][0]            
__________________________________________________________________________________________________
activation_571 (Activation)     (None, 57, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3192        activation_571[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_572 (Activation)     (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_572[0][0]             
__________________________________________________________________________________________________
concatenate_239 (Concatenate)   (None, 71, 48, 48)   0           concatenate_238[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 71, 48, 48)   284         concatenate_239[0][0]            
__________________________________________________________________________________________________
activation_573 (Activation)     (None, 71, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 48, 48)   2485        activation_573[0][0]             
__________________________________________________________________________________________________
average_pooling2d_65 (AveragePo (None, 35, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 24, 24)   140         average_pooling2d_65[0][0]       
__________________________________________________________________________________________________
activation_574 (Activation)     (None, 35, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 56, 24, 24)   1960        activation_574[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_575 (Activation)     (None, 56, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_575[0][0]             
__________________________________________________________________________________________________
concatenate_240 (Concatenate)   (None, 49, 24, 24)   0           average_pooling2d_65[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 24, 24)   196         concatenate_240[0][0]            
__________________________________________________________________________________________________
activation_576 (Activation)     (None, 49, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 56, 24, 24)   2744        activation_576[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_577 (Activation)     (None, 56, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_577[0][0]             
__________________________________________________________________________________________________
concatenate_241 (Concatenate)   (None, 63, 24, 24)   0           concatenate_240[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 63, 24, 24)   252         concatenate_241[0][0]            
__________________________________________________________________________________________________
activation_578 (Activation)     (None, 63, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 56, 24, 24)   3528        activation_578[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_579 (Activation)     (None, 56, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_579[0][0]             
__________________________________________________________________________________________________
concatenate_242 (Concatenate)   (None, 77, 24, 24)   0           concatenate_241[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 77, 24, 24)   308         concatenate_242[0][0]            
__________________________________________________________________________________________________
activation_580 (Activation)     (None, 77, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 38, 24, 24)   2926        activation_580[0][0]             
__________________________________________________________________________________________________
average_pooling2d_66 (AveragePo (None, 38, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_66[0][0]       
__________________________________________________________________________________________________
activation_581 (Activation)     (None, 38, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 56, 12, 12)   2128        activation_581[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_582 (Activation)     (None, 56, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_582[0][0]             
__________________________________________________________________________________________________
concatenate_243 (Concatenate)   (None, 52, 12, 12)   0           average_pooling2d_66[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_243[0][0]            
__________________________________________________________________________________________________
activation_583 (Activation)     (None, 52, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 56, 12, 12)   2912        activation_583[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_584 (Activation)     (None, 56, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_584[0][0]             
__________________________________________________________________________________________________
concatenate_244 (Concatenate)   (None, 66, 12, 12)   0           concatenate_243[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 66, 12, 12)   264         concatenate_244[0][0]            
__________________________________________________________________________________________________
activation_585 (Activation)     (None, 66, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 56, 12, 12)   3696        activation_585[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_586 (Activation)     (None, 56, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_586[0][0]             
__________________________________________________________________________________________________
concatenate_245 (Concatenate)   (None, 80, 12, 12)   0           concatenate_244[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_245[0][0]            
__________________________________________________________________________________________________
activation_587 (Activation)     (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_31 (Gl (None, 80)           0           activation_587[0][0]             
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 1)            81          global_average_pooling2d_31[0][0]
==================================================================================================
Total params: 127,286
Trainable params: 124,326
Non-trainable params: 2,960
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 70s - loss: 0.5814 - acc: 0.7944 - val_loss: 0.5123 - val_acc: 0.8230
Epoch 2/50
 - 50s - loss: 0.4592 - acc: 0.8604 - val_loss: 0.4229 - val_acc: 0.8737
Epoch 3/50
 - 50s - loss: 0.3959 - acc: 0.8911 - val_loss: 0.3786 - val_acc: 0.9042
Epoch 4/50
 - 50s - loss: 0.3574 - acc: 0.9082 - val_loss: 0.3364 - val_acc: 0.9180
Epoch 5/50
 - 50s - loss: 0.3267 - acc: 0.9225 - val_loss: 0.3219 - val_acc: 0.9258
Epoch 6/50
 - 50s - loss: 0.2976 - acc: 0.9348 - val_loss: 0.3186 - val_acc: 0.9266
Epoch 7/50
 - 50s - loss: 0.2788 - acc: 0.9409 - val_loss: 0.3274 - val_acc: 0.9209
Epoch 8/50
 - 50s - loss: 0.2614 - acc: 0.9490 - val_loss: 0.2818 - val_acc: 0.9380
Epoch 9/50
 - 50s - loss: 0.2472 - acc: 0.9535 - val_loss: 0.2639 - val_acc: 0.9433
Epoch 10/50
 - 50s - loss: 0.2347 - acc: 0.9574 - val_loss: 0.3143 - val_acc: 0.9183
Epoch 11/50
 - 50s - loss: 0.2247 - acc: 0.9622 - val_loss: 0.2638 - val_acc: 0.9445
Epoch 12/50
 - 50s - loss: 0.2166 - acc: 0.9645 - val_loss: 0.2603 - val_acc: 0.9449
Epoch 13/50
 - 50s - loss: 0.2023 - acc: 0.9689 - val_loss: 0.2534 - val_acc: 0.9514
Epoch 14/50
 - 50s - loss: 0.2007 - acc: 0.9702 - val_loss: 0.2976 - val_acc: 0.9278
Epoch 15/50
 - 50s - loss: 0.1906 - acc: 0.9720 - val_loss: 0.2408 - val_acc: 0.9544
Epoch 16/50
 - 50s - loss: 0.1839 - acc: 0.9750 - val_loss: 0.3746 - val_acc: 0.9132
Epoch 17/50
 - 50s - loss: 0.1776 - acc: 0.9769 - val_loss: 0.2979 - val_acc: 0.9316
Epoch 18/50
 - 50s - loss: 0.1771 - acc: 0.9770 - val_loss: 0.2421 - val_acc: 0.9512
Epoch 19/50
 - 50s - loss: 0.1674 - acc: 0.9799 - val_loss: 0.2469 - val_acc: 0.9492

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 20/50
 - 50s - loss: 0.1399 - acc: 0.9916 - val_loss: 0.1900 - val_acc: 0.9715
Epoch 21/50
 - 50s - loss: 0.1368 - acc: 0.9924 - val_loss: 0.1932 - val_acc: 0.9696
Epoch 22/50
 - 50s - loss: 0.1343 - acc: 0.9925 - val_loss: 0.1940 - val_acc: 0.9705
Epoch 23/50
 - 50s - loss: 0.1324 - acc: 0.9928 - val_loss: 0.2047 - val_acc: 0.9680
Epoch 24/50
 - 50s - loss: 0.1292 - acc: 0.9937 - val_loss: 0.2062 - val_acc: 0.9661

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 25/50
 - 50s - loss: 0.1246 - acc: 0.9960 - val_loss: 0.1878 - val_acc: 0.9733
Epoch 26/50
 - 50s - loss: 0.1225 - acc: 0.9967 - val_loss: 0.1866 - val_acc: 0.9714
Epoch 27/50
 - 50s - loss: 0.1209 - acc: 0.9975 - val_loss: 0.1844 - val_acc: 0.9731
Epoch 28/50
 - 50s - loss: 0.1221 - acc: 0.9964 - val_loss: 0.1910 - val_acc: 0.9726
Epoch 29/50
 - 50s - loss: 0.1213 - acc: 0.9969 - val_loss: 0.1889 - val_acc: 0.9734
Epoch 30/50
 - 50s - loss: 0.1190 - acc: 0.9972 - val_loss: 0.1834 - val_acc: 0.9738
Epoch 31/50
 - 50s - loss: 0.1181 - acc: 0.9980 - val_loss: 0.1892 - val_acc: 0.9724
Epoch 32/50
 - 50s - loss: 0.1185 - acc: 0.9974 - val_loss: 0.1907 - val_acc: 0.9723
Epoch 33/50
 - 50s - loss: 0.1181 - acc: 0.9971 - val_loss: 0.1877 - val_acc: 0.9739
Epoch 34/50
 - 50s - loss: 0.1180 - acc: 0.9970 - val_loss: 0.1840 - val_acc: 0.9734

Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 35/50
 - 50s - loss: 0.1162 - acc: 0.9978 - val_loss: 0.1849 - val_acc: 0.9740
Epoch 36/50
 - 50s - loss: 0.1150 - acc: 0.9985 - val_loss: 0.1850 - val_acc: 0.9740
Epoch 37/50
 - 50s - loss: 0.1145 - acc: 0.9985 - val_loss: 0.1842 - val_acc: 0.9738
Epoch 00037: early stopping

  32/7440 [..............................] - ETA: 3s
 128/7440 [..............................] - ETA: 3s
 256/7440 [>.............................] - ETA: 3s
 352/7440 [>.............................] - ETA: 3s
 448/7440 [>.............................] - ETA: 3s
 576/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 768/7440 [==>...........................] - ETA: 3s
 864/7440 [==>...........................] - ETA: 3s
 960/7440 [==>...........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 2s
1856/7440 [======>.......................] - ETA: 2s
1984/7440 [=======>......................] - ETA: 2s
2112/7440 [=======>......................] - ETA: 2s
2240/7440 [========>.....................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 2s
2560/7440 [=========>....................] - ETA: 2s
2656/7440 [=========>....................] - ETA: 2s
2752/7440 [==========>...................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2944/7440 [==========>...................] - ETA: 2s
3040/7440 [===========>..................] - ETA: 2s
3136/7440 [===========>..................] - ETA: 2s
3264/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 1s
3776/7440 [==============>...............] - ETA: 1s
3904/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4096/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4288/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4480/7440 [=================>............] - ETA: 1s
4576/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4800/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
4992/7440 [===================>..........] - ETA: 1s
5088/7440 [===================>..........] - ETA: 1s
5184/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5376/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 0s
5696/7440 [=====================>........] - ETA: 0s
5824/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7104/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7360/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 524us/step
current Test accuracy: 0.8123655913978495
current auc_score ------------------>  0.9115536116892128
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_32 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_32[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_588 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_588[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_589 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_589[0][0]             
__________________________________________________________________________________________________
concatenate_246 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_246[0][0]            
__________________________________________________________________________________________________
activation_590 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_590[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_591 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_591[0][0]             
__________________________________________________________________________________________________
concatenate_247 (Concatenate)   (None, 28, 96, 96)   0           concatenate_246[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_247[0][0]            
__________________________________________________________________________________________________
activation_592 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_592[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_593 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_593[0][0]             
__________________________________________________________________________________________________
concatenate_248 (Concatenate)   (None, 34, 96, 96)   0           concatenate_247[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_248[0][0]            
__________________________________________________________________________________________________
activation_594 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_594[0][0]             
__________________________________________________________________________________________________
average_pooling2d_67 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_67[0][0]       
__________________________________________________________________________________________________
activation_595 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_595[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_596 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_596[0][0]             
__________________________________________________________________________________________________
concatenate_249 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_67[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_249[0][0]            
__________________________________________________________________________________________________
activation_597 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_597[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_598 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_598[0][0]             
__________________________________________________________________________________________________
concatenate_250 (Concatenate)   (None, 29, 48, 48)   0           concatenate_249[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_250[0][0]            
__________________________________________________________________________________________________
activation_599 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_599[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_600 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_600[0][0]             
__________________________________________________________________________________________________
concatenate_251 (Concatenate)   (None, 35, 48, 48)   0           concatenate_250[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_251[0][0]            
__________________________________________________________________________________________________
activation_601 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_601[0][0]             
__________________________________________________________________________________________________
average_pooling2d_68 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_68[0][0]       
__________________________________________________________________________________________________
activation_602 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_602[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_603 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_603[0][0]             
__________________________________________________________________________________________________
concatenate_252 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_68[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_252[0][0]            
__________________________________________________________________________________________________
activation_604 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_604[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_605 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_605[0][0]             
__________________________________________________________________________________________________
concatenate_253 (Concatenate)   (None, 29, 24, 24)   0           concatenate_252[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_253[0][0]            
__________________________________________________________________________________________________
activation_606 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_606[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_607 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_607[0][0]             
__________________________________________________________________________________________________
concatenate_254 (Concatenate)   (None, 35, 24, 24)   0           concatenate_253[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 35, 24, 24)   140         concatenate_254[0][0]            
__________________________________________________________________________________________________
activation_608 (Activation)     (None, 35, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 17, 24, 24)   595         activation_608[0][0]             
__________________________________________________________________________________________________
average_pooling2d_69 (AveragePo (None, 17, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 17, 12, 12)   68          average_pooling2d_69[0][0]       
__________________________________________________________________________________________________
activation_609 (Activation)     (None, 17, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   408         activation_609[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_610 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_610[0][0]             
__________________________________________________________________________________________________
concatenate_255 (Concatenate)   (None, 23, 12, 12)   0           average_pooling2d_69[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 23, 12, 12)   92          concatenate_255[0][0]            
__________________________________________________________________________________________________
activation_611 (Activation)     (None, 23, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   552         activation_611[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_612 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_612[0][0]             
__________________________________________________________________________________________________
concatenate_256 (Concatenate)   (None, 29, 12, 12)   0           concatenate_255[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 29, 12, 12)   116         concatenate_256[0][0]            
__________________________________________________________________________________________________
activation_613 (Activation)     (None, 29, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 24, 12, 12)   696         activation_613[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_614 (Activation)     (None, 24, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_614[0][0]             
__________________________________________________________________________________________________
concatenate_257 (Concatenate)   (None, 35, 12, 12)   0           concatenate_256[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 12, 12)   140         concatenate_257[0][0]            
__________________________________________________________________________________________________
activation_615 (Activation)     (None, 35, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_32 (Gl (None, 35)           0           activation_615[0][0]             
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 1)            36          global_average_pooling2d_32[0][0]
==================================================================================================
Total params: 26,996
Trainable params: 25,596
Non-trainable params: 1,400
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 60s - loss: 0.5652 - acc: 0.7607 - val_loss: 0.5312 - val_acc: 0.7836
Epoch 2/50
 - 39s - loss: 0.4727 - acc: 0.8094 - val_loss: 0.4566 - val_acc: 0.8057
Epoch 3/50
 - 39s - loss: 0.4252 - acc: 0.8331 - val_loss: 0.4137 - val_acc: 0.8333
Epoch 4/50
 - 39s - loss: 0.3899 - acc: 0.8542 - val_loss: 0.3781 - val_acc: 0.8619
Epoch 5/50
 - 39s - loss: 0.3631 - acc: 0.8683 - val_loss: 0.3403 - val_acc: 0.8788
Epoch 6/50
 - 38s - loss: 0.3381 - acc: 0.8826 - val_loss: 0.3356 - val_acc: 0.8853
Epoch 7/50
 - 38s - loss: 0.3217 - acc: 0.8902 - val_loss: 0.3260 - val_acc: 0.8882
Epoch 8/50
 - 38s - loss: 0.3079 - acc: 0.8969 - val_loss: 0.2996 - val_acc: 0.9009
Epoch 9/50
 - 38s - loss: 0.2924 - acc: 0.9029 - val_loss: 0.3245 - val_acc: 0.8883
Epoch 10/50
 - 38s - loss: 0.2788 - acc: 0.9090 - val_loss: 0.2880 - val_acc: 0.9025
Epoch 11/50
 - 38s - loss: 0.2670 - acc: 0.9156 - val_loss: 0.2814 - val_acc: 0.9086
Epoch 12/50
 - 39s - loss: 0.2589 - acc: 0.9181 - val_loss: 0.2768 - val_acc: 0.9106
Epoch 13/50
 - 39s - loss: 0.2508 - acc: 0.9240 - val_loss: 0.2819 - val_acc: 0.9114
Epoch 14/50
 - 39s - loss: 0.2485 - acc: 0.9231 - val_loss: 0.2907 - val_acc: 0.9049
Epoch 15/50
 - 39s - loss: 0.2399 - acc: 0.9282 - val_loss: 0.2745 - val_acc: 0.9099
Epoch 16/50
 - 39s - loss: 0.2311 - acc: 0.9313 - val_loss: 0.3047 - val_acc: 0.8927
Epoch 17/50
 - 38s - loss: 0.2230 - acc: 0.9351 - val_loss: 0.2828 - val_acc: 0.9055
Epoch 18/50
 - 39s - loss: 0.2196 - acc: 0.9360 - val_loss: 0.2505 - val_acc: 0.9204
Epoch 19/50
 - 39s - loss: 0.2130 - acc: 0.9376 - val_loss: 0.2480 - val_acc: 0.9228
Epoch 20/50
 - 39s - loss: 0.2125 - acc: 0.9399 - val_loss: 0.2388 - val_acc: 0.9248
Epoch 21/50
 - 39s - loss: 0.2030 - acc: 0.9434 - val_loss: 0.2805 - val_acc: 0.9142
Epoch 22/50
 - 39s - loss: 0.2023 - acc: 0.9437 - val_loss: 0.2501 - val_acc: 0.9228
Epoch 23/50
 - 39s - loss: 0.1956 - acc: 0.9458 - val_loss: 0.2691 - val_acc: 0.9177
Epoch 24/50
 - 39s - loss: 0.1906 - acc: 0.9475 - val_loss: 0.2187 - val_acc: 0.9362
Epoch 25/50
 - 39s - loss: 0.1871 - acc: 0.9489 - val_loss: 0.2285 - val_acc: 0.9316
Epoch 26/50
 - 39s - loss: 0.1826 - acc: 0.9523 - val_loss: 0.2161 - val_acc: 0.9346
Epoch 27/50
 - 38s - loss: 0.1787 - acc: 0.9530 - val_loss: 0.2623 - val_acc: 0.9203
Epoch 28/50
 - 38s - loss: 0.1765 - acc: 0.9531 - val_loss: 0.2843 - val_acc: 0.9138
Epoch 29/50
 - 38s - loss: 0.1694 - acc: 0.9554 - val_loss: 0.2302 - val_acc: 0.9315
Epoch 30/50
 - 39s - loss: 0.1714 - acc: 0.9554 - val_loss: 0.2261 - val_acc: 0.9349

Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 31/50
 - 38s - loss: 0.1490 - acc: 0.9664 - val_loss: 0.2019 - val_acc: 0.9415
Epoch 32/50
 - 38s - loss: 0.1483 - acc: 0.9649 - val_loss: 0.1974 - val_acc: 0.9444
Epoch 33/50
 - 38s - loss: 0.1419 - acc: 0.9681 - val_loss: 0.1983 - val_acc: 0.9433
Epoch 34/50
 - 38s - loss: 0.1394 - acc: 0.9696 - val_loss: 0.2038 - val_acc: 0.9445
Epoch 35/50
 - 39s - loss: 0.1409 - acc: 0.9702 - val_loss: 0.1946 - val_acc: 0.9436
Epoch 36/50
 - 39s - loss: 0.1400 - acc: 0.9706 - val_loss: 0.2018 - val_acc: 0.9442
Epoch 37/50
 - 39s - loss: 0.1363 - acc: 0.9714 - val_loss: 0.2032 - val_acc: 0.9401
Epoch 38/50
 - 39s - loss: 0.1379 - acc: 0.9701 - val_loss: 0.2016 - val_acc: 0.9445
Epoch 39/50
 - 39s - loss: 0.1359 - acc: 0.9703 - val_loss: 0.2015 - val_acc: 0.9439

Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 40/50
 - 38s - loss: 0.1290 - acc: 0.9736 - val_loss: 0.1994 - val_acc: 0.9455
Epoch 41/50
 - 38s - loss: 0.1269 - acc: 0.9750 - val_loss: 0.1933 - val_acc: 0.9459
Epoch 42/50
 - 38s - loss: 0.1272 - acc: 0.9747 - val_loss: 0.1937 - val_acc: 0.9444
Epoch 43/50
 - 39s - loss: 0.1246 - acc: 0.9757 - val_loss: 0.1932 - val_acc: 0.9472
Epoch 44/50
 - 39s - loss: 0.1286 - acc: 0.9739 - val_loss: 0.1998 - val_acc: 0.9460
Epoch 45/50
 - 39s - loss: 0.1243 - acc: 0.9767 - val_loss: 0.1935 - val_acc: 0.9469
Epoch 46/50
 - 38s - loss: 0.1231 - acc: 0.9761 - val_loss: 0.1931 - val_acc: 0.9492
Epoch 47/50
 - 38s - loss: 0.1256 - acc: 0.9757 - val_loss: 0.1958 - val_acc: 0.9459
Epoch 48/50
 - 39s - loss: 0.1233 - acc: 0.9763 - val_loss: 0.1968 - val_acc: 0.9455
Epoch 49/50
 - 38s - loss: 0.1242 - acc: 0.9755 - val_loss: 0.1923 - val_acc: 0.9473
Epoch 50/50
 - 38s - loss: 0.1231 - acc: 0.9762 - val_loss: 0.1932 - val_acc: 0.9480

  32/7440 [..............................] - ETA: 2s
 192/7440 [..............................] - ETA: 2s
 352/7440 [>.............................] - ETA: 2s
 512/7440 [=>............................] - ETA: 2s
 640/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1088/7440 [===>..........................] - ETA: 2s
1216/7440 [===>..........................] - ETA: 2s
1344/7440 [====>.........................] - ETA: 2s
1472/7440 [====>.........................] - ETA: 2s
1600/7440 [=====>........................] - ETA: 2s
1728/7440 [=====>........................] - ETA: 2s
1888/7440 [======>.......................] - ETA: 2s
2016/7440 [=======>......................] - ETA: 2s
2176/7440 [=======>......................] - ETA: 2s
2304/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 1s
2560/7440 [=========>....................] - ETA: 1s
2688/7440 [=========>....................] - ETA: 1s
2816/7440 [==========>...................] - ETA: 1s
2944/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3520/7440 [=============>................] - ETA: 1s
3648/7440 [=============>................] - ETA: 1s
3776/7440 [==============>...............] - ETA: 1s
3904/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4160/7440 [===============>..............] - ETA: 1s
4288/7440 [================>.............] - ETA: 1s
4416/7440 [================>.............] - ETA: 1s
4576/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4864/7440 [==================>...........] - ETA: 1s
4992/7440 [===================>..........] - ETA: 0s
5120/7440 [===================>..........] - ETA: 0s
5248/7440 [====================>.........] - ETA: 0s
5376/7440 [====================>.........] - ETA: 0s
5504/7440 [=====================>........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6592/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 392us/step
current Test accuracy: 0.8099462365591398
current auc_score ------------------>  0.902846066019193
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_33[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_616 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_616[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_617 (Activation)     (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_617[0][0]             
__________________________________________________________________________________________________
concatenate_258 (Concatenate)   (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_258[0][0]            
__________________________________________________________________________________________________
activation_618 (Activation)     (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_618[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_619 (Activation)     (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_619[0][0]             
__________________________________________________________________________________________________
concatenate_259 (Concatenate)   (None, 44, 96, 96)   0           concatenate_258[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_259[0][0]            
__________________________________________________________________________________________________
activation_620 (Activation)     (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_620[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_621 (Activation)     (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_621[0][0]             
__________________________________________________________________________________________________
concatenate_260 (Concatenate)   (None, 58, 96, 96)   0           concatenate_259[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 58, 96, 96)   232         concatenate_260[0][0]            
__________________________________________________________________________________________________
activation_622 (Activation)     (None, 58, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 29, 96, 96)   1682        activation_622[0][0]             
__________________________________________________________________________________________________
average_pooling2d_70 (AveragePo (None, 29, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 29, 48, 48)   116         average_pooling2d_70[0][0]       
__________________________________________________________________________________________________
activation_623 (Activation)     (None, 29, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   1624        activation_623[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_624 (Activation)     (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_624[0][0]             
__________________________________________________________________________________________________
concatenate_261 (Concatenate)   (None, 43, 48, 48)   0           average_pooling2d_70[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_261[0][0]            
__________________________________________________________________________________________________
activation_625 (Activation)     (None, 43, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   2408        activation_625[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_626 (Activation)     (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_626[0][0]             
__________________________________________________________________________________________________
concatenate_262 (Concatenate)   (None, 57, 48, 48)   0           concatenate_261[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 57, 48, 48)   228         concatenate_262[0][0]            
__________________________________________________________________________________________________
activation_627 (Activation)     (None, 57, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3192        activation_627[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_628 (Activation)     (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_628[0][0]             
__________________________________________________________________________________________________
concatenate_263 (Concatenate)   (None, 71, 48, 48)   0           concatenate_262[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 71, 48, 48)   284         concatenate_263[0][0]            
__________________________________________________________________________________________________
activation_629 (Activation)     (None, 71, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 48, 48)   2485        activation_629[0][0]             
__________________________________________________________________________________________________
average_pooling2d_71 (AveragePo (None, 35, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 24, 24)   140         average_pooling2d_71[0][0]       
__________________________________________________________________________________________________
activation_630 (Activation)     (None, 35, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 56, 24, 24)   1960        activation_630[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_631 (Activation)     (None, 56, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_631[0][0]             
__________________________________________________________________________________________________
concatenate_264 (Concatenate)   (None, 49, 24, 24)   0           average_pooling2d_71[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 49, 24, 24)   196         concatenate_264[0][0]            
__________________________________________________________________________________________________
activation_632 (Activation)     (None, 49, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 56, 24, 24)   2744        activation_632[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_633 (Activation)     (None, 56, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_633[0][0]             
__________________________________________________________________________________________________
concatenate_265 (Concatenate)   (None, 63, 24, 24)   0           concatenate_264[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 63, 24, 24)   252         concatenate_265[0][0]            
__________________________________________________________________________________________________
activation_634 (Activation)     (None, 63, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 56, 24, 24)   3528        activation_634[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_635 (Activation)     (None, 56, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_635[0][0]             
__________________________________________________________________________________________________
concatenate_266 (Concatenate)   (None, 77, 24, 24)   0           concatenate_265[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 77, 24, 24)   308         concatenate_266[0][0]            
__________________________________________________________________________________________________
activation_636 (Activation)     (None, 77, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 38, 24, 24)   2926        activation_636[0][0]             
__________________________________________________________________________________________________
average_pooling2d_72 (AveragePo (None, 38, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_72[0][0]       
__________________________________________________________________________________________________
activation_637 (Activation)     (None, 38, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 56, 12, 12)   2128        activation_637[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_638 (Activation)     (None, 56, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_638[0][0]             
__________________________________________________________________________________________________
concatenate_267 (Concatenate)   (None, 52, 12, 12)   0           average_pooling2d_72[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_267[0][0]            
__________________________________________________________________________________________________
activation_639 (Activation)     (None, 52, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 56, 12, 12)   2912        activation_639[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_640 (Activation)     (None, 56, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_640[0][0]             
__________________________________________________________________________________________________
concatenate_268 (Concatenate)   (None, 66, 12, 12)   0           concatenate_267[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 66, 12, 12)   264         concatenate_268[0][0]            
__________________________________________________________________________________________________
activation_641 (Activation)     (None, 66, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 56, 12, 12)   3696        activation_641[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_642 (Activation)     (None, 56, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_642[0][0]             
__________________________________________________________________________________________________
concatenate_269 (Concatenate)   (None, 80, 12, 12)   0           concatenate_268[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_269[0][0]            
__________________________________________________________________________________________________
activation_643 (Activation)     (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_33 (Gl (None, 80)           0           activation_643[0][0]             
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 1)            81          global_average_pooling2d_33[0][0]
==================================================================================================
Total params: 127,286
Trainable params: 124,326
Non-trainable params: 2,960
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 73s - loss: 0.5844 - acc: 0.7931 - val_loss: 0.5061 - val_acc: 0.8266
Epoch 2/50
 - 51s - loss: 0.4690 - acc: 0.8559 - val_loss: 0.4191 - val_acc: 0.8770
Epoch 3/50
 - 51s - loss: 0.4056 - acc: 0.8861 - val_loss: 0.4489 - val_acc: 0.8804
Epoch 4/50
 - 51s - loss: 0.3648 - acc: 0.9062 - val_loss: 0.3893 - val_acc: 0.8927
Epoch 5/50
 - 51s - loss: 0.3408 - acc: 0.9149 - val_loss: 0.4649 - val_acc: 0.8702
Epoch 6/50
 - 51s - loss: 0.3161 - acc: 0.9258 - val_loss: 0.3159 - val_acc: 0.9239
Epoch 7/50
 - 51s - loss: 0.2916 - acc: 0.9365 - val_loss: 0.3062 - val_acc: 0.9302
Epoch 8/50
 - 51s - loss: 0.2761 - acc: 0.9422 - val_loss: 0.3297 - val_acc: 0.9198
Epoch 9/50
 - 51s - loss: 0.2612 - acc: 0.9483 - val_loss: 0.3204 - val_acc: 0.9221
Epoch 10/50
 - 51s - loss: 0.2471 - acc: 0.9523 - val_loss: 0.2861 - val_acc: 0.9346
Epoch 11/50
 - 51s - loss: 0.2330 - acc: 0.9590 - val_loss: 0.2908 - val_acc: 0.9357
Epoch 12/50
 - 51s - loss: 0.2252 - acc: 0.9615 - val_loss: 0.3288 - val_acc: 0.9172
Epoch 13/50
 - 51s - loss: 0.2149 - acc: 0.9642 - val_loss: 0.3317 - val_acc: 0.9221
Epoch 14/50
 - 51s - loss: 0.2033 - acc: 0.9696 - val_loss: 0.2384 - val_acc: 0.9524
Epoch 15/50
 - 51s - loss: 0.1996 - acc: 0.9692 - val_loss: 0.2495 - val_acc: 0.9472
Epoch 16/50
 - 51s - loss: 0.1912 - acc: 0.9724 - val_loss: 0.4737 - val_acc: 0.8845
Epoch 17/50
 - 51s - loss: 0.1803 - acc: 0.9770 - val_loss: 0.2415 - val_acc: 0.9536
Epoch 18/50
 - 51s - loss: 0.1795 - acc: 0.9757 - val_loss: 0.3324 - val_acc: 0.9231

Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 19/50
 - 50s - loss: 0.1535 - acc: 0.9870 - val_loss: 0.2004 - val_acc: 0.9711
Epoch 20/50
 - 50s - loss: 0.1449 - acc: 0.9898 - val_loss: 0.2132 - val_acc: 0.9647
Epoch 21/50
 - 50s - loss: 0.1411 - acc: 0.9920 - val_loss: 0.2040 - val_acc: 0.9672
Epoch 22/50
 - 50s - loss: 0.1414 - acc: 0.9910 - val_loss: 0.2014 - val_acc: 0.9676
Epoch 23/50
 - 51s - loss: 0.1379 - acc: 0.9919 - val_loss: 0.2123 - val_acc: 0.9644

Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 24/50
 - 50s - loss: 0.1322 - acc: 0.9946 - val_loss: 0.1963 - val_acc: 0.9711
Epoch 25/50
 - 50s - loss: 0.1292 - acc: 0.9955 - val_loss: 0.1934 - val_acc: 0.9715
Epoch 26/50
 - 50s - loss: 0.1281 - acc: 0.9957 - val_loss: 0.1955 - val_acc: 0.9710
Epoch 27/50
 - 50s - loss: 0.1261 - acc: 0.9964 - val_loss: 0.1921 - val_acc: 0.9703
Epoch 28/50
 - 50s - loss: 0.1255 - acc: 0.9964 - val_loss: 0.1902 - val_acc: 0.9720
Epoch 29/50
 - 50s - loss: 0.1262 - acc: 0.9963 - val_loss: 0.1914 - val_acc: 0.9710
Epoch 30/50
 - 50s - loss: 0.1237 - acc: 0.9973 - val_loss: 0.1909 - val_acc: 0.9723
Epoch 31/50
 - 50s - loss: 0.1251 - acc: 0.9960 - val_loss: 0.1910 - val_acc: 0.9716
Epoch 32/50
 - 50s - loss: 0.1240 - acc: 0.9965 - val_loss: 0.1940 - val_acc: 0.9716

Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 33/50
 - 50s - loss: 0.1221 - acc: 0.9976 - val_loss: 0.1898 - val_acc: 0.9724
Epoch 34/50
 - 50s - loss: 0.1212 - acc: 0.9976 - val_loss: 0.1889 - val_acc: 0.9741
Epoch 35/50
 - 50s - loss: 0.1206 - acc: 0.9976 - val_loss: 0.1885 - val_acc: 0.9728
Epoch 36/50
 - 50s - loss: 0.1221 - acc: 0.9971 - val_loss: 0.1908 - val_acc: 0.9726
Epoch 37/50
 - 51s - loss: 0.1216 - acc: 0.9975 - val_loss: 0.1896 - val_acc: 0.9730
Epoch 38/50
 - 51s - loss: 0.1206 - acc: 0.9979 - val_loss: 0.1934 - val_acc: 0.9715
Epoch 39/50
 - 50s - loss: 0.1203 - acc: 0.9976 - val_loss: 0.1895 - val_acc: 0.9728

Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 40/50
 - 50s - loss: 0.1203 - acc: 0.9977 - val_loss: 0.1900 - val_acc: 0.9731
Epoch 41/50
 - 50s - loss: 0.1194 - acc: 0.9979 - val_loss: 0.1891 - val_acc: 0.9726
Epoch 42/50
 - 50s - loss: 0.1198 - acc: 0.9978 - val_loss: 0.1901 - val_acc: 0.9730
Epoch 00042: early stopping

  32/7440 [..............................] - ETA: 4s
 128/7440 [..............................] - ETA: 3s
 224/7440 [..............................] - ETA: 3s
 320/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 512/7440 [=>............................] - ETA: 3s
 608/7440 [=>............................] - ETA: 3s
 704/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
 992/7440 [===>..........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2048/7440 [=======>......................] - ETA: 2s
2144/7440 [=======>......................] - ETA: 2s
2240/7440 [========>.....................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 2s
2528/7440 [=========>....................] - ETA: 2s
2624/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2816/7440 [==========>...................] - ETA: 2s
2912/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 1s
3776/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
3968/7440 [===============>..............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 1s
4160/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4448/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 0s
5696/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 532us/step
current Test accuracy: 0.7873655913978495
current auc_score ------------------>  0.9115197566192623
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_34 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_34[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_644 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_644[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_645 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_645[0][0]             
__________________________________________________________________________________________________
concatenate_270 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_270[0][0]            
__________________________________________________________________________________________________
activation_646 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_646[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_647 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_647[0][0]             
__________________________________________________________________________________________________
concatenate_271 (Concatenate)   (None, 28, 96, 96)   0           concatenate_270[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_271[0][0]            
__________________________________________________________________________________________________
activation_648 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_648[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_649 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_649[0][0]             
__________________________________________________________________________________________________
concatenate_272 (Concatenate)   (None, 34, 96, 96)   0           concatenate_271[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_272[0][0]            
__________________________________________________________________________________________________
activation_650 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_650[0][0]             
__________________________________________________________________________________________________
average_pooling2d_73 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_73[0][0]       
__________________________________________________________________________________________________
activation_651 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_651[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_652 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_652[0][0]             
__________________________________________________________________________________________________
concatenate_273 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_73[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_273[0][0]            
__________________________________________________________________________________________________
activation_653 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_653[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_654 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_654[0][0]             
__________________________________________________________________________________________________
concatenate_274 (Concatenate)   (None, 29, 48, 48)   0           concatenate_273[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_274[0][0]            
__________________________________________________________________________________________________
activation_655 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_655[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_656 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_656[0][0]             
__________________________________________________________________________________________________
concatenate_275 (Concatenate)   (None, 35, 48, 48)   0           concatenate_274[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_275[0][0]            
__________________________________________________________________________________________________
activation_657 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_657[0][0]             
__________________________________________________________________________________________________
average_pooling2d_74 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_74[0][0]       
__________________________________________________________________________________________________
activation_658 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_658[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_659 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_659[0][0]             
__________________________________________________________________________________________________
concatenate_276 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_74[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_276[0][0]            
__________________________________________________________________________________________________
activation_660 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_660[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_661 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_661[0][0]             
__________________________________________________________________________________________________
concatenate_277 (Concatenate)   (None, 29, 24, 24)   0           concatenate_276[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_277[0][0]            
__________________________________________________________________________________________________
activation_662 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_662[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_663 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_663[0][0]             
__________________________________________________________________________________________________
concatenate_278 (Concatenate)   (None, 35, 24, 24)   0           concatenate_277[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 24, 24)   140         concatenate_278[0][0]            
__________________________________________________________________________________________________
activation_664 (Activation)     (None, 35, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_34 (Gl (None, 35)           0           activation_664[0][0]             
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 1)            36          global_average_pooling2d_34[0][0]
==================================================================================================
Total params: 20,153
Trainable params: 19,105
Non-trainable params: 1,048
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 56s - loss: 0.5718 - acc: 0.7507 - val_loss: 0.5073 - val_acc: 0.7836
Epoch 2/50
 - 34s - loss: 0.4956 - acc: 0.7893 - val_loss: 0.4702 - val_acc: 0.7983
Epoch 3/50
 - 34s - loss: 0.4692 - acc: 0.7993 - val_loss: 0.4485 - val_acc: 0.8089
Epoch 4/50
 - 34s - loss: 0.4466 - acc: 0.8101 - val_loss: 0.4544 - val_acc: 0.8066
Epoch 5/50
 - 34s - loss: 0.4338 - acc: 0.8173 - val_loss: 0.4219 - val_acc: 0.8294
Epoch 6/50
 - 34s - loss: 0.4204 - acc: 0.8264 - val_loss: 0.4400 - val_acc: 0.8122
Epoch 7/50
 - 34s - loss: 0.4099 - acc: 0.8332 - val_loss: 0.4215 - val_acc: 0.8258
Epoch 8/50
 - 34s - loss: 0.3975 - acc: 0.8386 - val_loss: 0.4028 - val_acc: 0.8365
Epoch 9/50
 - 34s - loss: 0.3878 - acc: 0.8438 - val_loss: 0.3802 - val_acc: 0.8528
Epoch 10/50
 - 34s - loss: 0.3817 - acc: 0.8475 - val_loss: 0.3658 - val_acc: 0.8592
Epoch 11/50
 - 34s - loss: 0.3707 - acc: 0.8516 - val_loss: 0.4420 - val_acc: 0.8140
Epoch 12/50
 - 34s - loss: 0.3636 - acc: 0.8574 - val_loss: 0.3875 - val_acc: 0.8503
Epoch 13/50
 - 34s - loss: 0.3581 - acc: 0.8583 - val_loss: 0.3951 - val_acc: 0.8385
Epoch 14/50
 - 34s - loss: 0.3500 - acc: 0.8630 - val_loss: 0.4434 - val_acc: 0.8296

Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 15/50
 - 34s - loss: 0.3313 - acc: 0.8750 - val_loss: 0.3352 - val_acc: 0.8764
Epoch 16/50
 - 33s - loss: 0.3288 - acc: 0.8768 - val_loss: 0.3321 - val_acc: 0.8715
Epoch 17/50
 - 34s - loss: 0.3259 - acc: 0.8778 - val_loss: 0.3445 - val_acc: 0.8696
Epoch 18/50
 - 34s - loss: 0.3216 - acc: 0.8802 - val_loss: 0.3220 - val_acc: 0.8798
Epoch 19/50
 - 33s - loss: 0.3220 - acc: 0.8786 - val_loss: 0.3340 - val_acc: 0.8763
Epoch 20/50
 - 34s - loss: 0.3165 - acc: 0.8832 - val_loss: 0.3348 - val_acc: 0.8695
Epoch 21/50
 - 34s - loss: 0.3141 - acc: 0.8851 - val_loss: 0.3220 - val_acc: 0.8804
Epoch 22/50
 - 34s - loss: 0.3118 - acc: 0.8846 - val_loss: 0.3525 - val_acc: 0.8653

Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 23/50
 - 34s - loss: 0.3069 - acc: 0.8873 - val_loss: 0.3115 - val_acc: 0.8863
Epoch 24/50
 - 34s - loss: 0.3034 - acc: 0.8891 - val_loss: 0.3116 - val_acc: 0.8889
Epoch 25/50
 - 34s - loss: 0.3038 - acc: 0.8900 - val_loss: 0.3174 - val_acc: 0.8844
Epoch 26/50
 - 34s - loss: 0.3016 - acc: 0.8897 - val_loss: 0.3112 - val_acc: 0.8859
Epoch 27/50
 - 34s - loss: 0.3026 - acc: 0.8899 - val_loss: 0.3156 - val_acc: 0.8834
Epoch 28/50
 - 33s - loss: 0.3026 - acc: 0.8884 - val_loss: 0.3106 - val_acc: 0.8855
Epoch 29/50
 - 33s - loss: 0.3000 - acc: 0.8909 - val_loss: 0.3131 - val_acc: 0.8848
Epoch 30/50
 - 33s - loss: 0.2976 - acc: 0.8927 - val_loss: 0.3105 - val_acc: 0.8887
Epoch 31/50
 - 33s - loss: 0.2976 - acc: 0.8920 - val_loss: 0.3096 - val_acc: 0.8877
Epoch 32/50
 - 33s - loss: 0.2990 - acc: 0.8906 - val_loss: 0.3071 - val_acc: 0.8888
Epoch 33/50
 - 33s - loss: 0.2970 - acc: 0.8929 - val_loss: 0.3090 - val_acc: 0.8860
Epoch 34/50
 - 33s - loss: 0.2957 - acc: 0.8942 - val_loss: 0.3065 - val_acc: 0.8898
Epoch 35/50
 - 33s - loss: 0.2950 - acc: 0.8940 - val_loss: 0.3165 - val_acc: 0.8847
Epoch 36/50
 - 33s - loss: 0.2958 - acc: 0.8929 - val_loss: 0.3054 - val_acc: 0.8906
Epoch 37/50
 - 33s - loss: 0.2949 - acc: 0.8943 - val_loss: 0.3099 - val_acc: 0.8862
Epoch 38/50
 - 33s - loss: 0.2947 - acc: 0.8933 - val_loss: 0.3060 - val_acc: 0.8898
Epoch 39/50
 - 33s - loss: 0.2940 - acc: 0.8945 - val_loss: 0.3055 - val_acc: 0.8882
Epoch 40/50
 - 33s - loss: 0.2932 - acc: 0.8950 - val_loss: 0.3181 - val_acc: 0.8808

Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 41/50
 - 33s - loss: 0.2893 - acc: 0.8959 - val_loss: 0.3022 - val_acc: 0.8934
Epoch 42/50
 - 33s - loss: 0.2912 - acc: 0.8940 - val_loss: 0.3025 - val_acc: 0.8914
Epoch 43/50
 - 33s - loss: 0.2882 - acc: 0.8957 - val_loss: 0.3012 - val_acc: 0.8926
Epoch 44/50
 - 33s - loss: 0.2886 - acc: 0.8967 - val_loss: 0.3017 - val_acc: 0.8911
Epoch 45/50
 - 33s - loss: 0.2894 - acc: 0.8960 - val_loss: 0.3029 - val_acc: 0.8917
Epoch 46/50
 - 33s - loss: 0.2879 - acc: 0.8974 - val_loss: 0.3019 - val_acc: 0.8928
Epoch 47/50
 - 33s - loss: 0.2894 - acc: 0.8955 - val_loss: 0.3012 - val_acc: 0.8932

Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 48/50
 - 33s - loss: 0.2878 - acc: 0.8973 - val_loss: 0.3008 - val_acc: 0.8942
Epoch 49/50
 - 33s - loss: 0.2861 - acc: 0.8997 - val_loss: 0.3007 - val_acc: 0.8940
Epoch 50/50
 - 33s - loss: 0.2893 - acc: 0.8967 - val_loss: 0.3010 - val_acc: 0.8926

  32/7440 [..............................] - ETA: 2s
 192/7440 [..............................] - ETA: 2s
 352/7440 [>.............................] - ETA: 2s
 512/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 832/7440 [==>...........................] - ETA: 2s
 992/7440 [===>..........................] - ETA: 2s
1152/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1472/7440 [====>.........................] - ETA: 2s
1632/7440 [=====>........................] - ETA: 2s
1792/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2112/7440 [=======>......................] - ETA: 2s
2272/7440 [========>.....................] - ETA: 1s
2432/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2752/7440 [==========>...................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3392/7440 [============>.................] - ETA: 1s
3552/7440 [=============>................] - ETA: 1s
3712/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4032/7440 [===============>..............] - ETA: 1s
4192/7440 [===============>..............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4672/7440 [=================>............] - ETA: 1s
4832/7440 [==================>...........] - ETA: 0s
4992/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5312/7440 [====================>.........] - ETA: 0s
5472/7440 [=====================>........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6112/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6720/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 382us/step
current Test accuracy: 0.8224462365591397
current auc_score ------------------>  0.8952049369869349
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_35[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_665 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_665[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_666 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_666[0][0]             
__________________________________________________________________________________________________
concatenate_279 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_279[0][0]            
__________________________________________________________________________________________________
activation_667 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_667[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_668 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_668[0][0]             
__________________________________________________________________________________________________
concatenate_280 (Concatenate)   (None, 28, 96, 96)   0           concatenate_279[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_280[0][0]            
__________________________________________________________________________________________________
activation_669 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_669[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_670 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_670[0][0]             
__________________________________________________________________________________________________
concatenate_281 (Concatenate)   (None, 34, 96, 96)   0           concatenate_280[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_281[0][0]            
__________________________________________________________________________________________________
activation_671 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_671[0][0]             
__________________________________________________________________________________________________
average_pooling2d_75 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_75[0][0]       
__________________________________________________________________________________________________
activation_672 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_672[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_673 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_673[0][0]             
__________________________________________________________________________________________________
concatenate_282 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_75[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_282[0][0]            
__________________________________________________________________________________________________
activation_674 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_674[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_675 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_675[0][0]             
__________________________________________________________________________________________________
concatenate_283 (Concatenate)   (None, 29, 48, 48)   0           concatenate_282[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_283[0][0]            
__________________________________________________________________________________________________
activation_676 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_676[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_677 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_677[0][0]             
__________________________________________________________________________________________________
concatenate_284 (Concatenate)   (None, 35, 48, 48)   0           concatenate_283[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_284[0][0]            
__________________________________________________________________________________________________
activation_678 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_678[0][0]             
__________________________________________________________________________________________________
average_pooling2d_76 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_76[0][0]       
__________________________________________________________________________________________________
activation_679 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_679[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_680 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_680[0][0]             
__________________________________________________________________________________________________
concatenate_285 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_76[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_285[0][0]            
__________________________________________________________________________________________________
activation_681 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_681[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_682 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_682[0][0]             
__________________________________________________________________________________________________
concatenate_286 (Concatenate)   (None, 29, 24, 24)   0           concatenate_285[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_286[0][0]            
__________________________________________________________________________________________________
activation_683 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_683[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_684 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_684[0][0]             
__________________________________________________________________________________________________
concatenate_287 (Concatenate)   (None, 35, 24, 24)   0           concatenate_286[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 35, 24, 24)   140         concatenate_287[0][0]            
__________________________________________________________________________________________________
activation_685 (Activation)     (None, 35, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 17, 24, 24)   595         activation_685[0][0]             
__________________________________________________________________________________________________
average_pooling2d_77 (AveragePo (None, 17, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 17, 12, 12)   68          average_pooling2d_77[0][0]       
__________________________________________________________________________________________________
activation_686 (Activation)     (None, 17, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 24, 12, 12)   408         activation_686[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_687 (Activation)     (None, 24, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_687[0][0]             
__________________________________________________________________________________________________
concatenate_288 (Concatenate)   (None, 23, 12, 12)   0           average_pooling2d_77[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 23, 12, 12)   92          concatenate_288[0][0]            
__________________________________________________________________________________________________
activation_688 (Activation)     (None, 23, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 24, 12, 12)   552         activation_688[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_689 (Activation)     (None, 24, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_689[0][0]             
__________________________________________________________________________________________________
concatenate_289 (Concatenate)   (None, 29, 12, 12)   0           concatenate_288[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 29, 12, 12)   116         concatenate_289[0][0]            
__________________________________________________________________________________________________
activation_690 (Activation)     (None, 29, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 24, 12, 12)   696         activation_690[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 24, 12, 12)   96          dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_691 (Activation)     (None, 24, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 6, 12, 12)    1296        activation_691[0][0]             
__________________________________________________________________________________________________
concatenate_290 (Concatenate)   (None, 35, 12, 12)   0           concatenate_289[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 12, 12)   140         concatenate_290[0][0]            
__________________________________________________________________________________________________
activation_692 (Activation)     (None, 35, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_35 (Gl (None, 35)           0           activation_692[0][0]             
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 1)            36          global_average_pooling2d_35[0][0]
==================================================================================================
Total params: 26,996
Trainable params: 25,596
Non-trainable params: 1,400
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 63s - loss: 0.5555 - acc: 0.7634 - val_loss: 0.4947 - val_acc: 0.7859
Epoch 2/50
 - 39s - loss: 0.4604 - acc: 0.8112 - val_loss: 0.4383 - val_acc: 0.8249
Epoch 3/50
 - 39s - loss: 0.4146 - acc: 0.8429 - val_loss: 0.4267 - val_acc: 0.8288
Epoch 4/50
 - 39s - loss: 0.3858 - acc: 0.8558 - val_loss: 0.3903 - val_acc: 0.8554
Epoch 5/50
 - 39s - loss: 0.3615 - acc: 0.8713 - val_loss: 0.3485 - val_acc: 0.8727
Epoch 6/50
 - 39s - loss: 0.3406 - acc: 0.8811 - val_loss: 0.3728 - val_acc: 0.8691
Epoch 7/50
 - 39s - loss: 0.3230 - acc: 0.8910 - val_loss: 0.3166 - val_acc: 0.8921
Epoch 8/50
 - 39s - loss: 0.3097 - acc: 0.8962 - val_loss: 0.3579 - val_acc: 0.8742
Epoch 9/50
 - 39s - loss: 0.2974 - acc: 0.9009 - val_loss: 0.2977 - val_acc: 0.9020
Epoch 10/50
 - 39s - loss: 0.2852 - acc: 0.9068 - val_loss: 0.3083 - val_acc: 0.8932
Epoch 11/50
 - 39s - loss: 0.2763 - acc: 0.9116 - val_loss: 0.3149 - val_acc: 0.8965
Epoch 12/50
 - 39s - loss: 0.2710 - acc: 0.9127 - val_loss: 0.2830 - val_acc: 0.9089
Epoch 13/50
 - 39s - loss: 0.2592 - acc: 0.9185 - val_loss: 0.2868 - val_acc: 0.9093
Epoch 14/50
 - 39s - loss: 0.2511 - acc: 0.9225 - val_loss: 0.4743 - val_acc: 0.8507
Epoch 15/50
 - 39s - loss: 0.2479 - acc: 0.9238 - val_loss: 0.2849 - val_acc: 0.9060
Epoch 16/50
 - 39s - loss: 0.2418 - acc: 0.9262 - val_loss: 0.2559 - val_acc: 0.9217
Epoch 17/50
 - 39s - loss: 0.2304 - acc: 0.9318 - val_loss: 0.2978 - val_acc: 0.9040
Epoch 18/50
 - 39s - loss: 0.2276 - acc: 0.9327 - val_loss: 0.2519 - val_acc: 0.9203
Epoch 19/50
 - 39s - loss: 0.2248 - acc: 0.9345 - val_loss: 0.2666 - val_acc: 0.9128
Epoch 20/50
 - 39s - loss: 0.2163 - acc: 0.9378 - val_loss: 0.2735 - val_acc: 0.9134
Epoch 21/50
 - 39s - loss: 0.2102 - acc: 0.9402 - val_loss: 0.2795 - val_acc: 0.9104
Epoch 22/50
 - 39s - loss: 0.2080 - acc: 0.9391 - val_loss: 0.3234 - val_acc: 0.8887

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 23/50
 - 39s - loss: 0.1865 - acc: 0.9498 - val_loss: 0.2297 - val_acc: 0.9326
Epoch 24/50
 - 39s - loss: 0.1841 - acc: 0.9496 - val_loss: 0.2320 - val_acc: 0.9305
Epoch 25/50
 - 39s - loss: 0.1821 - acc: 0.9523 - val_loss: 0.2202 - val_acc: 0.9360
Epoch 26/50
 - 39s - loss: 0.1764 - acc: 0.9540 - val_loss: 0.2258 - val_acc: 0.9324
Epoch 27/50
 - 39s - loss: 0.1771 - acc: 0.9543 - val_loss: 0.2292 - val_acc: 0.9346
Epoch 28/50
 - 39s - loss: 0.1769 - acc: 0.9547 - val_loss: 0.2306 - val_acc: 0.9320
Epoch 29/50
 - 39s - loss: 0.1734 - acc: 0.9560 - val_loss: 0.2387 - val_acc: 0.9320

Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 30/50
 - 39s - loss: 0.1662 - acc: 0.9595 - val_loss: 0.2135 - val_acc: 0.9383
Epoch 31/50
 - 39s - loss: 0.1647 - acc: 0.9599 - val_loss: 0.2215 - val_acc: 0.9366
Epoch 32/50
 - 39s - loss: 0.1622 - acc: 0.9610 - val_loss: 0.2142 - val_acc: 0.9394
Epoch 33/50
 - 39s - loss: 0.1626 - acc: 0.9598 - val_loss: 0.2160 - val_acc: 0.9388
Epoch 34/50
 - 39s - loss: 0.1598 - acc: 0.9616 - val_loss: 0.2142 - val_acc: 0.9381

Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 35/50
 - 39s - loss: 0.1597 - acc: 0.9617 - val_loss: 0.2156 - val_acc: 0.9381
Epoch 36/50
 - 39s - loss: 0.1601 - acc: 0.9616 - val_loss: 0.2148 - val_acc: 0.9386
Epoch 37/50
 - 39s - loss: 0.1569 - acc: 0.9623 - val_loss: 0.2165 - val_acc: 0.9384
Epoch 00037: early stopping

  32/7440 [..............................] - ETA: 2s
 160/7440 [..............................] - ETA: 2s
 288/7440 [>.............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 544/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 1s
2592/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2848/7440 [==========>...................] - ETA: 1s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 402us/step
current Test accuracy: 0.8150537634408602
current auc_score ------------------>  0.9098711917562724
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_36 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_36[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_693 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_693[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_694 (Activation)     (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_694[0][0]             
__________________________________________________________________________________________________
concatenate_291 (Concatenate)   (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_291[0][0]            
__________________________________________________________________________________________________
activation_695 (Activation)     (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_695[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_696 (Activation)     (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_696[0][0]             
__________________________________________________________________________________________________
concatenate_292 (Concatenate)   (None, 44, 96, 96)   0           concatenate_291[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_292[0][0]            
__________________________________________________________________________________________________
activation_697 (Activation)     (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_697[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_698 (Activation)     (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_698[0][0]             
__________________________________________________________________________________________________
concatenate_293 (Concatenate)   (None, 58, 96, 96)   0           concatenate_292[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 58, 96, 96)   232         concatenate_293[0][0]            
__________________________________________________________________________________________________
activation_699 (Activation)     (None, 58, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 56, 96, 96)   3248        activation_699[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_700 (Activation)     (None, 56, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_700[0][0]             
__________________________________________________________________________________________________
concatenate_294 (Concatenate)   (None, 72, 96, 96)   0           concatenate_293[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 72, 96, 96)   288         concatenate_294[0][0]            
__________________________________________________________________________________________________
activation_701 (Activation)     (None, 72, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 56, 96, 96)   4032        activation_701[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_702 (Activation)     (None, 56, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_702[0][0]             
__________________________________________________________________________________________________
concatenate_295 (Concatenate)   (None, 86, 96, 96)   0           concatenate_294[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 86, 96, 96)   344         concatenate_295[0][0]            
__________________________________________________________________________________________________
activation_703 (Activation)     (None, 86, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 43, 96, 96)   3698        activation_703[0][0]             
__________________________________________________________________________________________________
average_pooling2d_78 (AveragePo (None, 43, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 43, 48, 48)   172         average_pooling2d_78[0][0]       
__________________________________________________________________________________________________
activation_704 (Activation)     (None, 43, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   2408        activation_704[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_705 (Activation)     (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_705[0][0]             
__________________________________________________________________________________________________
concatenate_296 (Concatenate)   (None, 57, 48, 48)   0           average_pooling2d_78[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 57, 48, 48)   228         concatenate_296[0][0]            
__________________________________________________________________________________________________
activation_706 (Activation)     (None, 57, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   3192        activation_706[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_707 (Activation)     (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_707[0][0]             
__________________________________________________________________________________________________
concatenate_297 (Concatenate)   (None, 71, 48, 48)   0           concatenate_296[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_297[0][0]            
__________________________________________________________________________________________________
activation_708 (Activation)     (None, 71, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3976        activation_708[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_709 (Activation)     (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_709[0][0]             
__________________________________________________________________________________________________
concatenate_298 (Concatenate)   (None, 85, 48, 48)   0           concatenate_297[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 85, 48, 48)   340         concatenate_298[0][0]            
__________________________________________________________________________________________________
activation_710 (Activation)     (None, 85, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 56, 48, 48)   4760        activation_710[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_711 (Activation)     (None, 56, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_711[0][0]             
__________________________________________________________________________________________________
concatenate_299 (Concatenate)   (None, 99, 48, 48)   0           concatenate_298[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 99, 48, 48)   396         concatenate_299[0][0]            
__________________________________________________________________________________________________
activation_712 (Activation)     (None, 99, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 56, 48, 48)   5544        activation_712[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_713 (Activation)     (None, 56, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_713[0][0]             
__________________________________________________________________________________________________
concatenate_300 (Concatenate)   (None, 113, 48, 48)  0           concatenate_299[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 113, 48, 48)  452         concatenate_300[0][0]            
__________________________________________________________________________________________________
activation_714 (Activation)     (None, 113, 48, 48)  0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 56, 48, 48)   6328        activation_714[0][0]             
__________________________________________________________________________________________________
average_pooling2d_79 (AveragePo (None, 56, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 56, 24, 24)   224         average_pooling2d_79[0][0]       
__________________________________________________________________________________________________
activation_715 (Activation)     (None, 56, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 56, 24, 24)   3136        activation_715[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_716 (Activation)     (None, 56, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_716[0][0]             
__________________________________________________________________________________________________
concatenate_301 (Concatenate)   (None, 70, 24, 24)   0           average_pooling2d_79[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_301[0][0]            
__________________________________________________________________________________________________
activation_717 (Activation)     (None, 70, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 56, 24, 24)   3920        activation_717[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_718 (Activation)     (None, 56, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_718[0][0]             
__________________________________________________________________________________________________
concatenate_302 (Concatenate)   (None, 84, 24, 24)   0           concatenate_301[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 84, 24, 24)   336         concatenate_302[0][0]            
__________________________________________________________________________________________________
activation_719 (Activation)     (None, 84, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 56, 24, 24)   4704        activation_719[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_720 (Activation)     (None, 56, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_720[0][0]             
__________________________________________________________________________________________________
concatenate_303 (Concatenate)   (None, 98, 24, 24)   0           concatenate_302[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 98, 24, 24)   392         concatenate_303[0][0]            
__________________________________________________________________________________________________
activation_721 (Activation)     (None, 98, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 56, 24, 24)   5488        activation_721[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_722 (Activation)     (None, 56, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_722[0][0]             
__________________________________________________________________________________________________
concatenate_304 (Concatenate)   (None, 112, 24, 24)  0           concatenate_303[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_304[0][0]            
__________________________________________________________________________________________________
activation_723 (Activation)     (None, 112, 24, 24)  0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 56, 24, 24)   6272        activation_723[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 56, 24, 24)   224         dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_724 (Activation)     (None, 56, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 14, 24, 24)   7056        activation_724[0][0]             
__________________________________________________________________________________________________
concatenate_305 (Concatenate)   (None, 126, 24, 24)  0           concatenate_304[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 126, 24, 24)  504         concatenate_305[0][0]            
__________________________________________________________________________________________________
activation_725 (Activation)     (None, 126, 24, 24)  0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 63, 24, 24)   7938        activation_725[0][0]             
__________________________________________________________________________________________________
average_pooling2d_80 (AveragePo (None, 63, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 63, 12, 12)   252         average_pooling2d_80[0][0]       
__________________________________________________________________________________________________
activation_726 (Activation)     (None, 63, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 56, 12, 12)   3528        activation_726[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_727 (Activation)     (None, 56, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_727[0][0]             
__________________________________________________________________________________________________
concatenate_306 (Concatenate)   (None, 77, 12, 12)   0           average_pooling2d_80[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 77, 12, 12)   308         concatenate_306[0][0]            
__________________________________________________________________________________________________
activation_728 (Activation)     (None, 77, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 56, 12, 12)   4312        activation_728[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_729 (Activation)     (None, 56, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_729[0][0]             
__________________________________________________________________________________________________
concatenate_307 (Concatenate)   (None, 91, 12, 12)   0           concatenate_306[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 91, 12, 12)   364         concatenate_307[0][0]            
__________________________________________________________________________________________________
activation_730 (Activation)     (None, 91, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 56, 12, 12)   5096        activation_730[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_731 (Activation)     (None, 56, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_731[0][0]             
__________________________________________________________________________________________________
concatenate_308 (Concatenate)   (None, 105, 12, 12)  0           concatenate_307[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_3_bn (BatchNormalizatio (None, 105, 12, 12)  420         concatenate_308[0][0]            
__________________________________________________________________________________________________
activation_732 (Activation)     (None, 105, 12, 12)  0           dense_3_3_bn[0][0]               
__________________________________________________________________________________________________
dense_3_3_bottleneck_conv2D (Co (None, 56, 12, 12)   5880        activation_732[0][0]             
__________________________________________________________________________________________________
dense_3_3_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_733 (Activation)     (None, 56, 12, 12)   0           dense_3_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_3_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_733[0][0]             
__________________________________________________________________________________________________
concatenate_309 (Concatenate)   (None, 119, 12, 12)  0           concatenate_308[0][0]            
                                                                 dense_3_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_4_bn (BatchNormalizatio (None, 119, 12, 12)  476         concatenate_309[0][0]            
__________________________________________________________________________________________________
activation_734 (Activation)     (None, 119, 12, 12)  0           dense_3_4_bn[0][0]               
__________________________________________________________________________________________________
dense_3_4_bottleneck_conv2D (Co (None, 56, 12, 12)   6664        activation_734[0][0]             
__________________________________________________________________________________________________
dense_3_4_bottleneck_bn (BatchN (None, 56, 12, 12)   224         dense_3_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_735 (Activation)     (None, 56, 12, 12)   0           dense_3_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_4_conv2D (Conv2D)       (None, 14, 12, 12)   7056        activation_735[0][0]             
__________________________________________________________________________________________________
concatenate_310 (Concatenate)   (None, 133, 12, 12)  0           concatenate_309[0][0]            
                                                                 dense_3_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 133, 12, 12)  532         concatenate_310[0][0]            
__________________________________________________________________________________________________
activation_736 (Activation)     (None, 133, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_36 (Gl (None, 133)          0           activation_736[0][0]             
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 1)            134         global_average_pooling2d_36[0][0]
==================================================================================================
Total params: 252,818
Trainable params: 246,762
Non-trainable params: 6,056
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 115s - loss: 0.6717 - acc: 0.8004 - val_loss: 0.5983 - val_acc: 0.8405
Epoch 2/50
 - 85s - loss: 0.5262 - acc: 0.8737 - val_loss: 0.5268 - val_acc: 0.8761
Epoch 3/50
 - 85s - loss: 0.4557 - acc: 0.9048 - val_loss: 0.5423 - val_acc: 0.8569
Epoch 4/50
 - 85s - loss: 0.4060 - acc: 0.9251 - val_loss: 0.3935 - val_acc: 0.9310
Epoch 5/50
 - 85s - loss: 0.3731 - acc: 0.9374 - val_loss: 0.3687 - val_acc: 0.9378
Epoch 6/50
 - 85s - loss: 0.3400 - acc: 0.9486 - val_loss: 0.3474 - val_acc: 0.9431
Epoch 7/50
 - 85s - loss: 0.3176 - acc: 0.9562 - val_loss: 0.3588 - val_acc: 0.9374
Epoch 8/50
 - 85s - loss: 0.2989 - acc: 0.9615 - val_loss: 0.3211 - val_acc: 0.9527
Epoch 9/50
 - 85s - loss: 0.2862 - acc: 0.9663 - val_loss: 0.3207 - val_acc: 0.9516
Epoch 10/50
 - 85s - loss: 0.2703 - acc: 0.9708 - val_loss: 0.3267 - val_acc: 0.9492
Epoch 11/50
 - 85s - loss: 0.2578 - acc: 0.9735 - val_loss: 0.3303 - val_acc: 0.9493
Epoch 12/50
 - 85s - loss: 0.2444 - acc: 0.9787 - val_loss: 0.3048 - val_acc: 0.9537
Epoch 13/50
 - 85s - loss: 0.2448 - acc: 0.9768 - val_loss: 0.2856 - val_acc: 0.9595
Epoch 14/50
 - 85s - loss: 0.2312 - acc: 0.9800 - val_loss: 0.3179 - val_acc: 0.9504
Epoch 15/50
 - 85s - loss: 0.2223 - acc: 0.9827 - val_loss: 0.4360 - val_acc: 0.9014
Epoch 16/50
 - 85s - loss: 0.2181 - acc: 0.9831 - val_loss: 0.3073 - val_acc: 0.9497
Epoch 17/50
 - 85s - loss: 0.2109 - acc: 0.9837 - val_loss: 0.2786 - val_acc: 0.9647
Epoch 18/50
 - 85s - loss: 0.2046 - acc: 0.9861 - val_loss: 0.2729 - val_acc: 0.9641
Epoch 19/50
 - 85s - loss: 0.1999 - acc: 0.9863 - val_loss: 0.2678 - val_acc: 0.9636
Epoch 20/50
 - 85s - loss: 0.1977 - acc: 0.9858 - val_loss: 0.2773 - val_acc: 0.9585
Epoch 21/50
 - 85s - loss: 0.1914 - acc: 0.9874 - val_loss: 0.2431 - val_acc: 0.9699
Epoch 22/50
 - 85s - loss: 0.1863 - acc: 0.9880 - val_loss: 0.2781 - val_acc: 0.9647
Epoch 23/50
 - 85s - loss: 0.1816 - acc: 0.9886 - val_loss: 0.2536 - val_acc: 0.9690
Epoch 24/50
 - 85s - loss: 0.1788 - acc: 0.9890 - val_loss: 0.3649 - val_acc: 0.9325
Epoch 25/50
 - 85s - loss: 0.1753 - acc: 0.9899 - val_loss: 0.2873 - val_acc: 0.9542

Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 26/50
 - 85s - loss: 0.1561 - acc: 0.9965 - val_loss: 0.2014 - val_acc: 0.9795
Epoch 27/50
 - 85s - loss: 0.1490 - acc: 0.9985 - val_loss: 0.1946 - val_acc: 0.9829
Epoch 28/50
 - 85s - loss: 0.1487 - acc: 0.9983 - val_loss: 0.2019 - val_acc: 0.9799
Epoch 29/50
 - 85s - loss: 0.1462 - acc: 0.9984 - val_loss: 0.1969 - val_acc: 0.9823
Epoch 30/50
 - 85s - loss: 0.1435 - acc: 0.9985 - val_loss: 0.2121 - val_acc: 0.9770
Epoch 31/50
 - 85s - loss: 0.1442 - acc: 0.9979 - val_loss: 0.1898 - val_acc: 0.9818
Epoch 32/50
 - 85s - loss: 0.1408 - acc: 0.9984 - val_loss: 0.1944 - val_acc: 0.9822
Epoch 33/50
 - 85s - loss: 0.1380 - acc: 0.9990 - val_loss: 0.1934 - val_acc: 0.9807
Epoch 34/50
 - 85s - loss: 0.1402 - acc: 0.9973 - val_loss: 0.2175 - val_acc: 0.9734
Epoch 35/50
 - 85s - loss: 0.1357 - acc: 0.9988 - val_loss: 0.1893 - val_acc: 0.9833
Epoch 36/50
 - 85s - loss: 0.1344 - acc: 0.9988 - val_loss: 0.1898 - val_acc: 0.9819
Epoch 37/50
 - 85s - loss: 0.1336 - acc: 0.9984 - val_loss: 0.1913 - val_acc: 0.9813
Epoch 38/50
 - 85s - loss: 0.1311 - acc: 0.9988 - val_loss: 0.1897 - val_acc: 0.9788
Epoch 39/50
 - 85s - loss: 0.1290 - acc: 0.9990 - val_loss: 0.1815 - val_acc: 0.9833
Epoch 40/50
 - 85s - loss: 0.1291 - acc: 0.9988 - val_loss: 0.1759 - val_acc: 0.9828
Epoch 41/50
 - 85s - loss: 0.1274 - acc: 0.9986 - val_loss: 0.1740 - val_acc: 0.9848
Epoch 42/50
 - 85s - loss: 0.1252 - acc: 0.9991 - val_loss: 0.1725 - val_acc: 0.9841
Epoch 43/50
 - 85s - loss: 0.1274 - acc: 0.9981 - val_loss: 0.1868 - val_acc: 0.9798
Epoch 44/50
 - 85s - loss: 0.1245 - acc: 0.9984 - val_loss: 0.1711 - val_acc: 0.9828
Epoch 45/50
 - 85s - loss: 0.1215 - acc: 0.9992 - val_loss: 0.1970 - val_acc: 0.9755
Epoch 46/50
 - 85s - loss: 0.1201 - acc: 0.9992 - val_loss: 0.1856 - val_acc: 0.9807
Epoch 47/50
 - 85s - loss: 0.1218 - acc: 0.9982 - val_loss: 0.1964 - val_acc: 0.9783
Epoch 48/50
 - 85s - loss: 0.1195 - acc: 0.9986 - val_loss: 0.1786 - val_acc: 0.9807

Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 49/50
 - 85s - loss: 0.1164 - acc: 0.9996 - val_loss: 0.1684 - val_acc: 0.9832
Epoch 50/50
 - 85s - loss: 0.1154 - acc: 0.9995 - val_loss: 0.1718 - val_acc: 0.9818

  32/7440 [..............................] - ETA: 6s
  96/7440 [..............................] - ETA: 6s
 160/7440 [..............................] - ETA: 6s
 224/7440 [..............................] - ETA: 5s
 288/7440 [>.............................] - ETA: 5s
 352/7440 [>.............................] - ETA: 5s
 416/7440 [>.............................] - ETA: 5s
 480/7440 [>.............................] - ETA: 5s
 544/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 5s
 672/7440 [=>............................] - ETA: 5s
 736/7440 [=>............................] - ETA: 5s
 800/7440 [==>...........................] - ETA: 5s
 864/7440 [==>...........................] - ETA: 5s
 928/7440 [==>...........................] - ETA: 5s
 992/7440 [===>..........................] - ETA: 5s
1056/7440 [===>..........................] - ETA: 5s
1120/7440 [===>..........................] - ETA: 5s
1184/7440 [===>..........................] - ETA: 5s
1248/7440 [====>.........................] - ETA: 5s
1312/7440 [====>.........................] - ETA: 5s
1376/7440 [====>.........................] - ETA: 5s
1440/7440 [====>.........................] - ETA: 4s
1504/7440 [=====>........................] - ETA: 4s
1568/7440 [=====>........................] - ETA: 4s
1632/7440 [=====>........................] - ETA: 4s
1696/7440 [=====>........................] - ETA: 4s
1760/7440 [======>.......................] - ETA: 4s
1824/7440 [======>.......................] - ETA: 4s
1888/7440 [======>.......................] - ETA: 4s
1952/7440 [======>.......................] - ETA: 4s
2016/7440 [=======>......................] - ETA: 4s
2080/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 4s
2208/7440 [=======>......................] - ETA: 4s
2272/7440 [========>.....................] - ETA: 4s
2336/7440 [========>.....................] - ETA: 4s
2400/7440 [========>.....................] - ETA: 4s
2464/7440 [========>.....................] - ETA: 4s
2528/7440 [=========>....................] - ETA: 4s
2592/7440 [=========>....................] - ETA: 4s
2656/7440 [=========>....................] - ETA: 3s
2720/7440 [=========>....................] - ETA: 3s
2784/7440 [==========>...................] - ETA: 3s
2848/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 3s
2976/7440 [===========>..................] - ETA: 3s
3040/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3168/7440 [===========>..................] - ETA: 3s
3232/7440 [============>.................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3360/7440 [============>.................] - ETA: 3s
3424/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 3s
3552/7440 [=============>................] - ETA: 3s
3616/7440 [=============>................] - ETA: 3s
3680/7440 [=============>................] - ETA: 3s
3744/7440 [==============>...............] - ETA: 3s
3808/7440 [==============>...............] - ETA: 3s
3872/7440 [==============>...............] - ETA: 2s
3936/7440 [==============>...............] - ETA: 2s
4000/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4128/7440 [===============>..............] - ETA: 2s
4192/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4320/7440 [================>.............] - ETA: 2s
4384/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4512/7440 [=================>............] - ETA: 2s
4576/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4704/7440 [=================>............] - ETA: 2s
4768/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4896/7440 [==================>...........] - ETA: 2s
4960/7440 [===================>..........] - ETA: 2s
5024/7440 [===================>..........] - ETA: 1s
5088/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5344/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5472/7440 [=====================>........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5664/7440 [=====================>........] - ETA: 1s
5728/7440 [======================>.......] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5856/7440 [======================>.......] - ETA: 1s
5920/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6048/7440 [=======================>......] - ETA: 1s
6112/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 1s
6240/7440 [========================>.....] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6496/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6880/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7264/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7392/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 834us/step
current Test accuracy: 0.7708333333333334
current auc_score ------------------>  0.902717185512776
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_37[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_737 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_737[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_738 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_738[0][0]             
__________________________________________________________________________________________________
concatenate_311 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_311[0][0]            
__________________________________________________________________________________________________
activation_739 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_739[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_740 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_740[0][0]             
__________________________________________________________________________________________________
concatenate_312 (Concatenate)   (None, 28, 96, 96)   0           concatenate_311[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_312[0][0]            
__________________________________________________________________________________________________
activation_741 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_741[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_742 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_742[0][0]             
__________________________________________________________________________________________________
concatenate_313 (Concatenate)   (None, 34, 96, 96)   0           concatenate_312[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_313[0][0]            
__________________________________________________________________________________________________
activation_743 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_743[0][0]             
__________________________________________________________________________________________________
average_pooling2d_81 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_81[0][0]       
__________________________________________________________________________________________________
activation_744 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_744[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_745 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_745[0][0]             
__________________________________________________________________________________________________
concatenate_314 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_81[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_314[0][0]            
__________________________________________________________________________________________________
activation_746 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_746[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_747 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_747[0][0]             
__________________________________________________________________________________________________
concatenate_315 (Concatenate)   (None, 29, 48, 48)   0           concatenate_314[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_315[0][0]            
__________________________________________________________________________________________________
activation_748 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_748[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_749 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_749[0][0]             
__________________________________________________________________________________________________
concatenate_316 (Concatenate)   (None, 35, 48, 48)   0           concatenate_315[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_316[0][0]            
__________________________________________________________________________________________________
activation_750 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_750[0][0]             
__________________________________________________________________________________________________
average_pooling2d_82 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_82[0][0]       
__________________________________________________________________________________________________
activation_751 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_751[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_752 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_752[0][0]             
__________________________________________________________________________________________________
concatenate_317 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_82[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_317[0][0]            
__________________________________________________________________________________________________
activation_753 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_753[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_754 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_754[0][0]             
__________________________________________________________________________________________________
concatenate_318 (Concatenate)   (None, 29, 24, 24)   0           concatenate_317[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_318[0][0]            
__________________________________________________________________________________________________
activation_755 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_755[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_756 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_756[0][0]             
__________________________________________________________________________________________________
concatenate_319 (Concatenate)   (None, 35, 24, 24)   0           concatenate_318[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 24, 24)   140         concatenate_319[0][0]            
__________________________________________________________________________________________________
activation_757 (Activation)     (None, 35, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_37 (Gl (None, 35)           0           activation_757[0][0]             
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 1)            36          global_average_pooling2d_37[0][0]
==================================================================================================
Total params: 20,153
Trainable params: 19,105
Non-trainable params: 1,048
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 61s - loss: 0.5625 - acc: 0.7515 - val_loss: 0.4966 - val_acc: 0.7854
Epoch 2/50
 - 34s - loss: 0.4868 - acc: 0.7923 - val_loss: 0.4834 - val_acc: 0.7900
Epoch 3/50
 - 35s - loss: 0.4605 - acc: 0.8047 - val_loss: 0.4396 - val_acc: 0.8120
Epoch 4/50
 - 34s - loss: 0.4409 - acc: 0.8165 - val_loss: 0.4290 - val_acc: 0.8178
Epoch 5/50
 - 35s - loss: 0.4211 - acc: 0.8280 - val_loss: 0.4200 - val_acc: 0.8291
Epoch 6/50
 - 35s - loss: 0.4047 - acc: 0.8362 - val_loss: 0.4095 - val_acc: 0.8279
Epoch 7/50
 - 35s - loss: 0.3914 - acc: 0.8440 - val_loss: 0.3834 - val_acc: 0.8499
Epoch 8/50
 - 34s - loss: 0.3788 - acc: 0.8498 - val_loss: 0.3929 - val_acc: 0.8325
Epoch 9/50
 - 35s - loss: 0.3695 - acc: 0.8524 - val_loss: 0.3902 - val_acc: 0.8453
Epoch 10/50
 - 35s - loss: 0.3586 - acc: 0.8602 - val_loss: 0.3600 - val_acc: 0.8623
Epoch 11/50
 - 35s - loss: 0.3495 - acc: 0.8642 - val_loss: 0.3680 - val_acc: 0.8545
Epoch 12/50
 - 35s - loss: 0.3400 - acc: 0.8697 - val_loss: 0.3809 - val_acc: 0.8539
Epoch 13/50
 - 36s - loss: 0.3340 - acc: 0.8727 - val_loss: 0.3393 - val_acc: 0.8705
Epoch 14/50
 - 36s - loss: 0.3262 - acc: 0.8769 - val_loss: 0.3279 - val_acc: 0.8789
Epoch 15/50
 - 35s - loss: 0.3228 - acc: 0.8796 - val_loss: 0.3098 - val_acc: 0.8863
Epoch 16/50
 - 34s - loss: 0.3092 - acc: 0.8858 - val_loss: 0.3257 - val_acc: 0.8814
Epoch 17/50
 - 35s - loss: 0.3051 - acc: 0.8875 - val_loss: 0.3390 - val_acc: 0.8677
Epoch 18/50
 - 35s - loss: 0.3029 - acc: 0.8882 - val_loss: 0.3362 - val_acc: 0.8680
Epoch 19/50
 - 35s - loss: 0.2948 - acc: 0.8950 - val_loss: 0.3120 - val_acc: 0.8845

Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 20/50
 - 34s - loss: 0.2755 - acc: 0.9036 - val_loss: 0.3129 - val_acc: 0.8892
Epoch 21/50
 - 35s - loss: 0.2741 - acc: 0.9045 - val_loss: 0.2775 - val_acc: 0.9041
Epoch 22/50
 - 34s - loss: 0.2698 - acc: 0.9065 - val_loss: 0.2826 - val_acc: 0.9005
Epoch 23/50
 - 34s - loss: 0.2692 - acc: 0.9067 - val_loss: 0.2803 - val_acc: 0.9020
Epoch 24/50
 - 34s - loss: 0.2629 - acc: 0.9097 - val_loss: 0.2771 - val_acc: 0.9027
Epoch 25/50
 - 35s - loss: 0.2647 - acc: 0.9084 - val_loss: 0.2768 - val_acc: 0.9036
Epoch 26/50
 - 35s - loss: 0.2628 - acc: 0.9106 - val_loss: 0.2709 - val_acc: 0.9066
Epoch 27/50
 - 35s - loss: 0.2617 - acc: 0.9107 - val_loss: 0.2671 - val_acc: 0.9084
Epoch 28/50
 - 35s - loss: 0.2586 - acc: 0.9112 - val_loss: 0.2685 - val_acc: 0.9049
Epoch 29/50
 - 34s - loss: 0.2569 - acc: 0.9130 - val_loss: 0.2654 - val_acc: 0.9084
Epoch 30/50
 - 34s - loss: 0.2530 - acc: 0.9145 - val_loss: 0.2725 - val_acc: 0.9069
Epoch 31/50
 - 35s - loss: 0.2574 - acc: 0.9125 - val_loss: 0.2684 - val_acc: 0.9049
Epoch 32/50
 - 34s - loss: 0.2485 - acc: 0.9171 - val_loss: 0.2675 - val_acc: 0.9080
Epoch 33/50
 - 34s - loss: 0.2500 - acc: 0.9147 - val_loss: 0.2923 - val_acc: 0.8936

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 34/50
 - 35s - loss: 0.2454 - acc: 0.9188 - val_loss: 0.2604 - val_acc: 0.9104
Epoch 35/50
 - 34s - loss: 0.2414 - acc: 0.9193 - val_loss: 0.2600 - val_acc: 0.9099
Epoch 36/50
 - 34s - loss: 0.2428 - acc: 0.9192 - val_loss: 0.2584 - val_acc: 0.9098
Epoch 37/50
 - 34s - loss: 0.2433 - acc: 0.9199 - val_loss: 0.2580 - val_acc: 0.9101
Epoch 38/50
 - 34s - loss: 0.2393 - acc: 0.9206 - val_loss: 0.2576 - val_acc: 0.9128
Epoch 39/50
 - 34s - loss: 0.2414 - acc: 0.9207 - val_loss: 0.2585 - val_acc: 0.9129
Epoch 40/50
 - 35s - loss: 0.2403 - acc: 0.9198 - val_loss: 0.2569 - val_acc: 0.9113
Epoch 41/50
 - 35s - loss: 0.2408 - acc: 0.9191 - val_loss: 0.2587 - val_acc: 0.9109
Epoch 42/50
 - 35s - loss: 0.2399 - acc: 0.9207 - val_loss: 0.2569 - val_acc: 0.9115
Epoch 43/50
 - 34s - loss: 0.2383 - acc: 0.9213 - val_loss: 0.2563 - val_acc: 0.9121
Epoch 44/50
 - 34s - loss: 0.2382 - acc: 0.9216 - val_loss: 0.2562 - val_acc: 0.9124
Epoch 45/50
 - 35s - loss: 0.2368 - acc: 0.9219 - val_loss: 0.2557 - val_acc: 0.9129
Epoch 46/50
 - 34s - loss: 0.2355 - acc: 0.9206 - val_loss: 0.2569 - val_acc: 0.9133
Epoch 47/50
 - 35s - loss: 0.2361 - acc: 0.9212 - val_loss: 0.2561 - val_acc: 0.9105
Epoch 48/50
 - 35s - loss: 0.2342 - acc: 0.9224 - val_loss: 0.2586 - val_acc: 0.9116
Epoch 49/50
 - 34s - loss: 0.2329 - acc: 0.9229 - val_loss: 0.2569 - val_acc: 0.9085

Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 50/50
 - 34s - loss: 0.2335 - acc: 0.9236 - val_loss: 0.2536 - val_acc: 0.9138

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 2s
 288/7440 [>.............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 544/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2848/7440 [==========>...................] - ETA: 1s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 0s
5152/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 405us/step
current Test accuracy: 0.7990591397849462
current auc_score ------------------>  0.8674817898022893
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_38 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_38[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_758 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_758[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_759 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_759[0][0]             
__________________________________________________________________________________________________
concatenate_320 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_320[0][0]            
__________________________________________________________________________________________________
activation_760 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_760[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_761 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_761[0][0]             
__________________________________________________________________________________________________
concatenate_321 (Concatenate)   (None, 28, 96, 96)   0           concatenate_320[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_321[0][0]            
__________________________________________________________________________________________________
activation_762 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_762[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_763 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_763[0][0]             
__________________________________________________________________________________________________
concatenate_322 (Concatenate)   (None, 34, 96, 96)   0           concatenate_321[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_322[0][0]            
__________________________________________________________________________________________________
activation_764 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_764[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_765 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_765[0][0]             
__________________________________________________________________________________________________
concatenate_323 (Concatenate)   (None, 40, 96, 96)   0           concatenate_322[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_323[0][0]            
__________________________________________________________________________________________________
activation_766 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_766[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_767 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_767[0][0]             
__________________________________________________________________________________________________
concatenate_324 (Concatenate)   (None, 46, 96, 96)   0           concatenate_323[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_324[0][0]            
__________________________________________________________________________________________________
activation_768 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_768[0][0]             
__________________________________________________________________________________________________
average_pooling2d_83 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_83[0][0]       
__________________________________________________________________________________________________
activation_769 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_769[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_770 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_770[0][0]             
__________________________________________________________________________________________________
concatenate_325 (Concatenate)   (None, 29, 48, 48)   0           average_pooling2d_83[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_325[0][0]            
__________________________________________________________________________________________________
activation_771 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_771[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_772 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_772[0][0]             
__________________________________________________________________________________________________
concatenate_326 (Concatenate)   (None, 35, 48, 48)   0           concatenate_325[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_326[0][0]            
__________________________________________________________________________________________________
activation_773 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_773[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_774 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_774[0][0]             
__________________________________________________________________________________________________
concatenate_327 (Concatenate)   (None, 41, 48, 48)   0           concatenate_326[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_327[0][0]            
__________________________________________________________________________________________________
activation_775 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_775[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_776 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_776[0][0]             
__________________________________________________________________________________________________
concatenate_328 (Concatenate)   (None, 47, 48, 48)   0           concatenate_327[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_328[0][0]            
__________________________________________________________________________________________________
activation_777 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_777[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_778 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_778[0][0]             
__________________________________________________________________________________________________
concatenate_329 (Concatenate)   (None, 53, 48, 48)   0           concatenate_328[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 53, 48, 48)   212         concatenate_329[0][0]            
__________________________________________________________________________________________________
activation_779 (Activation)     (None, 53, 48, 48)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_38 (Gl (None, 53)           0           activation_779[0][0]             
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 1)            54          global_average_pooling2d_38[0][0]
==================================================================================================
Total params: 24,536
Trainable params: 23,228
Non-trainable params: 1,308
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 72s - loss: 0.5835 - acc: 0.7453 - val_loss: 0.5255 - val_acc: 0.7728
Epoch 2/50
 - 45s - loss: 0.5109 - acc: 0.7766 - val_loss: 0.4938 - val_acc: 0.7833
Epoch 3/50
 - 45s - loss: 0.4764 - acc: 0.7907 - val_loss: 0.4752 - val_acc: 0.7800
Epoch 4/50
 - 45s - loss: 0.4540 - acc: 0.8057 - val_loss: 0.4785 - val_acc: 0.7849
Epoch 5/50
 - 45s - loss: 0.4356 - acc: 0.8170 - val_loss: 0.4787 - val_acc: 0.8006
Epoch 6/50
 - 45s - loss: 0.4238 - acc: 0.8224 - val_loss: 0.5063 - val_acc: 0.7833
Epoch 7/50
 - 45s - loss: 0.4117 - acc: 0.8293 - val_loss: 0.4000 - val_acc: 0.8343
Epoch 8/50
 - 45s - loss: 0.4025 - acc: 0.8353 - val_loss: 0.4478 - val_acc: 0.8076
Epoch 9/50
 - 45s - loss: 0.3955 - acc: 0.8376 - val_loss: 0.4040 - val_acc: 0.8351
Epoch 10/50
 - 45s - loss: 0.3864 - acc: 0.8432 - val_loss: 0.3787 - val_acc: 0.8535
Epoch 11/50
 - 45s - loss: 0.3802 - acc: 0.8464 - val_loss: 0.4029 - val_acc: 0.8340
Epoch 12/50
 - 45s - loss: 0.3709 - acc: 0.8498 - val_loss: 0.5332 - val_acc: 0.7802
Epoch 13/50
 - 45s - loss: 0.3675 - acc: 0.8522 - val_loss: 0.3738 - val_acc: 0.8515
Epoch 14/50
 - 45s - loss: 0.3593 - acc: 0.8595 - val_loss: 0.3672 - val_acc: 0.8583
Epoch 15/50
 - 45s - loss: 0.3545 - acc: 0.8603 - val_loss: 0.3543 - val_acc: 0.8612
Epoch 16/50
 - 45s - loss: 0.3497 - acc: 0.8631 - val_loss: 0.4160 - val_acc: 0.8200
Epoch 17/50
 - 45s - loss: 0.3429 - acc: 0.8662 - val_loss: 0.3532 - val_acc: 0.8627
Epoch 18/50
 - 45s - loss: 0.3389 - acc: 0.8680 - val_loss: 0.3476 - val_acc: 0.8704
Epoch 19/50
 - 45s - loss: 0.3360 - acc: 0.8715 - val_loss: 0.4288 - val_acc: 0.8353
Epoch 20/50
 - 45s - loss: 0.3298 - acc: 0.8757 - val_loss: 0.3429 - val_acc: 0.8720
Epoch 21/50
 - 45s - loss: 0.3261 - acc: 0.8742 - val_loss: 0.3533 - val_acc: 0.8631
Epoch 22/50
 - 45s - loss: 0.3195 - acc: 0.8784 - val_loss: 0.3480 - val_acc: 0.8680
Epoch 23/50
 - 45s - loss: 0.3158 - acc: 0.8816 - val_loss: 0.3343 - val_acc: 0.8685
Epoch 24/50
 - 45s - loss: 0.3115 - acc: 0.8826 - val_loss: 0.3413 - val_acc: 0.8714
Epoch 25/50
 - 45s - loss: 0.3103 - acc: 0.8812 - val_loss: 0.3357 - val_acc: 0.8638
Epoch 26/50
 - 45s - loss: 0.3022 - acc: 0.8865 - val_loss: 0.4635 - val_acc: 0.8028
Epoch 27/50
 - 45s - loss: 0.3026 - acc: 0.8859 - val_loss: 0.3283 - val_acc: 0.8794
Epoch 28/50
 - 45s - loss: 0.2964 - acc: 0.8902 - val_loss: 0.3114 - val_acc: 0.8810
Epoch 29/50
 - 45s - loss: 0.2921 - acc: 0.8913 - val_loss: 0.3325 - val_acc: 0.8753
Epoch 30/50
 - 45s - loss: 0.2903 - acc: 0.8923 - val_loss: 0.3126 - val_acc: 0.8809
Epoch 31/50
 - 45s - loss: 0.2884 - acc: 0.8948 - val_loss: 0.7731 - val_acc: 0.7743
Epoch 32/50
 - 45s - loss: 0.2833 - acc: 0.8967 - val_loss: 0.3232 - val_acc: 0.8843

Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 33/50
 - 45s - loss: 0.2644 - acc: 0.9080 - val_loss: 0.2917 - val_acc: 0.8898
Epoch 34/50
 - 45s - loss: 0.2601 - acc: 0.9082 - val_loss: 0.2840 - val_acc: 0.8940
Epoch 35/50
 - 45s - loss: 0.2603 - acc: 0.9079 - val_loss: 0.3054 - val_acc: 0.8796
Epoch 36/50
 - 45s - loss: 0.2572 - acc: 0.9105 - val_loss: 0.3100 - val_acc: 0.8783
Epoch 37/50
 - 45s - loss: 0.2568 - acc: 0.9092 - val_loss: 0.2996 - val_acc: 0.8876
Epoch 38/50
 - 45s - loss: 0.2532 - acc: 0.9100 - val_loss: 0.2761 - val_acc: 0.8993
Epoch 39/50
 - 45s - loss: 0.2531 - acc: 0.9100 - val_loss: 0.2845 - val_acc: 0.8967
Epoch 40/50
 - 45s - loss: 0.2501 - acc: 0.9138 - val_loss: 0.3227 - val_acc: 0.8837
Epoch 41/50
 - 45s - loss: 0.2489 - acc: 0.9125 - val_loss: 0.2969 - val_acc: 0.8864
Epoch 42/50
 - 45s - loss: 0.2508 - acc: 0.9128 - val_loss: 0.2853 - val_acc: 0.8923

Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 43/50
 - 45s - loss: 0.2429 - acc: 0.9164 - val_loss: 0.2729 - val_acc: 0.8991
Epoch 44/50
 - 45s - loss: 0.2405 - acc: 0.9161 - val_loss: 0.2721 - val_acc: 0.9001
Epoch 45/50
 - 45s - loss: 0.2391 - acc: 0.9198 - val_loss: 0.2701 - val_acc: 0.9012
Epoch 46/50
 - 45s - loss: 0.2398 - acc: 0.9189 - val_loss: 0.2714 - val_acc: 0.9006
Epoch 47/50
 - 45s - loss: 0.2375 - acc: 0.9199 - val_loss: 0.2761 - val_acc: 0.9005
Epoch 48/50
 - 45s - loss: 0.2394 - acc: 0.9180 - val_loss: 0.2678 - val_acc: 0.9041
Epoch 49/50
 - 45s - loss: 0.2360 - acc: 0.9194 - val_loss: 0.2704 - val_acc: 0.9000
Epoch 50/50
 - 45s - loss: 0.2404 - acc: 0.9173 - val_loss: 0.2804 - val_acc: 0.9002

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 928/7440 [==>...........................] - ETA: 3s
1056/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1312/7440 [====>.........................] - ETA: 3s
1440/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3232/7440 [============>.................] - ETA: 2s
3360/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 513us/step
current Test accuracy: 0.8189516129032258
current auc_score ------------------>  0.9028006850502949
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_39 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_39[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_780 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 40, 96, 96)   640         activation_780[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_781 (Activation)     (None, 40, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_781[0][0]             
__________________________________________________________________________________________________
concatenate_330 (Concatenate)   (None, 26, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 96, 96)   104         concatenate_330[0][0]            
__________________________________________________________________________________________________
activation_782 (Activation)     (None, 26, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 40, 96, 96)   1040        activation_782[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_783 (Activation)     (None, 40, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_783[0][0]             
__________________________________________________________________________________________________
concatenate_331 (Concatenate)   (None, 36, 96, 96)   0           concatenate_330[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 36, 96, 96)   144         concatenate_331[0][0]            
__________________________________________________________________________________________________
activation_784 (Activation)     (None, 36, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 40, 96, 96)   1440        activation_784[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 40, 96, 96)   160         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_785 (Activation)     (None, 40, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 10, 96, 96)   3600        activation_785[0][0]             
__________________________________________________________________________________________________
concatenate_332 (Concatenate)   (None, 46, 96, 96)   0           concatenate_331[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_332[0][0]            
__________________________________________________________________________________________________
activation_786 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_786[0][0]             
__________________________________________________________________________________________________
average_pooling2d_84 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_84[0][0]       
__________________________________________________________________________________________________
activation_787 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 40, 48, 48)   920         activation_787[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_788 (Activation)     (None, 40, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_788[0][0]             
__________________________________________________________________________________________________
concatenate_333 (Concatenate)   (None, 33, 48, 48)   0           average_pooling2d_84[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 33, 48, 48)   132         concatenate_333[0][0]            
__________________________________________________________________________________________________
activation_789 (Activation)     (None, 33, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 40, 48, 48)   1320        activation_789[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_790 (Activation)     (None, 40, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_790[0][0]             
__________________________________________________________________________________________________
concatenate_334 (Concatenate)   (None, 43, 48, 48)   0           concatenate_333[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 43, 48, 48)   172         concatenate_334[0][0]            
__________________________________________________________________________________________________
activation_791 (Activation)     (None, 43, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 40, 48, 48)   1720        activation_791[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 40, 48, 48)   160         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_792 (Activation)     (None, 40, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 10, 48, 48)   3600        activation_792[0][0]             
__________________________________________________________________________________________________
concatenate_335 (Concatenate)   (None, 53, 48, 48)   0           concatenate_334[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_335[0][0]            
__________________________________________________________________________________________________
activation_793 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_793[0][0]             
__________________________________________________________________________________________________
average_pooling2d_85 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_85[0][0]       
__________________________________________________________________________________________________
activation_794 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 40, 24, 24)   1040        activation_794[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_795 (Activation)     (None, 40, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_795[0][0]             
__________________________________________________________________________________________________
concatenate_336 (Concatenate)   (None, 36, 24, 24)   0           average_pooling2d_85[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 36, 24, 24)   144         concatenate_336[0][0]            
__________________________________________________________________________________________________
activation_796 (Activation)     (None, 36, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 40, 24, 24)   1440        activation_796[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_797 (Activation)     (None, 40, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_797[0][0]             
__________________________________________________________________________________________________
concatenate_337 (Concatenate)   (None, 46, 24, 24)   0           concatenate_336[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_337[0][0]            
__________________________________________________________________________________________________
activation_798 (Activation)     (None, 46, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 40, 24, 24)   1840        activation_798[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 40, 24, 24)   160         dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_799 (Activation)     (None, 40, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 10, 24, 24)   3600        activation_799[0][0]             
__________________________________________________________________________________________________
concatenate_338 (Concatenate)   (None, 56, 24, 24)   0           concatenate_337[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_2_bn (BatchNormalization)    (None, 56, 24, 24)   224         concatenate_338[0][0]            
__________________________________________________________________________________________________
activation_800 (Activation)     (None, 56, 24, 24)   0           tr_2_bn[0][0]                    
__________________________________________________________________________________________________
tr_2_conv2D (Conv2D)            (None, 28, 24, 24)   1568        activation_800[0][0]             
__________________________________________________________________________________________________
average_pooling2d_86 (AveragePo (None, 28, 12, 12)   0           tr_2_conv2D[0][0]                
__________________________________________________________________________________________________
dense_3_0_bn (BatchNormalizatio (None, 28, 12, 12)   112         average_pooling2d_86[0][0]       
__________________________________________________________________________________________________
activation_801 (Activation)     (None, 28, 12, 12)   0           dense_3_0_bn[0][0]               
__________________________________________________________________________________________________
dense_3_0_bottleneck_conv2D (Co (None, 40, 12, 12)   1120        activation_801[0][0]             
__________________________________________________________________________________________________
dense_3_0_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_802 (Activation)     (None, 40, 12, 12)   0           dense_3_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_0_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_802[0][0]             
__________________________________________________________________________________________________
concatenate_339 (Concatenate)   (None, 38, 12, 12)   0           average_pooling2d_86[0][0]       
                                                                 dense_3_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_1_bn (BatchNormalizatio (None, 38, 12, 12)   152         concatenate_339[0][0]            
__________________________________________________________________________________________________
activation_803 (Activation)     (None, 38, 12, 12)   0           dense_3_1_bn[0][0]               
__________________________________________________________________________________________________
dense_3_1_bottleneck_conv2D (Co (None, 40, 12, 12)   1520        activation_803[0][0]             
__________________________________________________________________________________________________
dense_3_1_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_804 (Activation)     (None, 40, 12, 12)   0           dense_3_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_1_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_804[0][0]             
__________________________________________________________________________________________________
concatenate_340 (Concatenate)   (None, 48, 12, 12)   0           concatenate_339[0][0]            
                                                                 dense_3_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_3_2_bn (BatchNormalizatio (None, 48, 12, 12)   192         concatenate_340[0][0]            
__________________________________________________________________________________________________
activation_805 (Activation)     (None, 48, 12, 12)   0           dense_3_2_bn[0][0]               
__________________________________________________________________________________________________
dense_3_2_bottleneck_conv2D (Co (None, 40, 12, 12)   1920        activation_805[0][0]             
__________________________________________________________________________________________________
dense_3_2_bottleneck_bn (BatchN (None, 40, 12, 12)   160         dense_3_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_806 (Activation)     (None, 40, 12, 12)   0           dense_3_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_3_2_conv2D (Conv2D)       (None, 10, 12, 12)   3600        activation_806[0][0]             
__________________________________________________________________________________________________
concatenate_341 (Concatenate)   (None, 58, 12, 12)   0           concatenate_340[0][0]            
                                                                 dense_3_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_341[0][0]            
__________________________________________________________________________________________________
activation_807 (Activation)     (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_39 (Gl (None, 58)           0           activation_807[0][0]             
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 1)            59          global_average_pooling2d_39[0][0]
==================================================================================================
Total params: 67,879
Trainable params: 65,695
Non-trainable params: 2,184
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 75s - loss: 0.5665 - acc: 0.7761 - val_loss: 0.5054 - val_acc: 0.8048
Epoch 2/50
 - 45s - loss: 0.4669 - acc: 0.8316 - val_loss: 0.4592 - val_acc: 0.8476
Epoch 3/50
 - 45s - loss: 0.4085 - acc: 0.8663 - val_loss: 0.3980 - val_acc: 0.8761
Epoch 4/50
 - 45s - loss: 0.3685 - acc: 0.8841 - val_loss: 0.3651 - val_acc: 0.8946
Epoch 5/50
 - 45s - loss: 0.3364 - acc: 0.9002 - val_loss: 0.3497 - val_acc: 0.8934
Epoch 6/50
 - 45s - loss: 0.3106 - acc: 0.9127 - val_loss: 0.3257 - val_acc: 0.9025
Epoch 7/50
 - 45s - loss: 0.2906 - acc: 0.9211 - val_loss: 0.3257 - val_acc: 0.9051
Epoch 8/50
 - 45s - loss: 0.2754 - acc: 0.9273 - val_loss: 0.3282 - val_acc: 0.8982
Epoch 9/50
 - 45s - loss: 0.2586 - acc: 0.9349 - val_loss: 0.3116 - val_acc: 0.9108
Epoch 10/50
 - 45s - loss: 0.2513 - acc: 0.9361 - val_loss: 0.2606 - val_acc: 0.9321
Epoch 11/50
 - 46s - loss: 0.2372 - acc: 0.9431 - val_loss: 0.2761 - val_acc: 0.9214
Epoch 12/50
 - 45s - loss: 0.2269 - acc: 0.9474 - val_loss: 0.2807 - val_acc: 0.9227
Epoch 13/50
 - 45s - loss: 0.2165 - acc: 0.9514 - val_loss: 0.4833 - val_acc: 0.8601
Epoch 14/50
 - 45s - loss: 0.2102 - acc: 0.9527 - val_loss: 0.2626 - val_acc: 0.9349

Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 15/50
 - 46s - loss: 0.1788 - acc: 0.9679 - val_loss: 0.2205 - val_acc: 0.9497
Epoch 16/50
 - 46s - loss: 0.1734 - acc: 0.9706 - val_loss: 0.2242 - val_acc: 0.9450
Epoch 17/50
 - 46s - loss: 0.1663 - acc: 0.9732 - val_loss: 0.2369 - val_acc: 0.9430
Epoch 18/50
 - 46s - loss: 0.1671 - acc: 0.9724 - val_loss: 0.2123 - val_acc: 0.9517
Epoch 19/50
 - 46s - loss: 0.1615 - acc: 0.9729 - val_loss: 0.2141 - val_acc: 0.9479
Epoch 20/50
 - 46s - loss: 0.1564 - acc: 0.9759 - val_loss: 0.2176 - val_acc: 0.9495
Epoch 21/50
 - 46s - loss: 0.1553 - acc: 0.9766 - val_loss: 0.2239 - val_acc: 0.9467
Epoch 22/50
 - 46s - loss: 0.1525 - acc: 0.9783 - val_loss: 0.2098 - val_acc: 0.9522
Epoch 23/50
 - 45s - loss: 0.1504 - acc: 0.9780 - val_loss: 0.2179 - val_acc: 0.9487
Epoch 24/50
 - 46s - loss: 0.1438 - acc: 0.9810 - val_loss: 0.2078 - val_acc: 0.9533
Epoch 25/50
 - 45s - loss: 0.1428 - acc: 0.9809 - val_loss: 0.2148 - val_acc: 0.9511
Epoch 26/50
 - 45s - loss: 0.1426 - acc: 0.9806 - val_loss: 0.2113 - val_acc: 0.9536
Epoch 27/50
 - 45s - loss: 0.1395 - acc: 0.9818 - val_loss: 0.2026 - val_acc: 0.9544
Epoch 28/50
 - 45s - loss: 0.1382 - acc: 0.9825 - val_loss: 0.2101 - val_acc: 0.9547
Epoch 29/50
 - 45s - loss: 0.1326 - acc: 0.9844 - val_loss: 0.2047 - val_acc: 0.9547
Epoch 30/50
 - 45s - loss: 0.1376 - acc: 0.9822 - val_loss: 0.2144 - val_acc: 0.9489
Epoch 31/50
 - 46s - loss: 0.1300 - acc: 0.9862 - val_loss: 0.2072 - val_acc: 0.9527

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 32/50
 - 45s - loss: 0.1231 - acc: 0.9888 - val_loss: 0.1979 - val_acc: 0.9567
Epoch 33/50
 - 45s - loss: 0.1207 - acc: 0.9891 - val_loss: 0.1980 - val_acc: 0.9571
Epoch 34/50
 - 46s - loss: 0.1213 - acc: 0.9897 - val_loss: 0.2012 - val_acc: 0.9572
Epoch 35/50
 - 46s - loss: 0.1199 - acc: 0.9897 - val_loss: 0.2010 - val_acc: 0.9561
Epoch 36/50
 - 45s - loss: 0.1195 - acc: 0.9894 - val_loss: 0.2040 - val_acc: 0.9566

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 37/50
 - 46s - loss: 0.1173 - acc: 0.9912 - val_loss: 0.1989 - val_acc: 0.9575
Epoch 38/50
 - 46s - loss: 0.1172 - acc: 0.9906 - val_loss: 0.1989 - val_acc: 0.9571
Epoch 39/50
 - 46s - loss: 0.1160 - acc: 0.9914 - val_loss: 0.1995 - val_acc: 0.9561
Epoch 00039: early stopping

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 3s
 672/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 928/7440 [==>...........................] - ETA: 3s
1056/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1312/7440 [====>.........................] - ETA: 3s
1440/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 2s
2976/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3232/7440 [============>.................] - ETA: 2s
3360/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 1s
5280/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 0s
5632/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
6016/7440 [=======================>......] - ETA: 0s
6144/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6528/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6784/7440 [==========================>...] - ETA: 0s
6912/7440 [==========================>...] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7168/7440 [===========================>..] - ETA: 0s
7296/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 503us/step
current Test accuracy: 0.7758064516129032
current auc_score ------------------>  0.889186647300266
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_40 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_40[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_808 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_808[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_809 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_809[0][0]             
__________________________________________________________________________________________________
concatenate_342 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_342[0][0]            
__________________________________________________________________________________________________
activation_810 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_810[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_811 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_811[0][0]             
__________________________________________________________________________________________________
concatenate_343 (Concatenate)   (None, 28, 96, 96)   0           concatenate_342[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_343[0][0]            
__________________________________________________________________________________________________
activation_812 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_812[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_813 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_813[0][0]             
__________________________________________________________________________________________________
concatenate_344 (Concatenate)   (None, 34, 96, 96)   0           concatenate_343[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 34, 96, 96)   136         concatenate_344[0][0]            
__________________________________________________________________________________________________
activation_814 (Activation)     (None, 34, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 24, 96, 96)   816         activation_814[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_815 (Activation)     (None, 24, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_815[0][0]             
__________________________________________________________________________________________________
concatenate_345 (Concatenate)   (None, 40, 96, 96)   0           concatenate_344[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 40, 96, 96)   160         concatenate_345[0][0]            
__________________________________________________________________________________________________
activation_816 (Activation)     (None, 40, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 24, 96, 96)   960         activation_816[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_817 (Activation)     (None, 24, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_817[0][0]             
__________________________________________________________________________________________________
concatenate_346 (Concatenate)   (None, 46, 96, 96)   0           concatenate_345[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 46, 96, 96)   184         concatenate_346[0][0]            
__________________________________________________________________________________________________
activation_818 (Activation)     (None, 46, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 23, 96, 96)   1058        activation_818[0][0]             
__________________________________________________________________________________________________
average_pooling2d_87 (AveragePo (None, 23, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 23, 48, 48)   92          average_pooling2d_87[0][0]       
__________________________________________________________________________________________________
activation_819 (Activation)     (None, 23, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_819[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_820 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_820[0][0]             
__________________________________________________________________________________________________
concatenate_347 (Concatenate)   (None, 29, 48, 48)   0           average_pooling2d_87[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_347[0][0]            
__________________________________________________________________________________________________
activation_821 (Activation)     (None, 29, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_821[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_822 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_822[0][0]             
__________________________________________________________________________________________________
concatenate_348 (Concatenate)   (None, 35, 48, 48)   0           concatenate_347[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 35, 48, 48)   140         concatenate_348[0][0]            
__________________________________________________________________________________________________
activation_823 (Activation)     (None, 35, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   840         activation_823[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_824 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_824[0][0]             
__________________________________________________________________________________________________
concatenate_349 (Concatenate)   (None, 41, 48, 48)   0           concatenate_348[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 41, 48, 48)   164         concatenate_349[0][0]            
__________________________________________________________________________________________________
activation_825 (Activation)     (None, 41, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 24, 48, 48)   984         activation_825[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_826 (Activation)     (None, 24, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_826[0][0]             
__________________________________________________________________________________________________
concatenate_350 (Concatenate)   (None, 47, 48, 48)   0           concatenate_349[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 47, 48, 48)   188         concatenate_350[0][0]            
__________________________________________________________________________________________________
activation_827 (Activation)     (None, 47, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 24, 48, 48)   1128        activation_827[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_828 (Activation)     (None, 24, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_828[0][0]             
__________________________________________________________________________________________________
concatenate_351 (Concatenate)   (None, 53, 48, 48)   0           concatenate_350[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 53, 48, 48)   212         concatenate_351[0][0]            
__________________________________________________________________________________________________
activation_829 (Activation)     (None, 53, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 26, 48, 48)   1378        activation_829[0][0]             
__________________________________________________________________________________________________
average_pooling2d_88 (AveragePo (None, 26, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 26, 24, 24)   104         average_pooling2d_88[0][0]       
__________________________________________________________________________________________________
activation_830 (Activation)     (None, 26, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   624         activation_830[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_831 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_831[0][0]             
__________________________________________________________________________________________________
concatenate_352 (Concatenate)   (None, 32, 24, 24)   0           average_pooling2d_88[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 32, 24, 24)   128         concatenate_352[0][0]            
__________________________________________________________________________________________________
activation_832 (Activation)     (None, 32, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   768         activation_832[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_833 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_833[0][0]             
__________________________________________________________________________________________________
concatenate_353 (Concatenate)   (None, 38, 24, 24)   0           concatenate_352[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_353[0][0]            
__________________________________________________________________________________________________
activation_834 (Activation)     (None, 38, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   912         activation_834[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_835 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_835[0][0]             
__________________________________________________________________________________________________
concatenate_354 (Concatenate)   (None, 44, 24, 24)   0           concatenate_353[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_3_bn (BatchNormalizatio (None, 44, 24, 24)   176         concatenate_354[0][0]            
__________________________________________________________________________________________________
activation_836 (Activation)     (None, 44, 24, 24)   0           dense_2_3_bn[0][0]               
__________________________________________________________________________________________________
dense_2_3_bottleneck_conv2D (Co (None, 24, 24, 24)   1056        activation_836[0][0]             
__________________________________________________________________________________________________
dense_2_3_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_837 (Activation)     (None, 24, 24, 24)   0           dense_2_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_3_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_837[0][0]             
__________________________________________________________________________________________________
concatenate_355 (Concatenate)   (None, 50, 24, 24)   0           concatenate_354[0][0]            
                                                                 dense_2_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_4_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_355[0][0]            
__________________________________________________________________________________________________
activation_838 (Activation)     (None, 50, 24, 24)   0           dense_2_4_bn[0][0]               
__________________________________________________________________________________________________
dense_2_4_bottleneck_conv2D (Co (None, 24, 24, 24)   1200        activation_838[0][0]             
__________________________________________________________________________________________________
dense_2_4_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_839 (Activation)     (None, 24, 24, 24)   0           dense_2_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_4_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_839[0][0]             
__________________________________________________________________________________________________
concatenate_356 (Concatenate)   (None, 56, 24, 24)   0           concatenate_355[0][0]            
                                                                 dense_2_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 56, 24, 24)   224         concatenate_356[0][0]            
__________________________________________________________________________________________________
activation_840 (Activation)     (None, 56, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_40 (Gl (None, 56)           0           activation_840[0][0]             
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 1)            57          global_average_pooling2d_40[0][0]
==================================================================================================
Total params: 38,421
Trainable params: 36,381
Non-trainable params: 2,040
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 84s - loss: 0.5892 - acc: 0.7486 - val_loss: 0.5184 - val_acc: 0.7843
Epoch 2/50
 - 53s - loss: 0.4947 - acc: 0.7973 - val_loss: 0.4788 - val_acc: 0.8071
Epoch 3/50
 - 53s - loss: 0.4527 - acc: 0.8217 - val_loss: 0.4261 - val_acc: 0.8326
Epoch 4/50
 - 53s - loss: 0.4255 - acc: 0.8344 - val_loss: 0.4467 - val_acc: 0.8217
Epoch 5/50
 - 53s - loss: 0.4004 - acc: 0.8513 - val_loss: 0.4135 - val_acc: 0.8439
Epoch 6/50
 - 53s - loss: 0.3855 - acc: 0.8602 - val_loss: 0.4491 - val_acc: 0.8351
Epoch 7/50
 - 53s - loss: 0.3645 - acc: 0.8703 - val_loss: 0.5245 - val_acc: 0.8284
Epoch 8/50
 - 52s - loss: 0.3534 - acc: 0.8750 - val_loss: 0.3400 - val_acc: 0.8834
Epoch 9/50
 - 53s - loss: 0.3407 - acc: 0.8826 - val_loss: 0.3434 - val_acc: 0.8755
Epoch 10/50
 - 53s - loss: 0.3279 - acc: 0.8902 - val_loss: 0.3403 - val_acc: 0.8839
Epoch 11/50
 - 53s - loss: 0.3152 - acc: 0.8934 - val_loss: 0.3337 - val_acc: 0.8918
Epoch 12/50
 - 53s - loss: 0.3073 - acc: 0.8996 - val_loss: 0.3921 - val_acc: 0.8706
Epoch 13/50
 - 52s - loss: 0.2964 - acc: 0.9033 - val_loss: 0.3174 - val_acc: 0.8941
Epoch 14/50
 - 52s - loss: 0.2877 - acc: 0.9062 - val_loss: 0.3131 - val_acc: 0.8916
Epoch 15/50
 - 52s - loss: 0.2814 - acc: 0.9088 - val_loss: 0.3074 - val_acc: 0.8980
Epoch 16/50
 - 52s - loss: 0.2711 - acc: 0.9132 - val_loss: 0.2937 - val_acc: 0.9035
Epoch 17/50
 - 52s - loss: 0.2635 - acc: 0.9193 - val_loss: 0.3038 - val_acc: 0.9025
Epoch 18/50
 - 52s - loss: 0.2596 - acc: 0.9212 - val_loss: 0.3515 - val_acc: 0.8691
Epoch 19/50
 - 52s - loss: 0.2527 - acc: 0.9215 - val_loss: 0.3132 - val_acc: 0.8987
Epoch 20/50
 - 52s - loss: 0.2446 - acc: 0.9264 - val_loss: 0.3715 - val_acc: 0.8827

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 21/50
 - 53s - loss: 0.2218 - acc: 0.9393 - val_loss: 0.2546 - val_acc: 0.9208
Epoch 22/50
 - 52s - loss: 0.2140 - acc: 0.9417 - val_loss: 0.2627 - val_acc: 0.9219
Epoch 23/50
 - 53s - loss: 0.2108 - acc: 0.9441 - val_loss: 0.2558 - val_acc: 0.9203
Epoch 24/50
 - 52s - loss: 0.2097 - acc: 0.9442 - val_loss: 0.2540 - val_acc: 0.9217
Epoch 25/50
 - 52s - loss: 0.2070 - acc: 0.9464 - val_loss: 0.2617 - val_acc: 0.9177
Epoch 26/50
 - 52s - loss: 0.2011 - acc: 0.9474 - val_loss: 0.2541 - val_acc: 0.9236
Epoch 27/50
 - 52s - loss: 0.1993 - acc: 0.9471 - val_loss: 0.2462 - val_acc: 0.9265
Epoch 28/50
 - 52s - loss: 0.1999 - acc: 0.9465 - val_loss: 0.2659 - val_acc: 0.9170
Epoch 29/50
 - 52s - loss: 0.1944 - acc: 0.9493 - val_loss: 0.2516 - val_acc: 0.9217
Epoch 30/50
 - 52s - loss: 0.1932 - acc: 0.9498 - val_loss: 0.2523 - val_acc: 0.9246
Epoch 31/50
 - 52s - loss: 0.1921 - acc: 0.9506 - val_loss: 0.2703 - val_acc: 0.9202

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 32/50
 - 52s - loss: 0.1827 - acc: 0.9544 - val_loss: 0.2388 - val_acc: 0.9297
Epoch 33/50
 - 52s - loss: 0.1823 - acc: 0.9555 - val_loss: 0.2391 - val_acc: 0.9297
Epoch 34/50
 - 53s - loss: 0.1806 - acc: 0.9557 - val_loss: 0.2400 - val_acc: 0.9292
Epoch 35/50
 - 52s - loss: 0.1796 - acc: 0.9565 - val_loss: 0.2391 - val_acc: 0.9298
Epoch 36/50
 - 52s - loss: 0.1783 - acc: 0.9571 - val_loss: 0.2389 - val_acc: 0.9302

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 37/50
 - 52s - loss: 0.1757 - acc: 0.9583 - val_loss: 0.2370 - val_acc: 0.9325
Epoch 38/50
 - 52s - loss: 0.1747 - acc: 0.9587 - val_loss: 0.2370 - val_acc: 0.9307
Epoch 39/50
 - 53s - loss: 0.1750 - acc: 0.9583 - val_loss: 0.2366 - val_acc: 0.9314
Epoch 40/50
 - 53s - loss: 0.1752 - acc: 0.9576 - val_loss: 0.2368 - val_acc: 0.9308
Epoch 41/50
 - 52s - loss: 0.1756 - acc: 0.9587 - val_loss: 0.2364 - val_acc: 0.9319
Epoch 42/50
 - 53s - loss: 0.1750 - acc: 0.9576 - val_loss: 0.2367 - val_acc: 0.9305
Epoch 43/50
 - 53s - loss: 0.1732 - acc: 0.9582 - val_loss: 0.2367 - val_acc: 0.9308
Epoch 44/50
 - 53s - loss: 0.1751 - acc: 0.9581 - val_loss: 0.2366 - val_acc: 0.9302
Epoch 45/50
 - 52s - loss: 0.1751 - acc: 0.9576 - val_loss: 0.2367 - val_acc: 0.9302

Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 46/50
 - 53s - loss: 0.1730 - acc: 0.9593 - val_loss: 0.2373 - val_acc: 0.9311
Epoch 47/50
 - 53s - loss: 0.1712 - acc: 0.9601 - val_loss: 0.2365 - val_acc: 0.9320
Epoch 48/50
 - 53s - loss: 0.1715 - acc: 0.9593 - val_loss: 0.2360 - val_acc: 0.9314
Epoch 49/50
 - 53s - loss: 0.1720 - acc: 0.9606 - val_loss: 0.2360 - val_acc: 0.9303
Epoch 50/50
 - 53s - loss: 0.1716 - acc: 0.9606 - val_loss: 0.2367 - val_acc: 0.9306

  32/7440 [..............................] - ETA: 4s
 128/7440 [..............................] - ETA: 4s
 224/7440 [..............................] - ETA: 4s
 320/7440 [>.............................] - ETA: 4s
 416/7440 [>.............................] - ETA: 3s
 512/7440 [=>............................] - ETA: 3s
 608/7440 [=>............................] - ETA: 3s
 704/7440 [=>............................] - ETA: 3s
 800/7440 [==>...........................] - ETA: 3s
 896/7440 [==>...........................] - ETA: 3s
 992/7440 [===>..........................] - ETA: 3s
1088/7440 [===>..........................] - ETA: 3s
1184/7440 [===>..........................] - ETA: 3s
1280/7440 [====>.........................] - ETA: 3s
1376/7440 [====>.........................] - ETA: 3s
1472/7440 [====>.........................] - ETA: 3s
1568/7440 [=====>........................] - ETA: 3s
1664/7440 [=====>........................] - ETA: 3s
1760/7440 [======>.......................] - ETA: 3s
1856/7440 [======>.......................] - ETA: 3s
1952/7440 [======>.......................] - ETA: 3s
2048/7440 [=======>......................] - ETA: 3s
2144/7440 [=======>......................] - ETA: 3s
2240/7440 [========>.....................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2432/7440 [========>.....................] - ETA: 2s
2528/7440 [=========>....................] - ETA: 2s
2624/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2816/7440 [==========>...................] - ETA: 2s
2912/7440 [==========>...................] - ETA: 2s
3008/7440 [===========>..................] - ETA: 2s
3104/7440 [===========>..................] - ETA: 2s
3200/7440 [===========>..................] - ETA: 2s
3296/7440 [============>.................] - ETA: 2s
3392/7440 [============>.................] - ETA: 2s
3488/7440 [=============>................] - ETA: 2s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 1s
4160/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4352/7440 [================>.............] - ETA: 1s
4448/7440 [================>.............] - ETA: 1s
4544/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4736/7440 [==================>...........] - ETA: 1s
4832/7440 [==================>...........] - ETA: 1s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5888/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 4s 567us/step
current Test accuracy: 0.8141129032258064
current auc_score ------------------>  0.901358321771303
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_41 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_41[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_841 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 56, 96, 96)   896         activation_841[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_842 (Activation)     (None, 56, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_842[0][0]             
__________________________________________________________________________________________________
concatenate_357 (Concatenate)   (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_357[0][0]            
__________________________________________________________________________________________________
activation_843 (Activation)     (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 56, 96, 96)   1680        activation_843[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_844 (Activation)     (None, 56, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_844[0][0]             
__________________________________________________________________________________________________
concatenate_358 (Concatenate)   (None, 44, 96, 96)   0           concatenate_357[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 44, 96, 96)   176         concatenate_358[0][0]            
__________________________________________________________________________________________________
activation_845 (Activation)     (None, 44, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 56, 96, 96)   2464        activation_845[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_846 (Activation)     (None, 56, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_846[0][0]             
__________________________________________________________________________________________________
concatenate_359 (Concatenate)   (None, 58, 96, 96)   0           concatenate_358[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 58, 96, 96)   232         concatenate_359[0][0]            
__________________________________________________________________________________________________
activation_847 (Activation)     (None, 58, 96, 96)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_bottleneck_conv2D (Co (None, 56, 96, 96)   3248        activation_847[0][0]             
__________________________________________________________________________________________________
dense_0_3_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_848 (Activation)     (None, 56, 96, 96)   0           dense_0_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_848[0][0]             
__________________________________________________________________________________________________
concatenate_360 (Concatenate)   (None, 72, 96, 96)   0           concatenate_359[0][0]            
                                                                 dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 72, 96, 96)   288         concatenate_360[0][0]            
__________________________________________________________________________________________________
activation_849 (Activation)     (None, 72, 96, 96)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_bottleneck_conv2D (Co (None, 56, 96, 96)   4032        activation_849[0][0]             
__________________________________________________________________________________________________
dense_0_4_bottleneck_bn (BatchN (None, 56, 96, 96)   224         dense_0_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_850 (Activation)     (None, 56, 96, 96)   0           dense_0_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 14, 96, 96)   7056        activation_850[0][0]             
__________________________________________________________________________________________________
concatenate_361 (Concatenate)   (None, 86, 96, 96)   0           concatenate_360[0][0]            
                                                                 dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 86, 96, 96)   344         concatenate_361[0][0]            
__________________________________________________________________________________________________
activation_851 (Activation)     (None, 86, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 43, 96, 96)   3698        activation_851[0][0]             
__________________________________________________________________________________________________
average_pooling2d_89 (AveragePo (None, 43, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 43, 48, 48)   172         average_pooling2d_89[0][0]       
__________________________________________________________________________________________________
activation_852 (Activation)     (None, 43, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 56, 48, 48)   2408        activation_852[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_853 (Activation)     (None, 56, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_853[0][0]             
__________________________________________________________________________________________________
concatenate_362 (Concatenate)   (None, 57, 48, 48)   0           average_pooling2d_89[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 57, 48, 48)   228         concatenate_362[0][0]            
__________________________________________________________________________________________________
activation_854 (Activation)     (None, 57, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 56, 48, 48)   3192        activation_854[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_855 (Activation)     (None, 56, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_855[0][0]             
__________________________________________________________________________________________________
concatenate_363 (Concatenate)   (None, 71, 48, 48)   0           concatenate_362[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 71, 48, 48)   284         concatenate_363[0][0]            
__________________________________________________________________________________________________
activation_856 (Activation)     (None, 71, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 56, 48, 48)   3976        activation_856[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_857 (Activation)     (None, 56, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_857[0][0]             
__________________________________________________________________________________________________
concatenate_364 (Concatenate)   (None, 85, 48, 48)   0           concatenate_363[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 85, 48, 48)   340         concatenate_364[0][0]            
__________________________________________________________________________________________________
activation_858 (Activation)     (None, 85, 48, 48)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_bottleneck_conv2D (Co (None, 56, 48, 48)   4760        activation_858[0][0]             
__________________________________________________________________________________________________
dense_1_3_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_3_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_859 (Activation)     (None, 56, 48, 48)   0           dense_1_3_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_859[0][0]             
__________________________________________________________________________________________________
concatenate_365 (Concatenate)   (None, 99, 48, 48)   0           concatenate_364[0][0]            
                                                                 dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 99, 48, 48)   396         concatenate_365[0][0]            
__________________________________________________________________________________________________
activation_860 (Activation)     (None, 99, 48, 48)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_bottleneck_conv2D (Co (None, 56, 48, 48)   5544        activation_860[0][0]             
__________________________________________________________________________________________________
dense_1_4_bottleneck_bn (BatchN (None, 56, 48, 48)   224         dense_1_4_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_861 (Activation)     (None, 56, 48, 48)   0           dense_1_4_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 14, 48, 48)   7056        activation_861[0][0]             
__________________________________________________________________________________________________
concatenate_366 (Concatenate)   (None, 113, 48, 48)  0           concatenate_365[0][0]            
                                                                 dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 48, 48)  452         concatenate_366[0][0]            
__________________________________________________________________________________________________
activation_862 (Activation)     (None, 113, 48, 48)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_41 (Gl (None, 113)          0           activation_862[0][0]             
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 1)            114         global_average_pooling2d_41[0][0]
==================================================================================================
Total params: 112,196
Trainable params: 109,528
Non-trainable params: 2,668
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 101s - loss: 0.6021 - acc: 0.7638 - val_loss: 0.5832 - val_acc: 0.7735
Epoch 2/50
 - 70s - loss: 0.5167 - acc: 0.8042 - val_loss: 0.5051 - val_acc: 0.8076
Epoch 3/50
 - 70s - loss: 0.4786 - acc: 0.8231 - val_loss: 0.4854 - val_acc: 0.8268
Epoch 4/50
 - 70s - loss: 0.4475 - acc: 0.8377 - val_loss: 0.4558 - val_acc: 0.8385
Epoch 5/50
 - 70s - loss: 0.4263 - acc: 0.8502 - val_loss: 0.4255 - val_acc: 0.8574
Epoch 6/50
 - 70s - loss: 0.4052 - acc: 0.8603 - val_loss: 0.4232 - val_acc: 0.8484
Epoch 7/50
 - 70s - loss: 0.3868 - acc: 0.8689 - val_loss: 0.4039 - val_acc: 0.8583
Epoch 8/50
 - 70s - loss: 0.3729 - acc: 0.8745 - val_loss: 0.4458 - val_acc: 0.8376
Epoch 9/50
 - 70s - loss: 0.3564 - acc: 0.8819 - val_loss: 0.4645 - val_acc: 0.8351
Epoch 10/50
 - 70s - loss: 0.3456 - acc: 0.8861 - val_loss: 0.4996 - val_acc: 0.8155
Epoch 11/50
 - 70s - loss: 0.3322 - acc: 0.8934 - val_loss: 0.5685 - val_acc: 0.7971

Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 12/50
 - 70s - loss: 0.2974 - acc: 0.9114 - val_loss: 0.3112 - val_acc: 0.9114
Epoch 13/50
 - 70s - loss: 0.2890 - acc: 0.9163 - val_loss: 0.3170 - val_acc: 0.8973
Epoch 14/50
 - 70s - loss: 0.2821 - acc: 0.9199 - val_loss: 0.2903 - val_acc: 0.9140
Epoch 15/50
 - 70s - loss: 0.2778 - acc: 0.9207 - val_loss: 0.3002 - val_acc: 0.9085
Epoch 16/50
 - 70s - loss: 0.2729 - acc: 0.9243 - val_loss: 0.2824 - val_acc: 0.9167
Epoch 17/50
 - 70s - loss: 0.2662 - acc: 0.9265 - val_loss: 0.3036 - val_acc: 0.9089
Epoch 18/50
 - 70s - loss: 0.2642 - acc: 0.9276 - val_loss: 0.2838 - val_acc: 0.9178
Epoch 19/50
 - 70s - loss: 0.2616 - acc: 0.9277 - val_loss: 0.2972 - val_acc: 0.9114
Epoch 20/50
 - 70s - loss: 0.2514 - acc: 0.9337 - val_loss: 0.2760 - val_acc: 0.9247
Epoch 21/50
 - 70s - loss: 0.2497 - acc: 0.9327 - val_loss: 0.2809 - val_acc: 0.9163
Epoch 22/50
 - 70s - loss: 0.2454 - acc: 0.9357 - val_loss: 0.2745 - val_acc: 0.9194
Epoch 23/50
 - 70s - loss: 0.2384 - acc: 0.9388 - val_loss: 0.2821 - val_acc: 0.9134
Epoch 24/50
 - 70s - loss: 0.2368 - acc: 0.9386 - val_loss: 0.2956 - val_acc: 0.9068
Epoch 25/50
 - 70s - loss: 0.2316 - acc: 0.9411 - val_loss: 0.2752 - val_acc: 0.9251
Epoch 26/50
 - 70s - loss: 0.2277 - acc: 0.9433 - val_loss: 0.2643 - val_acc: 0.9248
Epoch 27/50
 - 70s - loss: 0.2242 - acc: 0.9434 - val_loss: 0.3480 - val_acc: 0.8759
Epoch 28/50
 - 70s - loss: 0.2218 - acc: 0.9444 - val_loss: 0.2769 - val_acc: 0.9202
Epoch 29/50
 - 70s - loss: 0.2199 - acc: 0.9454 - val_loss: 0.2626 - val_acc: 0.9267
Epoch 30/50
 - 70s - loss: 0.2135 - acc: 0.9490 - val_loss: 0.3377 - val_acc: 0.8962
Epoch 31/50
 - 70s - loss: 0.2121 - acc: 0.9493 - val_loss: 0.3676 - val_acc: 0.8850
Epoch 32/50
 - 70s - loss: 0.2060 - acc: 0.9516 - val_loss: 0.2632 - val_acc: 0.9232
Epoch 33/50
 - 70s - loss: 0.2052 - acc: 0.9526 - val_loss: 0.2636 - val_acc: 0.9241

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 34/50
 - 70s - loss: 0.1886 - acc: 0.9611 - val_loss: 0.2461 - val_acc: 0.9342
Epoch 35/50
 - 70s - loss: 0.1851 - acc: 0.9631 - val_loss: 0.2555 - val_acc: 0.9300
Epoch 36/50
 - 70s - loss: 0.1851 - acc: 0.9627 - val_loss: 0.2476 - val_acc: 0.9327
Epoch 37/50
 - 70s - loss: 0.1838 - acc: 0.9634 - val_loss: 0.2481 - val_acc: 0.9341
Epoch 38/50
 - 70s - loss: 0.1802 - acc: 0.9633 - val_loss: 0.2433 - val_acc: 0.9346
Epoch 39/50
 - 70s - loss: 0.1822 - acc: 0.9638 - val_loss: 0.2475 - val_acc: 0.9349
Epoch 40/50
 - 70s - loss: 0.1804 - acc: 0.9638 - val_loss: 0.2468 - val_acc: 0.9335
Epoch 41/50
 - 70s - loss: 0.1786 - acc: 0.9648 - val_loss: 0.2509 - val_acc: 0.9302
Epoch 42/50
 - 70s - loss: 0.1753 - acc: 0.9669 - val_loss: 0.2488 - val_acc: 0.9320

Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.324554585350098e-06.
Epoch 43/50
 - 70s - loss: 0.1724 - acc: 0.9675 - val_loss: 0.2454 - val_acc: 0.9342
Epoch 44/50
 - 70s - loss: 0.1726 - acc: 0.9686 - val_loss: 0.2411 - val_acc: 0.9374
Epoch 45/50
 - 70s - loss: 0.1716 - acc: 0.9687 - val_loss: 0.2404 - val_acc: 0.9349
Epoch 46/50
 - 70s - loss: 0.1700 - acc: 0.9694 - val_loss: 0.2411 - val_acc: 0.9359
Epoch 47/50
 - 70s - loss: 0.1701 - acc: 0.9699 - val_loss: 0.2410 - val_acc: 0.9380
Epoch 48/50
 - 70s - loss: 0.1701 - acc: 0.9682 - val_loss: 0.2424 - val_acc: 0.9366
Epoch 49/50
 - 70s - loss: 0.1699 - acc: 0.9688 - val_loss: 0.2406 - val_acc: 0.9365

Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.9999998230573134e-06.
Epoch 50/50
 - 70s - loss: 0.1660 - acc: 0.9709 - val_loss: 0.2409 - val_acc: 0.9369

  32/7440 [..............................] - ETA: 5s
 128/7440 [..............................] - ETA: 5s
 224/7440 [..............................] - ETA: 5s
 320/7440 [>.............................] - ETA: 5s
 416/7440 [>.............................] - ETA: 5s
 512/7440 [=>............................] - ETA: 5s
 608/7440 [=>............................] - ETA: 5s
 704/7440 [=>............................] - ETA: 5s
 800/7440 [==>...........................] - ETA: 5s
 896/7440 [==>...........................] - ETA: 5s
 992/7440 [===>..........................] - ETA: 4s
1088/7440 [===>..........................] - ETA: 4s
1184/7440 [===>..........................] - ETA: 4s
1280/7440 [====>.........................] - ETA: 4s
1376/7440 [====>.........................] - ETA: 4s
1472/7440 [====>.........................] - ETA: 4s
1568/7440 [=====>........................] - ETA: 4s
1664/7440 [=====>........................] - ETA: 4s
1760/7440 [======>.......................] - ETA: 4s
1856/7440 [======>.......................] - ETA: 4s
1952/7440 [======>.......................] - ETA: 4s
2048/7440 [=======>......................] - ETA: 4s
2144/7440 [=======>......................] - ETA: 4s
2240/7440 [========>.....................] - ETA: 3s
2336/7440 [========>.....................] - ETA: 3s
2432/7440 [========>.....................] - ETA: 3s
2528/7440 [=========>....................] - ETA: 3s
2624/7440 [=========>....................] - ETA: 3s
2720/7440 [=========>....................] - ETA: 3s
2816/7440 [==========>...................] - ETA: 3s
2912/7440 [==========>...................] - ETA: 3s
3008/7440 [===========>..................] - ETA: 3s
3104/7440 [===========>..................] - ETA: 3s
3200/7440 [===========>..................] - ETA: 3s
3296/7440 [============>.................] - ETA: 3s
3392/7440 [============>.................] - ETA: 3s
3488/7440 [=============>................] - ETA: 3s
3584/7440 [=============>................] - ETA: 2s
3680/7440 [=============>................] - ETA: 2s
3776/7440 [==============>...............] - ETA: 2s
3872/7440 [==============>...............] - ETA: 2s
3968/7440 [===============>..............] - ETA: 2s
4064/7440 [===============>..............] - ETA: 2s
4160/7440 [===============>..............] - ETA: 2s
4256/7440 [================>.............] - ETA: 2s
4352/7440 [================>.............] - ETA: 2s
4448/7440 [================>.............] - ETA: 2s
4544/7440 [=================>............] - ETA: 2s
4640/7440 [=================>............] - ETA: 2s
4736/7440 [==================>...........] - ETA: 2s
4832/7440 [==================>...........] - ETA: 2s
4928/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5120/7440 [===================>..........] - ETA: 1s
5216/7440 [====================>.........] - ETA: 1s
5312/7440 [====================>.........] - ETA: 1s
5408/7440 [====================>.........] - ETA: 1s
5504/7440 [=====================>........] - ETA: 1s
5600/7440 [=====================>........] - ETA: 1s
5696/7440 [=====================>........] - ETA: 1s
5792/7440 [======================>.......] - ETA: 1s
5888/7440 [======================>.......] - ETA: 1s
5984/7440 [=======================>......] - ETA: 1s
6080/7440 [=======================>......] - ETA: 1s
6176/7440 [=======================>......] - ETA: 0s
6272/7440 [========================>.....] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6464/7440 [=========================>....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6848/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7040/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7424/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 6s 768us/step
current Test accuracy: 0.8077956989247311
current auc_score ------------------>  0.8787755809920222
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_42 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 96, 96)   288         input_42[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 96, 96)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_863 (Activation)     (None, 16, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 24, 96, 96)   384         activation_863[0][0]             
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_864 (Activation)     (None, 24, 96, 96)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_864[0][0]             
__________________________________________________________________________________________________
concatenate_367 (Concatenate)   (None, 22, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 22, 96, 96)   88          concatenate_367[0][0]            
__________________________________________________________________________________________________
activation_865 (Activation)     (None, 22, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 24, 96, 96)   528         activation_865[0][0]             
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_866 (Activation)     (None, 24, 96, 96)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_866[0][0]             
__________________________________________________________________________________________________
concatenate_368 (Concatenate)   (None, 28, 96, 96)   0           concatenate_367[0][0]            
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 28, 96, 96)   112         concatenate_368[0][0]            
__________________________________________________________________________________________________
activation_867 (Activation)     (None, 28, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_bottleneck_conv2D (Co (None, 24, 96, 96)   672         activation_867[0][0]             
__________________________________________________________________________________________________
dense_0_2_bottleneck_bn (BatchN (None, 24, 96, 96)   96          dense_0_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_868 (Activation)     (None, 24, 96, 96)   0           dense_0_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 6, 96, 96)    1296        activation_868[0][0]             
__________________________________________________________________________________________________
concatenate_369 (Concatenate)   (None, 34, 96, 96)   0           concatenate_368[0][0]            
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 34, 96, 96)   136         concatenate_369[0][0]            
__________________________________________________________________________________________________
activation_869 (Activation)     (None, 34, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 17, 96, 96)   578         activation_869[0][0]             
__________________________________________________________________________________________________
average_pooling2d_90 (AveragePo (None, 17, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 17, 48, 48)   68          average_pooling2d_90[0][0]       
__________________________________________________________________________________________________
activation_870 (Activation)     (None, 17, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 24, 48, 48)   408         activation_870[0][0]             
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_871 (Activation)     (None, 24, 48, 48)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_871[0][0]             
__________________________________________________________________________________________________
concatenate_370 (Concatenate)   (None, 23, 48, 48)   0           average_pooling2d_90[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 23, 48, 48)   92          concatenate_370[0][0]            
__________________________________________________________________________________________________
activation_872 (Activation)     (None, 23, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 24, 48, 48)   552         activation_872[0][0]             
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_873 (Activation)     (None, 24, 48, 48)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_873[0][0]             
__________________________________________________________________________________________________
concatenate_371 (Concatenate)   (None, 29, 48, 48)   0           concatenate_370[0][0]            
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 29, 48, 48)   116         concatenate_371[0][0]            
__________________________________________________________________________________________________
activation_874 (Activation)     (None, 29, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_bottleneck_conv2D (Co (None, 24, 48, 48)   696         activation_874[0][0]             
__________________________________________________________________________________________________
dense_1_2_bottleneck_bn (BatchN (None, 24, 48, 48)   96          dense_1_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_875 (Activation)     (None, 24, 48, 48)   0           dense_1_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 6, 48, 48)    1296        activation_875[0][0]             
__________________________________________________________________________________________________
concatenate_372 (Concatenate)   (None, 35, 48, 48)   0           concatenate_371[0][0]            
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 35, 48, 48)   140         concatenate_372[0][0]            
__________________________________________________________________________________________________
activation_876 (Activation)     (None, 35, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 17, 48, 48)   595         activation_876[0][0]             
__________________________________________________________________________________________________
average_pooling2d_91 (AveragePo (None, 17, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 17, 24, 24)   68          average_pooling2d_91[0][0]       
__________________________________________________________________________________________________
activation_877 (Activation)     (None, 17, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_bottleneck_conv2D (Co (None, 24, 24, 24)   408         activation_877[0][0]             
__________________________________________________________________________________________________
dense_2_0_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_878 (Activation)     (None, 24, 24, 24)   0           dense_2_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_878[0][0]             
__________________________________________________________________________________________________
concatenate_373 (Concatenate)   (None, 23, 24, 24)   0           average_pooling2d_91[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 23, 24, 24)   92          concatenate_373[0][0]            
__________________________________________________________________________________________________
activation_879 (Activation)     (None, 23, 24, 24)   0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_bottleneck_conv2D (Co (None, 24, 24, 24)   552         activation_879[0][0]             
__________________________________________________________________________________________________
dense_2_1_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_880 (Activation)     (None, 24, 24, 24)   0           dense_2_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_880[0][0]             
__________________________________________________________________________________________________
concatenate_374 (Concatenate)   (None, 29, 24, 24)   0           concatenate_373[0][0]            
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 29, 24, 24)   116         concatenate_374[0][0]            
__________________________________________________________________________________________________
activation_881 (Activation)     (None, 29, 24, 24)   0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_bottleneck_conv2D (Co (None, 24, 24, 24)   696         activation_881[0][0]             
__________________________________________________________________________________________________
dense_2_2_bottleneck_bn (BatchN (None, 24, 24, 24)   96          dense_2_2_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_882 (Activation)     (None, 24, 24, 24)   0           dense_2_2_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 6, 24, 24)    1296        activation_882[0][0]             
__________________________________________________________________________________________________
concatenate_375 (Concatenate)   (None, 35, 24, 24)   0           concatenate_374[0][0]            
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 35, 24, 24)   140         concatenate_375[0][0]            
__________________________________________________________________________________________________
activation_883 (Activation)     (None, 35, 24, 24)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_42 (Gl (None, 35)           0           activation_883[0][0]             
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 1)            36          global_average_pooling2d_42[0][0]
==================================================================================================
Total params: 20,153
Trainable params: 19,105
Non-trainable params: 1,048
__________________________________________________________________________________________________
Train on 31872 samples, validate on 7968 samples
Epoch 1/50
 - 68s - loss: 0.5721 - acc: 0.7479 - val_loss: 0.5159 - val_acc: 0.7755
Epoch 2/50
 - 36s - loss: 0.4963 - acc: 0.7876 - val_loss: 0.5033 - val_acc: 0.7869
Epoch 3/50
 - 36s - loss: 0.4629 - acc: 0.8031 - val_loss: 0.4887 - val_acc: 0.7789
Epoch 4/50
 - 36s - loss: 0.4395 - acc: 0.8168 - val_loss: 0.4478 - val_acc: 0.8129
Epoch 5/50
 - 36s - loss: 0.4234 - acc: 0.8234 - val_loss: 0.4361 - val_acc: 0.8178
Epoch 6/50
 - 35s - loss: 0.4076 - acc: 0.8341 - val_loss: 0.4255 - val_acc: 0.8242
Epoch 7/50
 - 36s - loss: 0.3963 - acc: 0.8376 - val_loss: 0.3935 - val_acc: 0.8406
Epoch 8/50
 - 36s - loss: 0.3855 - acc: 0.8436 - val_loss: 0.3873 - val_acc: 0.8498
Epoch 9/50
 - 36s - loss: 0.3732 - acc: 0.8508 - val_loss: 0.4430 - val_acc: 0.8156
Epoch 10/50
 - 36s - loss: 0.3645 - acc: 0.8585 - val_loss: 0.4152 - val_acc: 0.8317
Epoch 11/50
 - 36s - loss: 0.3532 - acc: 0.8624 - val_loss: 0.4108 - val_acc: 0.8312
Epoch 12/50
 - 36s - loss: 0.3461 - acc: 0.8661 - val_loss: 0.3446 - val_acc: 0.8668
Epoch 13/50
 - 35s - loss: 0.3406 - acc: 0.8702 - val_loss: 0.3293 - val_acc: 0.8770
Epoch 14/50
 - 35s - loss: 0.3324 - acc: 0.8764 - val_loss: 0.3489 - val_acc: 0.8663
Epoch 15/50
 - 35s - loss: 0.3244 - acc: 0.8798 - val_loss: 0.3686 - val_acc: 0.8574
Epoch 16/50
 - 35s - loss: 0.3179 - acc: 0.8807 - val_loss: 0.3297 - val_acc: 0.8768
Epoch 17/50
 - 35s - loss: 0.3118 - acc: 0.8845 - val_loss: 0.3392 - val_acc: 0.8760

Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.
Epoch 18/50
 - 36s - loss: 0.2930 - acc: 0.8953 - val_loss: 0.3067 - val_acc: 0.8902
Epoch 19/50
 - 36s - loss: 0.2914 - acc: 0.8963 - val_loss: 0.3082 - val_acc: 0.8854
Epoch 20/50
 - 36s - loss: 0.2907 - acc: 0.8953 - val_loss: 0.3003 - val_acc: 0.8948
Epoch 21/50
 - 36s - loss: 0.2844 - acc: 0.8997 - val_loss: 0.3335 - val_acc: 0.8731
Epoch 22/50
 - 36s - loss: 0.2843 - acc: 0.9001 - val_loss: 0.3024 - val_acc: 0.8923
Epoch 23/50
 - 36s - loss: 0.2807 - acc: 0.9000 - val_loss: 0.2930 - val_acc: 0.8945
Epoch 24/50
 - 36s - loss: 0.2773 - acc: 0.9035 - val_loss: 0.2911 - val_acc: 0.8940
Epoch 25/50
 - 36s - loss: 0.2738 - acc: 0.9034 - val_loss: 0.2898 - val_acc: 0.8968
Epoch 26/50
 - 36s - loss: 0.2740 - acc: 0.9043 - val_loss: 0.2945 - val_acc: 0.8956
Epoch 27/50
 - 36s - loss: 0.2728 - acc: 0.9053 - val_loss: 0.2826 - val_acc: 0.9006
Epoch 28/50
 - 36s - loss: 0.2672 - acc: 0.9065 - val_loss: 0.3115 - val_acc: 0.8868
Epoch 29/50
 - 36s - loss: 0.2663 - acc: 0.9070 - val_loss: 0.2879 - val_acc: 0.8977
Epoch 30/50
 - 36s - loss: 0.2657 - acc: 0.9093 - val_loss: 0.3009 - val_acc: 0.8923
Epoch 31/50
 - 36s - loss: 0.2630 - acc: 0.9108 - val_loss: 0.3119 - val_acc: 0.8903

Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.
Epoch 32/50
 - 36s - loss: 0.2562 - acc: 0.9126 - val_loss: 0.2786 - val_acc: 0.9024
Epoch 33/50
 - 36s - loss: 0.2542 - acc: 0.9143 - val_loss: 0.2751 - val_acc: 0.9037
Epoch 34/50
 - 36s - loss: 0.2543 - acc: 0.9125 - val_loss: 0.2746 - val_acc: 0.9024
Epoch 35/50
 - 36s - loss: 0.2547 - acc: 0.9138 - val_loss: 0.2729 - val_acc: 0.9022
Epoch 36/50
 - 36s - loss: 0.2509 - acc: 0.9143 - val_loss: 0.2752 - val_acc: 0.9029
Epoch 37/50
 - 36s - loss: 0.2523 - acc: 0.9134 - val_loss: 0.2738 - val_acc: 0.9034
Epoch 38/50
 - 36s - loss: 0.2557 - acc: 0.9144 - val_loss: 0.2732 - val_acc: 0.9064
Epoch 39/50
 - 36s - loss: 0.2531 - acc: 0.9136 - val_loss: 0.2725 - val_acc: 0.9029
Epoch 40/50
 - 36s - loss: 0.2502 - acc: 0.9145 - val_loss: 0.2759 - val_acc: 0.9005
Epoch 41/50
 - 36s - loss: 0.2502 - acc: 0.9157 - val_loss: 0.2731 - val_acc: 0.9044
Epoch 42/50
 - 36s - loss: 0.2491 - acc: 0.9165 - val_loss: 0.2832 - val_acc: 0.8992
Epoch 43/50
 - 36s - loss: 0.2482 - acc: 0.9162 - val_loss: 0.2720 - val_acc: 0.9050
Epoch 44/50
 - 36s - loss: 0.2477 - acc: 0.9166 - val_loss: 0.2719 - val_acc: 0.9052
Epoch 45/50
 - 36s - loss: 0.2487 - acc: 0.9159 - val_loss: 0.2720 - val_acc: 0.9037
Epoch 46/50
 - 36s - loss: 0.2483 - acc: 0.9168 - val_loss: 0.2736 - val_acc: 0.9061
Epoch 47/50
 - 36s - loss: 0.2491 - acc: 0.9164 - val_loss: 0.2726 - val_acc: 0.9042
Epoch 48/50
 - 36s - loss: 0.2450 - acc: 0.9181 - val_loss: 0.2718 - val_acc: 0.9052
Epoch 49/50
 - 35s - loss: 0.2455 - acc: 0.9167 - val_loss: 0.2702 - val_acc: 0.9040
Epoch 50/50
 - 36s - loss: 0.2436 - acc: 0.9184 - val_loss: 0.2693 - val_acc: 0.9068

  32/7440 [..............................] - ETA: 3s
 160/7440 [..............................] - ETA: 3s
 288/7440 [>.............................] - ETA: 3s
 416/7440 [>.............................] - ETA: 3s
 544/7440 [=>............................] - ETA: 2s
 672/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 928/7440 [==>...........................] - ETA: 2s
1056/7440 [===>..........................] - ETA: 2s
1184/7440 [===>..........................] - ETA: 2s
1312/7440 [====>.........................] - ETA: 2s
1440/7440 [====>.........................] - ETA: 2s
1568/7440 [=====>........................] - ETA: 2s
1696/7440 [=====>........................] - ETA: 2s
1824/7440 [======>.......................] - ETA: 2s
1952/7440 [======>.......................] - ETA: 2s
2080/7440 [=======>......................] - ETA: 2s
2208/7440 [=======>......................] - ETA: 2s
2336/7440 [========>.....................] - ETA: 2s
2464/7440 [========>.....................] - ETA: 2s
2592/7440 [=========>....................] - ETA: 2s
2720/7440 [=========>....................] - ETA: 2s
2848/7440 [==========>...................] - ETA: 1s
2976/7440 [===========>..................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3232/7440 [============>.................] - ETA: 1s
3360/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3616/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4000/7440 [===============>..............] - ETA: 1s
4128/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 1s
4384/7440 [================>.............] - ETA: 1s
4512/7440 [=================>............] - ETA: 1s
4640/7440 [=================>............] - ETA: 1s
4768/7440 [==================>...........] - ETA: 1s
4896/7440 [==================>...........] - ETA: 1s
5024/7440 [===================>..........] - ETA: 1s
5152/7440 [===================>..........] - ETA: 0s
5280/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5664/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5920/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6304/7440 [========================>.....] - ETA: 0s
6432/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7072/7440 [===========================>..] - ETA: 0s
7200/7440 [============================>.] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 3s 428us/step
python evaluate_saved_model_simple.py
