python hello-world.py
python hyperas_simple.py
python hyperas_contrastive_loss.py
python densenet_siamese_best_run.py
python hyperas_densenet.py
python hyperas_densenet_siamese.py
python densenet_simple.py
python keras_densenet_siamese.py
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_1[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 96, 96)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 96, 96)   0           concatenate_2[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 54, 96, 96)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 96, 96)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 54)           0           activation_4[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            55          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 10,675
Trainable params: 10,387
Non-trainable params: 288
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/10
 - 37s - loss: 0.5277 - acc: 0.7399 - val_loss: 0.6696 - val_acc: 0.7952
Epoch 2/10
 - 33s - loss: 0.4884 - acc: 0.7626 - val_loss: 0.4287 - val_acc: 0.8122
Epoch 3/10
 - 33s - loss: 0.4712 - acc: 0.7708 - val_loss: 0.5134 - val_acc: 0.8163
Epoch 4/10
 - 33s - loss: 0.4524 - acc: 0.7830 - val_loss: 0.4897 - val_acc: 0.8113
Epoch 5/10
 - 33s - loss: 0.4400 - acc: 0.7885 - val_loss: 0.5283 - val_acc: 0.8120
Epoch 6/10
 - 32s - loss: 0.4310 - acc: 0.7949 - val_loss: 0.3677 - val_acc: 0.8289
Epoch 7/10
 - 33s - loss: 0.4263 - acc: 0.7963 - val_loss: 0.3727 - val_acc: 0.8438
Epoch 8/10
 - 33s - loss: 0.4227 - acc: 0.7998 - val_loss: 0.5291 - val_acc: 0.7802
Epoch 9/10
 - 32s - loss: 0.4178 - acc: 0.8029 - val_loss: 0.5440 - val_acc: 0.8214
Epoch 10/10
 - 32s - loss: 0.4107 - acc: 0.8070 - val_loss: 0.3812 - val_acc: 0.8382
Epoch 00010: early stopping

  32/7440 [..............................] - ETA: 10s
 320/7440 [>.............................] - ETA: 2s 
 608/7440 [=>............................] - ETA: 1s
 896/7440 [==>...........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1472/7440 [====>.........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
2048/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 0s
2624/7440 [=========>....................] - ETA: 0s
2912/7440 [==========>...................] - ETA: 0s
3200/7440 [===========>..................] - ETA: 0s
3488/7440 [=============>................] - ETA: 0s
3776/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4352/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4928/7440 [==================>...........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5504/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
6080/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6656/7440 [=========================>....] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 185us/step
Test accuracy: 0.8381720430107527
Test accuracy 0.6: 0.8138440860215054
auc_score ------------------>  0.9195203202682392
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_2[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 96, 96)   0           concatenate_4[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_7[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 54, 96, 96)   0           concatenate_5[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 54, 96, 96)   216         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 96, 96)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 54)           0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            55          global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 10,675
Trainable params: 10,387
Non-trainable params: 288
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/10
 - 32s - loss: 0.5314 - acc: 0.7409 - val_loss: 0.7521 - val_acc: 0.5856
Epoch 2/10
 - 32s - loss: 0.4877 - acc: 0.7616 - val_loss: 0.7239 - val_acc: 0.7378
Epoch 3/10
 - 32s - loss: 0.4653 - acc: 0.7725 - val_loss: 0.5632 - val_acc: 0.7938
Epoch 4/10
 - 32s - loss: 0.4533 - acc: 0.7785 - val_loss: 0.4894 - val_acc: 0.8285
Epoch 5/10
 - 32s - loss: 0.4401 - acc: 0.7885 - val_loss: 0.5644 - val_acc: 0.7852
Epoch 6/10
 - 31s - loss: 0.4340 - acc: 0.7899 - val_loss: 0.5925 - val_acc: 0.7583
Epoch 7/10
 - 31s - loss: 0.4263 - acc: 0.7969 - val_loss: 0.4350 - val_acc: 0.8247
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 1s
 320/7440 [>.............................] - ETA: 1s
 640/7440 [=>............................] - ETA: 1s
 960/7440 [==>...........................] - ETA: 1s
1280/7440 [====>.........................] - ETA: 1s
1600/7440 [=====>........................] - ETA: 1s
1920/7440 [======>.......................] - ETA: 0s
2240/7440 [========>.....................] - ETA: 0s
2528/7440 [=========>....................] - ETA: 0s
2848/7440 [==========>...................] - ETA: 0s
3168/7440 [===========>..................] - ETA: 0s
3488/7440 [=============>................] - ETA: 0s
3808/7440 [==============>...............] - ETA: 0s
4128/7440 [===============>..............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4768/7440 [==================>...........] - ETA: 0s
5088/7440 [===================>..........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5728/7440 [======================>.......] - ETA: 0s
6048/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6688/7440 [=========================>....] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 1s 170us/step
Test accuracy: 0.8247311827956989
Test accuracy 0.6: 0.8314516129032258
auc_score ------------------>  0.900568851890392
[0.92, 0.901]
0.911 Â± 0.01
