python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
python custom_gridsearch_dn_siamese_layers.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, pooling
['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '32', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4812 - acc: 0.7700 - val_loss: 0.4175 - val_acc: 0.8033
Epoch 2/21
 - 37s - loss: 0.3935 - acc: 0.8230 - val_loss: 0.3540 - val_acc: 0.8417
Epoch 3/21
 - 38s - loss: 0.3565 - acc: 0.8460 - val_loss: 0.3452 - val_acc: 0.8449
Epoch 4/21
 - 37s - loss: 0.3279 - acc: 0.8630 - val_loss: 0.3005 - val_acc: 0.8714
Epoch 5/21
 - 37s - loss: 0.3057 - acc: 0.8748 - val_loss: 0.3091 - val_acc: 0.8715
Epoch 6/21
 - 37s - loss: 0.2885 - acc: 0.8850 - val_loss: 0.2776 - val_acc: 0.8902
Epoch 7/21
 - 37s - loss: 0.2718 - acc: 0.8948 - val_loss: 0.2624 - val_acc: 0.8986
Epoch 8/21
 - 36s - loss: 0.2565 - acc: 0.9027 - val_loss: 0.2193 - val_acc: 0.9179
Epoch 9/21
 - 37s - loss: 0.2425 - acc: 0.9071 - val_loss: 0.1977 - val_acc: 0.9287
Epoch 10/21
 - 36s - loss: 0.2344 - acc: 0.9110 - val_loss: 0.1859 - val_acc: 0.9349
Epoch 11/21
 - 37s - loss: 0.2236 - acc: 0.9169 - val_loss: 0.2463 - val_acc: 0.9024
Epoch 12/21
 - 37s - loss: 0.2139 - acc: 0.9203 - val_loss: 0.1896 - val_acc: 0.9332
Epoch 13/21
 - 38s - loss: 0.2045 - acc: 0.9253 - val_loss: 0.1710 - val_acc: 0.9421
Epoch 14/21
 - 37s - loss: 0.1989 - acc: 0.9275 - val_loss: 0.1686 - val_acc: 0.9410
Epoch 15/21
 - 37s - loss: 0.1906 - acc: 0.9321 - val_loss: 0.1419 - val_acc: 0.9531
Epoch 16/21
 - 37s - loss: 0.1819 - acc: 0.9355 - val_loss: 0.1417 - val_acc: 0.9544
Epoch 17/21
 - 37s - loss: 0.1759 - acc: 0.9381 - val_loss: 0.1446 - val_acc: 0.9498
Epoch 18/21
 - 38s - loss: 0.1752 - acc: 0.9389 - val_loss: 0.1628 - val_acc: 0.9415
Epoch 19/21
 - 37s - loss: 0.1651 - acc: 0.9435 - val_loss: 0.1708 - val_acc: 0.9438

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 38s - loss: 0.1581 - acc: 0.9464 - val_loss: 0.1317 - val_acc: 0.9585
Epoch 21/21
 - 38s - loss: 0.1545 - acc: 0.9485 - val_loss: 0.1081 - val_acc: 0.9694
Test accuracy:0.840
current auc_score ------------------> 0.942
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 39s - loss: 0.4847 - acc: 0.7680 - val_loss: 0.5620 - val_acc: 0.7285
Epoch 2/21
 - 37s - loss: 0.3925 - acc: 0.8187 - val_loss: 0.3641 - val_acc: 0.8389
Epoch 3/21
 - 36s - loss: 0.3537 - acc: 0.8439 - val_loss: 0.3604 - val_acc: 0.8361
Epoch 4/21
 - 37s - loss: 0.3222 - acc: 0.8630 - val_loss: 0.3559 - val_acc: 0.8461
Epoch 5/21
 - 38s - loss: 0.3003 - acc: 0.8762 - val_loss: 0.2832 - val_acc: 0.8873
Epoch 6/21
 - 37s - loss: 0.2810 - acc: 0.8875 - val_loss: 0.2701 - val_acc: 0.8906
Epoch 7/21
 - 37s - loss: 0.2646 - acc: 0.8958 - val_loss: 0.3173 - val_acc: 0.8666
Epoch 8/21
 - 36s - loss: 0.2492 - acc: 0.9036 - val_loss: 0.2304 - val_acc: 0.9101
Epoch 9/21
 - 37s - loss: 0.2352 - acc: 0.9108 - val_loss: 0.2563 - val_acc: 0.8995
Epoch 10/21
 - 36s - loss: 0.2231 - acc: 0.9182 - val_loss: 0.2254 - val_acc: 0.9120
Epoch 11/21
 - 37s - loss: 0.2120 - acc: 0.9216 - val_loss: 0.1953 - val_acc: 0.9272
Epoch 12/21
 - 36s - loss: 0.2033 - acc: 0.9260 - val_loss: 0.2202 - val_acc: 0.9150
Epoch 13/21
 - 35s - loss: 0.1974 - acc: 0.9295 - val_loss: 0.2030 - val_acc: 0.9246
Epoch 14/21
 - 36s - loss: 0.1863 - acc: 0.9341 - val_loss: 0.1573 - val_acc: 0.9448
Epoch 15/21
 - 36s - loss: 0.1803 - acc: 0.9373 - val_loss: 0.1902 - val_acc: 0.9307
Epoch 16/21
 - 36s - loss: 0.1730 - acc: 0.9402 - val_loss: 0.1494 - val_acc: 0.9478
Epoch 17/21
 - 36s - loss: 0.1635 - acc: 0.9448 - val_loss: 0.1281 - val_acc: 0.9582
Epoch 18/21
 - 35s - loss: 0.1601 - acc: 0.9443 - val_loss: 0.1097 - val_acc: 0.9646
Epoch 19/21
 - 36s - loss: 0.1551 - acc: 0.9483 - val_loss: 0.1213 - val_acc: 0.9597
Epoch 20/21
 - 35s - loss: 0.1506 - acc: 0.9494 - val_loss: 0.1499 - val_acc: 0.9490
Epoch 21/21
 - 36s - loss: 0.1464 - acc: 0.9506 - val_loss: 0.1158 - val_acc: 0.9637

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.768
current auc_score ------------------> 0.933
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 39s - loss: 0.4935 - acc: 0.7591 - val_loss: 0.4238 - val_acc: 0.7946
Epoch 2/21
 - 36s - loss: 0.3971 - acc: 0.8181 - val_loss: 0.3525 - val_acc: 0.8463
Epoch 3/21
 - 36s - loss: 0.3613 - acc: 0.8406 - val_loss: 0.3548 - val_acc: 0.8336
Epoch 4/21
 - 35s - loss: 0.3342 - acc: 0.8582 - val_loss: 0.3788 - val_acc: 0.8337
Epoch 5/21
 - 35s - loss: 0.3163 - acc: 0.8683 - val_loss: 0.2894 - val_acc: 0.8844
Epoch 6/21
 - 36s - loss: 0.2917 - acc: 0.8822 - val_loss: 0.2650 - val_acc: 0.8940
Epoch 7/21
 - 36s - loss: 0.2758 - acc: 0.8891 - val_loss: 0.2776 - val_acc: 0.8860
Epoch 8/21
 - 37s - loss: 0.2584 - acc: 0.8998 - val_loss: 0.2229 - val_acc: 0.9162
Epoch 9/21
 - 37s - loss: 0.2469 - acc: 0.9070 - val_loss: 0.2022 - val_acc: 0.9232
Epoch 10/21
 - 36s - loss: 0.2324 - acc: 0.9106 - val_loss: 0.3133 - val_acc: 0.8692
Epoch 11/21
 - 36s - loss: 0.2232 - acc: 0.9170 - val_loss: 0.1832 - val_acc: 0.9342
Epoch 12/21
 - 36s - loss: 0.2117 - acc: 0.9230 - val_loss: 0.1799 - val_acc: 0.9335
Epoch 13/21
 - 35s - loss: 0.2013 - acc: 0.9269 - val_loss: 0.1660 - val_acc: 0.9413
Epoch 14/21
 - 37s - loss: 0.1929 - acc: 0.9310 - val_loss: 0.1516 - val_acc: 0.9470
Epoch 15/21
 - 37s - loss: 0.1883 - acc: 0.9322 - val_loss: 0.1757 - val_acc: 0.9349
Epoch 16/21
 - 37s - loss: 0.1795 - acc: 0.9362 - val_loss: 0.1626 - val_acc: 0.9435
Epoch 17/21
 - 39s - loss: 0.1717 - acc: 0.9407 - val_loss: 0.2154 - val_acc: 0.9121

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 18/21
 - 37s - loss: 0.1597 - acc: 0.9454 - val_loss: 0.1266 - val_acc: 0.9607
Epoch 19/21
 - 36s - loss: 0.1574 - acc: 0.9459 - val_loss: 0.1169 - val_acc: 0.9646
Epoch 20/21
 - 37s - loss: 0.1527 - acc: 0.9487 - val_loss: 0.1189 - val_acc: 0.9631
Epoch 21/21
 - 37s - loss: 0.1530 - acc: 0.9495 - val_loss: 0.1165 - val_acc: 0.9637
Test accuracy:0.827
current auc_score ------------------> 0.939
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4873 - acc: 0.7701 - val_loss: 0.4038 - val_acc: 0.8171
Epoch 2/21
 - 38s - loss: 0.3977 - acc: 0.8207 - val_loss: 0.3545 - val_acc: 0.8427
Epoch 3/21
 - 38s - loss: 0.3585 - acc: 0.8439 - val_loss: 0.3087 - val_acc: 0.8705
Epoch 4/21
 - 37s - loss: 0.3298 - acc: 0.8607 - val_loss: 0.2795 - val_acc: 0.8884
Epoch 5/21
 - 36s - loss: 0.3051 - acc: 0.8745 - val_loss: 0.2580 - val_acc: 0.8957
Epoch 6/21
 - 36s - loss: 0.2847 - acc: 0.8853 - val_loss: 0.2536 - val_acc: 0.8982
Epoch 7/21
 - 39s - loss: 0.2683 - acc: 0.8943 - val_loss: 0.2238 - val_acc: 0.9139
Epoch 8/21
 - 37s - loss: 0.2526 - acc: 0.9036 - val_loss: 0.2118 - val_acc: 0.9185
Epoch 9/21
 - 37s - loss: 0.2386 - acc: 0.9108 - val_loss: 0.2235 - val_acc: 0.9113
Epoch 10/21
 - 38s - loss: 0.2304 - acc: 0.9145 - val_loss: 0.1910 - val_acc: 0.9312
Epoch 11/21
 - 38s - loss: 0.2204 - acc: 0.9186 - val_loss: 0.1769 - val_acc: 0.9364
Epoch 12/21
 - 38s - loss: 0.2098 - acc: 0.9236 - val_loss: 0.1673 - val_acc: 0.9410
Epoch 13/21
 - 37s - loss: 0.2000 - acc: 0.9280 - val_loss: 0.1776 - val_acc: 0.9345
Epoch 14/21
 - 37s - loss: 0.1957 - acc: 0.9301 - val_loss: 0.1734 - val_acc: 0.9389
Epoch 15/21
 - 37s - loss: 0.1887 - acc: 0.9332 - val_loss: 0.1626 - val_acc: 0.9438
Epoch 16/21
 - 37s - loss: 0.1811 - acc: 0.9356 - val_loss: 0.1443 - val_acc: 0.9497
Epoch 17/21
 - 37s - loss: 0.1763 - acc: 0.9368 - val_loss: 0.1397 - val_acc: 0.9533
Epoch 18/21
 - 37s - loss: 0.1681 - acc: 0.9417 - val_loss: 0.1370 - val_acc: 0.9536
Epoch 19/21
 - 38s - loss: 0.1652 - acc: 0.9435 - val_loss: 0.1299 - val_acc: 0.9552
Epoch 20/21
 - 37s - loss: 0.1605 - acc: 0.9445 - val_loss: 0.1238 - val_acc: 0.9598
Epoch 21/21
 - 36s - loss: 0.1552 - acc: 0.9476 - val_loss: 0.1443 - val_acc: 0.9495
Test accuracy:0.853
current auc_score ------------------> 0.925
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.5039 - acc: 0.7515 - val_loss: 0.4165 - val_acc: 0.7976
Epoch 2/21
 - 37s - loss: 0.4001 - acc: 0.8176 - val_loss: 0.4218 - val_acc: 0.8017
Epoch 3/21
 - 36s - loss: 0.3603 - acc: 0.8439 - val_loss: 0.4315 - val_acc: 0.8032
Epoch 4/21
 - 37s - loss: 0.3320 - acc: 0.8586 - val_loss: 0.3317 - val_acc: 0.8566
Epoch 5/21
 - 37s - loss: 0.3061 - acc: 0.8753 - val_loss: 0.2860 - val_acc: 0.8855
Epoch 6/21
 - 38s - loss: 0.2885 - acc: 0.8838 - val_loss: 0.3136 - val_acc: 0.8642
Epoch 7/21
 - 37s - loss: 0.2750 - acc: 0.8909 - val_loss: 0.2529 - val_acc: 0.9002
Epoch 8/21
 - 40s - loss: 0.2591 - acc: 0.8980 - val_loss: 0.2533 - val_acc: 0.8958
Epoch 9/21
 - 38s - loss: 0.2473 - acc: 0.9063 - val_loss: 0.1975 - val_acc: 0.9319
Epoch 10/21
 - 39s - loss: 0.2342 - acc: 0.9121 - val_loss: 0.1977 - val_acc: 0.9302
Epoch 11/21
 - 37s - loss: 0.2253 - acc: 0.9156 - val_loss: 0.1822 - val_acc: 0.9383
Epoch 12/21
 - 37s - loss: 0.2170 - acc: 0.9205 - val_loss: 0.1860 - val_acc: 0.9329
Epoch 13/21
 - 37s - loss: 0.2045 - acc: 0.9258 - val_loss: 0.1768 - val_acc: 0.9369
Epoch 14/21
 - 37s - loss: 0.1980 - acc: 0.9289 - val_loss: 0.1822 - val_acc: 0.9347
Epoch 15/21
 - 37s - loss: 0.1915 - acc: 0.9316 - val_loss: 0.1661 - val_acc: 0.9420
Epoch 16/21
 - 37s - loss: 0.1836 - acc: 0.9358 - val_loss: 0.1546 - val_acc: 0.9483
Epoch 17/21
 - 37s - loss: 0.1791 - acc: 0.9366 - val_loss: 0.1674 - val_acc: 0.9419
Epoch 18/21
 - 36s - loss: 0.1718 - acc: 0.9394 - val_loss: 0.1452 - val_acc: 0.9554
Epoch 19/21
 - 37s - loss: 0.1679 - acc: 0.9419 - val_loss: 0.1387 - val_acc: 0.9538
Epoch 20/21
 - 37s - loss: 0.1620 - acc: 0.9455 - val_loss: 0.1277 - val_acc: 0.9572
Epoch 21/21
 - 37s - loss: 0.1561 - acc: 0.9478 - val_loss: 0.1642 - val_acc: 0.9416
Test accuracy:0.829
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 39s - loss: 0.4802 - acc: 0.7717 - val_loss: 0.4134 - val_acc: 0.8057
Epoch 2/21
 - 38s - loss: 0.3913 - acc: 0.8206 - val_loss: 0.3840 - val_acc: 0.8197
Epoch 3/21
 - 37s - loss: 0.3600 - acc: 0.8422 - val_loss: 0.3320 - val_acc: 0.8587
Epoch 4/21
 - 37s - loss: 0.3341 - acc: 0.8576 - val_loss: 0.3003 - val_acc: 0.8827
Epoch 5/21
 - 37s - loss: 0.3122 - acc: 0.8703 - val_loss: 0.2907 - val_acc: 0.8850
Epoch 6/21
 - 36s - loss: 0.2942 - acc: 0.8797 - val_loss: 0.2699 - val_acc: 0.8937
Epoch 7/21
 - 37s - loss: 0.2801 - acc: 0.8887 - val_loss: 0.2491 - val_acc: 0.9086
Epoch 8/21
 - 37s - loss: 0.2637 - acc: 0.8965 - val_loss: 0.2302 - val_acc: 0.9098
Epoch 9/21
 - 37s - loss: 0.2496 - acc: 0.9029 - val_loss: 0.2288 - val_acc: 0.9113
Epoch 10/21
 - 36s - loss: 0.2343 - acc: 0.9123 - val_loss: 0.2129 - val_acc: 0.9184
Epoch 11/21
 - 37s - loss: 0.2290 - acc: 0.9131 - val_loss: 0.2041 - val_acc: 0.9252
Epoch 12/21
 - 37s - loss: 0.2192 - acc: 0.9172 - val_loss: 0.2088 - val_acc: 0.9288
Epoch 13/21
 - 37s - loss: 0.2092 - acc: 0.9227 - val_loss: 0.1729 - val_acc: 0.9419
Epoch 14/21
 - 37s - loss: 0.1994 - acc: 0.9275 - val_loss: 0.1658 - val_acc: 0.9435
Epoch 15/21
 - 37s - loss: 0.1921 - acc: 0.9316 - val_loss: 0.1501 - val_acc: 0.9537
Epoch 16/21
 - 37s - loss: 0.1873 - acc: 0.9343 - val_loss: 0.1439 - val_acc: 0.9556
Epoch 17/21
 - 40s - loss: 0.1817 - acc: 0.9348 - val_loss: 0.1510 - val_acc: 0.9519
Epoch 18/21
 - 38s - loss: 0.1738 - acc: 0.9381 - val_loss: 0.1498 - val_acc: 0.9504
Epoch 19/21
 - 38s - loss: 0.1720 - acc: 0.9389 - val_loss: 0.1803 - val_acc: 0.9329

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/21
 - 38s - loss: 0.1595 - acc: 0.9454 - val_loss: 0.1301 - val_acc: 0.9575
Epoch 21/21
 - 38s - loss: 0.1583 - acc: 0.9456 - val_loss: 0.1237 - val_acc: 0.9607
Test accuracy:0.861
current auc_score ------------------> 0.952
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4826 - acc: 0.7743 - val_loss: 0.4215 - val_acc: 0.8080
Epoch 2/21
 - 37s - loss: 0.3906 - acc: 0.8226 - val_loss: 0.3730 - val_acc: 0.8358
Epoch 3/21
 - 38s - loss: 0.3551 - acc: 0.8463 - val_loss: 0.3891 - val_acc: 0.8185
Epoch 4/21
 - 37s - loss: 0.3282 - acc: 0.8616 - val_loss: 0.3084 - val_acc: 0.8628
Epoch 5/21
 - 38s - loss: 0.3045 - acc: 0.8752 - val_loss: 0.3152 - val_acc: 0.8648
Epoch 6/21
 - 38s - loss: 0.2850 - acc: 0.8836 - val_loss: 0.3118 - val_acc: 0.8651
Epoch 7/21
 - 37s - loss: 0.2674 - acc: 0.8941 - val_loss: 0.3386 - val_acc: 0.8522

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 8/21
 - 38s - loss: 0.2523 - acc: 0.9033 - val_loss: 0.2261 - val_acc: 0.9068
Epoch 9/21
 - 38s - loss: 0.2449 - acc: 0.9072 - val_loss: 0.2218 - val_acc: 0.9118
Epoch 10/21
 - 38s - loss: 0.2405 - acc: 0.9102 - val_loss: 0.2086 - val_acc: 0.9187
Epoch 11/21
 - 37s - loss: 0.2378 - acc: 0.9107 - val_loss: 0.2092 - val_acc: 0.9165
Epoch 12/21
 - 37s - loss: 0.2339 - acc: 0.9126 - val_loss: 0.2103 - val_acc: 0.9154
Epoch 13/21
 - 37s - loss: 0.2292 - acc: 0.9148 - val_loss: 0.1835 - val_acc: 0.9336
Epoch 14/21
 - 37s - loss: 0.2280 - acc: 0.9156 - val_loss: 0.1852 - val_acc: 0.9316
Epoch 15/21
 - 38s - loss: 0.2224 - acc: 0.9170 - val_loss: 0.1781 - val_acc: 0.9359
Epoch 16/21
 - 37s - loss: 0.2183 - acc: 0.9194 - val_loss: 0.1894 - val_acc: 0.9298
Epoch 17/21
 - 36s - loss: 0.2170 - acc: 0.9218 - val_loss: 0.1737 - val_acc: 0.9375
Epoch 18/21
 - 37s - loss: 0.2142 - acc: 0.9212 - val_loss: 0.1795 - val_acc: 0.9359
Epoch 19/21
 - 36s - loss: 0.2093 - acc: 0.9233 - val_loss: 0.1593 - val_acc: 0.9452
Epoch 20/21
 - 37s - loss: 0.2053 - acc: 0.9248 - val_loss: 0.1615 - val_acc: 0.9431
Epoch 21/21
 - 37s - loss: 0.2024 - acc: 0.9271 - val_loss: 0.1572 - val_acc: 0.9443
Test accuracy:0.859
current auc_score ------------------> 0.944
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4824 - acc: 0.7724 - val_loss: 0.4320 - val_acc: 0.7962
Epoch 2/21
 - 38s - loss: 0.3958 - acc: 0.8209 - val_loss: 0.3480 - val_acc: 0.8426
Epoch 3/21
 - 37s - loss: 0.3577 - acc: 0.8468 - val_loss: 0.3742 - val_acc: 0.8373
Epoch 4/21
 - 38s - loss: 0.3302 - acc: 0.8620 - val_loss: 0.3398 - val_acc: 0.8505
Epoch 5/21
 - 38s - loss: 0.3101 - acc: 0.8727 - val_loss: 0.2980 - val_acc: 0.8786
Epoch 6/21
 - 38s - loss: 0.2911 - acc: 0.8826 - val_loss: 0.2578 - val_acc: 0.9017
Epoch 7/21
 - 37s - loss: 0.2751 - acc: 0.8931 - val_loss: 0.2375 - val_acc: 0.9095
Epoch 8/21
 - 38s - loss: 0.2617 - acc: 0.8990 - val_loss: 0.2471 - val_acc: 0.9071
Epoch 9/21
 - 38s - loss: 0.2458 - acc: 0.9064 - val_loss: 0.2069 - val_acc: 0.9258
Epoch 10/21
 - 38s - loss: 0.2360 - acc: 0.9117 - val_loss: 0.2029 - val_acc: 0.9237
Epoch 11/21
 - 37s - loss: 0.2225 - acc: 0.9179 - val_loss: 0.2000 - val_acc: 0.9272
Epoch 12/21
 - 38s - loss: 0.2146 - acc: 0.9215 - val_loss: 0.2050 - val_acc: 0.9231
Epoch 13/21
 - 37s - loss: 0.2092 - acc: 0.9244 - val_loss: 0.1507 - val_acc: 0.9509
Epoch 14/21
 - 37s - loss: 0.1998 - acc: 0.9291 - val_loss: 0.2111 - val_acc: 0.9179
Epoch 15/21
 - 37s - loss: 0.1918 - acc: 0.9315 - val_loss: 0.1587 - val_acc: 0.9449
Epoch 16/21
 - 37s - loss: 0.1888 - acc: 0.9329 - val_loss: 0.1418 - val_acc: 0.9519
Epoch 17/21
 - 38s - loss: 0.1805 - acc: 0.9364 - val_loss: 0.1610 - val_acc: 0.9420
Epoch 18/21
 - 38s - loss: 0.1753 - acc: 0.9392 - val_loss: 0.1376 - val_acc: 0.9533
Epoch 19/21
 - 38s - loss: 0.1676 - acc: 0.9426 - val_loss: 0.1508 - val_acc: 0.9470
Epoch 20/21
 - 38s - loss: 0.1645 - acc: 0.9433 - val_loss: 0.1238 - val_acc: 0.9615
Epoch 21/21
 - 37s - loss: 0.1585 - acc: 0.9471 - val_loss: 0.1288 - val_acc: 0.9582
Test accuracy:0.813
current auc_score ------------------> 0.948
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 40s - loss: 0.4874 - acc: 0.7685 - val_loss: 0.5064 - val_acc: 0.7420
Epoch 2/21
 - 37s - loss: 0.4077 - acc: 0.8137 - val_loss: 0.3846 - val_acc: 0.8356
Epoch 3/21
 - 39s - loss: 0.3713 - acc: 0.8363 - val_loss: 0.3410 - val_acc: 0.8623
Epoch 4/21
 - 38s - loss: 0.3415 - acc: 0.8541 - val_loss: 0.3129 - val_acc: 0.8726
Epoch 5/21
 - 37s - loss: 0.3186 - acc: 0.8695 - val_loss: 0.2999 - val_acc: 0.8778
Epoch 6/21
 - 37s - loss: 0.3006 - acc: 0.8784 - val_loss: 0.2689 - val_acc: 0.8958
Epoch 7/21
 - 38s - loss: 0.2792 - acc: 0.8885 - val_loss: 0.2399 - val_acc: 0.9129
Epoch 8/21
 - 38s - loss: 0.2644 - acc: 0.8974 - val_loss: 0.2393 - val_acc: 0.9108
Epoch 9/21
 - 38s - loss: 0.2522 - acc: 0.9032 - val_loss: 0.2194 - val_acc: 0.9184
Epoch 10/21
 - 37s - loss: 0.2362 - acc: 0.9112 - val_loss: 0.1997 - val_acc: 0.9287
Epoch 11/21
 - 38s - loss: 0.2307 - acc: 0.9141 - val_loss: 0.2175 - val_acc: 0.9175
Epoch 12/21
 - 37s - loss: 0.2202 - acc: 0.9195 - val_loss: 0.1959 - val_acc: 0.9290
Epoch 13/21
 - 37s - loss: 0.2111 - acc: 0.9230 - val_loss: 0.1814 - val_acc: 0.9341
Epoch 14/21
 - 37s - loss: 0.2032 - acc: 0.9258 - val_loss: 0.1772 - val_acc: 0.9378
Epoch 15/21
 - 38s - loss: 0.1983 - acc: 0.9277 - val_loss: 0.1785 - val_acc: 0.9340
Epoch 16/21
 - 38s - loss: 0.1891 - acc: 0.9327 - val_loss: 0.2108 - val_acc: 0.9191
Epoch 17/21
 - 37s - loss: 0.1808 - acc: 0.9365 - val_loss: 0.1415 - val_acc: 0.9506
Epoch 18/21
 - 38s - loss: 0.1796 - acc: 0.9369 - val_loss: 0.1278 - val_acc: 0.9570
Epoch 19/21
 - 38s - loss: 0.1716 - acc: 0.9394 - val_loss: 0.1322 - val_acc: 0.9575
Epoch 20/21
 - 37s - loss: 0.1631 - acc: 0.9437 - val_loss: 0.1232 - val_acc: 0.9591
Epoch 21/21
 - 37s - loss: 0.1589 - acc: 0.9461 - val_loss: 0.1500 - val_acc: 0.9445
Test accuracy:0.855
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  32  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 39s - loss: 0.4809 - acc: 0.7696 - val_loss: 0.4202 - val_acc: 0.8018
Epoch 2/21
 - 37s - loss: 0.3931 - acc: 0.8213 - val_loss: 0.3432 - val_acc: 0.8508
Epoch 3/21
 - 37s - loss: 0.3543 - acc: 0.8435 - val_loss: 0.3301 - val_acc: 0.8602
Epoch 4/21
 - 37s - loss: 0.3303 - acc: 0.8594 - val_loss: 0.2908 - val_acc: 0.8872
Epoch 5/21
 - 37s - loss: 0.3084 - acc: 0.8728 - val_loss: 0.2633 - val_acc: 0.8995
Epoch 6/21
 - 37s - loss: 0.2912 - acc: 0.8801 - val_loss: 0.2555 - val_acc: 0.8992
Epoch 7/21
 - 38s - loss: 0.2740 - acc: 0.8903 - val_loss: 0.2438 - val_acc: 0.9075
Epoch 8/21
 - 37s - loss: 0.2592 - acc: 0.8983 - val_loss: 0.2177 - val_acc: 0.9187
Epoch 9/21
 - 37s - loss: 0.2503 - acc: 0.9026 - val_loss: 0.2236 - val_acc: 0.9132
Epoch 10/21
 - 38s - loss: 0.2361 - acc: 0.9104 - val_loss: 0.2031 - val_acc: 0.9257
Epoch 11/21
 - 38s - loss: 0.2249 - acc: 0.9165 - val_loss: 0.1896 - val_acc: 0.9300
Epoch 12/21
 - 38s - loss: 0.2174 - acc: 0.9195 - val_loss: 0.1635 - val_acc: 0.9447
Epoch 13/21
 - 36s - loss: 0.2095 - acc: 0.9223 - val_loss: 0.1607 - val_acc: 0.9444
Epoch 14/21
 - 38s - loss: 0.1977 - acc: 0.9291 - val_loss: 0.1561 - val_acc: 0.9460
Epoch 15/21
 - 37s - loss: 0.1912 - acc: 0.9310 - val_loss: 0.1420 - val_acc: 0.9531
Epoch 16/21
 - 38s - loss: 0.1855 - acc: 0.9332 - val_loss: 0.1377 - val_acc: 0.9558
Epoch 17/21
 - 38s - loss: 0.1775 - acc: 0.9372 - val_loss: 0.1322 - val_acc: 0.9576
Epoch 18/21
 - 38s - loss: 0.1679 - acc: 0.9418 - val_loss: 0.1340 - val_acc: 0.9544
Epoch 19/21
 - 38s - loss: 0.1666 - acc: 0.9438 - val_loss: 0.1165 - val_acc: 0.9647
Epoch 20/21
 - 38s - loss: 0.1574 - acc: 0.9466 - val_loss: 0.1114 - val_acc: 0.9662
Epoch 21/21
 - 38s - loss: 0.1534 - acc: 0.9478 - val_loss: 0.1065 - val_acc: 0.9676
Test accuracy:0.822
current auc_score ------------------> 0.941
accuracies:  [0.8397849462365592, 0.7684139784946237, 0.826747311827957, 0.853225806451613, 0.8294354838709678, 0.860752688172043, 0.8594086021505376, 0.8133064516129033, 0.8547043010752688, 0.8217741935483871]
aucs:  [0.9423, 0.9332, 0.9391, 0.9247, 0.9435, 0.9524, 0.944, 0.9479, 0.9289, 0.9407]
mean and std AUC:  0.94+/-0.008  max:   0.9524
['2-2-2', '30', '3', '16', '0.2', '0.07', '23', 'adadelta', '0.5', 'FALSE', '128', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.5448 - acc: 0.7346 - val_loss: 0.4769 - val_acc: 0.7807
Epoch 2/23
 - 23s - loss: 0.4474 - acc: 0.7898 - val_loss: 0.4501 - val_acc: 0.7861
Epoch 3/23
 - 23s - loss: 0.4097 - acc: 0.8126 - val_loss: 0.4974 - val_acc: 0.7575
Epoch 4/23
 - 23s - loss: 0.3817 - acc: 0.8273 - val_loss: 0.4645 - val_acc: 0.7752
Epoch 5/23
 - 23s - loss: 0.3609 - acc: 0.8410 - val_loss: 0.4989 - val_acc: 0.7716

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/23
 - 24s - loss: 0.3449 - acc: 0.8509 - val_loss: 0.3857 - val_acc: 0.8213
Epoch 7/23
 - 24s - loss: 0.3383 - acc: 0.8548 - val_loss: 0.3921 - val_acc: 0.8184
Epoch 8/23
 - 24s - loss: 0.3327 - acc: 0.8569 - val_loss: 0.4221 - val_acc: 0.8060
Epoch 9/23
 - 24s - loss: 0.3287 - acc: 0.8612 - val_loss: 0.3975 - val_acc: 0.8164

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 10/23
 - 24s - loss: 0.3231 - acc: 0.8640 - val_loss: 0.3657 - val_acc: 0.8346
Epoch 11/23
 - 24s - loss: 0.3237 - acc: 0.8622 - val_loss: 0.3933 - val_acc: 0.8207
Epoch 12/23
 - 24s - loss: 0.3210 - acc: 0.8661 - val_loss: 0.3775 - val_acc: 0.8312
Epoch 13/23
 - 24s - loss: 0.3208 - acc: 0.8642 - val_loss: 0.3887 - val_acc: 0.8225

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00221359428318917.
Epoch 14/23
 - 23s - loss: 0.3190 - acc: 0.8666 - val_loss: 0.3939 - val_acc: 0.8208
Epoch 00014: early stopping
Test accuracy:0.837
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.5267 - acc: 0.7535 - val_loss: 0.5314 - val_acc: 0.7295
Epoch 2/23
 - 23s - loss: 0.4270 - acc: 0.7973 - val_loss: 0.4705 - val_acc: 0.7687
Epoch 3/23
 - 23s - loss: 0.3897 - acc: 0.8181 - val_loss: 0.4004 - val_acc: 0.8128
Epoch 4/23
 - 23s - loss: 0.3655 - acc: 0.8328 - val_loss: 0.3627 - val_acc: 0.8336
Epoch 5/23
 - 23s - loss: 0.3463 - acc: 0.8449 - val_loss: 0.3286 - val_acc: 0.8518
Epoch 6/23
 - 23s - loss: 0.3307 - acc: 0.8577 - val_loss: 0.3223 - val_acc: 0.8597
Epoch 7/23
 - 23s - loss: 0.3171 - acc: 0.8636 - val_loss: 0.3065 - val_acc: 0.8690
Epoch 8/23
 - 23s - loss: 0.3041 - acc: 0.8719 - val_loss: 0.3002 - val_acc: 0.8726
Epoch 9/23
 - 24s - loss: 0.2937 - acc: 0.8784 - val_loss: 0.2658 - val_acc: 0.8887
Epoch 10/23
 - 23s - loss: 0.2819 - acc: 0.8849 - val_loss: 0.2568 - val_acc: 0.8977
Epoch 11/23
 - 23s - loss: 0.2716 - acc: 0.8900 - val_loss: 0.2485 - val_acc: 0.9007
Epoch 12/23
 - 23s - loss: 0.2648 - acc: 0.8933 - val_loss: 0.2477 - val_acc: 0.9054
Epoch 13/23
 - 24s - loss: 0.2564 - acc: 0.8983 - val_loss: 0.2247 - val_acc: 0.9137
Epoch 14/23
 - 23s - loss: 0.2491 - acc: 0.9025 - val_loss: 0.2426 - val_acc: 0.9001
Epoch 15/23
 - 23s - loss: 0.2414 - acc: 0.9060 - val_loss: 0.2247 - val_acc: 0.9145
Epoch 16/23
 - 24s - loss: 0.2335 - acc: 0.9092 - val_loss: 0.2263 - val_acc: 0.9108

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/23
 - 23s - loss: 0.2263 - acc: 0.9134 - val_loss: 0.1991 - val_acc: 0.9295
Epoch 18/23
 - 23s - loss: 0.2235 - acc: 0.9145 - val_loss: 0.1897 - val_acc: 0.9316
Epoch 19/23
 - 24s - loss: 0.2192 - acc: 0.9165 - val_loss: 0.1939 - val_acc: 0.9307
Epoch 20/23
 - 24s - loss: 0.2202 - acc: 0.9159 - val_loss: 0.1847 - val_acc: 0.9340
Epoch 21/23
 - 23s - loss: 0.2168 - acc: 0.9178 - val_loss: 0.1975 - val_acc: 0.9268
Epoch 22/23
 - 23s - loss: 0.2142 - acc: 0.9207 - val_loss: 0.1852 - val_acc: 0.9310
Epoch 23/23
 - 23s - loss: 0.2127 - acc: 0.9201 - val_loss: 0.1908 - val_acc: 0.9293

Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Test accuracy:0.844
current auc_score ------------------> 0.941
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.5365 - acc: 0.7422 - val_loss: 0.5479 - val_acc: 0.7110
Epoch 2/23
 - 23s - loss: 0.4424 - acc: 0.7895 - val_loss: 0.6894 - val_acc: 0.6570
Epoch 3/23
 - 23s - loss: 0.3977 - acc: 0.8164 - val_loss: 0.5305 - val_acc: 0.7369
Epoch 4/23
 - 23s - loss: 0.3681 - acc: 0.8353 - val_loss: 0.4817 - val_acc: 0.7841
Epoch 5/23
 - 23s - loss: 0.3477 - acc: 0.8464 - val_loss: 0.4152 - val_acc: 0.8023
Epoch 6/23
 - 23s - loss: 0.3293 - acc: 0.8586 - val_loss: 0.3570 - val_acc: 0.8356
Epoch 7/23
 - 22s - loss: 0.3144 - acc: 0.8682 - val_loss: 0.3939 - val_acc: 0.8133
Epoch 8/23
 - 22s - loss: 0.3013 - acc: 0.8759 - val_loss: 0.3285 - val_acc: 0.8588
Epoch 9/23
 - 22s - loss: 0.2895 - acc: 0.8831 - val_loss: 0.3779 - val_acc: 0.8223
Epoch 10/23
 - 22s - loss: 0.2786 - acc: 0.8894 - val_loss: 0.2657 - val_acc: 0.8945
Epoch 11/23
 - 23s - loss: 0.2671 - acc: 0.8961 - val_loss: 0.2481 - val_acc: 0.9059
Epoch 12/23
 - 23s - loss: 0.2587 - acc: 0.8994 - val_loss: 0.2415 - val_acc: 0.9111
Epoch 13/23
 - 22s - loss: 0.2470 - acc: 0.9055 - val_loss: 0.2484 - val_acc: 0.9045
Epoch 14/23
 - 22s - loss: 0.2404 - acc: 0.9086 - val_loss: 0.2273 - val_acc: 0.9135
Epoch 15/23
 - 23s - loss: 0.2349 - acc: 0.9115 - val_loss: 0.2611 - val_acc: 0.8958
Epoch 16/23
 - 22s - loss: 0.2262 - acc: 0.9157 - val_loss: 0.2329 - val_acc: 0.9101
Epoch 17/23
 - 22s - loss: 0.2179 - acc: 0.9192 - val_loss: 0.2007 - val_acc: 0.9281
Epoch 18/23
 - 23s - loss: 0.2103 - acc: 0.9223 - val_loss: 0.1860 - val_acc: 0.9334
Epoch 19/23
 - 23s - loss: 0.2075 - acc: 0.9234 - val_loss: 0.1965 - val_acc: 0.9288
Epoch 20/23
 - 22s - loss: 0.1965 - acc: 0.9294 - val_loss: 0.2409 - val_acc: 0.9076
Epoch 21/23
 - 23s - loss: 0.1949 - acc: 0.9299 - val_loss: 0.2333 - val_acc: 0.9108

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 22/23
 - 22s - loss: 0.1866 - acc: 0.9340 - val_loss: 0.1620 - val_acc: 0.9445
Epoch 23/23
 - 23s - loss: 0.1851 - acc: 0.9337 - val_loss: 0.1559 - val_acc: 0.9438
Test accuracy:0.875
current auc_score ------------------> 0.965
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.5420 - acc: 0.7454 - val_loss: 0.5035 - val_acc: 0.7584
Epoch 2/23
 - 24s - loss: 0.4331 - acc: 0.7997 - val_loss: 0.5432 - val_acc: 0.7159
Epoch 3/23
 - 24s - loss: 0.3911 - acc: 0.8240 - val_loss: 0.4988 - val_acc: 0.7560
Epoch 4/23
 - 23s - loss: 0.3644 - acc: 0.8383 - val_loss: 0.3637 - val_acc: 0.8363
Epoch 5/23
 - 23s - loss: 0.3430 - acc: 0.8536 - val_loss: 0.4955 - val_acc: 0.7679
Epoch 6/23
 - 23s - loss: 0.3237 - acc: 0.8644 - val_loss: 0.3334 - val_acc: 0.8564
Epoch 7/23
 - 23s - loss: 0.3105 - acc: 0.8720 - val_loss: 0.4021 - val_acc: 0.8022
Epoch 8/23
 - 23s - loss: 0.2974 - acc: 0.8804 - val_loss: 0.3657 - val_acc: 0.8271
Epoch 9/23
 - 23s - loss: 0.2835 - acc: 0.8860 - val_loss: 0.3718 - val_acc: 0.8298

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/23
 - 24s - loss: 0.2723 - acc: 0.8929 - val_loss: 0.3174 - val_acc: 0.8611
Epoch 11/23
 - 23s - loss: 0.2699 - acc: 0.8931 - val_loss: 0.2841 - val_acc: 0.8860
Epoch 12/23
 - 23s - loss: 0.2654 - acc: 0.8982 - val_loss: 0.3162 - val_acc: 0.8602
Epoch 13/23
 - 23s - loss: 0.2623 - acc: 0.8989 - val_loss: 0.3177 - val_acc: 0.8599
Epoch 14/23
 - 23s - loss: 0.2597 - acc: 0.9001 - val_loss: 0.2944 - val_acc: 0.8758

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 15/23
 - 23s - loss: 0.2569 - acc: 0.9017 - val_loss: 0.3138 - val_acc: 0.8598
Epoch 00015: early stopping
Test accuracy:0.797
current auc_score ------------------> 0.927
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.5242 - acc: 0.7582 - val_loss: 0.4794 - val_acc: 0.7698
Epoch 2/23
 - 24s - loss: 0.4361 - acc: 0.7974 - val_loss: 0.6181 - val_acc: 0.7054
Epoch 3/23
 - 23s - loss: 0.3933 - acc: 0.8202 - val_loss: 0.4285 - val_acc: 0.8102
Epoch 4/23
 - 23s - loss: 0.3675 - acc: 0.8333 - val_loss: 0.4101 - val_acc: 0.8139
Epoch 5/23
 - 23s - loss: 0.3491 - acc: 0.8427 - val_loss: 0.5229 - val_acc: 0.7878
Epoch 6/23
 - 23s - loss: 0.3299 - acc: 0.8549 - val_loss: 0.3323 - val_acc: 0.8572
Epoch 7/23
 - 23s - loss: 0.3172 - acc: 0.8640 - val_loss: 0.5336 - val_acc: 0.7802
Epoch 8/23
 - 23s - loss: 0.3062 - acc: 0.8692 - val_loss: 0.3555 - val_acc: 0.8480
Epoch 9/23
 - 23s - loss: 0.2937 - acc: 0.8778 - val_loss: 0.3969 - val_acc: 0.8338

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 10/23
 - 23s - loss: 0.2845 - acc: 0.8828 - val_loss: 0.3272 - val_acc: 0.8599
Epoch 11/23
 - 23s - loss: 0.2804 - acc: 0.8863 - val_loss: 0.3146 - val_acc: 0.8663
Epoch 12/23
 - 23s - loss: 0.2770 - acc: 0.8880 - val_loss: 0.3480 - val_acc: 0.8535
Epoch 13/23
 - 23s - loss: 0.2707 - acc: 0.8907 - val_loss: 0.3660 - val_acc: 0.8470
Epoch 14/23
 - 23s - loss: 0.2690 - acc: 0.8923 - val_loss: 0.2936 - val_acc: 0.8785
Epoch 15/23
 - 23s - loss: 0.2675 - acc: 0.8922 - val_loss: 0.3333 - val_acc: 0.8627
Epoch 16/23
 - 23s - loss: 0.2640 - acc: 0.8942 - val_loss: 0.3076 - val_acc: 0.8697
Epoch 17/23
 - 23s - loss: 0.2612 - acc: 0.8961 - val_loss: 0.3130 - val_acc: 0.8696

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 18/23
 - 23s - loss: 0.2578 - acc: 0.8968 - val_loss: 0.3125 - val_acc: 0.8701
Epoch 00018: early stopping
Test accuracy:0.889
current auc_score ------------------> 0.961
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.5359 - acc: 0.7412 - val_loss: 0.5909 - val_acc: 0.7125
Epoch 2/23
 - 23s - loss: 0.4314 - acc: 0.7956 - val_loss: 0.7095 - val_acc: 0.6714
Epoch 3/23
 - 23s - loss: 0.3924 - acc: 0.8198 - val_loss: 0.3740 - val_acc: 0.8341
Epoch 4/23
 - 23s - loss: 0.3678 - acc: 0.8359 - val_loss: 0.4621 - val_acc: 0.7757
Epoch 5/23
 - 23s - loss: 0.3469 - acc: 0.8480 - val_loss: 0.3384 - val_acc: 0.8591
Epoch 6/23
 - 23s - loss: 0.3333 - acc: 0.8567 - val_loss: 0.3153 - val_acc: 0.8730
Epoch 7/23
 - 23s - loss: 0.3190 - acc: 0.8655 - val_loss: 0.2952 - val_acc: 0.8760
Epoch 8/23
 - 23s - loss: 0.3062 - acc: 0.8726 - val_loss: 0.2813 - val_acc: 0.8838
Epoch 9/23
 - 23s - loss: 0.2952 - acc: 0.8790 - val_loss: 0.2702 - val_acc: 0.8868
Epoch 10/23
 - 23s - loss: 0.2837 - acc: 0.8859 - val_loss: 0.2654 - val_acc: 0.8926
Epoch 11/23
 - 23s - loss: 0.2745 - acc: 0.8896 - val_loss: 0.2728 - val_acc: 0.8919
Epoch 12/23
 - 23s - loss: 0.2652 - acc: 0.8949 - val_loss: 0.2585 - val_acc: 0.8968
Epoch 13/23
 - 23s - loss: 0.2592 - acc: 0.8984 - val_loss: 0.2455 - val_acc: 0.9024
Epoch 14/23
 - 23s - loss: 0.2470 - acc: 0.9052 - val_loss: 0.2306 - val_acc: 0.9138
Epoch 15/23
 - 23s - loss: 0.2392 - acc: 0.9078 - val_loss: 0.2184 - val_acc: 0.9173
Epoch 16/23
 - 23s - loss: 0.2321 - acc: 0.9119 - val_loss: 0.2283 - val_acc: 0.9135
Epoch 17/23
 - 23s - loss: 0.2258 - acc: 0.9157 - val_loss: 0.1974 - val_acc: 0.9257
Epoch 18/23
 - 23s - loss: 0.2175 - acc: 0.9200 - val_loss: 0.1872 - val_acc: 0.9302
Epoch 19/23
 - 23s - loss: 0.2134 - acc: 0.9206 - val_loss: 0.2612 - val_acc: 0.8942
Epoch 20/23
 - 23s - loss: 0.2081 - acc: 0.9240 - val_loss: 0.1914 - val_acc: 0.9291
Epoch 21/23
 - 23s - loss: 0.2022 - acc: 0.9254 - val_loss: 0.2002 - val_acc: 0.9216

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 22/23
 - 23s - loss: 0.1937 - acc: 0.9307 - val_loss: 0.1752 - val_acc: 0.9374
Epoch 23/23
 - 23s - loss: 0.1908 - acc: 0.9318 - val_loss: 0.2000 - val_acc: 0.9234
Test accuracy:0.854
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.5426 - acc: 0.7405 - val_loss: 0.6007 - val_acc: 0.6860
Epoch 2/23
 - 23s - loss: 0.4477 - acc: 0.7897 - val_loss: 0.6636 - val_acc: 0.6616
Epoch 3/23
 - 24s - loss: 0.4101 - acc: 0.8108 - val_loss: 0.4416 - val_acc: 0.7938
Epoch 4/23
 - 24s - loss: 0.3843 - acc: 0.8282 - val_loss: 0.4763 - val_acc: 0.7684
Epoch 5/23
 - 24s - loss: 0.3641 - acc: 0.8409 - val_loss: 0.3879 - val_acc: 0.8195
Epoch 6/23
 - 24s - loss: 0.3449 - acc: 0.8512 - val_loss: 0.3532 - val_acc: 0.8420
Epoch 7/23
 - 24s - loss: 0.3312 - acc: 0.8589 - val_loss: 0.4028 - val_acc: 0.8110
Epoch 8/23
 - 24s - loss: 0.3175 - acc: 0.8678 - val_loss: 0.3354 - val_acc: 0.8515
Epoch 9/23
 - 24s - loss: 0.3051 - acc: 0.8740 - val_loss: 0.3710 - val_acc: 0.8311
Epoch 10/23
 - 24s - loss: 0.2944 - acc: 0.8799 - val_loss: 0.3406 - val_acc: 0.8529
Epoch 11/23
 - 23s - loss: 0.2849 - acc: 0.8844 - val_loss: 0.2975 - val_acc: 0.8780
Epoch 12/23
 - 23s - loss: 0.2764 - acc: 0.8890 - val_loss: 0.3903 - val_acc: 0.8198
Epoch 13/23
 - 23s - loss: 0.2661 - acc: 0.8932 - val_loss: 0.2919 - val_acc: 0.8761
Epoch 14/23
 - 23s - loss: 0.2567 - acc: 0.8995 - val_loss: 0.2664 - val_acc: 0.8918
Epoch 15/23
 - 23s - loss: 0.2514 - acc: 0.9024 - val_loss: 0.2410 - val_acc: 0.9086
Epoch 16/23
 - 24s - loss: 0.2424 - acc: 0.9053 - val_loss: 0.3120 - val_acc: 0.8637
Epoch 17/23
 - 24s - loss: 0.2355 - acc: 0.9116 - val_loss: 0.3509 - val_acc: 0.8406
Epoch 18/23
 - 24s - loss: 0.2272 - acc: 0.9142 - val_loss: 0.2659 - val_acc: 0.8931

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/23
 - 24s - loss: 0.2210 - acc: 0.9176 - val_loss: 0.2485 - val_acc: 0.9001
Epoch 00019: early stopping
Test accuracy:0.818
current auc_score ------------------> 0.928
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.5424 - acc: 0.7377 - val_loss: 0.4632 - val_acc: 0.7851
Epoch 2/23
 - 23s - loss: 0.4324 - acc: 0.7996 - val_loss: 0.3985 - val_acc: 0.8149
Epoch 3/23
 - 23s - loss: 0.3934 - acc: 0.8206 - val_loss: 0.3916 - val_acc: 0.8170
Epoch 4/23
 - 23s - loss: 0.3714 - acc: 0.8333 - val_loss: 0.3530 - val_acc: 0.8426
Epoch 5/23
 - 23s - loss: 0.3487 - acc: 0.8458 - val_loss: 0.3249 - val_acc: 0.8576
Epoch 6/23
 - 23s - loss: 0.3348 - acc: 0.8546 - val_loss: 0.3101 - val_acc: 0.8690
Epoch 7/23
 - 23s - loss: 0.3204 - acc: 0.8638 - val_loss: 0.3097 - val_acc: 0.8637
Epoch 8/23
 - 23s - loss: 0.3089 - acc: 0.8718 - val_loss: 0.2816 - val_acc: 0.8845
Epoch 9/23
 - 23s - loss: 0.2964 - acc: 0.8779 - val_loss: 0.2854 - val_acc: 0.8781
Epoch 10/23
 - 23s - loss: 0.2847 - acc: 0.8841 - val_loss: 0.3087 - val_acc: 0.8726
Epoch 11/23
 - 24s - loss: 0.2749 - acc: 0.8905 - val_loss: 0.3388 - val_acc: 0.8448

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 12/23
 - 24s - loss: 0.2662 - acc: 0.8945 - val_loss: 0.2551 - val_acc: 0.9000
Epoch 13/23
 - 23s - loss: 0.2635 - acc: 0.8944 - val_loss: 0.2411 - val_acc: 0.9075
Epoch 14/23
 - 23s - loss: 0.2607 - acc: 0.8981 - val_loss: 0.2417 - val_acc: 0.9052
Epoch 15/23
 - 23s - loss: 0.2555 - acc: 0.9011 - val_loss: 0.2466 - val_acc: 0.9017
Epoch 16/23
 - 23s - loss: 0.2558 - acc: 0.8998 - val_loss: 0.2375 - val_acc: 0.9081
Epoch 17/23
 - 23s - loss: 0.2490 - acc: 0.9045 - val_loss: 0.2304 - val_acc: 0.9140
Epoch 18/23
 - 23s - loss: 0.2490 - acc: 0.9020 - val_loss: 0.2313 - val_acc: 0.9109
Epoch 19/23
 - 23s - loss: 0.2482 - acc: 0.9028 - val_loss: 0.2256 - val_acc: 0.9159
Epoch 20/23
 - 23s - loss: 0.2442 - acc: 0.9048 - val_loss: 0.2197 - val_acc: 0.9197
Epoch 21/23
 - 23s - loss: 0.2401 - acc: 0.9071 - val_loss: 0.2203 - val_acc: 0.9192
Epoch 22/23
 - 23s - loss: 0.2394 - acc: 0.9075 - val_loss: 0.2224 - val_acc: 0.9159
Epoch 23/23
 - 23s - loss: 0.2367 - acc: 0.9088 - val_loss: 0.2098 - val_acc: 0.9229
Test accuracy:0.859
current auc_score ------------------> 0.949
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.5414 - acc: 0.7324 - val_loss: 0.5207 - val_acc: 0.7417
Epoch 2/23
 - 23s - loss: 0.4390 - acc: 0.7886 - val_loss: 0.4531 - val_acc: 0.7782
Epoch 3/23
 - 23s - loss: 0.4047 - acc: 0.8105 - val_loss: 0.4051 - val_acc: 0.8099
Epoch 4/23
 - 23s - loss: 0.3801 - acc: 0.8256 - val_loss: 0.3653 - val_acc: 0.8282
Epoch 5/23
 - 23s - loss: 0.3592 - acc: 0.8371 - val_loss: 0.3450 - val_acc: 0.8436
Epoch 6/23
 - 23s - loss: 0.3441 - acc: 0.8474 - val_loss: 0.3375 - val_acc: 0.8449
Epoch 7/23
 - 23s - loss: 0.3280 - acc: 0.8569 - val_loss: 0.3129 - val_acc: 0.8696
Epoch 8/23
 - 23s - loss: 0.3130 - acc: 0.8677 - val_loss: 0.3085 - val_acc: 0.8676
Epoch 9/23
 - 23s - loss: 0.3011 - acc: 0.8749 - val_loss: 0.2866 - val_acc: 0.8776
Epoch 10/23
 - 23s - loss: 0.2874 - acc: 0.8814 - val_loss: 0.2955 - val_acc: 0.8694
Epoch 11/23
 - 23s - loss: 0.2751 - acc: 0.8887 - val_loss: 0.2898 - val_acc: 0.8773
Epoch 12/23
 - 23s - loss: 0.2667 - acc: 0.8940 - val_loss: 0.2516 - val_acc: 0.8953
Epoch 13/23
 - 23s - loss: 0.2555 - acc: 0.9001 - val_loss: 0.2497 - val_acc: 0.8952
Epoch 14/23
 - 23s - loss: 0.2461 - acc: 0.9044 - val_loss: 0.2706 - val_acc: 0.8850
Epoch 15/23
 - 23s - loss: 0.2391 - acc: 0.9093 - val_loss: 0.2275 - val_acc: 0.9129
Epoch 16/23
 - 23s - loss: 0.2323 - acc: 0.9126 - val_loss: 0.2193 - val_acc: 0.9164
Epoch 17/23
 - 23s - loss: 0.2262 - acc: 0.9142 - val_loss: 0.1982 - val_acc: 0.9253
Epoch 18/23
 - 23s - loss: 0.2181 - acc: 0.9181 - val_loss: 0.1989 - val_acc: 0.9273
Epoch 19/23
 - 23s - loss: 0.2130 - acc: 0.9202 - val_loss: 0.1975 - val_acc: 0.9244
Epoch 20/23
 - 23s - loss: 0.2074 - acc: 0.9237 - val_loss: 0.1782 - val_acc: 0.9365
Epoch 21/23
 - 23s - loss: 0.2012 - acc: 0.9263 - val_loss: 0.1821 - val_acc: 0.9334
Epoch 22/23
 - 23s - loss: 0.1982 - acc: 0.9275 - val_loss: 0.1775 - val_acc: 0.9362
Epoch 23/23
 - 23s - loss: 0.1932 - acc: 0.9304 - val_loss: 0.1740 - val_acc: 0.9375
Test accuracy:0.858
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  23  batch_size:  128  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.5358 - acc: 0.7388 - val_loss: 0.5358 - val_acc: 0.7464
Epoch 2/23
 - 23s - loss: 0.4443 - acc: 0.7913 - val_loss: 0.5517 - val_acc: 0.7206
Epoch 3/23
 - 23s - loss: 0.4066 - acc: 0.8106 - val_loss: 0.4865 - val_acc: 0.7521
Epoch 4/23
 - 23s - loss: 0.3821 - acc: 0.8249 - val_loss: 0.4037 - val_acc: 0.8119
Epoch 5/23
 - 23s - loss: 0.3594 - acc: 0.8403 - val_loss: 0.3398 - val_acc: 0.8450
Epoch 6/23
 - 23s - loss: 0.3418 - acc: 0.8503 - val_loss: 0.5993 - val_acc: 0.7309
Epoch 7/23
 - 23s - loss: 0.3275 - acc: 0.8597 - val_loss: 0.3223 - val_acc: 0.8643
Epoch 8/23
 - 23s - loss: 0.3146 - acc: 0.8667 - val_loss: 0.2950 - val_acc: 0.8775
Epoch 9/23
 - 23s - loss: 0.3030 - acc: 0.8738 - val_loss: 0.2982 - val_acc: 0.8765
Epoch 10/23
 - 24s - loss: 0.2912 - acc: 0.8806 - val_loss: 0.2723 - val_acc: 0.8928
Epoch 11/23
 - 23s - loss: 0.2822 - acc: 0.8856 - val_loss: 0.2612 - val_acc: 0.8968
Epoch 12/23
 - 23s - loss: 0.2718 - acc: 0.8902 - val_loss: 0.2645 - val_acc: 0.8951
Epoch 13/23
 - 23s - loss: 0.2630 - acc: 0.8961 - val_loss: 0.2769 - val_acc: 0.8872
Epoch 14/23
 - 23s - loss: 0.2537 - acc: 0.8999 - val_loss: 0.2307 - val_acc: 0.9155
Epoch 15/23
 - 23s - loss: 0.2473 - acc: 0.9032 - val_loss: 0.2241 - val_acc: 0.9139
Epoch 16/23
 - 23s - loss: 0.2385 - acc: 0.9089 - val_loss: 0.2178 - val_acc: 0.9197
Epoch 17/23
 - 23s - loss: 0.2307 - acc: 0.9129 - val_loss: 0.2117 - val_acc: 0.9209
Epoch 18/23
 - 23s - loss: 0.2239 - acc: 0.9150 - val_loss: 0.2064 - val_acc: 0.9221
Epoch 19/23
 - 23s - loss: 0.2174 - acc: 0.9173 - val_loss: 0.1926 - val_acc: 0.9305
Epoch 20/23
 - 23s - loss: 0.2120 - acc: 0.9212 - val_loss: 0.2218 - val_acc: 0.9168
Epoch 21/23
 - 23s - loss: 0.2075 - acc: 0.9243 - val_loss: 0.2001 - val_acc: 0.9281
Epoch 22/23
 - 23s - loss: 0.2009 - acc: 0.9260 - val_loss: 0.1940 - val_acc: 0.9290

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 23/23
 - 23s - loss: 0.1924 - acc: 0.9320 - val_loss: 0.1789 - val_acc: 0.9369
Test accuracy:0.877
current auc_score ------------------> 0.951
Saved model to disk
accuracies:  [0.837231182795699, 0.8438172043010753, 0.8745967741935484, 0.7966397849462366, 0.8887096774193548, 0.853763440860215, 0.8182795698924731, 0.8586021505376344, 0.8579301075268817, 0.8772849462365592]
aucs:  [0.9304, 0.941, 0.9652, 0.9274, 0.9605, 0.9463, 0.9285, 0.9493, 0.9447, 0.951]
mean and std AUC:  0.944+/-0.012  max:   0.9652
['2-2-2', '30', '3', '16', '0.2', '0.07', '25', 'adadelta', '0.5', 'FALSE', '256', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 24s - loss: 0.5771 - acc: 0.7123 - val_loss: 0.5939 - val_acc: 0.7062
Epoch 2/25
 - 21s - loss: 0.4797 - acc: 0.7773 - val_loss: 0.5580 - val_acc: 0.7353
Epoch 3/25
 - 22s - loss: 0.4371 - acc: 0.7918 - val_loss: 0.5449 - val_acc: 0.7506
Epoch 4/25
 - 21s - loss: 0.4100 - acc: 0.8066 - val_loss: 0.4973 - val_acc: 0.7648
Epoch 5/25
 - 20s - loss: 0.3895 - acc: 0.8203 - val_loss: 0.4372 - val_acc: 0.7984
Epoch 6/25
 - 21s - loss: 0.3720 - acc: 0.8296 - val_loss: 0.3874 - val_acc: 0.8183
Epoch 7/25
 - 21s - loss: 0.3577 - acc: 0.8420 - val_loss: 0.3454 - val_acc: 0.8469
Epoch 8/25
 - 21s - loss: 0.3454 - acc: 0.8477 - val_loss: 0.3466 - val_acc: 0.8460
Epoch 9/25
 - 21s - loss: 0.3333 - acc: 0.8574 - val_loss: 0.3267 - val_acc: 0.8616
Epoch 10/25
 - 20s - loss: 0.3222 - acc: 0.8610 - val_loss: 0.3612 - val_acc: 0.8394
Epoch 11/25
 - 21s - loss: 0.3139 - acc: 0.8686 - val_loss: 0.3028 - val_acc: 0.8760
Epoch 12/25
 - 21s - loss: 0.3051 - acc: 0.8730 - val_loss: 0.3120 - val_acc: 0.8717
Epoch 13/25
 - 20s - loss: 0.2969 - acc: 0.8782 - val_loss: 0.2879 - val_acc: 0.8891
Epoch 14/25
 - 20s - loss: 0.2884 - acc: 0.8825 - val_loss: 0.2914 - val_acc: 0.8852
Epoch 15/25
 - 21s - loss: 0.2829 - acc: 0.8845 - val_loss: 0.2857 - val_acc: 0.8864
Epoch 16/25
 - 20s - loss: 0.2757 - acc: 0.8890 - val_loss: 0.2697 - val_acc: 0.8937
Epoch 17/25
 - 20s - loss: 0.2675 - acc: 0.8933 - val_loss: 0.2598 - val_acc: 0.8951
Epoch 18/25
 - 21s - loss: 0.2615 - acc: 0.8960 - val_loss: 0.2519 - val_acc: 0.9046
Epoch 19/25
 - 21s - loss: 0.2538 - acc: 0.9017 - val_loss: 0.2509 - val_acc: 0.9021
Epoch 20/25
 - 21s - loss: 0.2499 - acc: 0.9031 - val_loss: 0.2622 - val_acc: 0.9027
Epoch 21/25
 - 21s - loss: 0.2437 - acc: 0.9071 - val_loss: 0.2776 - val_acc: 0.8889
Epoch 22/25
 - 20s - loss: 0.2377 - acc: 0.9081 - val_loss: 0.2675 - val_acc: 0.8936

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 00022: early stopping
Test accuracy:0.825
current auc_score ------------------> 0.947
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5813 - acc: 0.7088 - val_loss: 0.6259 - val_acc: 0.6810
Epoch 2/25
 - 20s - loss: 0.4832 - acc: 0.7768 - val_loss: 0.7354 - val_acc: 0.6301
Epoch 3/25
 - 20s - loss: 0.4409 - acc: 0.7935 - val_loss: 0.5131 - val_acc: 0.7361
Epoch 4/25
 - 20s - loss: 0.4130 - acc: 0.8110 - val_loss: 0.6164 - val_acc: 0.6936
Epoch 5/25
 - 20s - loss: 0.3901 - acc: 0.8235 - val_loss: 0.4940 - val_acc: 0.7610
Epoch 6/25
 - 20s - loss: 0.3736 - acc: 0.8348 - val_loss: 0.4426 - val_acc: 0.7859
Epoch 7/25
 - 20s - loss: 0.3591 - acc: 0.8421 - val_loss: 0.4613 - val_acc: 0.7799
Epoch 8/25
 - 21s - loss: 0.3453 - acc: 0.8491 - val_loss: 0.4532 - val_acc: 0.7828
Epoch 9/25
 - 20s - loss: 0.3349 - acc: 0.8540 - val_loss: 0.3761 - val_acc: 0.8313
Epoch 10/25
 - 21s - loss: 0.3257 - acc: 0.8628 - val_loss: 0.3766 - val_acc: 0.8340
Epoch 11/25
 - 20s - loss: 0.3153 - acc: 0.8670 - val_loss: 0.4032 - val_acc: 0.8186
Epoch 12/25
 - 21s - loss: 0.3076 - acc: 0.8724 - val_loss: 0.3642 - val_acc: 0.8390
Epoch 13/25
 - 20s - loss: 0.2975 - acc: 0.8783 - val_loss: 0.3297 - val_acc: 0.8588
Epoch 14/25
 - 20s - loss: 0.2912 - acc: 0.8792 - val_loss: 0.3562 - val_acc: 0.8454
Epoch 15/25
 - 21s - loss: 0.2836 - acc: 0.8843 - val_loss: 0.3619 - val_acc: 0.8431
Epoch 16/25
 - 21s - loss: 0.2775 - acc: 0.8882 - val_loss: 0.3531 - val_acc: 0.8440

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/25
 - 20s - loss: 0.2689 - acc: 0.8940 - val_loss: 0.3526 - val_acc: 0.8454
Epoch 00017: early stopping
Test accuracy:0.803
current auc_score ------------------> 0.946
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.6124 - acc: 0.6700 - val_loss: 0.9265 - val_acc: 0.5228
Epoch 2/25
 - 20s - loss: 0.4928 - acc: 0.7742 - val_loss: 0.6615 - val_acc: 0.6673
Epoch 3/25
 - 20s - loss: 0.4499 - acc: 0.7878 - val_loss: 0.4709 - val_acc: 0.7766
Epoch 4/25
 - 20s - loss: 0.4234 - acc: 0.8028 - val_loss: 0.5420 - val_acc: 0.7299
Epoch 5/25
 - 20s - loss: 0.4032 - acc: 0.8139 - val_loss: 0.7678 - val_acc: 0.6491
Epoch 6/25
 - 20s - loss: 0.3866 - acc: 0.8241 - val_loss: 0.6418 - val_acc: 0.6962

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 7/25
 - 20s - loss: 0.3745 - acc: 0.8307 - val_loss: 0.5762 - val_acc: 0.7176
Epoch 00007: early stopping
Test accuracy:0.778
current auc_score ------------------> 0.911
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.5786 - acc: 0.7007 - val_loss: 0.5076 - val_acc: 0.7624
Epoch 2/25
 - 20s - loss: 0.4794 - acc: 0.7725 - val_loss: 0.4740 - val_acc: 0.7668
Epoch 3/25
 - 21s - loss: 0.4401 - acc: 0.7890 - val_loss: 0.6169 - val_acc: 0.6929
Epoch 4/25
 - 20s - loss: 0.4127 - acc: 0.8067 - val_loss: 0.5164 - val_acc: 0.7516
Epoch 5/25
 - 20s - loss: 0.3912 - acc: 0.8207 - val_loss: 0.5345 - val_acc: 0.7462

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 6/25
 - 20s - loss: 0.3784 - acc: 0.8280 - val_loss: 0.3821 - val_acc: 0.8180
Epoch 7/25
 - 20s - loss: 0.3721 - acc: 0.8323 - val_loss: 0.3894 - val_acc: 0.8154
Epoch 8/25
 - 20s - loss: 0.3684 - acc: 0.8348 - val_loss: 0.3688 - val_acc: 0.8243
Epoch 9/25
 - 20s - loss: 0.3627 - acc: 0.8380 - val_loss: 0.3670 - val_acc: 0.8323
Epoch 10/25
 - 20s - loss: 0.3588 - acc: 0.8411 - val_loss: 0.3672 - val_acc: 0.8296
Epoch 11/25
 - 20s - loss: 0.3539 - acc: 0.8441 - val_loss: 0.3532 - val_acc: 0.8357
Epoch 12/25
 - 20s - loss: 0.3504 - acc: 0.8461 - val_loss: 0.3560 - val_acc: 0.8337
Epoch 13/25
 - 20s - loss: 0.3464 - acc: 0.8497 - val_loss: 0.3555 - val_acc: 0.8387
Epoch 14/25
 - 20s - loss: 0.3430 - acc: 0.8506 - val_loss: 0.3512 - val_acc: 0.8426
Epoch 15/25
 - 20s - loss: 0.3400 - acc: 0.8523 - val_loss: 0.3429 - val_acc: 0.8480
Epoch 16/25
 - 20s - loss: 0.3388 - acc: 0.8533 - val_loss: 0.3356 - val_acc: 0.8509
Epoch 17/25
 - 20s - loss: 0.3330 - acc: 0.8566 - val_loss: 0.3417 - val_acc: 0.8478
Epoch 18/25
 - 20s - loss: 0.3286 - acc: 0.8607 - val_loss: 0.3415 - val_acc: 0.8489
Epoch 19/25
 - 20s - loss: 0.3271 - acc: 0.8620 - val_loss: 0.3301 - val_acc: 0.8530
Epoch 20/25
 - 20s - loss: 0.3217 - acc: 0.8639 - val_loss: 0.3269 - val_acc: 0.8563
Epoch 21/25
 - 20s - loss: 0.3195 - acc: 0.8662 - val_loss: 0.3175 - val_acc: 0.8647
Epoch 22/25
 - 20s - loss: 0.3160 - acc: 0.8661 - val_loss: 0.3162 - val_acc: 0.8650
Epoch 23/25
 - 20s - loss: 0.3139 - acc: 0.8675 - val_loss: 0.3155 - val_acc: 0.8656
Epoch 24/25
 - 20s - loss: 0.3121 - acc: 0.8691 - val_loss: 0.3199 - val_acc: 0.8643
Epoch 25/25
 - 20s - loss: 0.3081 - acc: 0.8716 - val_loss: 0.3082 - val_acc: 0.8666
Test accuracy:0.888
current auc_score ------------------> 0.959
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5791 - acc: 0.7085 - val_loss: 0.6455 - val_acc: 0.6338
Epoch 2/25
 - 20s - loss: 0.4810 - acc: 0.7747 - val_loss: 0.4781 - val_acc: 0.7684
Epoch 3/25
 - 20s - loss: 0.4406 - acc: 0.7910 - val_loss: 0.5240 - val_acc: 0.7352
Epoch 4/25
 - 20s - loss: 0.4124 - acc: 0.8066 - val_loss: 0.4157 - val_acc: 0.8010
Epoch 5/25
 - 20s - loss: 0.3917 - acc: 0.8190 - val_loss: 0.3940 - val_acc: 0.8140
Epoch 6/25
 - 20s - loss: 0.3759 - acc: 0.8295 - val_loss: 0.3978 - val_acc: 0.8180
Epoch 7/25
 - 20s - loss: 0.3632 - acc: 0.8367 - val_loss: 0.3803 - val_acc: 0.8233
Epoch 8/25
 - 20s - loss: 0.3505 - acc: 0.8445 - val_loss: 0.4960 - val_acc: 0.7470
Epoch 9/25
 - 20s - loss: 0.3382 - acc: 0.8528 - val_loss: 0.4258 - val_acc: 0.7909
Epoch 10/25
 - 20s - loss: 0.3284 - acc: 0.8601 - val_loss: 0.3355 - val_acc: 0.8554
Epoch 11/25
 - 20s - loss: 0.3194 - acc: 0.8647 - val_loss: 0.3524 - val_acc: 0.8465
Epoch 12/25
 - 20s - loss: 0.3090 - acc: 0.8720 - val_loss: 0.3958 - val_acc: 0.8212
Epoch 13/25
 - 20s - loss: 0.3006 - acc: 0.8758 - val_loss: 0.4110 - val_acc: 0.8114

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/25
 - 20s - loss: 0.2920 - acc: 0.8821 - val_loss: 0.3357 - val_acc: 0.8528
Epoch 00014: early stopping
Test accuracy:0.817
current auc_score ------------------> 0.943
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5661 - acc: 0.7323 - val_loss: 0.5189 - val_acc: 0.7544
Epoch 2/25
 - 20s - loss: 0.4739 - acc: 0.7814 - val_loss: 0.4745 - val_acc: 0.7799
Epoch 3/25
 - 20s - loss: 0.4321 - acc: 0.7984 - val_loss: 0.4554 - val_acc: 0.7890
Epoch 4/25
 - 20s - loss: 0.4035 - acc: 0.8149 - val_loss: 0.3952 - val_acc: 0.8224
Epoch 5/25
 - 20s - loss: 0.3851 - acc: 0.8267 - val_loss: 0.3727 - val_acc: 0.8325
Epoch 6/25
 - 20s - loss: 0.3687 - acc: 0.8359 - val_loss: 0.3630 - val_acc: 0.8381
Epoch 7/25
 - 20s - loss: 0.3536 - acc: 0.8459 - val_loss: 0.3715 - val_acc: 0.8328
Epoch 8/25
 - 20s - loss: 0.3432 - acc: 0.8519 - val_loss: 0.3328 - val_acc: 0.8572
Epoch 9/25
 - 20s - loss: 0.3338 - acc: 0.8568 - val_loss: 0.3275 - val_acc: 0.8578
Epoch 10/25
 - 20s - loss: 0.3244 - acc: 0.8618 - val_loss: 0.3197 - val_acc: 0.8624
Epoch 11/25
 - 20s - loss: 0.3155 - acc: 0.8697 - val_loss: 0.3170 - val_acc: 0.8643
Epoch 12/25
 - 20s - loss: 0.3077 - acc: 0.8725 - val_loss: 0.3048 - val_acc: 0.8710
Epoch 13/25
 - 20s - loss: 0.2997 - acc: 0.8765 - val_loss: 0.2910 - val_acc: 0.8773
Epoch 14/25
 - 20s - loss: 0.2914 - acc: 0.8808 - val_loss: 0.3004 - val_acc: 0.8734
Epoch 15/25
 - 20s - loss: 0.2873 - acc: 0.8839 - val_loss: 0.2783 - val_acc: 0.8855
Epoch 16/25
 - 20s - loss: 0.2821 - acc: 0.8861 - val_loss: 0.2584 - val_acc: 0.8953
Epoch 17/25
 - 20s - loss: 0.2731 - acc: 0.8920 - val_loss: 0.2543 - val_acc: 0.8981
Epoch 18/25
 - 20s - loss: 0.2685 - acc: 0.8933 - val_loss: 0.2695 - val_acc: 0.8921
Epoch 19/25
 - 21s - loss: 0.2652 - acc: 0.8959 - val_loss: 0.2788 - val_acc: 0.8883
Epoch 20/25
 - 20s - loss: 0.2577 - acc: 0.8990 - val_loss: 0.2414 - val_acc: 0.9050
Epoch 21/25
 - 20s - loss: 0.2529 - acc: 0.9035 - val_loss: 0.2322 - val_acc: 0.9071
Epoch 22/25
 - 20s - loss: 0.2475 - acc: 0.9045 - val_loss: 0.2357 - val_acc: 0.9071
Epoch 23/25
 - 20s - loss: 0.2432 - acc: 0.9075 - val_loss: 0.2383 - val_acc: 0.9036
Epoch 24/25
 - 20s - loss: 0.2403 - acc: 0.9081 - val_loss: 0.2200 - val_acc: 0.9149
Epoch 25/25
 - 20s - loss: 0.2354 - acc: 0.9105 - val_loss: 0.2123 - val_acc: 0.9207
Test accuracy:0.871
current auc_score ------------------> 0.958
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5765 - acc: 0.7227 - val_loss: 0.5250 - val_acc: 0.7545
Epoch 2/25
 - 21s - loss: 0.4768 - acc: 0.7750 - val_loss: 0.6563 - val_acc: 0.6545
Epoch 3/25
 - 20s - loss: 0.4366 - acc: 0.7918 - val_loss: 0.6127 - val_acc: 0.6992
Epoch 4/25
 - 20s - loss: 0.4072 - acc: 0.8112 - val_loss: 0.5148 - val_acc: 0.7553
Epoch 5/25
 - 20s - loss: 0.3843 - acc: 0.8236 - val_loss: 0.5595 - val_acc: 0.7383
Epoch 6/25
 - 20s - loss: 0.3632 - acc: 0.8393 - val_loss: 0.3831 - val_acc: 0.8209
Epoch 7/25
 - 20s - loss: 0.3473 - acc: 0.8497 - val_loss: 0.3758 - val_acc: 0.8332
Epoch 8/25
 - 20s - loss: 0.3331 - acc: 0.8578 - val_loss: 0.4186 - val_acc: 0.8130
Epoch 9/25
 - 20s - loss: 0.3206 - acc: 0.8643 - val_loss: 0.3525 - val_acc: 0.8400
Epoch 10/25
 - 20s - loss: 0.3095 - acc: 0.8704 - val_loss: 0.3207 - val_acc: 0.8637
Epoch 11/25
 - 20s - loss: 0.2997 - acc: 0.8769 - val_loss: 0.2818 - val_acc: 0.8873
Epoch 12/25
 - 21s - loss: 0.2903 - acc: 0.8828 - val_loss: 0.3137 - val_acc: 0.8655
Epoch 13/25
 - 20s - loss: 0.2804 - acc: 0.8880 - val_loss: 0.2736 - val_acc: 0.8864
Epoch 14/25
 - 21s - loss: 0.2742 - acc: 0.8903 - val_loss: 0.2717 - val_acc: 0.8887
Epoch 15/25
 - 20s - loss: 0.2674 - acc: 0.8944 - val_loss: 0.2816 - val_acc: 0.8873
Epoch 16/25
 - 20s - loss: 0.2620 - acc: 0.8968 - val_loss: 0.2489 - val_acc: 0.9024
Epoch 17/25
 - 20s - loss: 0.2542 - acc: 0.9010 - val_loss: 0.2824 - val_acc: 0.8838
Epoch 18/25
 - 20s - loss: 0.2464 - acc: 0.9046 - val_loss: 0.2392 - val_acc: 0.9066
Epoch 19/25
 - 20s - loss: 0.2431 - acc: 0.9074 - val_loss: 0.2215 - val_acc: 0.9149
Epoch 20/25
 - 20s - loss: 0.2363 - acc: 0.9088 - val_loss: 0.2161 - val_acc: 0.9224
Epoch 21/25
 - 21s - loss: 0.2328 - acc: 0.9134 - val_loss: 0.2147 - val_acc: 0.9208
Epoch 22/25
 - 20s - loss: 0.2274 - acc: 0.9141 - val_loss: 0.2074 - val_acc: 0.9226
Epoch 23/25
 - 20s - loss: 0.2232 - acc: 0.9172 - val_loss: 0.2009 - val_acc: 0.9261
Epoch 24/25
 - 20s - loss: 0.2174 - acc: 0.9184 - val_loss: 0.2028 - val_acc: 0.9249
Epoch 25/25
 - 20s - loss: 0.2129 - acc: 0.9211 - val_loss: 0.2042 - val_acc: 0.9224
Test accuracy:0.838
current auc_score ------------------> 0.932
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5751 - acc: 0.7143 - val_loss: 0.5188 - val_acc: 0.7401
Epoch 2/25
 - 20s - loss: 0.4756 - acc: 0.7762 - val_loss: 0.4916 - val_acc: 0.7628
Epoch 3/25
 - 20s - loss: 0.4362 - acc: 0.7919 - val_loss: 0.5344 - val_acc: 0.7391
Epoch 4/25
 - 21s - loss: 0.4065 - acc: 0.8083 - val_loss: 0.4743 - val_acc: 0.7804
Epoch 5/25
 - 21s - loss: 0.3837 - acc: 0.8246 - val_loss: 0.3830 - val_acc: 0.8262
Epoch 6/25
 - 21s - loss: 0.3657 - acc: 0.8350 - val_loss: 0.3800 - val_acc: 0.8304
Epoch 7/25
 - 20s - loss: 0.3499 - acc: 0.8446 - val_loss: 0.3697 - val_acc: 0.8389
Epoch 8/25
 - 20s - loss: 0.3389 - acc: 0.8519 - val_loss: 0.3609 - val_acc: 0.8387
Epoch 9/25
 - 20s - loss: 0.3282 - acc: 0.8602 - val_loss: 0.3430 - val_acc: 0.8548
Epoch 10/25
 - 20s - loss: 0.3170 - acc: 0.8650 - val_loss: 0.3390 - val_acc: 0.8540
Epoch 11/25
 - 20s - loss: 0.3087 - acc: 0.8725 - val_loss: 0.3337 - val_acc: 0.8538
Epoch 12/25
 - 20s - loss: 0.3013 - acc: 0.8750 - val_loss: 0.3069 - val_acc: 0.8742
Epoch 13/25
 - 20s - loss: 0.2918 - acc: 0.8804 - val_loss: 0.3151 - val_acc: 0.8692
Epoch 14/25
 - 20s - loss: 0.2850 - acc: 0.8841 - val_loss: 0.2937 - val_acc: 0.8811
Epoch 15/25
 - 20s - loss: 0.2779 - acc: 0.8876 - val_loss: 0.2658 - val_acc: 0.8941
Epoch 16/25
 - 20s - loss: 0.2737 - acc: 0.8879 - val_loss: 0.2745 - val_acc: 0.8914
Epoch 17/25
 - 20s - loss: 0.2659 - acc: 0.8949 - val_loss: 0.2724 - val_acc: 0.8923
Epoch 18/25
 - 20s - loss: 0.2598 - acc: 0.8963 - val_loss: 0.2670 - val_acc: 0.8892

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/25
 - 20s - loss: 0.2547 - acc: 0.8986 - val_loss: 0.2566 - val_acc: 0.8991
Epoch 20/25
 - 20s - loss: 0.2517 - acc: 0.9017 - val_loss: 0.2461 - val_acc: 0.9079
Epoch 21/25
 - 20s - loss: 0.2522 - acc: 0.9010 - val_loss: 0.2494 - val_acc: 0.9057
Epoch 22/25
 - 20s - loss: 0.2475 - acc: 0.9037 - val_loss: 0.2457 - val_acc: 0.9070
Epoch 23/25
 - 20s - loss: 0.2458 - acc: 0.9047 - val_loss: 0.2406 - val_acc: 0.9091
Epoch 24/25
 - 20s - loss: 0.2453 - acc: 0.9041 - val_loss: 0.2435 - val_acc: 0.9066
Epoch 25/25
 - 20s - loss: 0.2428 - acc: 0.9056 - val_loss: 0.2486 - val_acc: 0.9034
Test accuracy:0.842
current auc_score ------------------> 0.945
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.6943 - acc: 0.6286 - val_loss: 0.5325 - val_acc: 0.7494
Epoch 2/25
 - 21s - loss: 0.5063 - acc: 0.7656 - val_loss: 0.4841 - val_acc: 0.7681
Epoch 3/25
 - 21s - loss: 0.4608 - acc: 0.7841 - val_loss: 0.4806 - val_acc: 0.7671
Epoch 4/25
 - 20s - loss: 0.4306 - acc: 0.8006 - val_loss: 0.4955 - val_acc: 0.7555
Epoch 5/25
 - 20s - loss: 0.4088 - acc: 0.8107 - val_loss: 0.4899 - val_acc: 0.7614
Epoch 6/25
 - 20s - loss: 0.3885 - acc: 0.8217 - val_loss: 0.4975 - val_acc: 0.7514

Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 00006: early stopping
Test accuracy:0.807
current auc_score ------------------> 0.926
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  25  batch_size:  256  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 49, 12, 12)   4802        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 49, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 49, 6, 6)     196         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 49, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 30, 6, 6)     13230       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 79, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 79, 6, 6)     316         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 79, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 30, 6, 6)     21330       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 109, 6, 6)    0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 109, 6, 6)    436         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 109, 6, 6)    0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 109)          0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            110         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 91,668
Trainable params: 90,478
Non-trainable params: 1,190
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5823 - acc: 0.7190 - val_loss: 0.7146 - val_acc: 0.5826
Epoch 2/25
 - 20s - loss: 0.4780 - acc: 0.7760 - val_loss: 0.7134 - val_acc: 0.6142
Epoch 3/25
 - 21s - loss: 0.4317 - acc: 0.7963 - val_loss: 0.6097 - val_acc: 0.7019
Epoch 4/25
 - 20s - loss: 0.4030 - acc: 0.8140 - val_loss: 0.4576 - val_acc: 0.7786
Epoch 5/25
 - 20s - loss: 0.3820 - acc: 0.8256 - val_loss: 0.4203 - val_acc: 0.7976
Epoch 6/25
 - 20s - loss: 0.3693 - acc: 0.8344 - val_loss: 0.5086 - val_acc: 0.7593
Epoch 7/25
 - 20s - loss: 0.3560 - acc: 0.8433 - val_loss: 0.4693 - val_acc: 0.7759
Epoch 8/25
 - 20s - loss: 0.3463 - acc: 0.8489 - val_loss: 0.4678 - val_acc: 0.7780

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/25
 - 20s - loss: 0.3382 - acc: 0.8531 - val_loss: 0.3936 - val_acc: 0.8135
Epoch 10/25
 - 21s - loss: 0.3351 - acc: 0.8563 - val_loss: 0.4033 - val_acc: 0.8105
Epoch 11/25
 - 20s - loss: 0.3317 - acc: 0.8568 - val_loss: 0.4293 - val_acc: 0.7988
Epoch 12/25
 - 20s - loss: 0.3285 - acc: 0.8595 - val_loss: 0.4123 - val_acc: 0.8042

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.006999999858704226.
Epoch 13/25
 - 20s - loss: 0.3274 - acc: 0.8582 - val_loss: 0.3970 - val_acc: 0.8130
Epoch 00013: early stopping
Test accuracy:0.826
current auc_score ------------------> 0.922
accuracies:  [0.8254032258064516, 0.8028225806451613, 0.7776881720430108, 0.8884408602150538, 0.8170698924731182, 0.8709677419354839, 0.8384408602150538, 0.8418010752688172, 0.8067204301075269, 0.826478494623656]
aucs:  [0.9468, 0.9456, 0.911, 0.9594, 0.9431, 0.958, 0.9322, 0.9453, 0.9256, 0.9224]
mean and std AUC:  0.939+/-0.015  max:   0.9594
(['2-2-2', '30', '3', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '32', 'avg'], '0.94+/-0.008', 0.952)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '23', 'adadelta', '0.5', 'FALSE', '128', 'avg'], '0.944+/-0.012', 0.965)
(['2-2-2', '30', '3', '16', '0.2', '0.07', '25', 'adadelta', '0.5', 'FALSE', '256', 'avg'], '0.939+/-0.015', 0.959)
